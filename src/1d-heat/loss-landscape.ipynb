{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing loss-landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize new model\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"_summary_\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "            t (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return self.linear_stack(torch.Tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_stack): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model\n",
    "loaded_model = torch.load(\"/Users/harry/1d-heat-pinn/src/model.pt\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "model_initial = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup time-space geometry\n",
    "num_points = 51\n",
    "x_start = 0\n",
    "x_stop = 1\n",
    "num_timesteps = 1000\n",
    "t_start = 0\n",
    "t_stop = 1 \n",
    "x = np.linspace(start=x_start, stop=x_stop, num=num_points)\n",
    "t = np.linspace(start=t_start, stop=t_stop, num=num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_load = np.load(\"./1d-heat.npy\")\n",
    "\n",
    "features = np.ones((U_load.shape[0]*U_load.shape[1],2))\n",
    "features[:,1] = np.tile(x,U_load.shape[0])\n",
    "features[:,0] = np.repeat(t,U_load.shape[1])\n",
    "\n",
    "labels = np.ones((U_load.shape[0]*U_load.shape[1],1))\n",
    "labels = U_load.ravel()\n",
    "\n",
    "labels = labels.astype(np.float32)\n",
    "features = features.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# compute loss data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m STEPS \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m----> 8\u001b[0m loss_data \u001b[39m=\u001b[39m loss_landscapes\u001b[39m.\u001b[39;49mlinear_interpolation(model_initial, loaded_model, metric, STEPS, deepcopy_model\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/loss_landscapes/main.py:82\u001b[0m, in \u001b[0;36mlinear_interpolation\u001b[0;34m(model_start, model_end, metric, steps, deepcopy_model)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[1;32m     80\u001b[0m     \u001b[39m# add a step along the line to the model parameters, then evaluate\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     start_point\u001b[39m.\u001b[39madd_(direction)\n\u001b[0;32m---> 82\u001b[0m     data_values\u001b[39m.\u001b[39mappend(metric(model_start_wrapper))\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(data_values)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/loss_landscapes/metrics/sl_metrics.py:27\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, model_wrapper)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, model_wrapper: ModelWrapper) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_fn(model_wrapper\u001b[39m.\u001b[39;49mforward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget)\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "# data that the evaluator will use when evaluating loss\n",
    "features = torch.from_numpy(features).float()\n",
    "labels = torch.from_numpy(labels).float()\n",
    "metric = loss_landscapes.metrics.Loss(criterion, features, labels)\n",
    "\n",
    "# compute loss data\n",
    "STEPS = 40\n",
    "loss_data = loss_landscapes.linear_interpolation(model_initial, loaded_model, metric, STEPS, deepcopy_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
