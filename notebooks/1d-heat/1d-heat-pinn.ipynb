{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"cbLmRmVZY3Uj"},"source":["# 1D Heat equation; PINN"]},{"cell_type":"code","execution_count":750,"metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1682006964918,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"KagVwUl-Y3Um"},"outputs":[],"source":["# initial plot\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import os\n","import pandas as pd\n","from torch.utils.tensorboard import SummaryWriter\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import datetime\n","from softadapt import LossWeightedSoftAdapt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tyLuJAltY3Un"},"source":["We will store the temperature u, at a given x,t in a 2D tensor called U(t,x)"]},{"cell_type":"code","execution_count":751,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682006965161,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"Yg7kv5-pY3Un"},"outputs":[],"source":["# setup time-space geometry\n","num_points = 51\n","x_start = 0\n","x_stop = 1\n","num_timesteps = 1000\n","t_start = 0\n","t_stop = 1 \n","x = np.linspace(start=x_start, stop=x_stop, num=num_points)\n","t = np.linspace(start=t_start, stop=t_stop, num=num_timesteps)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0S5okgh2Y3Un"},"source":["## PINN to learn the 1D-heat diffusion equation"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DUfhuyD3Y3Uo"},"source":["The goal of the following section is to show a PINN using:\n","\n","- Initial condition loss\n","- Boundary condition loss\n","- PDE loss\n","- Data driven loss"]},{"cell_type":"code","execution_count":752,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682006965162,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"RwfR2FrJY3Uo","outputId":"7458c7f0-a6d9-4c0b-e099-544736a95a30"},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":752,"metadata":{},"output_type":"execute_result"}],"source":["#Use GPU if available\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":753,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2086,"status":"ok","timestamp":1682006967241,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"r0RiMYaRY3Uo","outputId":"7596e602-1555-49c2-a0af-359487c5d921"},"outputs":[],"source":["#Allow access to Google drive data when using colab\n","colab = False\n","if colab == True:\n","    from google.colab import drive\n","    drive.mount('/gdrive')\n","    %cd /gdrive/My Drive/colab_scratch"]},{"cell_type":"code","execution_count":754,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682006967241,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"ktPCNNVlY3Up","outputId":"6dcdc622-e33c-4518-f436-d129e1a7c716"},"outputs":[{"name":"stdout","output_type":"stream","text":["U shape: (1000, 51)\n"]}],"source":["U_load = np.load(\"../../data/1d-heat-U.npy\")\n","print(f\"U shape: {U_load.shape}\")"]},{"cell_type":"code","execution_count":755,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682006967241,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"X275czBhY3Up","outputId":"af451370-fdf0-43e4-9238-420408739870"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 5 features [[0.   0.  ]\n"," [0.   0.02]\n"," [0.   0.04]\n"," [0.   0.06]\n"," [0.   0.08]]\n","\n","Last 5 features  [[1.   0.92]\n"," [1.   0.94]\n"," [1.   0.96]\n"," [1.   0.98]\n"," [1.   1.  ]]\n"]}],"source":["#Store x,t in a feature array of 2 columns\n","features = np.ones((U_load.shape[0]*U_load.shape[1],2))\n","features[:,1] = np.tile(x,U_load.shape[0])\n","features[:,0] = np.repeat(t,U_load.shape[1])\n","print(f\"First 5 features {features[0:5]}\\n\")\n","print(f\"Last 5 features  {features[-5:]}\")"]},{"cell_type":"code","execution_count":756,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1682006967242,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"klJeMDo_Y3Up","outputId":"4819b6cd-33c8-4507-f165-0b2dd5865eb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 5 temperature label data: [0.         0.06279052 0.12533323 0.18738131 0.24868989]\n"]}],"source":["labels = np.ones((U_load.shape[0]*U_load.shape[1],1))\n","labels = U_load.ravel()\n","print(f\"First 5 temperature label data: {labels[0:5]}\")"]},{"cell_type":"code","execution_count":757,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682006967242,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"GrqGDZCwY3Up"},"outputs":[],"source":["#Set datatype expected by PyTorch\n","labels = labels.astype(np.float32)\n","features = features.astype(np.float32)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ov9JOnV8Y3Uq"},"source":["Data now needs pre-processing ready for PyTorch training including:\n","\n","- Feature scaling\n","- Train-test splitting for model validation"]},{"cell_type":"code","execution_count":758,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682006967242,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"8i6_8KX5Y3Uq","outputId":"c2f67c11-a208-41e7-d433-3256d40811a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Pre-scaling:\n"," [[0.   0.  ]\n"," [0.   0.02]\n"," [0.   0.04]\n"," [0.   0.06]\n"," [0.   0.08]]\n","Mean: 0.5000000596046448 Std: 0.2916906177997589\n","\n","Post-scaling:\n"," [[-1.7303196 -1.6984155]\n"," [-1.7303196 -1.6304789]\n"," [-1.7303196 -1.5625423]\n"," [-1.7303196 -1.4946057]\n"," [-1.7303196 -1.426669 ]]\n","Mean: 2.1541818995274298e-08 Std: 1.0\n"]}],"source":["### Pre-processing stage\n","std_scaler = StandardScaler()\n","scaler_features = std_scaler.fit(features)\n","scaled_features = scaler_features.transform(features)\n","\n","print(f\"\\nPre-scaling:\\n {features[0:5]}\")\n","print(f\"Mean: {features.mean()} Std: {features.std()}\")\n","print(f\"\\nPost-scaling:\\n {scaled_features[0:5]}\")\n","print(f\"Mean: {scaled_features.mean()} Std: {scaled_features.std()}\")"]},{"cell_type":"code","execution_count":759,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682006967242,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"oV7bgGyqY3Uq","outputId":"eab6d686-d987-4556-c4d4-dd4cc7228ac9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Time vals init condition shape: (51,)\n","Time vals boundary condition shape: (2000,)\n","Time vals interior condition shape: (49000,)\n","Space vals init condition shape: (51,)\n","Space vals boundary condition shape: (2000,)\n","Space vals interior shape: (49000,)\n"]}],"source":["# Get feature data for initial condition, boundary condition and interior points\n","features_init = scaled_features[0:51]\n","\n","features_x0 = scaled_features[0::51]\n","features_xstop = scaled_features[50::51]\n","features_bound = np.append(features_x0, features_xstop, axis=0)\n","\n","features_interior = np.empty((0,1))\n","start=1\n","block_size=49\n","skip=2\n","while start < features.shape[0]:\n","    features_interior = np.append(features_interior, scaled_features[start:start+block_size])\n","    start = start + block_size + skip\n","\n","length = features_interior.ravel().shape[0]\n","features_interior = features_interior.reshape((int(length/2),2))\n","\n","#Now split them into x and t as this is more generic for future multi-dimensional \n","t_init = features_init[:, 0]\n","t_bound = features_bound[:, 0]\n","t_interior = features_interior[:, 0]\n","x_init = features_init[:, 1]\n","x_bound = features_bound[:, 1]\n","x_interior = features_interior[:, 1]\n","\n","print(f\"Time vals init condition shape: {t_init.shape}\")\n","print(f\"Time vals boundary condition shape: {t_bound.shape}\")\n","print(f\"Time vals interior condition shape: {t_interior.shape}\")\n","print(f\"Space vals init condition shape: {x_init.shape}\")\n","print(f\"Space vals boundary condition shape: {x_bound.shape}\")\n","print(f\"Space vals interior shape: {x_interior.shape}\")"]},{"cell_type":"code","execution_count":760,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682006967243,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"pXOz5eQCY3Ur","outputId":"20a12cbc-f79c-4ca8-b8d0-fd1f35e28b30"},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels for init condition shape: (51,)\n","Labels for left boundary condition shape: (1000,)\n","Labels for right boundary condition shape: (1000,)\n","\tLabels for both boundary condition shape: (2000,)\n","Labels for interior shape: (49000,)\n"]}],"source":["# Get label data for initial condition, boundary condition and interior points\n","labels_init = labels[0:51]\n","\n","labels_x0 = labels[0::51]\n","labels_xstop = labels[50::51]\n","labels_bound = np.append(labels_x0, labels_xstop, axis=0)\n","\n","labels_interior = np.empty((0,1))\n","start=1\n","block_size=49\n","skip=2\n","while start < labels.shape[0]:\n","    labels_interior = np.append(labels_interior, labels[start:start+block_size])\n","    start = start + block_size + skip\n","\n","print(f\"Labels for init condition shape: {labels_init.shape}\")\n","print(f\"Labels for left boundary condition shape: {labels_x0.shape}\")\n","print(f\"Labels for right boundary condition shape: {labels_xstop.shape}\")\n","print(f\"\\tLabels for both boundary condition shape: {labels_bound.shape}\")\n","print(f\"Labels for interior shape: {labels_interior.shape}\")"]},{"cell_type":"code","execution_count":761,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["x_interior_train shape((39200,)) type(<class 'numpy.ndarray'>)\n","x_interior_test shape((9800,)) type(<class 'numpy.ndarray'>)\n","t_interior_train shape((39200,)) type(<class 'numpy.ndarray'>)\n","t_interior_test shape((9800,)) type(<class 'numpy.ndarray'>)\n","labels_interior_train shape((39200,)) type(<class 'numpy.ndarray'>)\n","labels_interior_test shape((9800,)) type(<class 'numpy.ndarray'>)\n","\n","x_bound_train shape((1600,)) type(<class 'numpy.ndarray'>)\n","x_bound_test shape((400,)) type(<class 'numpy.ndarray'>)\n","t_bound_train shape((1600,)) type(<class 'numpy.ndarray'>)\n","t_bound_test shape((400,)) type(<class 'numpy.ndarray'>)\n","labels_bound_train shape((1600,)) type(<class 'numpy.ndarray'>)\n","labels_bound_test shape((400,)) type(<class 'numpy.ndarray'>)\n","\n","x_init_train shape((40,)) type(<class 'numpy.ndarray'>)\n","x_init_test shape((11,)) type(<class 'numpy.ndarray'>)\n","t_init_train shape((40,)) type(<class 'numpy.ndarray'>)\n","t_init_test shape((11,)) type(<class 'numpy.ndarray'>)\n","labels_init_train shape((40,)) type(<class 'numpy.ndarray'>)\n","labels_init_test shape((11,)) type(<class 'numpy.ndarray'>)\n"]}],"source":["#Train test splitting\n","test_size = 0.2\n","\n","#Interior data\n","(\n","    x_interior_train,\n","    x_interior_test,\n","    t_interior_train,\n","    t_interior_test,\n","    labels_interior_train,\n","    labels_interior_test,\n",") = train_test_split(x_interior, t_interior, labels_interior, test_size=test_size)\n","\n","#Initial condition data\n","(\n","    x_init_train,\n","    x_init_test,\n","    t_init_train,\n","    t_init_test,\n","    labels_init_train,\n","    labels_init_test,\n",") = train_test_split(x_init, t_init, labels_init, test_size=test_size)\n","\n","#Boundary condition data\n","(\n","    x_bound_train,\n","    x_bound_test,\n","    t_bound_train,\n","    t_bound_test,\n","    labels_bound_train,\n","    labels_bound_test,\n",") = train_test_split(x_bound, t_bound, labels_bound, test_size=test_size)\n","\n","print(f\"x_interior_train shape({x_interior_train.shape}) type({type(x_interior_train)})\")\n","print(f\"x_interior_test shape({x_interior_test.shape}) type({type(x_interior_test)})\")\n","print(f\"t_interior_train shape({t_interior_train.shape}) type({type(t_interior_train)})\")\n","print(f\"t_interior_test shape({t_interior_test.shape}) type({type(t_interior_test)})\")\n","print(f\"labels_interior_train shape({labels_interior_train.shape}) type({type(labels_interior_train)})\")\n","print(f\"labels_interior_test shape({labels_interior_test.shape}) type({type(labels_interior_test)})\")\n","\n","print()\n","print(f\"x_bound_train shape({x_bound_train.shape}) type({type(x_bound_train)})\")\n","print(f\"x_bound_test shape({x_bound_test.shape}) type({type(x_bound_test)})\")\n","print(f\"t_bound_train shape({t_bound_train.shape}) type({type(t_bound_train)})\")\n","print(f\"t_bound_test shape({t_bound_test.shape}) type({type(t_bound_test)})\")\n","print(f\"labels_bound_train shape({labels_bound_train.shape}) type({type(labels_bound_train)})\")\n","print(f\"labels_bound_test shape({labels_bound_test.shape}) type({type(labels_bound_test)})\")\n","\n","print()\n","print(f\"x_init_train shape({x_init_train.shape}) type({type(x_init_train)})\")\n","print(f\"x_init_test shape({x_init_test.shape}) type({type(x_init_test)})\")\n","print(f\"t_init_train shape({t_init_train.shape}) type({type(t_init_train)})\")\n","print(f\"t_init_test shape({t_init_test.shape}) type({type(t_init_test)})\")\n","print(f\"labels_init_train shape({labels_init_train.shape}) type({type(labels_init_train)})\")\n","print(f\"labels_init_test shape({labels_init_test.shape}) type({type(labels_init_test)})\")"]},{"cell_type":"code","execution_count":762,"metadata":{},"outputs":[{"data":{"text/plain":["array([-1.73031962, -1.73031962, -1.73031962, ...,  1.73031962,\n","        1.73031962,  1.73031962])"]},"execution_count":762,"metadata":{},"output_type":"execute_result"}],"source":["features_interior[:, 0]"]},{"cell_type":"code","execution_count":763,"metadata":{},"outputs":[{"data":{"text/plain":["(1000, 51)"]},"execution_count":763,"metadata":{},"output_type":"execute_result"}],"source":["U_load.shape"]},{"cell_type":"code","execution_count":764,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#Lets QC these training and testing locations\n","f,ax = plt.subplots()\n","ax.pcolormesh(features[:,0].reshape((1000,51)), features[:,1].reshape((1000,51)), labels.reshape((1000,51)), shading='gouraud',alpha=0.1)\n","ax.scatter(x_interior_train,t_interior_train,alpha=0.2,c=\"Red\")\n","ax.scatter(x_interior_test,t_interior_test,alpha=0.01,c=\"Black\")\n","ax.scatter(x_interior_test,t_interior_test,alpha=0.01,c=\"Black\")\n","plt.show()"]},{"cell_type":"code","execution_count":765,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1682006967558,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"Pgf3zijSY3Ur"},"outputs":[],"source":["# Define MLP model architecture class\n","class NeuralNetwork(torch.nn.Module):\n","    def __init__(self):\n","        \"\"\"_summary_\n","        \"\"\"\n","        super().__init__()\n","        self.linear_stack = torch.nn.Sequential(\n","            torch.nn.Linear(2, 64),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(64, 64),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(64, 64),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(64, 64),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(64, 1)\n","        )\n","\n","        # torch.nn.init.xavier_uniform_(self.linear_stack.weight)\n","\n","    def forward(self, x, t):\n","        \"\"\"_summary_\n","\n","        Args:\n","            x (_type_): _description_\n","            t (_type_): _description_\n","\n","        Returns:\n","            _type_: _description_\n","        \"\"\"\n","        inputs = torch.cat([x,t], axis=1).to(device)\n","        return self.linear_stack(inputs)"]},{"cell_type":"code","execution_count":766,"metadata":{},"outputs":[],"source":["def train_loop(x_bound, x_init, x_interior, t_bound, t_init, t_interior,labels_bound, labels_init, labels_interior, boundary_loss_weights,pde_loss_weights,init_loss_weights, model, loss_fn, optimizer, writer=None):\n","    \"\"\"_summary_\n","\n","    Args:\n","        x_bound (_type_): _description_\n","        x_init (_type_): _description_\n","        x_interior (_type_): _description_\n","        t_bound (_type_): _description_\n","        t_init (_type_): _description_\n","        t_interior (_type_): _description_\n","        labels_bound (_type_): _description_\n","        labels_init (_type_): _description_\n","        labels_interior (_type_): _description_\n","        model (_type_): _description_\n","        loss_fn (_type_): _description_\n","        optimizer (_type_): _description_\n","    \"\"\"\n","    optimizer.zero_grad()\n","\n","    interior_pred = model(x_interior, t_interior)\n","    bound_pred = model(x_bound, t_bound)\n","    init_pred = model(x_init, t_init)\n","    \n","    boundary_loss, initial_loss, pde_loss, data_loss = \\\n","        loss_fn(\n","            interior_pred, bound_pred, init_pred, \n","            labels_interior, labels_bound, labels_init, \n","            x_interior, t_interior)\n","    \n","    print(f\"\\tBefore adaption: Initial condition loss: {initial_loss}\")\n","    print(f\"\\tBefore adaption: Boundary condition loss: {boundary_loss}\")\n","    print(f\"\\tBefore adaption: PDE loss: {pde_loss}\")\n","    print(f\"\\tBefore adaption: Data loss: {data_loss}\")\n","\n","    #Calculate dBoundaryLoss/dTheta\n","    boundary_loss.backward(retain_graph=True)\n","    bound_grads = []\n","    for name, param in model.named_parameters():\n","        if \"weight\" in name:\n","            bound_grads.append(param.grad.view(-1))\n","    \n","    bound_grads = torch.cat(bound_grads)\n","    optimizer.zero_grad()\n","    \n","    #Calculate dInitialLoss/dTheta\n","    initial_loss.backward(retain_graph=True)\n","    init_grads = []\n","    for name, param in model.named_parameters():\n","        if \"weight\" in name:\n","            init_grads.append(param.grad.view(-1))\n","    \n","    init_grads = torch.cat(init_grads)\n","    optimizer.zero_grad()\n","\n","    #Calculate dInitialLoss/dTheta\n","    pde_loss.backward(retain_graph=True)\n","    pde_grads = []\n","    for name, param in model.named_parameters():\n","        if \"weight\" in name:\n","            pde_grads.append(param.grad.view(-1))\n","    \n","    pde_grads = torch.cat(pde_grads)\n","    optimizer.zero_grad()\n","\n","    #Calculate dDataLoss/dTheta\n","    data_loss.backward(retain_graph=True)\n","    data_grads = []\n","    for name, param in model.named_parameters():\n","        if \"weight\" in name:\n","            data_grads.append(param.grad.view(-1))    \n","    \n","    data_grads = torch.cat(data_grads)\n","    optimizer.zero_grad()\n","\n","    #Compute adaptive weight for each component of total loss\n","    #relative to the mean gradient of data_loss w.r.t layer weights\n","    boundary_loss_lambda_hat = torch.max(torch.abs(data_grads)) / torch.mean(torch.abs(bound_grads))\n","    init_loss_lambda_hat = torch.max(torch.abs(data_grads)) / torch.mean(torch.abs(init_grads))\n","    pde_loss_lambda_hat = torch.max(torch.abs(data_grads)) / torch.mean(torch.abs(pde_grads))\n","    \n","    alpha = 0.1\n","    if epoch == 0:\n","        boundary_loss_weights.append((alpha * boundary_loss_lambda_hat)) \n","        init_loss_weights.append((alpha * init_loss_lambda_hat))\n","        pde_loss_weights.append((alpha * pde_loss_lambda_hat))\n","    else:\n","        boundary_loss_weights.append((alpha * boundary_loss_lambda_hat) + ((1 - alpha)*boundary_loss_weights[epoch-1]))\n","        init_loss_weights.append((alpha * init_loss_lambda_hat) + ((1 - alpha)*init_loss_weights[epoch-1]))\n","        pde_loss_weights.append((alpha * pde_loss_lambda_hat) + ((1 - alpha)*pde_loss_weights[epoch-1]))\n","\n","    # boundary_loss_weight = 1\n","    # init_loss_weight = 1\n","    # pde_loss_weight = 1\n","    # data_loss_weight = 1\n","\n","    #Create total loss to update all network parameters\n","    total_loss = \\\n","        data_loss + \\\n","        (init_loss_weights[epoch] * initial_loss) + \\\n","        (pde_loss_weights[epoch] * pde_loss) + \\\n","        (boundary_loss_weights[epoch] * boundary_loss)\n","    \n","    print(f\"\\t\\tAfter adaption: Initial condition loss: {initial_loss * init_loss_weights[epoch]}\")\n","    print(f\"\\t\\tAfter adaption: Boundary condition loss: {boundary_loss * boundary_loss_weights[epoch]}\")\n","    print(f\"\\t\\tAfter adaption: PDE loss: {pde_loss * pde_loss_weights[epoch]}\")\n","    print(f\"\\t\\tAfter adaption: Data loss: {data_loss}\")\n","\n","    if writer:\n","        writer.add_scalar('training_boundary_loss',boundary_loss,epoch)\n","        writer.add_scalar('training_init_loss',initial_loss,epoch)\n","        writer.add_scalar('training_pde_loss',pde_loss,epoch)\n","        writer.add_scalar('training_data_loss',data_loss,epoch)\n","        writer.add_scalar('training_weighted_boundary_loss',boundary_loss * boundary_loss_weights[epoch],epoch)\n","        writer.add_scalar('training_weighted_init_loss',initial_loss * init_loss_weights[epoch],epoch)\n","        writer.add_scalar('training_weighted_pde_loss',pde_loss * pde_loss_weights[epoch],epoch)\n","        writer.add_scalar('training_boundary_loss_weight',boundary_loss_weights[epoch],epoch)\n","        writer.add_scalar('training_init_loss_weight',init_loss_weights[epoch],epoch)\n","        writer.add_scalar('training_pde_loss_weight',pde_loss_weights[epoch],epoch)\n","    \n","    total_loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":767,"metadata":{},"outputs":[],"source":["def train_loop_softadapt(x_bound, x_init, x_interior, t_bound, t_init, t_interior,labels_bound, labels_init, labels_interior, boundary_losses,pde_losses,init_losses,data_losses,adapt_weights, model, loss_fn, optimizer, writer=None):\n","    optimizer.zero_grad()\n","\n","    interior_pred = model(x_interior, t_interior)\n","    bound_pred = model(x_bound, t_bound)\n","    init_pred = model(x_init, t_init)\n","    \n","    boundary_loss, initial_loss, pde_loss, data_loss = \\\n","        loss_fn(\n","            interior_pred, bound_pred, init_pred, \n","            labels_interior, labels_bound, labels_init, \n","            x_interior, t_interior)\n","    \n","    print(f\"\\tBefore adaption: Initial condition loss: {initial_loss}\")\n","    print(f\"\\tBefore adaption: Boundary condition loss: {boundary_loss}\")\n","    print(f\"\\tBefore adaption: PDE loss: {pde_loss}\")\n","    print(f\"\\tBefore adaption: Data loss: {data_loss}\")\n","\n","    loss_weighted_softadapt_object  = LossWeightedSoftAdapt(beta=0.1)\n","    \n","    print(boundary_loss)\n","    \n","    boundary_losses.append(boundary_loss)\n","    pde_losses.append(pde_loss)\n","    data_losses.append(data_loss)\n","    init_losses.append(initial_loss)\n","        \n","    if epoch >= 5:\n","        adapt_weights = loss_weighted_softadapt_object.get_component_weights(\n","            torch.tensor(boundary_losses[epoch-5:epoch]),\n","            torch.tensor(init_losses[epoch-5:epoch]),\n","            torch.tensor(pde_losses[epoch-5:epoch]),\n","            torch.tensor(data_losses[epoch-5:epoch]))\n","\n","        #Create total loss to update all network parameters\n","    total_loss = \\\n","        adapt_weights[0]*boundary_loss + \\\n","        adapt_weights[1]*initial_loss + \\\n","        adapt_weights[2]*pde_loss + \\\n","        adapt_weights[3]*data_loss\n","    \n","    print(boundary_loss)\n","\n","    print(f\"\\t\\tAdapt weights (bound,init,pde,data): {adapt_weights}\")\n","    print(f\"\\t\\tAfter adaption: Initial condition loss: {adapt_weights[1]*initial_loss}\")\n","    print(f\"\\t\\tAfter adaption: Boundary condition loss: {adapt_weights[0]*boundary_loss}\")\n","    print(f\"\\t\\tAfter adaption: PDE loss: {adapt_weights[2]*pde_loss}\")\n","    print(f\"\\t\\tAfter adaption: Data loss: {adapt_weights[3]*data_loss}\")\n","\n","    if writer:\n","        writer.add_scalar('training_boundary_loss',boundary_loss,epoch)\n","        writer.add_scalar('training_init_loss',initial_loss,epoch)\n","        writer.add_scalar('training_pde_loss',pde_loss,epoch)\n","        writer.add_scalar('training_data_loss',data_loss,epoch)\n","        writer.add_scalar('training_boundary_loss_weight',adapt_weights[0],epoch)\n","        writer.add_scalar('training_init_loss_weight',adapt_weights[1],epoch)\n","        writer.add_scalar('training_pde_loss_weight',adapt_weights[2],epoch)\n","        writer.add_scalar('training_data_loss_weight',adapt_weights[3],epoch)\n","\n","    total_loss.backward()\n","    optimizer.step()\n","    "]},{"cell_type":"code","execution_count":768,"metadata":{},"outputs":[],"source":["def train_loop_softadapt_man(x_bound, x_init, x_interior, t_bound, t_init, t_interior,labels_bound, labels_init, labels_interior, boundary_losses,pde_losses,init_losses,data_losses, model, loss_fn, optimizer, writer=None):\n","    optimizer.zero_grad()\n","\n","    interior_pred = model(x_interior, t_interior)\n","    bound_pred = model(x_bound, t_bound)\n","    init_pred = model(x_init, t_init)\n","    \n","    boundary_loss, initial_loss, pde_loss, data_loss = \\\n","        loss_fn(\n","            interior_pred, bound_pred, init_pred, \n","            labels_interior, labels_bound, labels_init, \n","            x_interior, t_interior)\n","    \n","    print(f\"\\tBefore adaption: Initial condition loss: {initial_loss}\")\n","    print(f\"\\tBefore adaption: Boundary condition loss: {boundary_loss}\")\n","    print(f\"\\tBefore adaption: PDE loss: {pde_loss}\")\n","    print(f\"\\tBefore adaption: Data loss: {data_loss}\")\n","\n","    #Append loss to list of previous losses\n","    boundary_losses.append(boundary_loss)\n","    pde_losses.append(pde_loss)\n","    data_losses.append(data_loss)\n","    init_losses.append(initial_loss)\n","\n","    #Compute weight\n","    if epoch != 0:\n","        adapt_weights = torch.nn.functional.softmax(torch.tensor([boundary_loss,initial_loss,pde_loss,data_loss]))\n","    else:\n","        adapt_weights = torch.tensor([1,1,1,1])\n","\n","        #Create total loss to update all network parameters\n","    total_loss = \\\n","        adapt_weights[0]*boundary_loss + \\\n","        adapt_weights[1]*initial_loss + \\\n","        adapt_weights[2]*pde_loss + \\\n","        adapt_weights[3]*data_loss\n","\n","    print(f\"\\t\\tAdapt weights (bound,init,pde,data): {adapt_weights}\")\n","    print(f\"\\t\\tAfter adaption: Initial condition loss: {adapt_weights[1]*initial_loss}\")\n","    print(f\"\\t\\tAfter adaption: Boundary condition loss: {adapt_weights[0]*boundary_loss}\")\n","    print(f\"\\t\\tAfter adaption: PDE loss: {adapt_weights[2]*pde_loss}\")\n","    print(f\"\\t\\tAfter adaption: Data loss: {adapt_weights[3]*data_loss}\")\n","\n","    if writer:\n","        writer.add_scalar('training_boundary_loss',boundary_loss,epoch)\n","        writer.add_scalar('training_init_loss',initial_loss,epoch)\n","        writer.add_scalar('training_pde_loss',pde_loss,epoch)\n","        writer.add_scalar('training_data_loss',data_loss,epoch)\n","        writer.add_scalar('training_boundary_loss_weight',adapt_weights[0],epoch)\n","        writer.add_scalar('training_init_loss_weight',adapt_weights[1],epoch)\n","        writer.add_scalar('training_pde_loss_weight',adapt_weights[2],epoch)\n","        writer.add_scalar('training_data_loss_weight',adapt_weights[3],epoch)\n","\n","    total_loss.backward()\n","    optimizer.step()\n","    "]},{"cell_type":"code","execution_count":769,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682006967559,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"VkKv_FDAY3Ur"},"outputs":[],"source":["def combined_physics_data_loss(interior_pred, bound_pred, init_pred, interior_labels, bound_labels, init_labels, x_interior, t_interior):\n","    \"\"\"_summary_\n","\n","    Args:\n","        interior_pred (_type_): _description_\n","        bound_pred (_type_): _description_\n","        init_pred (_type_): _description_\n","        interior_labels (_type_): _description_\n","        bound_labels (_type_): _description_\n","        init_labels (_type_): _description_\n","        x_interior (_type_): _description_\n","        t_interior (_type_): _description_\n","\n","    Returns:\n","        _type_: _description_\n","    \"\"\"\n","    dudx = torch.autograd.grad(interior_pred.sum(), x_interior, retain_graph=True, create_graph=True)[0]\n","    dudt = torch.autograd.grad(interior_pred.sum(), t_interior, retain_graph=True, create_graph=True)[0]\n","    d2udt2 = torch.autograd.grad(dudt.sum(), t_interior, retain_graph=True, create_graph=True)[0]\n","    pde_values = (dudx * d2udt2) - dudt\n","\n","    mse = torch.nn.MSELoss()\n","    pde_zeros = torch.zeros_like(pde_values)\n","    pde_loss = mse(pde_zeros,pde_values)\n","\n","    initial_loss = mse(init_labels, init_pred)\n","    boundary_loss = mse(bound_labels, bound_pred)\n","    data_loss = mse(interior_pred, interior_labels)\n","    \n","    return boundary_loss, initial_loss, pde_loss, data_loss"]},{"cell_type":"code","execution_count":770,"metadata":{},"outputs":[],"source":["def test_loop(x_bound, x_init, x_interior, t_bound, t_init, t_interior,labels_bound, labels_init, labels_interior, model, loss_fn, writer=None):\n","    \n","    interior_pred = model(x_interior, t_interior)\n","    bound_pred = model(x_bound, t_bound)\n","    init_pred = model(x_init, t_init)\n","\n","    boundary_loss, initial_loss, pde_loss, data_loss = \\\n","        loss_fn(\n","            interior_pred, bound_pred, init_pred, \n","            labels_interior, labels_bound, labels_init, \n","            x_interior, t_interior)\n","    \n","    if writer:\n","        writer.add_scalar('testing_boundary_loss',boundary_loss,epoch)\n","        writer.add_scalar('testing_init_loss',initial_loss,epoch)\n","        writer.add_scalar('testing_pde_loss',pde_loss,epoch)\n","        writer.add_scalar('testing_data_loss',data_loss,epoch)\n","    \n","    print(f\"\\n\\tTesting: Initial condition loss: {initial_loss}\")\n","    print(f\"\\tTesting: Boundary condition loss: {boundary_loss}\")\n","    print(f\"\\tTesting: PDE loss: {pde_loss}\")\n","    print(f\"\\tTesting: Data loss: {data_loss}\")"]},{"cell_type":"code","execution_count":771,"metadata":{},"outputs":[{"data":{"text/plain":["(39200,)"]},"execution_count":771,"metadata":{},"output_type":"execute_result"}],"source":["x_interior_train.shape"]},{"cell_type":"code","execution_count":772,"metadata":{},"outputs":[],"source":["def init_weights(model):\n","    if isinstance(model, torch.nn.Linear):\n","        print(\"Xavier init on linear layer\")\n","        torch.nn.init.xavier_uniform(model.weight)\n","        model.bias.data.fill_(0.01)"]},{"cell_type":"code","execution_count":773,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16247,"status":"ok","timestamp":1682006983798,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"izWjVhH2Y3Us","outputId":"b2a38c39-b383-44ff-a0a0-401ad33d0cce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Xavier init on linear layer\n","Xavier init on linear layer\n","Xavier init on linear layer\n","Xavier init on linear layer\n","Xavier init on linear layer\n","\n","Epoch 1\n","-------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/cl/wp9kmsjx5ln9dxmrjh4hw3740000gn/T/ipykernel_15692/199353368.py:4: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  torch.nn.init.xavier_uniform(model.weight)\n"]},{"name":"stdout","output_type":"stream","text":["\tBefore adaption: Initial condition loss: 0.3029494881629944\n","\tBefore adaption: Boundary condition loss: 0.030323904007673264\n","\tBefore adaption: PDE loss: 0.0069586788304150105\n","\tBefore adaption: Data loss: 0.07648434489965439\n","tensor(0.0303, grad_fn=<MseLossBackward0>)\n","tensor(0.0303, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([1, 1, 1, 1])\n","\t\tAfter adaption: Initial condition loss: 0.3029494881629944\n","\t\tAfter adaption: Boundary condition loss: 0.030323904007673264\n","\t\tAfter adaption: PDE loss: 0.0069586788304150105\n","\t\tAfter adaption: Data loss: 0.07648434489965439\n","\n","\tTesting: Initial condition loss: 0.1593063920736313\n","\tTesting: Boundary condition loss: 0.03659781068563461\n","\tTesting: PDE loss: 0.00963111687451601\n","\tTesting: Data loss: 0.05947760120034218\n","\n","Epoch 2\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.2257899045944214\n","\tBefore adaption: Boundary condition loss: 0.03602265194058418\n","\tBefore adaption: PDE loss: 0.009508928284049034\n","\tBefore adaption: Data loss: 0.059322744607925415\n","tensor(0.0360, grad_fn=<MseLossBackward0>)\n","tensor(0.0360, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([1, 1, 1, 1])\n","\t\tAfter adaption: Initial condition loss: 0.2257899045944214\n","\t\tAfter adaption: Boundary condition loss: 0.03602265194058418\n","\t\tAfter adaption: PDE loss: 0.009508928284049034\n","\t\tAfter adaption: Data loss: 0.059322744607925415\n","\n","\tTesting: Initial condition loss: 0.11499901115894318\n","\tTesting: Boundary condition loss: 0.04540304094552994\n","\tTesting: PDE loss: 0.013780192472040653\n","\tTesting: Data loss: 0.046517468988895416\n","\n","Epoch 3\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.1699332296848297\n","\tBefore adaption: Boundary condition loss: 0.043878186494112015\n","\tBefore adaption: PDE loss: 0.013638228178024292\n","\tBefore adaption: Data loss: 0.04639817029237747\n","tensor(0.0439, grad_fn=<MseLossBackward0>)\n","tensor(0.0439, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([1, 1, 1, 1])\n","\t\tAfter adaption: Initial condition loss: 0.1699332296848297\n","\t\tAfter adaption: Boundary condition loss: 0.043878186494112015\n","\t\tAfter adaption: PDE loss: 0.013638228178024292\n","\t\tAfter adaption: Data loss: 0.04639817029237747\n","\n","\tTesting: Initial condition loss: 0.08535314351320267\n","\tTesting: Boundary condition loss: 0.05310792103409767\n","\tTesting: PDE loss: 0.019777091220021248\n","\tTesting: Data loss: 0.037245769053697586\n","\n","Epoch 4\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.12984178960323334\n","\tBefore adaption: Boundary condition loss: 0.05075610801577568\n","\tBefore adaption: PDE loss: 0.019632313400506973\n","\tBefore adaption: Data loss: 0.03714262321591377\n","tensor(0.0508, grad_fn=<MseLossBackward0>)\n","tensor(0.0508, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([1, 1, 1, 1])\n","\t\tAfter adaption: Initial condition loss: 0.12984178960323334\n","\t\tAfter adaption: Boundary condition loss: 0.05075610801577568\n","\t\tAfter adaption: PDE loss: 0.019632313400506973\n","\t\tAfter adaption: Data loss: 0.03714262321591377\n","\n","\tTesting: Initial condition loss: 0.06727582961320877\n","\tTesting: Boundary condition loss: 0.05706775188446045\n","\tTesting: PDE loss: 0.026922697201371193\n","\tTesting: Data loss: 0.03101678378880024\n","\n","Epoch 5\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.10280738025903702\n","\tBefore adaption: Boundary condition loss: 0.05398758500814438\n","\tBefore adaption: PDE loss: 0.02674250677227974\n","\tBefore adaption: Data loss: 0.030920157209038734\n","tensor(0.0540, grad_fn=<MseLossBackward0>)\n","tensor(0.0540, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([1, 1, 1, 1])\n","\t\tAfter adaption: Initial condition loss: 0.10280738025903702\n","\t\tAfter adaption: Boundary condition loss: 0.05398758500814438\n","\t\tAfter adaption: PDE loss: 0.02674250677227974\n","\t\tAfter adaption: Data loss: 0.030920157209038734\n","\n","\tTesting: Initial condition loss: 0.0571596585214138\n","\tTesting: Boundary condition loss: 0.05565285310149193\n","\tTesting: PDE loss: 0.03399402275681496\n","\tTesting: Data loss: 0.02728603221476078\n","\n","Epoch 6\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.08559028804302216\n","\tBefore adaption: Boundary condition loss: 0.05204484984278679\n","\tBefore adaption: PDE loss: 0.03386170417070389\n","\tBefore adaption: Data loss: 0.027183935046195984\n","tensor(0.0520, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0520, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1469, 0.6303, 0.0522, 0.1706], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.05394858027042873\n","\t\tAfter adaption: Boundary condition loss: 0.007643335812979661\n","\t\tAfter adaption: PDE loss: 0.0017690190553141067\n","\t\tAfter adaption: Data loss: 0.004637171516996557\n","\n","\tTesting: Initial condition loss: 0.05077227205038071\n","\tTesting: Boundary condition loss: 0.05480390414595604\n","\tTesting: PDE loss: 0.04130782559514046\n","\tTesting: Data loss: 0.024684926494956017\n","\n","Epoch 7\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.07359510660171509\n","\tBefore adaption: Boundary condition loss: 0.050702229142189026\n","\tBefore adaption: PDE loss: 0.04116711765527725\n","\tBefore adaption: Data loss: 0.024565868079662323\n","tensor(0.0507, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0507, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1894, 0.5674, 0.0827, 0.1605], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.04175458986829783\n","\t\tAfter adaption: Boundary condition loss: 0.009605027740763862\n","\t\tAfter adaption: PDE loss: 0.0034049892532518767\n","\t\tAfter adaption: Data loss: 0.0039426525251266276\n","\n","\tTesting: Initial condition loss: 0.04674443230032921\n","\tTesting: Boundary condition loss: 0.053268563002347946\n","\tTesting: PDE loss: 0.04849750176072121\n","\tTesting: Data loss: 0.023093760013580322\n","\n","Epoch 8\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.06523925065994263\n","\tBefore adaption: Boundary condition loss: 0.04879647120833397\n","\tBefore adaption: PDE loss: 0.04829091578722\n","\tBefore adaption: Data loss: 0.022964881733059883\n","tensor(0.0488, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0488, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2262, 0.5029, 0.1215, 0.1493], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.032808757245894306\n","\t\tAfter adaption: Boundary condition loss: 0.011039702988033522\n","\t\tAfter adaption: PDE loss: 0.005868415612795183\n","\t\tAfter adaption: Data loss: 0.0034295519816164464\n","\n","\tTesting: Initial condition loss: 0.04397262632846832\n","\tTesting: Boundary condition loss: 0.05021291226148605\n","\tTesting: PDE loss: 0.05511705204844475\n","\tTesting: Data loss: 0.02236584946513176\n","\n","Epoch 9\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.05890456959605217\n","\tBefore adaption: Boundary condition loss: 0.04554587975144386\n","\tBefore adaption: PDE loss: 0.0548534020781517\n","\tBefore adaption: Data loss: 0.022228965535759926\n","tensor(0.0455, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0455, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2504, 0.4446, 0.1658, 0.1392], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.02618955319967851\n","\t\tAfter adaption: Boundary condition loss: 0.011404256335551173\n","\t\tAfter adaption: PDE loss: 0.009092174543823626\n","\t\tAfter adaption: Data loss: 0.003095283289581569\n","\n","\tTesting: Initial condition loss: 0.04116215929389\n","\tTesting: Boundary condition loss: 0.0452292263507843\n","\tTesting: PDE loss: 0.060541775077581406\n","\tTesting: Data loss: 0.022361740469932556\n","\n","Epoch 10\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.053829800337553024\n","\tBefore adaption: Boundary condition loss: 0.04067249596118927\n","\tBefore adaption: PDE loss: 0.06021890416741371\n","\tBefore adaption: Data loss: 0.022232763469219208\n","tensor(0.0407, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0407, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2590, 0.3976, 0.2116, 0.1319], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.021402027719563073\n","\t\tAfter adaption: Boundary condition loss: 0.0105332952306117\n","\t\tAfter adaption: PDE loss: 0.012740391102650794\n","\t\tAfter adaption: Data loss: 0.0029317604550229558\n","\n","\tTesting: Initial condition loss: 0.03760329261422157\n","\tTesting: Boundary condition loss: 0.038869503885507584\n","\tTesting: PDE loss: 0.06416311115026474\n","\tTesting: Data loss: 0.02293759398162365\n","\n","Epoch 11\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0487205907702446\n","\tBefore adaption: Boundary condition loss: 0.03467432036995888\n","\tBefore adaption: PDE loss: 0.06394589692354202\n","\tBefore adaption: Data loss: 0.022838760167360306\n","tensor(0.0347, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0347, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2550, 0.3612, 0.2559, 0.1278], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01759752375130053\n","\t\tAfter adaption: Boundary condition loss: 0.008843503473687979\n","\t\tAfter adaption: PDE loss: 0.016366654463219117\n","\t\tAfter adaption: Data loss: 0.002919184313115719\n","\n","\tTesting: Initial condition loss: 0.0330524779856205\n","\tTesting: Boundary condition loss: 0.03188340738415718\n","\tTesting: PDE loss: 0.0662807822227478\n","\tTesting: Data loss: 0.024008892476558685\n","\n","Epoch 12\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.04331362619996071\n","\tBefore adaption: Boundary condition loss: 0.028207123279571533\n","\tBefore adaption: PDE loss: 0.065915048122406\n","\tBefore adaption: Data loss: 0.02396431751549244\n","tensor(0.0282, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0282, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2438, 0.3319, 0.2973, 0.1270], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014376785652924518\n","\t\tAfter adaption: Boundary condition loss: 0.006876964401873986\n","\t\tAfter adaption: PDE loss: 0.01959341175049096\n","\t\tAfter adaption: Data loss: 0.003043998677332384\n","\n","\tTesting: Initial condition loss: 0.028200125321745872\n","\tTesting: Boundary condition loss: 0.02487463876605034\n","\tTesting: PDE loss: 0.06668424606323242\n","\tTesting: Data loss: 0.02553127147257328\n","\n","Epoch 13\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.037950120866298676\n","\tBefore adaption: Boundary condition loss: 0.02183966152369976\n","\tBefore adaption: PDE loss: 0.06638193130493164\n","\tBefore adaption: Data loss: 0.025556543841958046\n","tensor(0.0218, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0218, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2260, 0.3082, 0.3352, 0.1305], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011697749805506431\n","\t\tAfter adaption: Boundary condition loss: 0.004936604001178281\n","\t\tAfter adaption: PDE loss: 0.02225337643063767\n","\t\tAfter adaption: Data loss: 0.0033348453878201617\n","\n","\tTesting: Initial condition loss: 0.023971449583768845\n","\tTesting: Boundary condition loss: 0.018519148230552673\n","\tTesting: PDE loss: 0.06581622362136841\n","\tTesting: Data loss: 0.0274457186460495\n","\n","Epoch 14\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03347966447472572\n","\tBefore adaption: Boundary condition loss: 0.016183553263545036\n","\tBefore adaption: PDE loss: 0.06551773101091385\n","\tBefore adaption: Data loss: 0.027564799413084984\n","tensor(0.0162, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0162, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2030, 0.2882, 0.3701, 0.1388], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009648395191444416\n","\t\tAfter adaption: Boundary condition loss: 0.0032850366821916247\n","\t\tAfter adaption: PDE loss: 0.02424502899002754\n","\t\tAfter adaption: Data loss: 0.003825281489582501\n","\n","\tTesting: Initial condition loss: 0.021185876801609993\n","\tTesting: Boundary condition loss: 0.013402610085904598\n","\tTesting: PDE loss: 0.06395678967237473\n","\tTesting: Data loss: 0.02968042530119419\n","\n","Epoch 15\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030559325590729713\n","\tBefore adaption: Boundary condition loss: 0.011704763397574425\n","\tBefore adaption: PDE loss: 0.06372950971126556\n","\tBefore adaption: Data loss: 0.02990550734102726\n","tensor(0.0117, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0117, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1762, 0.2705, 0.4012, 0.1521], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008265560843118497\n","\t\tAfter adaption: Boundary condition loss: 0.0020625785705983115\n","\t\tAfter adaption: PDE loss: 0.025566466627857297\n","\t\tAfter adaption: Data loss: 0.004549688270931149\n","\n","\tTesting: Initial condition loss: 0.02042894810438156\n","\tTesting: Boundary condition loss: 0.009700853377580643\n","\tTesting: PDE loss: 0.06163923069834709\n","\tTesting: Data loss: 0.032052747905254364\n","\n","Epoch 16\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029635122045874596\n","\tBefore adaption: Boundary condition loss: 0.008540716022253036\n","\tBefore adaption: PDE loss: 0.06125297769904137\n","\tBefore adaption: Data loss: 0.03238794580101967\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1477, 0.2545, 0.4273, 0.1704], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00754311651243495\n","\t\tAfter adaption: Boundary condition loss: 0.001261560248724639\n","\t\tAfter adaption: PDE loss: 0.026175479627820537\n","\t\tAfter adaption: Data loss: 0.00551960691447571\n","\n","\tTesting: Initial condition loss: 0.021540574729442596\n","\tTesting: Boundary condition loss: 0.007264724932610989\n","\tTesting: PDE loss: 0.05905824527144432\n","\tTesting: Data loss: 0.03425540030002594\n","\n","Epoch 17\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030479395762085915\n","\tBefore adaption: Boundary condition loss: 0.006564697250723839\n","\tBefore adaption: PDE loss: 0.05863907188177109\n","\tBefore adaption: Data loss: 0.034693747758865356\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1194, 0.2417, 0.4462, 0.1927], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007365663804777351\n","\t\tAfter adaption: Boundary condition loss: 0.0007841333852789454\n","\t\tAfter adaption: PDE loss: 0.026165919922130746\n","\t\tAfter adaption: Data loss: 0.00668453525986895\n","\n","\tTesting: Initial condition loss: 0.023879121989011765\n","\tTesting: Boundary condition loss: 0.00583595409989357\n","\tTesting: PDE loss: 0.056626323610544205\n","\tTesting: Data loss: 0.03594547137618065\n","\n","Epoch 18\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0323515422642231\n","\tBefore adaption: Boundary condition loss: 0.0054655736312270164\n","\tBefore adaption: PDE loss: 0.056162029504776\n","\tBefore adaption: Data loss: 0.036467067897319794\n","tensor(0.0055, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0055, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0936, 0.2340, 0.4556, 0.2168], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007569687169094041\n","\t\tAfter adaption: Boundary condition loss: 0.0005114137198456374\n","\t\tAfter adaption: PDE loss: 0.02558928404749086\n","\t\tAfter adaption: Data loss: 0.007906588491857899\n","\n","\tTesting: Initial condition loss: 0.026419203728437424\n","\tTesting: Boundary condition loss: 0.0050220973789691925\n","\tTesting: PDE loss: 0.05453548952937126\n","\tTesting: Data loss: 0.036791034042835236\n","\n","Epoch 19\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03452020138502121\n","\tBefore adaption: Boundary condition loss: 0.004861684516072273\n","\tBefore adaption: PDE loss: 0.0541280061006546\n","\tBefore adaption: Data loss: 0.03737281262874603\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0722, 0.2331, 0.4548, 0.2400], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008046056325210781\n","\t\tAfter adaption: Boundary condition loss: 0.00035082479985373025\n","\t\tAfter adaption: PDE loss: 0.02461774649190539\n","\t\tAfter adaption: Data loss: 0.008967611519436569\n","\n","\tTesting: Initial condition loss: 0.028218949213624\n","\tTesting: Boundary condition loss: 0.004436352755874395\n","\tTesting: PDE loss: 0.05309661105275154\n","\tTesting: Data loss: 0.03654499351978302\n","\n","Epoch 20\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03607059642672539\n","\tBefore adaption: Boundary condition loss: 0.004408134613186121\n","\tBefore adaption: PDE loss: 0.052670013159513474\n","\tBefore adaption: Data loss: 0.037157751619815826\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0563, 0.2389, 0.4457, 0.2591], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008616980654182538\n","\t\tAfter adaption: Boundary condition loss: 0.0002481902454707185\n","\t\tAfter adaption: PDE loss: 0.023472758893766394\n","\t\tAfter adaption: Data loss: 0.009629359244601853\n","\n","\tTesting: Initial condition loss: 0.02849874645471573\n","\tTesting: Boundary condition loss: 0.0038659905549138784\n","\tTesting: PDE loss: 0.05243106186389923\n","\tTesting: Data loss: 0.03508080169558525\n","\n","Epoch 21\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.036054741591215134\n","\tBefore adaption: Boundary condition loss: 0.003912205342203379\n","\tBefore adaption: PDE loss: 0.05196996033191681\n","\tBefore adaption: Data loss: 0.03569294884800911\n","tensor(0.0039, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0039, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0456, 0.2494, 0.4325, 0.2724], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008992187000180727\n","\t\tAfter adaption: Boundary condition loss: 0.0001785169938200429\n","\t\tAfter adaption: PDE loss: 0.022478108846222884\n","\t\tAfter adaption: Data loss: 0.009724337820988242\n","\n","\tTesting: Initial condition loss: 0.026880407705903053\n","\tTesting: Boundary condition loss: 0.0033902982249855995\n","\tTesting: PDE loss: 0.05253157764673233\n","\tTesting: Data loss: 0.032541751861572266\n","\n","Epoch 22\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.034138210117816925\n","\tBefore adaption: Boundary condition loss: 0.0034729070030152798\n","\tBefore adaption: PDE loss: 0.05209890007972717\n","\tBefore adaption: Data loss: 0.03312220796942711\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0388, 0.2609, 0.4210, 0.2793], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008907333133118039\n","\t\tAfter adaption: Boundary condition loss: 0.00013476461713374395\n","\t\tAfter adaption: PDE loss: 0.021933869193993524\n","\t\tAfter adaption: Data loss: 0.009250077492175006\n","\n","\tTesting: Initial condition loss: 0.023712871596217155\n","\tTesting: Boundary condition loss: 0.0032824298832565546\n","\tTesting: PDE loss: 0.05344691500067711\n","\tTesting: Data loss: 0.029274381697177887\n","\n","Epoch 23\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03055356815457344\n","\tBefore adaption: Boundary condition loss: 0.003361622104421258\n","\tBefore adaption: PDE loss: 0.052975550293922424\n","\tBefore adaption: Data loss: 0.029796812683343887\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0344, 0.2697, 0.4158, 0.2801], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008240153563214267\n","\t\tAfter adaption: Boundary condition loss: 0.00011580011905864667\n","\t\tAfter adaption: PDE loss: 0.022026085472019362\n","\t\tAfter adaption: Data loss: 0.008345449982715032\n","\n","\tTesting: Initial condition loss: 0.019658608362078667\n","\tTesting: Boundary condition loss: 0.0037942572962492704\n","\tTesting: PDE loss: 0.05498076230287552\n","\tTesting: Data loss: 0.025724519044160843\n","\n","Epoch 24\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026065999642014503\n","\tBefore adaption: Boundary condition loss: 0.0038261080626398325\n","\tBefore adaption: PDE loss: 0.05445067211985588\n","\tBefore adaption: Data loss: 0.02616521157324314\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0319, 0.2727, 0.4198, 0.2756], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007109290600965889\n","\t\tAfter adaption: Boundary condition loss: 0.00012188123302578203\n","\t\tAfter adaption: PDE loss: 0.02286021623001784\n","\t\tAfter adaption: Data loss: 0.00721033064705376\n","\n","\tTesting: Initial condition loss: 0.01560311671346426\n","\tTesting: Boundary condition loss: 0.005017120391130447\n","\tTesting: PDE loss: 0.056742459535598755\n","\tTesting: Data loss: 0.022282108664512634\n","\n","Epoch 25\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021587684750556946\n","\tBefore adaption: Boundary condition loss: 0.004946309607475996\n","\tBefore adaption: PDE loss: 0.05619232356548309\n","\tBefore adaption: Data loss: 0.022633332759141922\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0312, 0.2680, 0.4345, 0.2663], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005784467416821303\n","\t\tAfter adaption: Boundary condition loss: 0.00015442740074713115\n","\t\tAfter adaption: PDE loss: 0.024414433625346735\n","\t\tAfter adaption: Data loss: 0.00602832306648188\n","\n","\tTesting: Initial condition loss: 0.012393771670758724\n","\tTesting: Boundary condition loss: 0.006863879039883614\n","\tTesting: PDE loss: 0.058343805372714996\n","\tTesting: Data loss: 0.019223658367991447\n","\n","Epoch 26\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01791800558567047\n","\tBefore adaption: Boundary condition loss: 0.006633066572248936\n","\tBefore adaption: PDE loss: 0.05781854689121246\n","\tBefore adaption: Data loss: 0.019490830600261688\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0335, 0.2545, 0.4592, 0.2528], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004560817639458003\n","\t\tAfter adaption: Boundary condition loss: 0.0002220805887337316\n","\t\tAfter adaption: PDE loss: 0.02654852400774439\n","\t\tAfter adaption: Data loss: 0.0049274993847079895\n","\n","\tTesting: Initial condition loss: 0.01041475310921669\n","\tTesting: Boundary condition loss: 0.009043489582836628\n","\tTesting: PDE loss: 0.059559810906648636\n","\tTesting: Data loss: 0.016709983348846436\n","\n","Epoch 27\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015459185466170311\n","\tBefore adaption: Boundary condition loss: 0.008618520572781563\n","\tBefore adaption: PDE loss: 0.05897270515561104\n","\tBefore adaption: Data loss: 0.016904911026358604\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0399, 0.2337, 0.4909, 0.2354], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0036131725462910003\n","\t\tAfter adaption: Boundary condition loss: 0.00034399688090869273\n","\t\tAfter adaption: PDE loss: 0.028952590766734402\n","\t\tAfter adaption: Data loss: 0.003979650717616482\n","\n","\tTesting: Initial condition loss: 0.009543006308376789\n","\tTesting: Boundary condition loss: 0.011099700815975666\n","\tTesting: PDE loss: 0.05998774990439415\n","\tTesting: Data loss: 0.014765930362045765\n","\n","Epoch 28\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014149485155940056\n","\tBefore adaption: Boundary condition loss: 0.010488263331353664\n","\tBefore adaption: PDE loss: 0.059398166835308075\n","\tBefore adaption: Data loss: 0.014907299540936947\n","tensor(0.0105, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0105, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0513, 0.2087, 0.5249, 0.2151], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0029536901045989095\n","\t\tAfter adaption: Boundary condition loss: 0.0005375671324811219\n","\t\tAfter adaption: PDE loss: 0.03117586966866759\n","\t\tAfter adaption: Data loss: 0.0032070716270606366\n","\n","\tTesting: Initial condition loss: 0.009295685216784477\n","\tTesting: Boundary condition loss: 0.01257507223635912\n","\tTesting: PDE loss: 0.059472087770700455\n","\tTesting: Data loss: 0.013312943279743195\n","\n","Epoch 29\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013658793643116951\n","\tBefore adaption: Boundary condition loss: 0.011824989691376686\n","\tBefore adaption: PDE loss: 0.058870259672403336\n","\tBefore adaption: Data loss: 0.013422735966742039\n","tensor(0.0118, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0118, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0668, 0.1842, 0.5553, 0.1937], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002515400552915216\n","\t\tAfter adaption: Boundary condition loss: 0.0007900543189040995\n","\t\tAfter adaption: PDE loss: 0.03269224191309631\n","\t\tAfter adaption: Data loss: 0.0025999960209978513\n","\n","\tTesting: Initial condition loss: 0.009297962300479412\n","\tTesting: Boundary condition loss: 0.013132737949490547\n","\tTesting: PDE loss: 0.057924773544073105\n","\tTesting: Data loss: 0.012259687297046185\n","\n","Epoch 30\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013609725050628185\n","\tBefore adaption: Boundary condition loss: 0.012316498905420303\n","\tBefore adaption: PDE loss: 0.057331930845975876\n","\tBefore adaption: Data loss: 0.01235915720462799\n","tensor(0.0123, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0123, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0844, 0.1642, 0.5781, 0.1733], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022347085013567887\n","\t\tAfter adaption: Boundary condition loss: 0.001039241755950649\n","\t\tAfter adaption: PDE loss: 0.033144230348444624\n","\t\tAfter adaption: Data loss: 0.0021419817820202904\n","\n","\tTesting: Initial condition loss: 0.00941507425159216\n","\tTesting: Boundary condition loss: 0.01264102105051279\n","\tTesting: PDE loss: 0.05546523630619049\n","\tTesting: Data loss: 0.01156200934201479\n","\n","Epoch 31\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013903695158660412\n","\tBefore adaption: Boundary condition loss: 0.011836599558591843\n","\tBefore adaption: PDE loss: 0.054885245859622955\n","\tBefore adaption: Data loss: 0.011671029031276703\n","tensor(0.0118, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0118, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1010, 0.1513, 0.5918, 0.1559], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021037899647253643\n","\t\tAfter adaption: Boundary condition loss: 0.0011950361927152823\n","\t\tAfter adaption: PDE loss: 0.03247998421597711\n","\t\tAfter adaption: Data loss: 0.0018200659357002762\n","\n","\tTesting: Initial condition loss: 0.009869039990007877\n","\tTesting: Boundary condition loss: 0.011211023665964603\n","\tTesting: PDE loss: 0.05227544158697128\n","\tTesting: Data loss: 0.011245176196098328\n","\n","Epoch 32\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014739525504410267\n","\tBefore adaption: Boundary condition loss: 0.010490881279110909\n","\tBefore adaption: PDE loss: 0.0517297126352787\n","\tBefore adaption: Data loss: 0.011378665454685688\n","tensor(0.0105, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0105, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1137, 0.1460, 0.5974, 0.1429], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021524707672940153\n","\t\tAfter adaption: Boundary condition loss: 0.0011927557246165122\n","\t\tAfter adaption: PDE loss: 0.030901791467573065\n","\t\tAfter adaption: Data loss: 0.0016260249283792856\n","\n","\tTesting: Initial condition loss: 0.011086293496191502\n","\tTesting: Boundary condition loss: 0.0091951759532094\n","\tTesting: PDE loss: 0.04869508370757103\n","\tTesting: Data loss: 0.011391475796699524\n","\n","Epoch 33\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01650131121277809\n","\tBefore adaption: Boundary condition loss: 0.00859823264181614\n","\tBefore adaption: PDE loss: 0.048105064779520035\n","\tBefore adaption: Data loss: 0.011558081954717636\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1204, 0.1481, 0.5967, 0.1347], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0024441709602977648\n","\t\tAfter adaption: Boundary condition loss: 0.0010356214936851397\n","\t\tAfter adaption: PDE loss: 0.02870395724114691\n","\t\tAfter adaption: Data loss: 0.0015573498019059186\n","\n","\tTesting: Initial condition loss: 0.013508693315088749\n","\tTesting: Boundary condition loss: 0.007036468479782343\n","\tTesting: PDE loss: 0.04485536366701126\n","\tTesting: Data loss: 0.012053146958351135\n","\n","Epoch 34\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.019544992595911026\n","\tBefore adaption: Boundary condition loss: 0.006591628771275282\n","\tBefore adaption: PDE loss: 0.04432312026619911\n","\tBefore adaption: Data loss: 0.012255566194653511\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1200, 0.1578, 0.5905, 0.1316], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003085016866552873\n","\t\tAfter adaption: Boundary condition loss: 0.0007913002933260465\n","\t\tAfter adaption: PDE loss: 0.026172440988770605\n","\t\tAfter adaption: Data loss: 0.0016130776008171266\n","\n","\tTesting: Initial condition loss: 0.017370356246829033\n","\tTesting: Boundary condition loss: 0.005072649568319321\n","\tTesting: PDE loss: 0.04112740606069565\n","\tTesting: Data loss: 0.013188354671001434\n","\n","Epoch 35\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02398841641843319\n","\tBefore adaption: Boundary condition loss: 0.00477249501273036\n","\tBefore adaption: PDE loss: 0.040618374943733215\n","\tBefore adaption: Data loss: 0.0134225869551301\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1123, 0.1765, 0.5777, 0.1335], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0042335148817686285\n","\t\tAfter adaption: Boundary condition loss: 0.0005360511450752595\n","\t\tAfter adaption: PDE loss: 0.02346633174107645\n","\t\tAfter adaption: Data loss: 0.0017915169104912932\n","\n","\tTesting: Initial condition loss: 0.022393282502889633\n","\tTesting: Boundary condition loss: 0.0035724372137337923\n","\tTesting: PDE loss: 0.0376923494040966\n","\tTesting: Data loss: 0.014596917666494846\n","\n","Epoch 36\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029494550079107285\n","\tBefore adaption: Boundary condition loss: 0.003390592522919178\n","\tBefore adaption: PDE loss: 0.0372341126203537\n","\tBefore adaption: Data loss: 0.014857360161840916\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0981, 0.2058, 0.5561, 0.1399], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0060709809307126\n","\t\tAfter adaption: Boundary condition loss: 0.00033277470441009306\n","\t\tAfter adaption: PDE loss: 0.0207059591783626\n","\t\tAfter adaption: Data loss: 0.0020788056052855517\n","\n","\tTesting: Initial condition loss: 0.027662353590130806\n","\tTesting: Boundary condition loss: 0.002654718467965722\n","\tTesting: PDE loss: 0.034836795181035995\n","\tTesting: Data loss: 0.01590297743678093\n","\n","Epoch 37\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03513619676232338\n","\tBefore adaption: Boundary condition loss: 0.0025467134546488523\n","\tBefore adaption: PDE loss: 0.034390680491924286\n","\tBefore adaption: Data loss: 0.016179965808987617\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0799, 0.2462, 0.5240, 0.1499], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008651372534527453\n","\t\tAfter adaption: Boundary condition loss: 0.00020347232712850598\n","\t\tAfter adaption: PDE loss: 0.01802120804167088\n","\t\tAfter adaption: Data loss: 0.0024248205458276503\n","\n","\tTesting: Initial condition loss: 0.03155013546347618\n","\tTesting: Boundary condition loss: 0.0023227857891470194\n","\tTesting: PDE loss: 0.03278336301445961\n","\tTesting: Data loss: 0.016575446352362633\n","\n","Epoch 38\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.039308540523052216\n","\tBefore adaption: Boundary condition loss: 0.002251950092613697\n","\tBefore adaption: PDE loss: 0.03237292915582657\n","\tBefore adaption: Data loss: 0.016857216134667397\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0611, 0.2945, 0.4831, 0.1612], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011575046838591474\n","\t\tAfter adaption: Boundary condition loss: 0.00013770612129132784\n","\t\tAfter adaption: PDE loss: 0.01564095467620332\n","\t\tAfter adaption: Data loss: 0.002717964868921907\n","\n","\tTesting: Initial condition loss: 0.03244688734412193\n","\tTesting: Boundary condition loss: 0.0025367019698023796\n","\tTesting: PDE loss: 0.03178269788622856\n","\tTesting: Data loss: 0.016132095828652382\n","\n","Epoch 39\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.040348149836063385\n","\tBefore adaption: Boundary condition loss: 0.0024757336359471083\n","\tBefore adaption: PDE loss: 0.031340181827545166\n","\tBefore adaption: Data loss: 0.01640421710908413\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0455, 0.3435, 0.4397, 0.1713], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013858326901854654\n","\t\tAfter adaption: Boundary condition loss: 0.00011268117848722191\n","\t\tAfter adaption: PDE loss: 0.01378065902282559\n","\t\tAfter adaption: Data loss: 0.0028101204501818438\n","\n","\tTesting: Initial condition loss: 0.029694365337491035\n","\tTesting: Boundary condition loss: 0.003403137903660536\n","\tTesting: PDE loss: 0.03190149366855621\n","\tTesting: Data loss: 0.014420716091990471\n","\n","Epoch 40\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.037562593817710876\n","\tBefore adaption: Boundary condition loss: 0.0033158469013869762\n","\tBefore adaption: PDE loss: 0.0313819944858551\n","\tBefore adaption: Data loss: 0.014668949879705906\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0353, 0.3849, 0.4021, 0.1777], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014457494845123733\n","\t\tAfter adaption: Boundary condition loss: 0.00011700433399218626\n","\t\tAfter adaption: PDE loss: 0.012619266807269679\n","\t\tAfter adaption: Data loss: 0.002606740823620349\n","\n","\tTesting: Initial condition loss: 0.02424103207886219\n","\tTesting: Boundary condition loss: 0.005232451483607292\n","\tTesting: PDE loss: 0.03295324742794037\n","\tTesting: Data loss: 0.011798109859228134\n","\n","Epoch 41\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03190921992063522\n","\tBefore adaption: Boundary condition loss: 0.0050589339807629585\n","\tBefore adaption: PDE loss: 0.032406505197286606\n","\tBefore adaption: Data loss: 0.0120107876136899\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0317, 0.4120, 0.3774, 0.1789], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0131481918932484\n","\t\tAfter adaption: Boundary condition loss: 0.000160153332597882\n","\t\tAfter adaption: PDE loss: 0.012231380778064025\n","\t\tAfter adaption: Data loss: 0.002148206923975124\n","\n","\tTesting: Initial condition loss: 0.018185051158070564\n","\tTesting: Boundary condition loss: 0.00843878649175167\n","\tTesting: PDE loss: 0.03480347990989685\n","\tTesting: Data loss: 0.009005275554955006\n","\n","Epoch 42\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025412464514374733\n","\tBefore adaption: Boundary condition loss: 0.00808619149029255\n","\tBefore adaption: PDE loss: 0.034213267266750336\n","\tBefore adaption: Data loss: 0.009177500382065773\n","tensor(0.0081, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0081, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0357, 0.4209, 0.3695, 0.1738], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010696629767449927\n","\t\tAfter adaption: Boundary condition loss: 0.00028890003956286316\n","\t\tAfter adaption: PDE loss: 0.012643045114129975\n","\t\tAfter adaption: Data loss: 0.001595190738229991\n","\n","\tTesting: Initial condition loss: 0.013761413283646107\n","\tTesting: Boundary condition loss: 0.013146471232175827\n","\tTesting: PDE loss: 0.037143509835004807\n","\tTesting: Data loss: 0.006825590971857309\n","\n","Epoch 43\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020286498591303825\n","\tBefore adaption: Boundary condition loss: 0.012505985796451569\n","\tBefore adaption: PDE loss: 0.03654659166932106\n","\tBefore adaption: Data loss: 0.006954743526875973\n","tensor(0.0125, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0125, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0497, 0.4093, 0.3790, 0.1620], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008302762016535792\n","\t\tAfter adaption: Boundary condition loss: 0.0006211671046765204\n","\t\tAfter adaption: PDE loss: 0.013852117759146639\n","\t\tAfter adaption: Data loss: 0.00112686863114382\n","\n","\tTesting: Initial condition loss: 0.011941066011786461\n","\tTesting: Boundary condition loss: 0.018721647560596466\n","\tTesting: PDE loss: 0.03952302411198616\n","\tTesting: Data loss: 0.0056860316544771194\n","\n","Epoch 44\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.017681241035461426\n","\tBefore adaption: Boundary condition loss: 0.017714763060212135\n","\tBefore adaption: PDE loss: 0.03894481807947159\n","\tBefore adaption: Data loss: 0.00577525096014142\n","tensor(0.0177, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0177, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0763, 0.3774, 0.4026, 0.1437], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006673021095168833\n","\t\tAfter adaption: Boundary condition loss: 0.0013518807835053198\n","\t\tAfter adaption: PDE loss: 0.01567841755231461\n","\t\tAfter adaption: Data loss: 0.0008298973863203744\n","\n","\tTesting: Initial condition loss: 0.012163094244897366\n","\tTesting: Boundary condition loss: 0.023812590166926384\n","\tTesting: PDE loss: 0.04144570976495743\n","\tTesting: Data loss: 0.00543241947889328\n","\n","Epoch 45\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01715986803174019\n","\tBefore adaption: Boundary condition loss: 0.022397194057703018\n","\tBefore adaption: PDE loss: 0.04082782566547394\n","\tBefore adaption: Data loss: 0.005487879738211632\n","tensor(0.0224, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0224, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1163, 0.3307, 0.4321, 0.1210], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005674713496321561\n","\t\tAfter adaption: Boundary condition loss: 0.0026040124357887646\n","\t\tAfter adaption: PDE loss: 0.017640469060199466\n","\t\tAfter adaption: Data loss: 0.0006638588675618351\n","\n","\tTesting: Initial condition loss: 0.012651653029024601\n","\tTesting: Boundary condition loss: 0.026660649105906487\n","\tTesting: PDE loss: 0.04236842319369316\n","\tTesting: Data loss: 0.005512239411473274\n","\n","Epoch 46\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01725326105952263\n","\tBefore adaption: Boundary condition loss: 0.024919405579566956\n","\tBefore adaption: PDE loss: 0.04169861599802971\n","\tBefore adaption: Data loss: 0.005544860847294331\n","tensor(0.0249, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0249, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1642, 0.2806, 0.4568, 0.0984], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004840949029695476\n","\t\tAfter adaption: Boundary condition loss: 0.0040926118151736164\n","\t\tAfter adaption: PDE loss: 0.019048915556704696\n","\t\tAfter adaption: Data loss: 0.0005453957148768893\n","\n","\tTesting: Initial condition loss: 0.012237558141350746\n","\tTesting: Boundary condition loss: 0.02619944140315056\n","\tTesting: PDE loss: 0.04205557703971863\n","\tTesting: Data loss: 0.005455575883388519\n","\n","Epoch 47\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016744118183851242\n","\tBefore adaption: Boundary condition loss: 0.02437608875334263\n","\tBefore adaption: PDE loss: 0.04142284020781517\n","\tBefore adaption: Data loss: 0.0054793632589280605\n","tensor(0.0244, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0244, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2096, 0.2392, 0.4706, 0.0806], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004005085718226861\n","\t\tAfter adaption: Boundary condition loss: 0.005110096833021932\n","\t\tAfter adaption: PDE loss: 0.019492470662619076\n","\t\tAfter adaption: Data loss: 0.00044162376281552975\n","\n","\tTesting: Initial condition loss: 0.011039300821721554\n","\tTesting: Boundary condition loss: 0.022422950714826584\n","\tTesting: PDE loss: 0.040666867047548294\n","\tTesting: Data loss: 0.005157519597560167\n","\n","Epoch 48\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015682894736528397\n","\tBefore adaption: Boundary condition loss: 0.02077271230518818\n","\tBefore adaption: PDE loss: 0.040054742246866226\n","\tBefore adaption: Data loss: 0.005190735217183828\n","tensor(0.0208, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0208, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2429, 0.2122, 0.4752, 0.0696], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003328334954534924\n","\t\tAfter adaption: Boundary condition loss: 0.005045618790909548\n","\t\tAfter adaption: PDE loss: 0.019035120805853536\n","\t\tAfter adaption: Data loss: 0.00036152781495317807\n","\n","\tTesting: Initial condition loss: 0.010287385433912277\n","\tTesting: Boundary condition loss: 0.016644764691591263\n","\tTesting: PDE loss: 0.03843330591917038\n","\tTesting: Data loss: 0.004990681074559689\n","\n","Epoch 49\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015222412534058094\n","\tBefore adaption: Boundary condition loss: 0.015322553925216198\n","\tBefore adaption: PDE loss: 0.03778690844774246\n","\tBefore adaption: Data loss: 0.005050763953477144\n","tensor(0.0153, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0153, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2593, 0.1987, 0.4774, 0.0646], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003025319577826737\n","\t\tAfter adaption: Boundary condition loss: 0.003972376605168167\n","\t\tAfter adaption: PDE loss: 0.01803916033548624\n","\t\tAfter adaption: Data loss: 0.0003263634413221659\n","\n","\tTesting: Initial condition loss: 0.01160826999694109\n","\tTesting: Boundary condition loss: 0.010618530213832855\n","\tTesting: PDE loss: 0.0355917252600193\n","\tTesting: Data loss: 0.005502369254827499\n","\n","Epoch 50\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01682601310312748\n","\tBefore adaption: Boundary condition loss: 0.00971168838441372\n","\tBefore adaption: PDE loss: 0.03492401912808418\n","\tBefore adaption: Data loss: 0.005599476397037506\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2577, 0.1961, 0.4823, 0.0639], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0032996859635164915\n","\t\tAfter adaption: Boundary condition loss: 0.002502467581211088\n","\t\tAfter adaption: PDE loss: 0.016843343027202706\n","\t\tAfter adaption: Data loss: 0.0003579882072499706\n","\n","\tTesting: Initial condition loss: 0.016058938577771187\n","\tTesting: Boundary condition loss: 0.005712525919079781\n","\tTesting: PDE loss: 0.03239310160279274\n","\tTesting: Data loss: 0.006996395997703075\n","\n","Epoch 51\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021448420360684395\n","\tBefore adaption: Boundary condition loss: 0.005168005358427763\n","\tBefore adaption: PDE loss: 0.031805168837308884\n","\tBefore adaption: Data loss: 0.0071360282599925995\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2380, 0.2045, 0.4902, 0.0672], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004386769815919617\n","\t\tAfter adaption: Boundary condition loss: 0.0012301034186727995\n","\t\tAfter adaption: PDE loss: 0.015591526239712368\n","\t\tAfter adaption: Data loss: 0.000479759840755155\n","\n","\tTesting: Initial condition loss: 0.02341417595744133\n","\tTesting: Boundary condition loss: 0.002652868628501892\n","\tTesting: PDE loss: 0.029267434030771255\n","\tTesting: Data loss: 0.009321107529103756\n","\n","Epoch 52\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028843741863965988\n","\tBefore adaption: Boundary condition loss: 0.002365137916058302\n","\tBefore adaption: PDE loss: 0.028758756816387177\n","\tBefore adaption: Data loss: 0.009502888657152653\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2005, 0.2287, 0.4950, 0.0757], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006596382691583764\n","\t\tAfter adaption: Boundary condition loss: 0.0004742765798899561\n","\t\tAfter adaption: PDE loss: 0.01423657010058456\n","\t\tAfter adaption: Data loss: 0.0007197848163917866\n","\n","\tTesting: Initial condition loss: 0.03191915154457092\n","\tTesting: Boundary condition loss: 0.0012129222741350532\n","\tTesting: PDE loss: 0.026635626330971718\n","\tTesting: Data loss: 0.011820103041827679\n","\n","Epoch 53\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03711001202464104\n","\tBefore adaption: Boundary condition loss: 0.001066953525878489\n","\tBefore adaption: PDE loss: 0.02615533396601677\n","\tBefore adaption: Data loss: 0.012036554515361786\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1493, 0.2745, 0.4853, 0.0910], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010185593219846696\n","\t\tAfter adaption: Boundary condition loss: 0.00015929164030002428\n","\t\tAfter adaption: PDE loss: 0.01269274450453223\n","\t\tAfter adaption: Data loss: 0.0010947326120749922\n","\n","\tTesting: Initial condition loss: 0.03808697685599327\n","\tTesting: Boundary condition loss: 0.0007092314190231264\n","\tTesting: PDE loss: 0.024903811514377594\n","\tTesting: Data loss: 0.013496220111846924\n","\n","Epoch 54\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.042943574488162994\n","\tBefore adaption: Boundary condition loss: 0.0006163772777654231\n","\tBefore adaption: PDE loss: 0.024480251595377922\n","\tBefore adaption: Data loss: 0.013731767423450947\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0956, 0.3396, 0.4531, 0.1118], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014582343838911622\n","\t\tAfter adaption: Boundary condition loss: 5.889854846508647e-05\n","\t\tAfter adaption: PDE loss: 0.011091600441935665\n","\t\tAfter adaption: Data loss: 0.0015350796753733913\n","\n","\tTesting: Initial condition loss: 0.03838840499520302\n","\tTesting: Boundary condition loss: 0.0006087513756938279\n","\tTesting: PDE loss: 0.024513551965355873\n","\tTesting: Data loss: 0.01347919087857008\n","\n","Epoch 55\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.04300117865204811\n","\tBefore adaption: Boundary condition loss: 0.0005166713381186128\n","\tBefore adaption: PDE loss: 0.024124575778841972\n","\tBefore adaption: Data loss: 0.013708444312214851\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0525, 0.4087, 0.4055, 0.1333], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.017573612233792016\n","\t\tAfter adaption: Boundary condition loss: 2.7134186892482062e-05\n","\t\tAfter adaption: PDE loss: 0.009783063647739565\n","\t\tAfter adaption: Data loss: 0.0018270940555307922\n","\n","\tTesting: Initial condition loss: 0.032009612768888474\n","\tTesting: Boundary condition loss: 0.0008642326574772596\n","\tTesting: PDE loss: 0.02567063830792904\n","\tTesting: Data loss: 0.011643236503005028\n","\n","Epoch 56\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03648998588323593\n","\tBefore adaption: Boundary condition loss: 0.0007242689025588334\n","\tBefore adaption: PDE loss: 0.02526184171438217\n","\tBefore adaption: Data loss: 0.011836751364171505\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0260, 0.4630, 0.3612, 0.1498], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.016896316257642437\n","\t\tAfter adaption: Boundary condition loss: 1.8811987029967046e-05\n","\t\tAfter adaption: PDE loss: 0.00912333354010285\n","\t\tAfter adaption: Data loss: 0.0017735658463539823\n","\n","\tTesting: Initial condition loss: 0.021831797435879707\n","\tTesting: Boundary condition loss: 0.00212349952198565\n","\tTesting: PDE loss: 0.028255801647901535\n","\tTesting: Data loss: 0.00883200392127037\n","\n","Epoch 57\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026250997558236122\n","\tBefore adaption: Boundary condition loss: 0.0018398563843220472\n","\tBefore adaption: PDE loss: 0.027817968279123306\n","\tBefore adaption: Data loss: 0.00896226242184639\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0138, 0.4917, 0.3358, 0.1587], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0129088167462998\n","\t\tAfter adaption: Boundary condition loss: 2.5377841478130365e-05\n","\t\tAfter adaption: PDE loss: 0.00934118025527036\n","\t\tAfter adaption: Data loss: 0.001421989198651872\n","\n","\tTesting: Initial condition loss: 0.012854517437517643\n","\tTesting: Boundary condition loss: 0.005361933261156082\n","\tTesting: PDE loss: 0.031928788870573044\n","\tTesting: Data loss: 0.00635007256641984\n","\n","Epoch 58\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016881408169865608\n","\tBefore adaption: Boundary condition loss: 0.004758712835609913\n","\tBefore adaption: PDE loss: 0.03144649416208267\n","\tBefore adaption: Data loss: 0.00639842264354229\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0126, 0.4909, 0.3374, 0.1592], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008286310742695575\n","\t\tAfter adaption: Boundary condition loss: 5.984487685540041e-05\n","\t\tAfter adaption: PDE loss: 0.010610397497179241\n","\t\tAfter adaption: Data loss: 0.0010183642107888817\n","\n","\tTesting: Initial condition loss: 0.00843123160302639\n","\tTesting: Boundary condition loss: 0.010866331867873669\n","\tTesting: PDE loss: 0.036055516451597214\n","\tTesting: Data loss: 0.0051385206170380116\n","\n","Epoch 59\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011997277848422527\n","\tBefore adaption: Boundary condition loss: 0.009767202660441399\n","\tBefore adaption: PDE loss: 0.03558644279837608\n","\tBefore adaption: Data loss: 0.005105087533593178\n","tensor(0.0098, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0098, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0234, 0.4577, 0.3679, 0.1510], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0054915988849735175\n","\t\tAfter adaption: Boundary condition loss: 0.00022824358310561703\n","\t\tAfter adaption: PDE loss: 0.013091606973116753\n","\t\tAfter adaption: Data loss: 0.0007709322969937249\n","\n","\tTesting: Initial condition loss: 0.00872628204524517\n","\tTesting: Boundary condition loss: 0.0174275953322649\n","\tTesting: PDE loss: 0.039907850325107574\n","\tTesting: Data loss: 0.005182311404496431\n","\n","Epoch 60\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011849644593894482\n","\tBefore adaption: Boundary condition loss: 0.01577427238225937\n","\tBefore adaption: PDE loss: 0.03937673941254616\n","\tBefore adaption: Data loss: 0.005084309261292219\n","tensor(0.0158, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0158, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0514, 0.3930, 0.4212, 0.1344], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004657037838195836\n","\t\tAfter adaption: Boundary condition loss: 0.0008110604850936783\n","\t\tAfter adaption: PDE loss: 0.016586318999639693\n","\t\tAfter adaption: Data loss: 0.0006830829881656344\n","\n","\tTesting: Initial condition loss: 0.011030558496713638\n","\tTesting: Boundary condition loss: 0.022565161809325218\n","\tTesting: PDE loss: 0.04254711791872978\n","\tTesting: Data loss: 0.005645297467708588\n","\n","Epoch 61\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013765253126621246\n","\tBefore adaption: Boundary condition loss: 0.02049083448946476\n","\tBefore adaption: PDE loss: 0.04197681322693825\n","\tBefore adaption: Data loss: 0.005510753486305475\n","tensor(0.0205, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0205, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0987, 0.3103, 0.4788, 0.1122], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00427158417890548\n","\t\tAfter adaption: Boundary condition loss: 0.002021531129506852\n","\t\tAfter adaption: PDE loss: 0.020099822500137532\n","\t\tAfter adaption: Data loss: 0.0006182871971250861\n","\n","\tTesting: Initial condition loss: 0.012234839610755444\n","\tTesting: Boundary condition loss: 0.024280231446027756\n","\tTesting: PDE loss: 0.043444544076919556\n","\tTesting: Data loss: 0.005645067896693945\n","\n","Epoch 62\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014744088053703308\n","\tBefore adaption: Boundary condition loss: 0.02205030433833599\n","\tBefore adaption: PDE loss: 0.04289725050330162\n","\tBefore adaption: Data loss: 0.005504647269845009\n","tensor(0.0221, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0221, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1545, 0.2368, 0.5175, 0.0912], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0034914612297230435\n","\t\tAfter adaption: Boundary condition loss: 0.003407836330001702\n","\t\tAfter adaption: PDE loss: 0.022198573794075922\n","\t\tAfter adaption: Data loss: 0.0005018311572102914\n","\n","\tTesting: Initial condition loss: 0.011056159622967243\n","\tTesting: Boundary condition loss: 0.022054921835660934\n","\tTesting: PDE loss: 0.04262891411781311\n","\tTesting: Data loss: 0.004883607383817434\n","\n","Epoch 63\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013574687764048576\n","\tBefore adaption: Boundary condition loss: 0.019985707476735115\n","\tBefore adaption: PDE loss: 0.042120613157749176\n","\tBefore adaption: Data loss: 0.004765734076499939\n","tensor(0.0200, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0200, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2018, 0.1916, 0.5301, 0.0764], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0026014024697663726\n","\t\tAfter adaption: Boundary condition loss: 0.004034045705861604\n","\t\tAfter adaption: PDE loss: 0.022326953981761165\n","\t\tAfter adaption: Data loss: 0.0003643172707007765\n","\n","\tTesting: Initial condition loss: 0.008470472879707813\n","\tTesting: Boundary condition loss: 0.016905637457966805\n","\tTesting: PDE loss: 0.04045558348298073\n","\tTesting: Data loss: 0.003763624234125018\n","\n","Epoch 64\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011146869510412216\n","\tBefore adaption: Boundary condition loss: 0.015262053348124027\n","\tBefore adaption: PDE loss: 0.03996128961443901\n","\tBefore adaption: Data loss: 0.003687294665724039\n","tensor(0.0153, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0153, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2307, 0.1725, 0.5288, 0.0680], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019231694378720615\n","\t\tAfter adaption: Boundary condition loss: 0.0035202115003699925\n","\t\tAfter adaption: PDE loss: 0.021133327458967777\n","\t\tAfter adaption: Data loss: 0.00025063886219073387\n","\n","\tTesting: Initial condition loss: 0.006757829803973436\n","\tTesting: Boundary condition loss: 0.010802273638546467\n","\tTesting: PDE loss: 0.03728194907307625\n","\tTesting: Data loss: 0.003050114493817091\n","\n","Epoch 65\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009603112004697323\n","\tBefore adaption: Boundary condition loss: 0.009691772982478142\n","\tBefore adaption: PDE loss: 0.03681834414601326\n","\tBefore adaption: Data loss: 0.0030259094201028347\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2403, 0.1670, 0.5297, 0.0630], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016041218723233577\n","\t\tAfter adaption: Boundary condition loss: 0.002328467822034493\n","\t\tAfter adaption: PDE loss: 0.01950243600430992\n","\t\tAfter adaption: Data loss: 0.0001906702308423157\n","\n","\tTesting: Initial condition loss: 0.008162951096892357\n","\tTesting: Boundary condition loss: 0.005548633169382811\n","\tTesting: PDE loss: 0.03358124569058418\n","\tTesting: Data loss: 0.0034044557251036167\n","\n","Epoch 66\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01105572935193777\n","\tBefore adaption: Boundary condition loss: 0.004941635299474001\n","\tBefore adaption: PDE loss: 0.033122818917036057\n","\tBefore adaption: Data loss: 0.0034370236098766327\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2323, 0.1669, 0.5411, 0.0597], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018446543782800375\n","\t\tAfter adaption: Boundary condition loss: 0.001148096515753105\n","\t\tAfter adaption: PDE loss: 0.017922622997993395\n","\t\tAfter adaption: Data loss: 0.00020526624381293337\n","\n","\tTesting: Initial condition loss: 0.013803801499307156\n","\tTesting: Boundary condition loss: 0.0021785174030810595\n","\tTesting: PDE loss: 0.029752997681498528\n","\tTesting: Data loss: 0.005049495492130518\n","\n","Epoch 67\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01660613901913166\n","\tBefore adaption: Boundary condition loss: 0.0019402143079787493\n","\tBefore adaption: PDE loss: 0.029332255944609642\n","\tBefore adaption: Data loss: 0.005138292443007231\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2071, 0.1731, 0.5611, 0.0588], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00287409574267428\n","\t\tAfter adaption: Boundary condition loss: 0.00040173328609585635\n","\t\tAfter adaption: PDE loss: 0.016458019705208264\n","\t\tAfter adaption: Data loss: 0.0003020286367442349\n","\n","\tTesting: Initial condition loss: 0.023476630449295044\n","\tTesting: Boundary condition loss: 0.0007831922266632318\n","\tTesting: PDE loss: 0.026162821799516678\n","\tTesting: Data loss: 0.007683863863348961\n","\n","Epoch 68\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0259054247289896\n","\tBefore adaption: Boundary condition loss: 0.0007229045149870217\n","\tBefore adaption: PDE loss: 0.02576424367725849\n","\tBefore adaption: Data loss: 0.007824990898370743\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1644, 0.1966, 0.5754, 0.0636], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005094215102320708\n","\t\tAfter adaption: Boundary condition loss: 0.00011882492803763265\n","\t\tAfter adaption: PDE loss: 0.014823593607447285\n","\t\tAfter adaption: Data loss: 0.0004978757551100724\n","\n","\tTesting: Initial condition loss: 0.034980498254299164\n","\tTesting: Boundary condition loss: 0.0006665315013378859\n","\tTesting: PDE loss: 0.023069966584444046\n","\tTesting: Data loss: 0.010558304376900196\n","\n","Epoch 69\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.036772020161151886\n","\tBefore adaption: Boundary condition loss: 0.0006437319680117071\n","\tBefore adaption: PDE loss: 0.02275092341005802\n","\tBefore adaption: Data loss: 0.010740622878074646\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1103, 0.2519, 0.5593, 0.0784], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009264496889631406\n","\t\tAfter adaption: Boundary condition loss: 7.103115913154556e-05\n","\t\tAfter adaption: PDE loss: 0.012725616846399303\n","\t\tAfter adaption: Data loss: 0.0008417191310178962\n","\n","\tTesting: Initial condition loss: 0.04402006044983864\n","\tTesting: Boundary condition loss: 0.0008910716860555112\n","\tTesting: PDE loss: 0.02091502584517002\n","\tTesting: Data loss: 0.012595042586326599\n","\n","Epoch 70\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.045301929116249084\n","\tBefore adaption: Boundary condition loss: 0.0008495936053805053\n","\tBefore adaption: PDE loss: 0.0206284336745739\n","\tBefore adaption: Data loss: 0.012799825519323349\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0606, 0.3379, 0.4995, 0.1020], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015307253921102338\n","\t\tAfter adaption: Boundary condition loss: 5.15045200849894e-05\n","\t\tAfter adaption: PDE loss: 0.010303741579004329\n","\t\tAfter adaption: Data loss: 0.0013054671916841324\n","\n","\tTesting: Initial condition loss: 0.045560453087091446\n","\tTesting: Boundary condition loss: 0.0007696402608416975\n","\tTesting: PDE loss: 0.020053720101714134\n","\tTesting: Data loss: 0.012712033465504646\n","\n","Epoch 71\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.04676973074674606\n","\tBefore adaption: Boundary condition loss: 0.0007142368704080582\n","\tBefore adaption: PDE loss: 0.01979084312915802\n","\tBefore adaption: Data loss: 0.01290777139365673\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0288, 0.4290, 0.4159, 0.1263], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.020064957045740853\n","\t\tAfter adaption: Boundary condition loss: 2.0537644724195587e-05\n","\t\tAfter adaption: PDE loss: 0.008231632545243815\n","\t\tAfter adaption: Data loss: 0.0016302247258445915\n","\n","\tTesting: Initial condition loss: 0.03761131316423416\n","\tTesting: Boundary condition loss: 0.0004013066354673356\n","\tTesting: PDE loss: 0.020720910280942917\n","\tTesting: Data loss: 0.010718334466218948\n","\n","Epoch 72\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03923118859529495\n","\tBefore adaption: Boundary condition loss: 0.00034765113377943635\n","\tBefore adaption: PDE loss: 0.020486924797296524\n","\tBefore adaption: Data loss: 0.010865914635360241\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0142, 0.4985, 0.3437, 0.1437], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.019556741639870093\n","\t\tAfter adaption: Boundary condition loss: 4.921374173401837e-06\n","\t\tAfter adaption: PDE loss: 0.007040798408913687\n","\t\tAfter adaption: Data loss: 0.001561118480578811\n","\n","\tTesting: Initial condition loss: 0.02405998669564724\n","\tTesting: Boundary condition loss: 0.0010660062544047832\n","\tTesting: PDE loss: 0.022940702736377716\n","\tTesting: Data loss: 0.007888488471508026\n","\n","Epoch 73\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026269232854247093\n","\tBefore adaption: Boundary condition loss: 0.0009883345337584615\n","\tBefore adaption: PDE loss: 0.022689878940582275\n","\tBefore adaption: Data loss: 0.007952284999191761\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0091, 0.5364, 0.3022, 0.1524], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014090797259186154\n","\t\tAfter adaption: Boundary condition loss: 8.949697628536408e-06\n","\t\tAfter adaption: PDE loss: 0.006856427335272624\n","\t\tAfter adaption: Data loss: 0.0012116520865713732\n","\n","\tTesting: Initial condition loss: 0.011997797526419163\n","\tTesting: Boundary condition loss: 0.004800653550773859\n","\tTesting: PDE loss: 0.026416856795549393\n","\tTesting: Data loss: 0.006200963631272316\n","\n","Epoch 74\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014641811139881611\n","\tBefore adaption: Boundary condition loss: 0.004546293523162603\n","\tBefore adaption: PDE loss: 0.026095334440469742\n","\tBefore adaption: Data loss: 0.0061570219695568085\n","tensor(0.0045, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0045, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0099, 0.5409, 0.2956, 0.1537], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007919215360739593\n","\t\tAfter adaption: Boundary condition loss: 4.479007574480769e-05\n","\t\tAfter adaption: PDE loss: 0.007713561395671762\n","\t\tAfter adaption: Data loss: 0.0009462922419696192\n","\n","\tTesting: Initial condition loss: 0.006702057551592588\n","\tTesting: Boundary condition loss: 0.01257028803229332\n","\tTesting: PDE loss: 0.03050808422267437\n","\tTesting: Data loss: 0.006867306772619486\n","\n","Epoch 75\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00938035361468792\n","\tBefore adaption: Boundary condition loss: 0.011951552703976631\n","\tBefore adaption: PDE loss: 0.03018340840935707\n","\tBefore adaption: Data loss: 0.0067126015201210976\n","tensor(0.0120, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0120, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0219, 0.5066, 0.3224, 0.1490], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004752404014950678\n","\t\tAfter adaption: Boundary condition loss: 0.00026164521666095444\n","\t\tAfter adaption: PDE loss: 0.00973247190332096\n","\t\tAfter adaption: Data loss: 0.001000375582418463\n","\n","\tTesting: Initial condition loss: 0.00821725931018591\n","\tTesting: Boundary condition loss: 0.022353941574692726\n","\tTesting: PDE loss: 0.034326933324337006\n","\tTesting: Data loss: 0.009326907806098461\n","\n","Epoch 76\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01058497466146946\n","\tBefore adaption: Boundary condition loss: 0.021291527897119522\n","\tBefore adaption: PDE loss: 0.03398885950446129\n","\tBefore adaption: Data loss: 0.009085915982723236\n","tensor(0.0213, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0213, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0582, 0.4276, 0.3742, 0.1399], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004526433011458711\n","\t\tAfter adaption: Boundary condition loss: 0.0012393499470413928\n","\t\tAfter adaption: PDE loss: 0.012719358587849738\n","\t\tAfter adaption: Data loss: 0.001271498605387841\n","\n","\tTesting: Initial condition loss: 0.012254064902663231\n","\tTesting: Boundary condition loss: 0.030010215938091278\n","\tTesting: PDE loss: 0.037023257464170456\n","\tTesting: Data loss: 0.01166092325001955\n","\n","Epoch 77\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014235803857445717\n","\tBefore adaption: Boundary condition loss: 0.02857532538473606\n","\tBefore adaption: PDE loss: 0.03668086230754852\n","\tBefore adaption: Data loss: 0.011377006769180298\n","tensor(0.0286, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0286, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1249, 0.3191, 0.4259, 0.1301], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004543048794728677\n","\t\tAfter adaption: Boundary condition loss: 0.0035679796357681506\n","\t\tAfter adaption: PDE loss: 0.015623228577222512\n","\t\tAfter adaption: Data loss: 0.001479990038075703\n","\n","\tTesting: Initial condition loss: 0.01428334042429924\n","\tTesting: Boundary condition loss: 0.03201114758849144\n","\tTesting: PDE loss: 0.03810404986143112\n","\tTesting: Data loss: 0.012050768360495567\n","\n","Epoch 78\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016064215451478958\n","\tBefore adaption: Boundary condition loss: 0.030419420450925827\n","\tBefore adaption: PDE loss: 0.037756599485874176\n","\tBefore adaption: Data loss: 0.011773708276450634\n","tensor(0.0304, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0304, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2021, 0.2250, 0.4490, 0.1238], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0036149782862791463\n","\t\tAfter adaption: Boundary condition loss: 0.006147617923511461\n","\t\tAfter adaption: PDE loss: 0.01695454996797052\n","\t\tAfter adaption: Data loss: 0.0014578564872262784\n","\n","\tTesting: Initial condition loss: 0.012586301192641258\n","\tTesting: Boundary condition loss: 0.027596302330493927\n","\tTesting: PDE loss: 0.03758992254734039\n","\tTesting: Data loss: 0.010030309669673443\n","\n","Epoch 79\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014397397637367249\n","\tBefore adaption: Boundary condition loss: 0.02614164538681507\n","\tBefore adaption: PDE loss: 0.03728632628917694\n","\tBefore adaption: Data loss: 0.009802157990634441\n","tensor(0.0261, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0261, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2606, 0.1745, 0.4435, 0.1214], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0025126909953906073\n","\t\tAfter adaption: Boundary condition loss: 0.006813012043960184\n","\t\tAfter adaption: PDE loss: 0.01653527967521272\n","\t\tAfter adaption: Data loss: 0.001189875551296019\n","\n","\tTesting: Initial condition loss: 0.008573781698942184\n","\tTesting: Boundary condition loss: 0.019115695729851723\n","\tTesting: PDE loss: 0.03581903129816055\n","\tTesting: Data loss: 0.006672916933894157\n","\n","Epoch 80\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010619739070534706\n","\tBefore adaption: Boundary condition loss: 0.018016183748841286\n","\tBefore adaption: PDE loss: 0.0355667807161808\n","\tBefore adaption: Data loss: 0.0065173739567399025\n","tensor(0.0180, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0180, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2905, 0.1585, 0.4314, 0.1195], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016833337310411403\n","\t\tAfter adaption: Boundary condition loss: 0.005233644461178629\n","\t\tAfter adaption: PDE loss: 0.015345096528934371\n","\t\tAfter adaption: Data loss: 0.0007791423553329134\n","\n","\tTesting: Initial condition loss: 0.005555423442274332\n","\tTesting: Boundary condition loss: 0.010298405773937702\n","\tTesting: PDE loss: 0.03310356289148331\n","\tTesting: Data loss: 0.003782121231779456\n","\n","Epoch 81\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007780719548463821\n","\tBefore adaption: Boundary condition loss: 0.00963335856795311\n","\tBefore adaption: PDE loss: 0.032888151705265045\n","\tBefore adaption: Data loss: 0.0037064766511321068\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2963, 0.1568, 0.4314, 0.1155], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012201290427979478\n","\t\tAfter adaption: Boundary condition loss: 0.0028542391226104935\n","\t\tAfter adaption: PDE loss: 0.014186800027287259\n","\t\tAfter adaption: Data loss: 0.00042822170629201094\n","\n","\tTesting: Initial condition loss: 0.0067425440065562725\n","\tTesting: Boundary condition loss: 0.004115986172109842\n","\tTesting: PDE loss: 0.029999246820807457\n","\tTesting: Data loss: 0.0028006539214402437\n","\n","Epoch 82\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008858198300004005\n","\tBefore adaption: Boundary condition loss: 0.003837107215076685\n","\tBefore adaption: PDE loss: 0.029878562316298485\n","\tBefore adaption: Data loss: 0.0027991831302642822\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2826, 0.1581, 0.4513, 0.1081], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014000623849397618\n","\t\tAfter adaption: Boundary condition loss: 0.0010842277478525309\n","\t\tAfter adaption: PDE loss: 0.013482730005377882\n","\t\tAfter adaption: Data loss: 0.00030268224140465855\n","\n","\tTesting: Initial condition loss: 0.01328613143414259\n","\tTesting: Boundary condition loss: 0.0014713159762322903\n","\tTesting: PDE loss: 0.026929115876555443\n","\tTesting: Data loss: 0.004047858063131571\n","\n","Epoch 83\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015006001107394695\n","\tBefore adaption: Boundary condition loss: 0.0014471282484009862\n","\tBefore adaption: PDE loss: 0.026835061609745026\n","\tBefore adaption: Data loss: 0.004106414038687944\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2489, 0.1632, 0.4901, 0.0978], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002448668874848547\n","\t\tAfter adaption: Boundary condition loss: 0.0003601648195048176\n","\t\tAfter adaption: PDE loss: 0.013152798906148717\n","\t\tAfter adaption: Data loss: 0.00040162065307088615\n","\n","\tTesting: Initial condition loss: 0.024059580639004707\n","\tTesting: Boundary condition loss: 0.0014279504539445043\n","\tTesting: PDE loss: 0.02399958111345768\n","\tTesting: Data loss: 0.006781318224966526\n","\n","Epoch 84\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02518395520746708\n","\tBefore adaption: Boundary condition loss: 0.0014994903467595577\n","\tBefore adaption: PDE loss: 0.023949889466166496\n","\tBefore adaption: Data loss: 0.0068881819024682045\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1935, 0.1857, 0.5325, 0.0883], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004676581035686729\n","\t\tAfter adaption: Boundary condition loss: 0.00029020177980961556\n","\t\tAfter adaption: PDE loss: 0.012753482764964142\n","\t\tAfter adaption: Data loss: 0.0006079676292593104\n","\n","\tTesting: Initial condition loss: 0.0358901172876358\n","\tTesting: Boundary condition loss: 0.002387263113632798\n","\tTesting: PDE loss: 0.021496038883924484\n","\tTesting: Data loss: 0.009770520031452179\n","\n","Epoch 85\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03644870966672897\n","\tBefore adaption: Boundary condition loss: 0.0024608909152448177\n","\tBefore adaption: PDE loss: 0.021458009257912636\n","\tBefore adaption: Data loss: 0.009914728812873363\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1251, 0.2452, 0.5423, 0.0873], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0089389220437693\n","\t\tAfter adaption: Boundary condition loss: 0.00030794949432195117\n","\t\tAfter adaption: PDE loss: 0.011636300795115859\n","\t\tAfter adaption: Data loss: 0.0008658871477118238\n","\n","\tTesting: Initial condition loss: 0.04433603584766388\n","\tTesting: Boundary condition loss: 0.0031048471573740244\n","\tTesting: PDE loss: 0.01972651295363903\n","\tTesting: Data loss: 0.011702237650752068\n","\n","Epoch 86\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.044478293508291245\n","\tBefore adaption: Boundary condition loss: 0.003135452512651682\n","\tBefore adaption: PDE loss: 0.01969238370656967\n","\tBefore adaption: Data loss: 0.011870522983372211\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0687, 0.3398, 0.4917, 0.0998], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01511168604828768\n","\t\tAfter adaption: Boundary condition loss: 0.00021546038171298278\n","\t\tAfter adaption: PDE loss: 0.009682350046989037\n","\t\tAfter adaption: Data loss: 0.0011852506362419876\n","\n","\tTesting: Initial condition loss: 0.044745102524757385\n","\tTesting: Boundary condition loss: 0.002782416297122836\n","\tTesting: PDE loss: 0.019098328426480293\n","\tTesting: Data loss: 0.011517133563756943\n","\n","Epoch 87\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.044729821383953094\n","\tBefore adaption: Boundary condition loss: 0.002785144839435816\n","\tBefore adaption: PDE loss: 0.019057173281908035\n","\tBefore adaption: Data loss: 0.011687449179589748\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0413, 0.4338, 0.4063, 0.1187], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.019402051474198476\n","\t\tAfter adaption: Boundary condition loss: 0.00011498109796502588\n","\t\tAfter adaption: PDE loss: 0.007742128800753196\n","\t\tAfter adaption: Data loss: 0.00138726698951367\n","\n","\tTesting: Initial condition loss: 0.035887524485588074\n","\tTesting: Boundary condition loss: 0.0014959785621613264\n","\tTesting: PDE loss: 0.019848819822072983\n","\tTesting: Data loss: 0.009211872704327106\n","\n","Epoch 88\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.036075569689273834\n","\tBefore adaption: Boundary condition loss: 0.0014984834706410766\n","\tBefore adaption: PDE loss: 0.01979297399520874\n","\tBefore adaption: Data loss: 0.009352777153253555\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0340, 0.4988, 0.3335, 0.1337], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01799551727841622\n","\t\tAfter adaption: Boundary condition loss: 5.101000977071649e-05\n","\t\tAfter adaption: PDE loss: 0.006600255986054697\n","\t\tAfter adaption: Data loss: 0.0012501465191701042\n","\n","\tTesting: Initial condition loss: 0.021920055150985718\n","\tTesting: Boundary condition loss: 0.0004681341233663261\n","\tTesting: PDE loss: 0.021996621042490005\n","\tTesting: Data loss: 0.006232492160052061\n","\n","Epoch 89\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02266806736588478\n","\tBefore adaption: Boundary condition loss: 0.00044476360199041665\n","\tBefore adaption: PDE loss: 0.02192489244043827\n","\tBefore adaption: Data loss: 0.006310015916824341\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0323, 0.5314, 0.2951, 0.1412], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012044755691175035\n","\t\tAfter adaption: Boundary condition loss: 1.4373378415142328e-05\n","\t\tAfter adaption: PDE loss: 0.00647033797670585\n","\t\tAfter adaption: Data loss: 0.000891073528638162\n","\n","\tTesting: Initial condition loss: 0.00994026754051447\n","\tTesting: Boundary condition loss: 0.0017279810272157192\n","\tTesting: PDE loss: 0.025327732786536217\n","\tTesting: Data loss: 0.0046609677374362946\n","\n","Epoch 90\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01138256210833788\n","\tBefore adaption: Boundary condition loss: 0.0015810183249413967\n","\tBefore adaption: PDE loss: 0.025160154327750206\n","\tBefore adaption: Data loss: 0.004648418631404638\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0298, 0.5335, 0.2945, 0.1421], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006073122747209798\n","\t\tAfter adaption: Boundary condition loss: 4.718706435971829e-05\n","\t\tAfter adaption: PDE loss: 0.007410823954735863\n","\t\tAfter adaption: Data loss: 0.0006603618652415857\n","\n","\tTesting: Initial condition loss: 0.004799884743988514\n","\tTesting: Boundary condition loss: 0.006553510203957558\n","\tTesting: PDE loss: 0.029201218858361244\n","\tTesting: Data loss: 0.00569630041718483\n","\n","Epoch 91\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006609039846807718\n","\tBefore adaption: Boundary condition loss: 0.006133090239018202\n","\tBefore adaption: PDE loss: 0.02895786426961422\n","\tBefore adaption: Data loss: 0.005584786646068096\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0297, 0.5008, 0.3318, 0.1378], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0033095670179261504\n","\t\tAfter adaption: Boundary condition loss: 0.00018196051487421883\n","\t\tAfter adaption: PDE loss: 0.009606804437524123\n","\t\tAfter adaption: Data loss: 0.0007696751230698072\n","\n","\tTesting: Initial condition loss: 0.00613821716979146\n","\tTesting: Boundary condition loss: 0.013866796158254147\n","\tTesting: PDE loss: 0.032692573964595795\n","\tTesting: Data loss: 0.008786996826529503\n","\n","Epoch 92\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007931098341941833\n","\tBefore adaption: Boundary condition loss: 0.013102455995976925\n","\tBefore adaption: PDE loss: 0.03243418037891388\n","\tBefore adaption: Data loss: 0.008587907068431377\n","tensor(0.0131, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0131, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0435, 0.4241, 0.4012, 0.1312], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003363246729668742\n","\t\tAfter adaption: Boundary condition loss: 0.0005693192250895194\n","\t\tAfter adaption: PDE loss: 0.013014184754315601\n","\t\tAfter adaption: Data loss: 0.0011270879834002483\n","\n","\tTesting: Initial condition loss: 0.009989208541810513\n","\tTesting: Boundary condition loss: 0.02068452537059784\n","\tTesting: PDE loss: 0.035058196634054184\n","\tTesting: Data loss: 0.012191721238195896\n","\n","Epoch 93\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011550876311957836\n","\tBefore adaption: Boundary condition loss: 0.019639097154140472\n","\tBefore adaption: PDE loss: 0.034794606268405914\n","\tBefore adaption: Data loss: 0.011928379535675049\n","tensor(0.0196, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0196, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0843, 0.3131, 0.4750, 0.1276], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0036166785793175686\n","\t\tAfter adaption: Boundary condition loss: 0.001654762213011029\n","\t\tAfter adaption: PDE loss: 0.016527172925022305\n","\t\tAfter adaption: Data loss: 0.0015225416484464683\n","\n","\tTesting: Initial condition loss: 0.012339133769273758\n","\tTesting: Boundary condition loss: 0.024237312376499176\n","\tTesting: PDE loss: 0.035985250025987625\n","\tTesting: Data loss: 0.014220544137060642\n","\n","Epoch 94\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013729785569012165\n","\tBefore adaption: Boundary condition loss: 0.023054733872413635\n","\tBefore adaption: PDE loss: 0.03566691651940346\n","\tBefore adaption: Data loss: 0.013925137929618359\n","tensor(0.0231, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0231, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1454, 0.2135, 0.5094, 0.1317], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002931192360031957\n","\t\tAfter adaption: Boundary condition loss: 0.0033517752414595303\n","\t\tAfter adaption: PDE loss: 0.018169652445433955\n","\t\tAfter adaption: Data loss: 0.0018339268764411237\n","\n","\tTesting: Initial condition loss: 0.01152405422180891\n","\tTesting: Boundary condition loss: 0.02325667068362236\n","\tTesting: PDE loss: 0.03544636070728302\n","\tTesting: Data loss: 0.014004192315042019\n","\n","Epoch 95\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012938978150486946\n","\tBefore adaption: Boundary condition loss: 0.022115204483270645\n","\tBefore adaption: PDE loss: 0.03511933609843254\n","\tBefore adaption: Data loss: 0.01371169276535511\n","tensor(0.0221, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0221, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2008, 0.1617, 0.4964, 0.1412], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020918666567296346\n","\t\tAfter adaption: Boundary condition loss: 0.0044398554211564625\n","\t\tAfter adaption: PDE loss: 0.01743293776822757\n","\t\tAfter adaption: Data loss: 0.0019357671942319998\n","\n","\tTesting: Initial condition loss: 0.008286282420158386\n","\tTesting: Boundary condition loss: 0.01830248534679413\n","\tTesting: PDE loss: 0.033719372004270554\n","\tTesting: Data loss: 0.011735480278730392\n","\n","Epoch 96\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009865505620837212\n","\tBefore adaption: Boundary condition loss: 0.017351500689983368\n","\tBefore adaption: PDE loss: 0.0334012471139431\n","\tBefore adaption: Data loss: 0.011479421518743038\n","tensor(0.0174, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0174, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2351, 0.1475, 0.4671, 0.1503], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014551792208982697\n","\t\tAfter adaption: Boundary condition loss: 0.004080081967155133\n","\t\tAfter adaption: PDE loss: 0.015600499775622265\n","\t\tAfter adaption: Data loss: 0.001725263421734404\n","\n","\tTesting: Initial condition loss: 0.004952188581228256\n","\tTesting: Boundary condition loss: 0.01148411724716425\n","\tTesting: PDE loss: 0.0311907771974802\n","\tTesting: Data loss: 0.008536944165825844\n","\n","Epoch 97\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006667766720056534\n","\tBefore adaption: Boundary condition loss: 0.010799538344144821\n","\tBefore adaption: PDE loss: 0.03090982511639595\n","\tBefore adaption: Data loss: 0.008342097513377666\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2492, 0.1465, 0.4483, 0.1560], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009768272459786155\n","\t\tAfter adaption: Boundary condition loss: 0.0026916904277379345\n","\t\tAfter adaption: PDE loss: 0.013856819490961448\n","\t\tAfter adaption: Data loss: 0.0013010376126934874\n","\n","\tTesting: Initial condition loss: 0.004119857680052519\n","\tTesting: Boundary condition loss: 0.005354730878025293\n","\tTesting: PDE loss: 0.02833930216729641\n","\tTesting: Data loss: 0.005826754495501518\n","\n","Epoch 98\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005780019331723452\n","\tBefore adaption: Boundary condition loss: 0.004961090162396431\n","\tBefore adaption: PDE loss: 0.028077496215701103\n","\tBefore adaption: Data loss: 0.005705961957573891\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2466, 0.1452, 0.4506, 0.1575], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008395099993043816\n","\t\tAfter adaption: Boundary condition loss: 0.0012236130213588842\n","\t\tAfter adaption: PDE loss: 0.012651386400911787\n","\t\tAfter adaption: Data loss: 0.00089883918146736\n","\n","\tTesting: Initial condition loss: 0.007382815703749657\n","\tTesting: Boundary condition loss: 0.0016112822340801358\n","\tTesting: PDE loss: 0.025543397292494774\n","\tTesting: Data loss: 0.004588389303535223\n","\n","Epoch 99\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008687891066074371\n","\tBefore adaption: Boundary condition loss: 0.0014443668769672513\n","\tBefore adaption: PDE loss: 0.025306079536676407\n","\tBefore adaption: Data loss: 0.004541133064776659\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2278, 0.1426, 0.4749, 0.1547], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001238526909032104\n","\t\tAfter adaption: Boundary condition loss: 0.0003290918174198552\n","\t\tAfter adaption: PDE loss: 0.012016987616899918\n","\t\tAfter adaption: Data loss: 0.0007026556614018628\n","\n","\tTesting: Initial condition loss: 0.014661172404885292\n","\tTesting: Boundary condition loss: 0.0004059009370394051\n","\tTesting: PDE loss: 0.02302655018866062\n","\tTesting: Data loss: 0.005004153121262789\n","\n","Epoch 100\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015340295620262623\n","\tBefore adaption: Boundary condition loss: 0.0003531268157530576\n","\tBefore adaption: PDE loss: 0.022780144587159157\n","\tBefore adaption: Data loss: 0.005019522272050381\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1907, 0.1478, 0.5142, 0.1473], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002267891071432603\n","\t\tAfter adaption: Boundary condition loss: 6.732662660045337e-05\n","\t\tAfter adaption: PDE loss: 0.011713330629347728\n","\t\tAfter adaption: Data loss: 0.0007394367295915175\n","\n","\tTesting: Initial condition loss: 0.024470048025250435\n","\tTesting: Boundary condition loss: 0.0008731468697078526\n","\tTesting: PDE loss: 0.02078133262693882\n","\tTesting: Data loss: 0.0065800040028989315\n","\n","Epoch 101\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024422895163297653\n","\tBefore adaption: Boundary condition loss: 0.0008506753947585821\n","\tBefore adaption: PDE loss: 0.020599395036697388\n","\tBefore adaption: Data loss: 0.006643221247941256\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1359, 0.1804, 0.5470, 0.1366], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004406843615916948\n","\t\tAfter adaption: Boundary condition loss: 0.00011560059713369536\n","\t\tAfter adaption: PDE loss: 0.011268644679598294\n","\t\tAfter adaption: Data loss: 0.0009076659442733546\n","\n","\tTesting: Initial condition loss: 0.034353528171777725\n","\tTesting: Boundary condition loss: 0.00191589561291039\n","\tTesting: PDE loss: 0.018980935215950012\n","\tTesting: Data loss: 0.008475658483803272\n","\n","Epoch 102\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03362677991390228\n","\tBefore adaption: Boundary condition loss: 0.0018790909089148045\n","\tBefore adaption: PDE loss: 0.018820254132151604\n","\tBefore adaption: Data loss: 0.00857191439718008\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0776, 0.2567, 0.5382, 0.1275], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008632666022976071\n","\t\tAfter adaption: Boundary condition loss: 0.00014576036046894605\n","\t\tAfter adaption: PDE loss: 0.0101288949997558\n","\t\tAfter adaption: Data loss: 0.001093082026076284\n","\n","\tTesting: Initial condition loss: 0.04077857732772827\n","\tTesting: Boundary condition loss: 0.0025943806394934654\n","\tTesting: PDE loss: 0.017771653831005096\n","\tTesting: Data loss: 0.009713321924209595\n","\n","Epoch 103\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03968576341867447\n","\tBefore adaption: Boundary condition loss: 0.002529466524720192\n","\tBefore adaption: PDE loss: 0.017642851918935776\n","\tBefore adaption: Data loss: 0.00982475932687521\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0390, 0.3610, 0.4748, 0.1252], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014327698789710994\n","\t\tAfter adaption: Boundary condition loss: 9.856636448665331e-05\n","\t\tAfter adaption: PDE loss: 0.00837653796011667\n","\t\tAfter adaption: Data loss: 0.0012302582461449307\n","\n","\tTesting: Initial condition loss: 0.04016684740781784\n","\tTesting: Boundary condition loss: 0.0022896199952811003\n","\tTesting: PDE loss: 0.01746552437543869\n","\tTesting: Data loss: 0.009482810273766518\n","\n","Epoch 104\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0392635203897953\n","\tBefore adaption: Boundary condition loss: 0.0022258867975324392\n","\tBefore adaption: PDE loss: 0.017323007807135582\n","\tBefore adaption: Data loss: 0.00958722922950983\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0263, 0.4536, 0.3914, 0.1288], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01780807465922683\n","\t\tAfter adaption: Boundary condition loss: 5.846616194445029e-05\n","\t\tAfter adaption: PDE loss: 0.006779636400160969\n","\t\tAfter adaption: Data loss: 0.0012349758136161375\n","\n","\tTesting: Initial condition loss: 0.0318974144756794\n","\tTesting: Boundary condition loss: 0.0011464636772871017\n","\tTesting: PDE loss: 0.018188273534178734\n","\tTesting: Data loss: 0.007813653908669949\n","\n","Epoch 105\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.031712256371974945\n","\tBefore adaption: Boundary condition loss: 0.001109599368646741\n","\tBefore adaption: PDE loss: 0.018052037805318832\n","\tBefore adaption: Data loss: 0.007885897532105446\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0264, 0.5132, 0.3270, 0.1335], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01627392625646029\n","\t\tAfter adaption: Boundary condition loss: 2.927430058491134e-05\n","\t\tAfter adaption: PDE loss: 0.00590263583905547\n","\t\tAfter adaption: Data loss: 0.0010524793959699294\n","\n","\tTesting: Initial condition loss: 0.01966424100100994\n","\tTesting: Boundary condition loss: 0.0002793761668726802\n","\tTesting: PDE loss: 0.02001401223242283\n","\tTesting: Data loss: 0.005838033743202686\n","\n","Epoch 106\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020383866503834724\n","\tBefore adaption: Boundary condition loss: 0.0002397865173406899\n","\tBefore adaption: PDE loss: 0.019838232547044754\n","\tBefore adaption: Data loss: 0.005856088828295469\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0275, 0.5405, 0.2958, 0.1361], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011018241674480924\n","\t\tAfter adaption: Boundary condition loss: 6.597576559820386e-06\n","\t\tAfter adaption: PDE loss: 0.005868900259948094\n","\t\tAfter adaption: Data loss: 0.0007970735923599219\n","\n","\tTesting: Initial condition loss: 0.009178023785352707\n","\tTesting: Boundary condition loss: 0.0013272949727252126\n","\tTesting: PDE loss: 0.022682033479213715\n","\tTesting: Data loss: 0.005128517746925354\n","\n","Epoch 107\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010648943483829498\n","\tBefore adaption: Boundary condition loss: 0.0011723358184099197\n","\tBefore adaption: PDE loss: 0.022496916353702545\n","\tBefore adaption: Data loss: 0.005076978355646133\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0261, 0.5383, 0.2994, 0.1363], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00573182419264417\n","\t\tAfter adaption: Boundary condition loss: 3.057168228720537e-05\n","\t\tAfter adaption: PDE loss: 0.0067348895698313375\n","\t\tAfter adaption: Data loss: 0.0006919918967172674\n","\n","\tTesting: Initial condition loss: 0.004394870717078447\n","\tTesting: Boundary condition loss: 0.005318174138665199\n","\tTesting: PDE loss: 0.025827718898653984\n","\tTesting: Data loss: 0.006580233573913574\n","\n","Epoch 108\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006211286876350641\n","\tBefore adaption: Boundary condition loss: 0.0048790075816214085\n","\tBefore adaption: PDE loss: 0.025591829791665077\n","\tBefore adaption: Data loss: 0.006453491747379303\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0258, 0.5016, 0.3374, 0.1353], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031154334444613452\n","\t\tAfter adaption: Boundary condition loss: 0.00012563887605455848\n","\t\tAfter adaption: PDE loss: 0.008634211515669694\n","\t\tAfter adaption: Data loss: 0.0008731005698008906\n","\n","\tTesting: Initial condition loss: 0.005346246995031834\n","\tTesting: Boundary condition loss: 0.011482623405754566\n","\tTesting: PDE loss: 0.028720609843730927\n","\tTesting: Data loss: 0.009734970517456532\n","\n","Epoch 109\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007051248103380203\n","\tBefore adaption: Boundary condition loss: 0.010677499696612358\n","\tBefore adaption: PDE loss: 0.02852618135511875\n","\tBefore adaption: Data loss: 0.00954018346965313\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0376, 0.4226, 0.4036, 0.1362], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0029801271038125497\n","\t\tAfter adaption: Boundary condition loss: 0.0004015411979259002\n","\t\tAfter adaption: PDE loss: 0.01151259132171995\n","\t\tAfter adaption: Data loss: 0.0012991386957425608\n","\n","\tTesting: Initial condition loss: 0.008840590715408325\n","\tTesting: Boundary condition loss: 0.017571447417140007\n","\tTesting: PDE loss: 0.030827537178993225\n","\tTesting: Data loss: 0.013131553307175636\n","\n","Epoch 110\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01023175474256277\n","\tBefore adaption: Boundary condition loss: 0.0164537001401186\n","\tBefore adaption: PDE loss: 0.030645325779914856\n","\tBefore adaption: Data loss: 0.012887285090982914\n","tensor(0.0165, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0165, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0743, 0.3120, 0.4706, 0.1430], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003192808416980281\n","\t\tAfter adaption: Boundary condition loss: 0.0012222858706010355\n","\t\tAfter adaption: PDE loss: 0.014422539224066342\n","\t\tAfter adaption: Data loss: 0.0018433553913272925\n","\n","\tTesting: Initial condition loss: 0.01134150754660368\n","\tTesting: Boundary condition loss: 0.021161340177059174\n","\tTesting: PDE loss: 0.03178418055176735\n","\tTesting: Data loss: 0.015246591530740261\n","\n","Epoch 111\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012514270842075348\n","\tBefore adaption: Boundary condition loss: 0.0198792926967144\n","\tBefore adaption: PDE loss: 0.031608499586582184\n","\tBefore adaption: Data loss: 0.014978088438510895\n","tensor(0.0199, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0199, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1312, 0.2137, 0.4989, 0.1562], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0026747281000090574\n","\t\tAfter adaption: Boundary condition loss: 0.002607303938639201\n","\t\tAfter adaption: PDE loss: 0.01576922436304817\n","\t\tAfter adaption: Data loss: 0.0023398304660492164\n","\n","\tTesting: Initial condition loss: 0.011104277335107327\n","\tTesting: Boundary condition loss: 0.020815901458263397\n","\tTesting: PDE loss: 0.03156357631087303\n","\tTesting: Data loss: 0.01518118754029274\n","\n","Epoch 112\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012265573255717754\n","\tBefore adaption: Boundary condition loss: 0.019540837034583092\n","\tBefore adaption: PDE loss: 0.031390298157930374\n","\tBefore adaption: Data loss: 0.014916925691068172\n","tensor(0.0195, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0195, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1846, 0.1621, 0.4831, 0.1702], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001988692947407809\n","\t\tAfter adaption: Boundary condition loss: 0.003606763580288136\n","\t\tAfter adaption: PDE loss: 0.015164564690632508\n","\t\tAfter adaption: Data loss: 0.002538723299912076\n","\n","\tTesting: Initial condition loss: 0.008439931087195873\n","\tTesting: Boundary condition loss: 0.016798250377178192\n","\tTesting: PDE loss: 0.030351785942912102\n","\tTesting: Data loss: 0.012969004921615124\n","\n","Epoch 113\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00979312602430582\n","\tBefore adaption: Boundary condition loss: 0.015687493607401848\n","\tBefore adaption: PDE loss: 0.030201703310012817\n","\tBefore adaption: Data loss: 0.012738058343529701\n","tensor(0.0157, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0157, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2190, 0.1479, 0.4529, 0.1802], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001448446570766331\n","\t\tAfter adaption: Boundary condition loss: 0.0034355025416981538\n","\t\tAfter adaption: PDE loss: 0.013679703400930351\n","\t\tAfter adaption: Data loss: 0.0022948172612723334\n","\n","\tTesting: Initial condition loss: 0.00524026807397604\n","\tTesting: Boundary condition loss: 0.010965497232973576\n","\tTesting: PDE loss: 0.02849411405622959\n","\tTesting: Data loss: 0.009598895907402039\n","\n","Epoch 114\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006833327002823353\n","\tBefore adaption: Boundary condition loss: 0.010134861804544926\n","\tBefore adaption: PDE loss: 0.028325460851192474\n","\tBefore adaption: Data loss: 0.009420879185199738\n","tensor(0.0101, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0101, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2340, 0.1475, 0.4334, 0.1851], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010079274768710741\n","\t\tAfter adaption: Boundary condition loss: 0.002371611192490838\n","\t\tAfter adaption: PDE loss: 0.01227670193780287\n","\t\tAfter adaption: Data loss: 0.0017435887090594437\n","\n","\tTesting: Initial condition loss: 0.003839233424514532\n","\tTesting: Boundary condition loss: 0.005523615051060915\n","\tTesting: PDE loss: 0.02630428783595562\n","\tTesting: Data loss: 0.006460985634475946\n","\n","Epoch 115\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005515148397535086\n","\tBefore adaption: Boundary condition loss: 0.005016182083636522\n","\tBefore adaption: PDE loss: 0.026106035336852074\n","\tBefore adaption: Data loss: 0.006345522124320269\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2332, 0.1474, 0.4342, 0.1853], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008126851101100072\n","\t\tAfter adaption: Boundary condition loss: 0.0011696190973081858\n","\t\tAfter adaption: PDE loss: 0.01133432362385431\n","\t\tAfter adaption: Data loss: 0.0011758932583416318\n","\n","\tTesting: Initial condition loss: 0.00583283044397831\n","\tTesting: Boundary condition loss: 0.001986255869269371\n","\tTesting: PDE loss: 0.024006761610507965\n","\tTesting: Data loss: 0.004586160182952881\n","\n","Epoch 116\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007328801788389683\n","\tBefore adaption: Boundary condition loss: 0.0017475277418270707\n","\tBefore adaption: PDE loss: 0.023842982947826385\n","\tBefore adaption: Data loss: 0.004530337639153004\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2174, 0.1452, 0.4567, 0.1807], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010639773844488393\n","\t\tAfter adaption: Boundary condition loss: 0.0003799077520168035\n","\t\tAfter adaption: PDE loss: 0.010889948731114683\n","\t\tAfter adaption: Data loss: 0.000818582364254915\n","\n","\tTesting: Initial condition loss: 0.011488577350974083\n","\tTesting: Boundary condition loss: 0.0006617676699534059\n","\tTesting: PDE loss: 0.02179664373397827\n","\tTesting: Data loss: 0.004273925442248583\n","\n","Epoch 117\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012587236240506172\n","\tBefore adaption: Boundary condition loss: 0.0005780900246463716\n","\tBefore adaption: PDE loss: 0.0216432586312294\n","\tBefore adaption: Data loss: 0.004270180594176054\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1850, 0.1482, 0.4966, 0.1702], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018649757297970857\n","\t\tAfter adaption: Boundary condition loss: 0.00010696874636708367\n","\t\tAfter adaption: PDE loss: 0.010747226621302817\n","\t\tAfter adaption: Data loss: 0.0007269352836171756\n","\n","\tTesting: Initial condition loss: 0.019798437133431435\n","\tTesting: Boundary condition loss: 0.0008359637577086687\n","\tTesting: PDE loss: 0.019746964797377586\n","\tTesting: Data loss: 0.005173851735889912\n","\n","Epoch 118\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020347077399492264\n","\tBefore adaption: Boundary condition loss: 0.000817476655356586\n","\tBefore adaption: PDE loss: 0.019609972834587097\n","\tBefore adaption: Data loss: 0.0052116611041128635\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1366, 0.1733, 0.5363, 0.1537], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0035265611562179332\n","\t\tAfter adaption: Boundary condition loss: 0.00011170207183019858\n","\t\tAfter adaption: PDE loss: 0.010516855995456537\n","\t\tAfter adaption: Data loss: 0.0008012177745608156\n","\n","\tTesting: Initial condition loss: 0.02868652157485485\n","\tTesting: Boundary condition loss: 0.0015485537005588412\n","\tTesting: PDE loss: 0.017953593283891678\n","\tTesting: Data loss: 0.006598307751119137\n","\n","Epoch 119\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028756622225046158\n","\tBefore adaption: Boundary condition loss: 0.0015458085108548403\n","\tBefore adaption: PDE loss: 0.01781841367483139\n","\tBefore adaption: Data loss: 0.00666584400460124\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0830, 0.2389, 0.5428, 0.1352], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006870502685049271\n","\t\tAfter adaption: Boundary condition loss: 0.00012837938939591202\n","\t\tAfter adaption: PDE loss: 0.009672084369525154\n","\t\tAfter adaption: Data loss: 0.0009013341304200527\n","\n","\tTesting: Initial condition loss: 0.0352078340947628\n","\tTesting: Boundary condition loss: 0.0019960827194154263\n","\tTesting: PDE loss: 0.01657380722463131\n","\tTesting: Data loss: 0.0077350023202598095\n","\n","Epoch 120\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.034894995391368866\n","\tBefore adaption: Boundary condition loss: 0.001979401335120201\n","\tBefore adaption: PDE loss: 0.016457486897706985\n","\tBefore adaption: Data loss: 0.007818002253770828\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0440, 0.3384, 0.4949, 0.1227], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01180892645563082\n","\t\tAfter adaption: Boundary condition loss: 8.718178311714835e-05\n","\t\tAfter adaption: PDE loss: 0.008144455473786755\n","\t\tAfter adaption: Data loss: 0.0009589845163013395\n","\n","\tTesting: Initial condition loss: 0.03588702529668808\n","\tTesting: Boundary condition loss: 0.0016680839471518993\n","\tTesting: PDE loss: 0.015923278406262398\n","\tTesting: Data loss: 0.007905272766947746\n","\n","Epoch 121\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03554825112223625\n","\tBefore adaption: Boundary condition loss: 0.0016406887443736196\n","\tBefore adaption: PDE loss: 0.015820587053894997\n","\tBefore adaption: Data loss: 0.007982525043189526\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0280, 0.4359, 0.4166, 0.1195], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015496547612780805\n","\t\tAfter adaption: Boundary condition loss: 4.586973213520789e-05\n","\t\tAfter adaption: PDE loss: 0.006591262451672947\n","\t\tAfter adaption: Data loss: 0.0009538045317598055\n","\n","\tTesting: Initial condition loss: 0.029501765966415405\n","\tTesting: Boundary condition loss: 0.0007030749111436307\n","\tTesting: PDE loss: 0.01624908298254013\n","\tTesting: Data loss: 0.007117290981113911\n","\n","Epoch 122\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02960558608174324\n","\tBefore adaption: Boundary condition loss: 0.0006799967377446592\n","\tBefore adaption: PDE loss: 0.016140898689627647\n","\tBefore adaption: Data loss: 0.007163478527218103\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0250, 0.5045, 0.3485, 0.1219], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014937197425703576\n","\t\tAfter adaption: Boundary condition loss: 1.70250865944842e-05\n","\t\tAfter adaption: PDE loss: 0.005625220324052067\n","\t\tAfter adaption: Data loss: 0.0008733405580113016\n","\n","\tTesting: Initial condition loss: 0.019148923456668854\n","\tTesting: Boundary condition loss: 0.0001226609165314585\n","\tTesting: PDE loss: 0.017528608441352844\n","\tTesting: Data loss: 0.006353810429573059\n","\n","Epoch 123\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.019790073856711388\n","\tBefore adaption: Boundary condition loss: 8.902837726054713e-05\n","\tBefore adaption: PDE loss: 0.017379606142640114\n","\tBefore adaption: Data loss: 0.006344560068100691\n","tensor(8.9028e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.9028e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0241, 0.5396, 0.3103, 0.1260], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010679542062157573\n","\t\tAfter adaption: Boundary condition loss: 2.1447478036098106e-06\n","\t\tAfter adaption: PDE loss: 0.005392796411759033\n","\t\tAfter adaption: Data loss: 0.0007992455092164972\n","\n","\tTesting: Initial condition loss: 0.009631502442061901\n","\tTesting: Boundary condition loss: 0.001349372905679047\n","\tTesting: PDE loss: 0.019471965730190277\n","\tTesting: Data loss: 0.00692987022921443\n","\n","Epoch 124\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010828523896634579\n","\tBefore adaption: Boundary condition loss: 0.0012378750834614038\n","\tBefore adaption: PDE loss: 0.01935478299856186\n","\tBefore adaption: Data loss: 0.006850242614746094\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0216, 0.5423, 0.3049, 0.1312], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0058721033017936596\n","\t\tAfter adaption: Boundary condition loss: 2.67923830567796e-05\n","\t\tAfter adaption: PDE loss: 0.005900720606189912\n","\t\tAfter adaption: Data loss: 0.0008987756398620507\n","\n","\tTesting: Initial condition loss: 0.004497940186411142\n","\tTesting: Boundary condition loss: 0.005280759185552597\n","\tTesting: PDE loss: 0.02187104895710945\n","\tTesting: Data loss: 0.009489744901657104\n","\n","Epoch 125\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006080868653953075\n","\tBefore adaption: Boundary condition loss: 0.004984573926776648\n","\tBefore adaption: PDE loss: 0.02177213504910469\n","\tBefore adaption: Data loss: 0.009337919764220715\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0218, 0.5074, 0.3305, 0.1403], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0030851703333698156\n","\t\tAfter adaption: Boundary condition loss: 0.00010886047367250042\n","\t\tAfter adaption: PDE loss: 0.00719469417551224\n","\t\tAfter adaption: Data loss: 0.0013105700778784685\n","\n","\tTesting: Initial condition loss: 0.004359163343906403\n","\tTesting: Boundary condition loss: 0.011244970373809338\n","\tTesting: PDE loss: 0.02431471459567547\n","\tTesting: Data loss: 0.013407575897872448\n","\n","Epoch 126\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005957919172942638\n","\tBefore adaption: Boundary condition loss: 0.010690553113818169\n","\tBefore adaption: PDE loss: 0.024199189618229866\n","\tBefore adaption: Data loss: 0.013195671141147614\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0362, 0.4268, 0.3791, 0.1579], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0025426918028611718\n","\t\tAfter adaption: Boundary condition loss: 0.00038673203005121736\n","\t\tAfter adaption: PDE loss: 0.009174938389048424\n","\t\tAfter adaption: Data loss: 0.00208369078879012\n","\n","\tTesting: Initial condition loss: 0.006853438448160887\n","\tTesting: Boundary condition loss: 0.016899200156331062\n","\tTesting: PDE loss: 0.02621004730463028\n","\tTesting: Data loss: 0.01706058159470558\n","\n","Epoch 127\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008246021345257759\n","\tBefore adaption: Boundary condition loss: 0.016097931191325188\n","\tBefore adaption: PDE loss: 0.026116227731108665\n","\tBefore adaption: Data loss: 0.016813231632113457\n","tensor(0.0161, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0161, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0763, 0.3117, 0.4268, 0.1852], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002570453738789583\n","\t\tAfter adaption: Boundary condition loss: 0.00122879954380736\n","\t\tAfter adaption: PDE loss: 0.01114604930742321\n","\t\tAfter adaption: Data loss: 0.0031131413215819415\n","\n","\tTesting: Initial condition loss: 0.008936876431107521\n","\tTesting: Boundary condition loss: 0.019652456045150757\n","\tTesting: PDE loss: 0.027326716110110283\n","\tTesting: Data loss: 0.018769821152091026\n","\n","Epoch 128\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010139098390936852\n","\tBefore adaption: Boundary condition loss: 0.0187052171677351\n","\tBefore adaption: PDE loss: 0.027231115847826004\n","\tBefore adaption: Data loss: 0.01851731352508068\n","tensor(0.0187, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0187, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1349, 0.2073, 0.4436, 0.2142], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00210159375492212\n","\t\tAfter adaption: Boundary condition loss: 0.0025237184406966297\n","\t\tAfter adaption: PDE loss: 0.012080963939191345\n","\t\tAfter adaption: Data loss: 0.003965620917888069\n","\n","\tTesting: Initial condition loss: 0.008891712874174118\n","\tTesting: Boundary condition loss: 0.018263576552271843\n","\tTesting: PDE loss: 0.027660202234983444\n","\tTesting: Data loss: 0.017673393711447716\n","\n","Epoch 129\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010061334818601608\n","\tBefore adaption: Boundary condition loss: 0.017298391088843346\n","\tBefore adaption: PDE loss: 0.0275465976446867\n","\tBefore adaption: Data loss: 0.01744764856994152\n","tensor(0.0173, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0173, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1872, 0.1492, 0.4295, 0.2342], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015006599939566192\n","\t\tAfter adaption: Boundary condition loss: 0.0032376607624978295\n","\t\tAfter adaption: PDE loss: 0.011831114642329745\n","\t\tAfter adaption: Data loss: 0.004086040722602107\n","\n","\tTesting: Initial condition loss: 0.006846454925835133\n","\tTesting: Boundary condition loss: 0.01351329404860735\n","\tTesting: PDE loss: 0.027369091287255287\n","\tTesting: Data loss: 0.01420739758759737\n","\n","Epoch 130\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008125503547489643\n","\tBefore adaption: Boundary condition loss: 0.012664185836911201\n","\tBefore adaption: PDE loss: 0.027245962992310524\n","\tBefore adaption: Data loss: 0.014031479135155678\n","tensor(0.0127, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0127, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2184, 0.1303, 0.4087, 0.2426], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010591332629659802\n","\t\tAfter adaption: Boundary condition loss: 0.00276552038937476\n","\t\tAfter adaption: PDE loss: 0.011134460374792455\n","\t\tAfter adaption: Data loss: 0.003404249198264844\n","\n","\tTesting: Initial condition loss: 0.004324635490775108\n","\tTesting: Boundary condition loss: 0.0077976747415959835\n","\tTesting: PDE loss: 0.02670988067984581\n","\tTesting: Data loss: 0.009857061319053173\n","\n","Epoch 131\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0057316734455525875\n","\tBefore adaption: Boundary condition loss: 0.007183907087892294\n","\tBefore adaption: PDE loss: 0.02653723582625389\n","\tBefore adaption: Data loss: 0.009737914428114891\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2285, 0.1287, 0.4006, 0.2422], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007378109036199017\n","\t\tAfter adaption: Boundary condition loss: 0.0016414027421804886\n","\t\tAfter adaption: PDE loss: 0.010630293923371214\n","\t\tAfter adaption: Data loss: 0.002358630370089928\n","\n","\tTesting: Initial condition loss: 0.0032499858643859625\n","\tTesting: Boundary condition loss: 0.0034976780880242586\n","\tTesting: PDE loss: 0.025703787803649902\n","\tTesting: Data loss: 0.006240814458578825\n","\n","Epoch 132\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004659957252442837\n","\tBefore adaption: Boundary condition loss: 0.0031513147987425327\n","\tBefore adaption: PDE loss: 0.02559475041925907\n","\tBefore adaption: Data loss: 0.00617506867274642\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2211, 0.1300, 0.4137, 0.2352], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006056676275531182\n","\t\tAfter adaption: Boundary condition loss: 0.000696749942753253\n","\t\tAfter adaption: PDE loss: 0.01058949011060124\n","\t\tAfter adaption: Data loss: 0.0014523272990800073\n","\n","\tTesting: Initial condition loss: 0.004960803780704737\n","\tTesting: Boundary condition loss: 0.0015132604166865349\n","\tTesting: PDE loss: 0.024554451927542686\n","\tTesting: Data loss: 0.00426288228482008\n","\n","Epoch 133\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006104797590523958\n","\tBefore adaption: Boundary condition loss: 0.0013667404418811202\n","\tBefore adaption: PDE loss: 0.024457518011331558\n","\tBefore adaption: Data loss: 0.004238357301801443\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1981, 0.1300, 0.4505, 0.2213], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007937683083606927\n","\t\tAfter adaption: Boundary condition loss: 0.00027081081855386425\n","\t\tAfter adaption: PDE loss: 0.011018264220851273\n","\t\tAfter adaption: Data loss: 0.0009380601579485496\n","\n","\tTesting: Initial condition loss: 0.009553682059049606\n","\tTesting: Boundary condition loss: 0.001410025986842811\n","\tTesting: PDE loss: 0.023269319906830788\n","\tTesting: Data loss: 0.003914807923138142\n","\n","Epoch 134\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010214744135737419\n","\tBefore adaption: Boundary condition loss: 0.0013943561352789402\n","\tBefore adaption: PDE loss: 0.023169346153736115\n","\tBefore adaption: Data loss: 0.00391926197335124\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1606, 0.1337, 0.5066, 0.1990], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013659932070032848\n","\t\tAfter adaption: Boundary condition loss: 0.00022394940377481228\n","\t\tAfter adaption: PDE loss: 0.011737962923949786\n","\t\tAfter adaption: Data loss: 0.0007801087473769552\n","\n","\tTesting: Initial condition loss: 0.016333332285284996\n","\tTesting: Boundary condition loss: 0.0022261107806116343\n","\tTesting: PDE loss: 0.021720880642533302\n","\tTesting: Data loss: 0.004637945909053087\n","\n","Epoch 135\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016343653202056885\n","\tBefore adaption: Boundary condition loss: 0.0022616724018007517\n","\tBefore adaption: PDE loss: 0.02162531390786171\n","\tBefore adaption: Data loss: 0.004663833416998386\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1141, 0.1543, 0.5628, 0.1688], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0025224975744023476\n","\t\tAfter adaption: Boundary condition loss: 0.0002580409059527825\n","\t\tAfter adaption: PDE loss: 0.01217044215939794\n","\t\tAfter adaption: Data loss: 0.0007871564952417442\n","\n","\tTesting: Initial condition loss: 0.02370099350810051\n","\tTesting: Boundary condition loss: 0.0030683442018926144\n","\tTesting: PDE loss: 0.020014548674225807\n","\tTesting: Data loss: 0.005745898466557264\n","\n","Epoch 136\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023127030581235886\n","\tBefore adaption: Boundary condition loss: 0.0030936982948333025\n","\tBefore adaption: PDE loss: 0.019917650148272514\n","\tBefore adaption: Data loss: 0.005789207294583321\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0736, 0.2065, 0.5822, 0.1378], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004774856757812629\n","\t\tAfter adaption: Boundary condition loss: 0.00022777021445157675\n","\t\tAfter adaption: PDE loss: 0.011595105925285544\n","\t\tAfter adaption: Data loss: 0.0007975291112735752\n","\n","\tTesting: Initial condition loss: 0.029687659814953804\n","\tTesting: Boundary condition loss: 0.003348682541400194\n","\tTesting: PDE loss: 0.018325084820389748\n","\tTesting: Data loss: 0.006665669847279787\n","\n","Epoch 137\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028672179207205772\n","\tBefore adaption: Boundary condition loss: 0.003336109919473529\n","\tBefore adaption: PDE loss: 0.018252598121762276\n","\tBefore adaption: Data loss: 0.006720672361552715\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0533, 0.2862, 0.5432, 0.1173], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008204934625081553\n","\t\tAfter adaption: Boundary condition loss: 0.00017789357942933469\n","\t\tAfter adaption: PDE loss: 0.009915081956952164\n","\t\tAfter adaption: Data loss: 0.0007883191237104287\n","\n","\tTesting: Initial condition loss: 0.031818632036447525\n","\tTesting: Boundary condition loss: 0.002773912623524666\n","\tTesting: PDE loss: 0.01700427569448948\n","\tTesting: Data loss: 0.007002734113484621\n","\n","Epoch 138\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03073912300169468\n","\tBefore adaption: Boundary condition loss: 0.002738635055720806\n","\tBefore adaption: PDE loss: 0.016947291791439056\n","\tBefore adaption: Data loss: 0.00705580972135067\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0501, 0.3695, 0.4697, 0.1108], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011356766845582216\n","\t\tAfter adaption: Boundary condition loss: 0.0001371460668548377\n","\t\tAfter adaption: PDE loss: 0.007960202402535779\n","\t\tAfter adaption: Data loss: 0.0007815126411138462\n","\n","\tTesting: Initial condition loss: 0.028584929183125496\n","\tTesting: Boundary condition loss: 0.0014916547806933522\n","\tTesting: PDE loss: 0.016314184293150902\n","\tTesting: Data loss: 0.006767300423234701\n","\n","Epoch 139\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027915265411138535\n","\tBefore adaption: Boundary condition loss: 0.0014646112686023116\n","\tBefore adaption: PDE loss: 0.0163018386811018\n","\tBefore adaption: Data loss: 0.006797132082283497\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0513, 0.4366, 0.3995, 0.1126], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012186941677504715\n","\t\tAfter adaption: Boundary condition loss: 7.512801251676016e-05\n","\t\tAfter adaption: PDE loss: 0.006513377806282128\n","\t\tAfter adaption: Data loss: 0.0007652655211976011\n","\n","\tTesting: Initial condition loss: 0.020920874550938606\n","\tTesting: Boundary condition loss: 0.0002993975067511201\n","\tTesting: PDE loss: 0.01652904972434044\n","\tTesting: Data loss: 0.006589295342564583\n","\n","Epoch 140\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021031294018030167\n","\tBefore adaption: Boundary condition loss: 0.00028620948432944715\n","\tBefore adaption: PDE loss: 0.016491569578647614\n","\tBefore adaption: Data loss: 0.006572114769369364\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0489, 0.4809, 0.3526, 0.1176], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010114036660969694\n","\t\tAfter adaption: Boundary condition loss: 1.3989609078878929e-05\n","\t\tAfter adaption: PDE loss: 0.00581502894901928\n","\t\tAfter adaption: Data loss: 0.0007729502660411064\n","\n","\tTesting: Initial condition loss: 0.012169399298727512\n","\tTesting: Boundary condition loss: 0.00038747501093894243\n","\tTesting: PDE loss: 0.01756412722170353\n","\tTesting: Data loss: 0.00748671917244792\n","\n","Epoch 141\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013075578026473522\n","\tBefore adaption: Boundary condition loss: 0.00034771458012983203\n","\tBefore adaption: PDE loss: 0.017507480457425117\n","\tBefore adaption: Data loss: 0.007404317148029804\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0415, 0.4996, 0.3338, 0.1251], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006533142251636139\n","\t\tAfter adaption: Boundary condition loss: 1.4419645479517442e-05\n","\t\tAfter adaption: PDE loss: 0.005843943289142603\n","\t\tAfter adaption: Data loss: 0.0009261947661695629\n","\n","\tTesting: Initial condition loss: 0.005891873966902494\n","\tTesting: Boundary condition loss: 0.0027685423847287893\n","\tTesting: PDE loss: 0.019088640809059143\n","\tTesting: Data loss: 0.010175518691539764\n","\n","Epoch 142\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007390886545181274\n","\tBefore adaption: Boundary condition loss: 0.0026056214701384306\n","\tBefore adaption: PDE loss: 0.019057076424360275\n","\tBefore adaption: Data loss: 0.010017603635787964\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0327, 0.4865, 0.3424, 0.1384], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0035958640420823314\n","\t\tAfter adaption: Boundary condition loss: 8.528791212794331e-05\n","\t\tAfter adaption: PDE loss: 0.006524447356694215\n","\t\tAfter adaption: Data loss: 0.0013862086860922398\n","\n","\tTesting: Initial condition loss: 0.0035850389394909143\n","\tTesting: Boundary condition loss: 0.00748833641409874\n","\tTesting: PDE loss: 0.020852485671639442\n","\tTesting: Data loss: 0.014394909143447876\n","\n","Epoch 143\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005217810161411762\n","\tBefore adaption: Boundary condition loss: 0.0071236323565244675\n","\tBefore adaption: PDE loss: 0.02080448903143406\n","\tBefore adaption: Data loss: 0.014164777472615242\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0321, 0.4322, 0.3724, 0.1633], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002255034182540286\n","\t\tAfter adaption: Boundary condition loss: 0.00022876957031333478\n","\t\tAfter adaption: PDE loss: 0.00774730678300621\n","\t\tAfter adaption: Data loss: 0.002313378943815737\n","\n","\tTesting: Initial condition loss: 0.0042410059832036495\n","\tTesting: Boundary condition loss: 0.013019471429288387\n","\tTesting: PDE loss: 0.022391561418771744\n","\tTesting: Data loss: 0.018838968127965927\n","\n","Epoch 144\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0057507664896547794\n","\tBefore adaption: Boundary condition loss: 0.012416272424161434\n","\tBefore adaption: PDE loss: 0.02237253077328205\n","\tBefore adaption: Data loss: 0.018552791327238083\n","tensor(0.0124, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0124, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0534, 0.3367, 0.4070, 0.2029], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019363968114983693\n","\t\tAfter adaption: Boundary condition loss: 0.0006628191744120742\n","\t\tAfter adaption: PDE loss: 0.009105046778586567\n","\t\tAfter adaption: Data loss: 0.0037647790730711743\n","\n","\tTesting: Initial condition loss: 0.005741673521697521\n","\tTesting: Boundary condition loss: 0.016936806961894035\n","\tTesting: PDE loss: 0.02346082031726837\n","\tTesting: Data loss: 0.021679192781448364\n","\n","Epoch 145\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007090101484209299\n","\tBefore adaption: Boundary condition loss: 0.016151804476976395\n","\tBefore adaption: PDE loss: 0.023417197167873383\n","\tBefore adaption: Data loss: 0.021368352696299553\n","tensor(0.0162, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0162, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0998, 0.2298, 0.4218, 0.2486], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016291155255326257\n","\t\tAfter adaption: Boundary condition loss: 0.0016125395276194515\n","\t\tAfter adaption: PDE loss: 0.009877818375368767\n","\t\tAfter adaption: Data loss: 0.005311554286232952\n","\n","\tTesting: Initial condition loss: 0.0063193184323608875\n","\tTesting: Boundary condition loss: 0.017282914370298386\n","\tTesting: PDE loss: 0.02388005703687668\n","\tTesting: Data loss: 0.021490884944796562\n","\n","Epoch 146\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007603171281516552\n","\tBefore adaption: Boundary condition loss: 0.016433730721473694\n","\tBefore adaption: PDE loss: 0.02381201833486557\n","\tBefore adaption: Data loss: 0.021196765825152397\n","tensor(0.0164, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0164, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1535, 0.1529, 0.4097, 0.2840], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001162246176417194\n","\t\tAfter adaption: Boundary condition loss: 0.0025220205579845707\n","\t\tAfter adaption: PDE loss: 0.009755320584315358\n","\t\tAfter adaption: Data loss: 0.00601966564362398\n","\n","\tTesting: Initial condition loss: 0.005458718165755272\n","\tTesting: Boundary condition loss: 0.01384339202195406\n","\tTesting: PDE loss: 0.02371533215045929\n","\tTesting: Data loss: 0.01820307783782482\n","\n","Epoch 147\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006807132624089718\n","\tBefore adaption: Boundary condition loss: 0.013062710873782635\n","\tBefore adaption: PDE loss: 0.02370346151292324\n","\tBefore adaption: Data loss: 0.01796060800552368\n","tensor(0.0131, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0131, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1937, 0.1169, 0.3874, 0.3019], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007958279932778302\n","\t\tAfter adaption: Boundary condition loss: 0.002530691583309725\n","\t\tAfter adaption: PDE loss: 0.009182986236388085\n","\t\tAfter adaption: Data loss: 0.005423092558639735\n","\n","\tTesting: Initial condition loss: 0.003976648673415184\n","\tTesting: Boundary condition loss: 0.00853846874088049\n","\tTesting: PDE loss: 0.02337752841413021\n","\tTesting: Data loss: 0.013205028139054775\n","\n","Epoch 148\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005420324858278036\n","\tBefore adaption: Boundary condition loss: 0.007933423854410648\n","\tBefore adaption: PDE loss: 0.023379402235150337\n","\tBefore adaption: Data loss: 0.01303426455706358\n","tensor(0.0079, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0079, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2138, 0.1064, 0.3741, 0.3057], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005767929631359487\n","\t\tAfter adaption: Boundary condition loss: 0.0016959130383468425\n","\t\tAfter adaption: PDE loss: 0.008745548349075729\n","\t\tAfter adaption: Data loss: 0.003985201356420599\n","\n","\tTesting: Initial condition loss: 0.0033289713319391012\n","\tTesting: Boundary condition loss: 0.003877921961247921\n","\tTesting: PDE loss: 0.023053279146552086\n","\tTesting: Data loss: 0.008421015925705433\n","\n","Epoch 149\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00475282734259963\n","\tBefore adaption: Boundary condition loss: 0.0034950554836541414\n","\tBefore adaption: PDE loss: 0.023102905601263046\n","\tBefore adaption: Data loss: 0.008321820758283138\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2147, 0.1062, 0.3794, 0.2996], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005049560818695865\n","\t\tAfter adaption: Boundary condition loss: 0.0007503649341656896\n","\t\tAfter adaption: PDE loss: 0.008766307967264023\n","\t\tAfter adaption: Data loss: 0.0024933600290497114\n","\n","\tTesting: Initial condition loss: 0.004659720230847597\n","\tTesting: Boundary condition loss: 0.0013265445595607162\n","\tTesting: PDE loss: 0.02291303128004074\n","\tTesting: Data loss: 0.005226765759289265\n","\n","Epoch 150\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005839581601321697\n","\tBefore adaption: Boundary condition loss: 0.0011539036640897393\n","\tBefore adaption: PDE loss: 0.022935565561056137\n","\tBefore adaption: Data loss: 0.005183501169085503\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1982, 0.1100, 0.4076, 0.2843], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006421067834169099\n","\t\tAfter adaption: Boundary condition loss: 0.00022867335975734095\n","\t\tAfter adaption: PDE loss: 0.00934844703685387\n","\t\tAfter adaption: Data loss: 0.0014735260975936378\n","\n","\tTesting: Initial condition loss: 0.008343107998371124\n","\tTesting: Boundary condition loss: 0.0009849747875705361\n","\tTesting: PDE loss: 0.02277231030166149\n","\tTesting: Data loss: 0.00397895323112607\n","\n","Epoch 151\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009038321673870087\n","\tBefore adaption: Boundary condition loss: 0.000945858599152416\n","\tBefore adaption: PDE loss: 0.022784743458032608\n","\tBefore adaption: Data loss: 0.0039706602692604065\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1649, 0.1193, 0.4584, 0.2575], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010778312603639375\n","\t\tAfter adaption: Boundary condition loss: 0.00015598704811144181\n","\t\tAfter adaption: PDE loss: 0.010443562475659078\n","\t\tAfter adaption: Data loss: 0.0010223458586501469\n","\n","\tTesting: Initial condition loss: 0.013894032686948776\n","\tTesting: Boundary condition loss: 0.0019503034418448806\n","\tTesting: PDE loss: 0.02240152843296528\n","\tTesting: Data loss: 0.004206034354865551\n","\n","Epoch 152\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013913029804825783\n","\tBefore adaption: Boundary condition loss: 0.001968477154150605\n","\tBefore adaption: PDE loss: 0.022399302572011948\n","\tBefore adaption: Data loss: 0.004217064008116722\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1193, 0.1430, 0.5202, 0.2175], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001989309846193607\n","\t\tAfter adaption: Boundary condition loss: 0.00023484150394791292\n","\t\tAfter adaption: PDE loss: 0.011653094463694716\n","\t\tAfter adaption: Data loss: 0.0009170986295915809\n","\n","\tTesting: Initial condition loss: 0.020215289667248726\n","\tTesting: Boundary condition loss: 0.003125804476439953\n","\tTesting: PDE loss: 0.021667705848813057\n","\tTesting: Data loss: 0.005091967526823282\n","\n","Epoch 153\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01952817663550377\n","\tBefore adaption: Boundary condition loss: 0.0031279472168534994\n","\tBefore adaption: PDE loss: 0.02164531871676445\n","\tBefore adaption: Data loss: 0.005115853622555733\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0760, 0.1912, 0.5624, 0.1703], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0037339070717461544\n","\t\tAfter adaption: Boundary condition loss: 0.0002377728110998848\n","\t\tAfter adaption: PDE loss: 0.012173978064350851\n","\t\tAfter adaption: Data loss: 0.0008714751728157636\n","\n","\tTesting: Initial condition loss: 0.02585390955209732\n","\tTesting: Boundary condition loss: 0.003799216356128454\n","\tTesting: PDE loss: 0.020646316930651665\n","\tTesting: Data loss: 0.005915607325732708\n","\n","Epoch 154\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024509379640221596\n","\tBefore adaption: Boundary condition loss: 0.003759415354579687\n","\tBefore adaption: PDE loss: 0.020584246143698692\n","\tBefore adaption: Data loss: 0.005950015503913164\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0525, 0.2609, 0.5548, 0.1317], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0063944105279818905\n","\t\tAfter adaption: Boundary condition loss: 0.00019751143443870323\n","\t\tAfter adaption: PDE loss: 0.011420770564130767\n","\t\tAfter adaption: Data loss: 0.0007838243251362774\n","\n","\tTesting: Initial condition loss: 0.028735600411891937\n","\tTesting: Boundary condition loss: 0.0035824766382575035\n","\tTesting: PDE loss: 0.01954670250415802\n","\tTesting: Data loss: 0.006182039622217417\n","\n","Epoch 155\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027115393429994583\n","\tBefore adaption: Boundary condition loss: 0.003519011428579688\n","\tBefore adaption: PDE loss: 0.019494550302624702\n","\tBefore adaption: Data loss: 0.006222845055162907\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0501, 0.3333, 0.5048, 0.1118], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009036594060049367\n","\t\tAfter adaption: Boundary condition loss: 0.00017635772723873986\n","\t\tAfter adaption: PDE loss: 0.009841712140942907\n","\t\tAfter adaption: Data loss: 0.0006955612416380319\n","\n","\tTesting: Initial condition loss: 0.027220962569117546\n","\tTesting: Boundary condition loss: 0.002500241156667471\n","\tTesting: PDE loss: 0.018709653988480568\n","\tTesting: Data loss: 0.00575435534119606\n","\n","Epoch 156\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02589462324976921\n","\tBefore adaption: Boundary condition loss: 0.002448274986818433\n","\tBefore adaption: PDE loss: 0.01868010312318802\n","\tBefore adaption: Data loss: 0.00579299870878458\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0555, 0.3925, 0.4457, 0.1062], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010164037562033271\n","\t\tAfter adaption: Boundary condition loss: 0.00013598261917338508\n","\t\tAfter adaption: PDE loss: 0.008326211570193661\n","\t\tAfter adaption: Data loss: 0.0006153091354954753\n","\n","\tTesting: Initial condition loss: 0.02153511345386505\n","\tTesting: Boundary condition loss: 0.0010449502151459455\n","\tTesting: PDE loss: 0.01839173212647438\n","\tTesting: Data loss: 0.00503934221342206\n","\n","Epoch 157\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021046079695224762\n","\tBefore adaption: Boundary condition loss: 0.0010214811190962791\n","\tBefore adaption: PDE loss: 0.018353797495365143\n","\tBefore adaption: Data loss: 0.005063687451183796\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0579, 0.4338, 0.4016, 0.1067], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009129058319304734\n","\t\tAfter adaption: Boundary condition loss: 5.9166990446637624e-05\n","\t\tAfter adaption: PDE loss: 0.007371710816345357\n","\t\tAfter adaption: Data loss: 0.0005401273620269632\n","\n","\tTesting: Initial condition loss: 0.014062301255762577\n","\tTesting: Boundary condition loss: 0.00021355719945859164\n","\tTesting: PDE loss: 0.018601855263113976\n","\tTesting: Data loss: 0.004885995294898748\n","\n","Epoch 158\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014584025368094444\n","\tBefore adaption: Boundary condition loss: 0.0001753054530126974\n","\tBefore adaption: PDE loss: 0.01859341748058796\n","\tBefore adaption: Data loss: 0.0048812199383974075\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0536, 0.4563, 0.3814, 0.1087], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00665502870547992\n","\t\tAfter adaption: Boundary condition loss: 9.395567607791146e-06\n","\t\tAfter adaption: PDE loss: 0.007091016047905844\n","\t\tAfter adaption: Data loss: 0.0005306317400976034\n","\n","\tTesting: Initial condition loss: 0.007783045992255211\n","\tTesting: Boundary condition loss: 0.0010416102595627308\n","\tTesting: PDE loss: 0.01927475817501545\n","\tTesting: Data loss: 0.00609924690797925\n","\n","Epoch 159\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009047542698681355\n","\tBefore adaption: Boundary condition loss: 0.0008985927561298013\n","\tBefore adaption: PDE loss: 0.019303539767861366\n","\tBefore adaption: Data loss: 0.0060507189482450485\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0441, 0.4569, 0.3863, 0.1127], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004134163604966709\n","\t\tAfter adaption: Boundary condition loss: 3.9624028695642195e-05\n","\t\tAfter adaption: PDE loss: 0.007456805727357667\n","\t\tAfter adaption: Data loss: 0.000681760408508327\n","\n","\tTesting: Initial condition loss: 0.004395693074911833\n","\tTesting: Boundary condition loss: 0.0038501862436532974\n","\tTesting: PDE loss: 0.020255407318472862\n","\tTesting: Data loss: 0.008930431678891182\n","\n","Epoch 160\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005989895202219486\n","\tBefore adaption: Boundary condition loss: 0.0035358064342290163\n","\tBefore adaption: PDE loss: 0.020246848464012146\n","\tBefore adaption: Data loss: 0.008828623220324516\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0353, 0.4281, 0.4138, 0.1228], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0025645688026140648\n","\t\tAfter adaption: Boundary condition loss: 0.00012492447431155325\n","\t\tAfter adaption: PDE loss: 0.008377404506514188\n","\t\tAfter adaption: Data loss: 0.0010837660361003643\n","\n","\tTesting: Initial condition loss: 0.0037997618783265352\n","\tTesting: Boundary condition loss: 0.008119272999465466\n","\tTesting: PDE loss: 0.02118418551981449\n","\tTesting: Data loss: 0.012887993827462196\n","\n","Epoch 161\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0054373047314584255\n","\tBefore adaption: Boundary condition loss: 0.007618691306561232\n","\tBefore adaption: PDE loss: 0.021206215023994446\n","\tBefore adaption: Data loss: 0.012731343507766724\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0384, 0.3638, 0.4523, 0.1455], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001977938514803526\n","\t\tAfter adaption: Boundary condition loss: 0.00029251791437966807\n","\t\tAfter adaption: PDE loss: 0.009592129879372118\n","\t\tAfter adaption: Data loss: 0.0018524966429190014\n","\n","\tTesting: Initial condition loss: 0.004692021291702986\n","\tTesting: Boundary condition loss: 0.012536636553704739\n","\tTesting: PDE loss: 0.021853797137737274\n","\tTesting: Data loss: 0.016893712803721428\n","\n","Epoch 162\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006224154960364103\n","\tBefore adaption: Boundary condition loss: 0.011886639520525932\n","\tBefore adaption: PDE loss: 0.02191893383860588\n","\tBefore adaption: Data loss: 0.016688436269760132\n","tensor(0.0119, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0119, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0648, 0.2741, 0.4776, 0.1836], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017059454826276056\n","\t\tAfter adaption: Boundary condition loss: 0.0007697682314734522\n","\t\tAfter adaption: PDE loss: 0.010468236442060658\n","\t\tAfter adaption: Data loss: 0.003063449656786557\n","\n","\tTesting: Initial condition loss: 0.005528388079255819\n","\tTesting: Boundary condition loss: 0.015394916757941246\n","\tTesting: PDE loss: 0.022110383957624435\n","\tTesting: Data loss: 0.019646668806672096\n","\n","Epoch 163\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00694810226559639\n","\tBefore adaption: Boundary condition loss: 0.014663130976259708\n","\tBefore adaption: PDE loss: 0.022198660299181938\n","\tBefore adaption: Data loss: 0.01940932683646679\n","tensor(0.0147, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0147, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1117, 0.1912, 0.4692, 0.2279], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013281568739986723\n","\t\tAfter adaption: Boundary condition loss: 0.001638324926509665\n","\t\tAfter adaption: PDE loss: 0.01041645421028869\n","\t\tAfter adaption: Data loss: 0.0044229389943604034\n","\n","\tTesting: Initial condition loss: 0.005363802891224623\n","\tTesting: Boundary condition loss: 0.015383655205368996\n","\tTesting: PDE loss: 0.021904990077018738\n","\tTesting: Data loss: 0.02009025402367115\n","\n","Epoch 164\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006776407361030579\n","\tBefore adaption: Boundary condition loss: 0.014665975235402584\n","\tBefore adaption: PDE loss: 0.02197466976940632\n","\tBefore adaption: Data loss: 0.019847465679049492\n","tensor(0.0147, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0147, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1603, 0.1396, 0.4355, 0.2646], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009462556568422368\n","\t\tAfter adaption: Boundary condition loss: 0.0023510617198308215\n","\t\tAfter adaption: PDE loss: 0.009569542105836725\n","\t\tAfter adaption: Data loss: 0.005251088851713123\n","\n","\tTesting: Initial condition loss: 0.004306809511035681\n","\tTesting: Boundary condition loss: 0.01238551177084446\n","\tTesting: PDE loss: 0.021250655874609947\n","\tTesting: Data loss: 0.01799798756837845\n","\n","Epoch 165\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0058068884536623955\n","\tBefore adaption: Boundary condition loss: 0.011770094744861126\n","\tBefore adaption: PDE loss: 0.021325698122382164\n","\tBefore adaption: Data loss: 0.017778636887669563\n","tensor(0.0118, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0118, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1949, 0.1167, 0.4001, 0.2884], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006775746391323506\n","\t\tAfter adaption: Boundary condition loss: 0.002293542855365053\n","\t\tAfter adaption: PDE loss: 0.008531697567318966\n","\t\tAfter adaption: Data loss: 0.005127124012804749\n","\n","\tTesting: Initial condition loss: 0.0034164569806307554\n","\tTesting: Boundary condition loss: 0.007749273907393217\n","\tTesting: PDE loss: 0.020360153168439865\n","\tTesting: Data loss: 0.014219566248357296\n","\n","Epoch 166\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004986227490007877\n","\tBefore adaption: Boundary condition loss: 0.007283832412213087\n","\tBefore adaption: PDE loss: 0.020408786833286285\n","\tBefore adaption: Data loss: 0.014045428484678268\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2113, 0.1087, 0.3786, 0.3014], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005420475208351196\n","\t\tAfter adaption: Boundary condition loss: 0.0015390346585378134\n","\t\tAfter adaption: PDE loss: 0.007726416790600917\n","\t\tAfter adaption: Data loss: 0.004233480346991327\n","\n","\tTesting: Initial condition loss: 0.0041246977634727955\n","\tTesting: Boundary condition loss: 0.003459376050159335\n","\tTesting: PDE loss: 0.019414514303207397\n","\tTesting: Data loss: 0.010195617564022541\n","\n","Epoch 167\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005608771461993456\n","\tBefore adaption: Boundary condition loss: 0.003161464584991336\n","\tBefore adaption: PDE loss: 0.019434425979852676\n","\tBefore adaption: Data loss: 0.010075174272060394\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.2103, 0.1072, 0.3762, 0.3063], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006015304398571834\n","\t\tAfter adaption: Boundary condition loss: 0.000664918424328706\n","\t\tAfter adaption: PDE loss: 0.007310370183864661\n","\t\tAfter adaption: Data loss: 0.0030857862241086445\n","\n","\tTesting: Initial condition loss: 0.007464143447577953\n","\tTesting: Boundary condition loss: 0.0008989224443212152\n","\tTesting: PDE loss: 0.018572209402918816\n","\tTesting: Data loss: 0.0071672056801617146\n","\n","Epoch 168\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008572591468691826\n","\tBefore adaption: Boundary condition loss: 0.000764042604714632\n","\tBefore adaption: PDE loss: 0.01856490783393383\n","\tBefore adaption: Data loss: 0.007097630295902491\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1922, 0.1123, 0.3928, 0.3027], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009630062126519494\n","\t\tAfter adaption: Boundary condition loss: 0.00014686721779925534\n","\t\tAfter adaption: PDE loss: 0.007291997521237556\n","\t\tAfter adaption: Data loss: 0.002148144207971123\n","\n","\tTesting: Initial condition loss: 0.013348652981221676\n","\tTesting: Boundary condition loss: 0.0002955605450551957\n","\tTesting: PDE loss: 0.017889942973852158\n","\tTesting: Data loss: 0.005670088343322277\n","\n","Epoch 169\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013842207379639149\n","\tBefore adaption: Boundary condition loss: 0.0002787442645058036\n","\tBefore adaption: PDE loss: 0.017850080505013466\n","\tBefore adaption: Data loss: 0.00564150046557188\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1569, 0.1323, 0.4239, 0.2869], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018316744013755599\n","\t\tAfter adaption: Boundary condition loss: 4.372913449369908e-05\n","\t\tAfter adaption: PDE loss: 0.007566377197513086\n","\t\tAfter adaption: Data loss: 0.001618606664661003\n","\n","\tTesting: Initial condition loss: 0.02050810120999813\n","\tTesting: Boundary condition loss: 0.0009701360249891877\n","\tTesting: PDE loss: 0.01736743375658989\n","\tTesting: Data loss: 0.00549695547670126\n","\n","Epoch 170\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020321525633335114\n","\tBefore adaption: Boundary condition loss: 0.0010127788409590721\n","\tBefore adaption: PDE loss: 0.01731879636645317\n","\tBefore adaption: Data loss: 0.005495268385857344\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1085, 0.1811, 0.4554, 0.2549], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003681207637196108\n","\t\tAfter adaption: Boundary condition loss: 0.00010989538139979577\n","\t\tAfter adaption: PDE loss: 0.007887154217429398\n","\t\tAfter adaption: Data loss: 0.0014009238365073195\n","\n","\tTesting: Initial condition loss: 0.02680099569261074\n","\tTesting: Boundary condition loss: 0.0020043300464749336\n","\tTesting: PDE loss: 0.017023315653204918\n","\tTesting: Data loss: 0.005949339363723993\n","\n","Epoch 171\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026100516319274902\n","\tBefore adaption: Boundary condition loss: 0.002062200102955103\n","\tBefore adaption: PDE loss: 0.01695403642952442\n","\tBefore adaption: Data loss: 0.0059637329541146755\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0619, 0.2644, 0.4638, 0.2099], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006899984974995765\n","\t\tAfter adaption: Boundary condition loss: 0.00012773092536568612\n","\t\tAfter adaption: PDE loss: 0.007863721038753298\n","\t\tAfter adaption: Data loss: 0.00125162473357238\n","\n","\tTesting: Initial condition loss: 0.0296452809125185\n","\tTesting: Boundary condition loss: 0.0025880765169858932\n","\tTesting: PDE loss: 0.01694379933178425\n","\tTesting: Data loss: 0.0062356009148061275\n","\n","Epoch 172\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028780579566955566\n","\tBefore adaption: Boundary condition loss: 0.0026540521066635847\n","\tBefore adaption: PDE loss: 0.016855895519256592\n","\tBefore adaption: Data loss: 0.006257446017116308\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0353, 0.3613, 0.4372, 0.1662], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010397116230451916\n","\t\tAfter adaption: Boundary condition loss: 9.370099331780048e-05\n","\t\tAfter adaption: PDE loss: 0.00736964106028712\n","\t\tAfter adaption: Data loss: 0.0010401492618005352\n","\n","\tTesting: Initial condition loss: 0.027163995429873466\n","\tTesting: Boundary condition loss: 0.0023001462686806917\n","\tTesting: PDE loss: 0.01724834367632866\n","\tTesting: Data loss: 0.005873220507055521\n","\n","Epoch 173\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02657163515686989\n","\tBefore adaption: Boundary condition loss: 0.0023810823913663626\n","\tBefore adaption: PDE loss: 0.01717676967382431\n","\tBefore adaption: Data loss: 0.005892662331461906\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0304, 0.4391, 0.3936, 0.1369], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011667137027084265\n","\t\tAfter adaption: Boundary condition loss: 7.248632620757764e-05\n","\t\tAfter adaption: PDE loss: 0.006760337161554818\n","\t\tAfter adaption: Data loss: 0.0008067076655869518\n","\n","\tTesting: Initial condition loss: 0.02002403698861599\n","\tTesting: Boundary condition loss: 0.0013917790492996573\n","\tTesting: PDE loss: 0.01810307987034321\n","\tTesting: Data loss: 0.005093469750136137\n","\n","Epoch 174\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02013351395726204\n","\tBefore adaption: Boundary condition loss: 0.0014675201382488012\n","\tBefore adaption: PDE loss: 0.018014390021562576\n","\tBefore adaption: Data loss: 0.005100216716527939\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0350, 0.4831, 0.3598, 0.1221], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009726111818183109\n","\t\tAfter adaption: Boundary condition loss: 5.1409274901950645e-05\n","\t\tAfter adaption: PDE loss: 0.006480699738946908\n","\t\tAfter adaption: Data loss: 0.0006229222873286857\n","\n","\tTesting: Initial condition loss: 0.011561579070985317\n","\tTesting: Boundary condition loss: 0.0007481054053641856\n","\tTesting: PDE loss: 0.019394448027014732\n","\tTesting: Data loss: 0.004763494245707989\n","\n","Epoch 175\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012533384375274181\n","\tBefore adaption: Boundary condition loss: 0.0007402365445159376\n","\tBefore adaption: PDE loss: 0.01934915781021118\n","\tBefore adaption: Data loss: 0.004748383536934853\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0388, 0.4947, 0.3500, 0.1164], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006200049190072553\n","\t\tAfter adaption: Boundary condition loss: 2.8754191271171932e-05\n","\t\tAfter adaption: PDE loss: 0.006773041264342439\n","\t\tAfter adaption: Data loss: 0.0005528506385767976\n","\n","\tTesting: Initial condition loss: 0.005521014798432589\n","\tTesting: Boundary condition loss: 0.0013437074376270175\n","\tTesting: PDE loss: 0.020996013656258583\n","\tTesting: Data loss: 0.005750587675720453\n","\n","Epoch 176\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007141487207263708\n","\tBefore adaption: Boundary condition loss: 0.0011507777962833643\n","\tBefore adaption: PDE loss: 0.020893197506666183\n","\tBefore adaption: Data loss: 0.005704814102500677\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0388, 0.4761, 0.3684, 0.1166], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003400326321204814\n","\t\tAfter adaption: Boundary condition loss: 4.4660025276976404e-05\n","\t\tAfter adaption: PDE loss: 0.007697818532607736\n","\t\tAfter adaption: Data loss: 0.000665281938678009\n","\n","\tTesting: Initial condition loss: 0.0035374590661376715\n","\tTesting: Boundary condition loss: 0.003552967682480812\n","\tTesting: PDE loss: 0.02247980795800686\n","\tTesting: Data loss: 0.008246900513768196\n","\n","Epoch 177\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005238560028374195\n","\tBefore adaption: Boundary condition loss: 0.003104870207607746\n","\tBefore adaption: PDE loss: 0.022402631118893623\n","\tBefore adaption: Data loss: 0.008163326419889927\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0375, 0.4257, 0.4128, 0.1239], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002230065277733558\n","\t\tAfter adaption: Boundary condition loss: 0.00011657876956957042\n","\t\tAfter adaption: PDE loss: 0.009248424077013083\n","\t\tAfter adaption: Data loss: 0.001011625241541205\n","\n","\tTesting: Initial condition loss: 0.004478557035326958\n","\tTesting: Boundary condition loss: 0.006943294778466225\n","\tTesting: PDE loss: 0.02357427403330803\n","\tTesting: Data loss: 0.011646910570561886\n","\n","Epoch 178\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005988867953419685\n","\tBefore adaption: Boundary condition loss: 0.006224953103810549\n","\tBefore adaption: PDE loss: 0.023528389632701874\n","\tBefore adaption: Data loss: 0.011521018110215664\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0425, 0.3444, 0.4707, 0.1424], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020623982610873904\n","\t\tAfter adaption: Boundary condition loss: 0.00026483155258843826\n","\t\tAfter adaption: PDE loss: 0.011073820891155646\n","\t\tAfter adaption: Data loss: 0.0016408972851782219\n","\n","\tTesting: Initial condition loss: 0.006191368214786053\n","\tTesting: Boundary condition loss: 0.010205531492829323\n","\tTesting: PDE loss: 0.02405516244471073\n","\tTesting: Data loss: 0.014932856895029545\n","\n","Epoch 179\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007494278252124786\n","\tBefore adaption: Boundary condition loss: 0.009283364750444889\n","\tBefore adaption: PDE loss: 0.02404545433819294\n","\tBefore adaption: Data loss: 0.014768284745514393\n","tensor(0.0093, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0093, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0625, 0.2511, 0.5130, 0.1735], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018815623033662178\n","\t\tAfter adaption: Boundary condition loss: 0.0005798546847785459\n","\t\tAfter adaption: PDE loss: 0.012335336745409625\n","\t\tAfter adaption: Data loss: 0.0025618657470055646\n","\n","\tTesting: Initial condition loss: 0.007073226850479841\n","\tTesting: Boundary condition loss: 0.012072726152837276\n","\tTesting: PDE loss: 0.023952918127179146\n","\tTesting: Data loss: 0.017140796408057213\n","\n","Epoch 180\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008276478387415409\n","\tBefore adaption: Boundary condition loss: 0.011068901978433132\n","\tBefore adaption: PDE loss: 0.023948436602950096\n","\tBefore adaption: Data loss: 0.01694873347878456\n","tensor(0.0111, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0111, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0958, 0.1793, 0.5151, 0.2098], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001483837575814937\n","\t\tAfter adaption: Boundary condition loss: 0.001060459826056599\n","\t\tAfter adaption: PDE loss: 0.012335396039914865\n","\t\tAfter adaption: Data loss: 0.003556340392964833\n","\n","\tTesting: Initial condition loss: 0.006513615138828754\n","\tTesting: Boundary condition loss: 0.011799944564700127\n","\tTesting: PDE loss: 0.0233292318880558\n","\tTesting: Data loss: 0.017605340108275414\n","\n","Epoch 181\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007776652462780476\n","\tBefore adaption: Boundary condition loss: 0.010846549645066261\n","\tBefore adaption: PDE loss: 0.023336660116910934\n","\tBefore adaption: Data loss: 0.017402615398168564\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1302, 0.1440, 0.4847, 0.2411], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001120184010929203\n","\t\tAfter adaption: Boundary condition loss: 0.0014117466640562245\n","\t\tAfter adaption: PDE loss: 0.011311675967917892\n","\t\tAfter adaption: Data loss: 0.004195457248315019\n","\n","\tTesting: Initial condition loss: 0.004932845011353493\n","\tTesting: Boundary condition loss: 0.009427672252058983\n","\tTesting: PDE loss: 0.022366616874933243\n","\tTesting: Data loss: 0.016187215223908424\n","\n","Epoch 182\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006353657692670822\n","\tBefore adaption: Boundary condition loss: 0.0086347796022892\n","\tBefore adaption: PDE loss: 0.02235632762312889\n","\tBefore adaption: Data loss: 0.015993911772966385\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1551, 0.1330, 0.4486, 0.2633], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008451658937787973\n","\t\tAfter adaption: Boundary condition loss: 0.001339046572342768\n","\t\tAfter adaption: PDE loss: 0.010029640247672786\n","\t\tAfter adaption: Data loss: 0.004210829629307329\n","\n","\tTesting: Initial condition loss: 0.0035332704428583384\n","\tTesting: Boundary condition loss: 0.0059160818345844746\n","\tTesting: PDE loss: 0.021184615790843964\n","\tTesting: Data loss: 0.01343492977321148\n","\n","Epoch 183\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005070736166089773\n","\tBefore adaption: Boundary condition loss: 0.00535878399387002\n","\tBefore adaption: PDE loss: 0.02113661728799343\n","\tBefore adaption: Data loss: 0.013268426060676575\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1670, 0.1301, 0.4250, 0.2779], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006598210644870227\n","\t\tAfter adaption: Boundary condition loss: 0.0008950300057794922\n","\t\tAfter adaption: PDE loss: 0.008982057984791524\n","\t\tAfter adaption: Data loss: 0.0036873341726908026\n","\n","\tTesting: Initial condition loss: 0.00372277176938951\n","\tTesting: Boundary condition loss: 0.002768276957795024\n","\tTesting: PDE loss: 0.019912725314497948\n","\tTesting: Data loss: 0.010362477973103523\n","\n","Epoch 184\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005190388765186071\n","\tBefore adaption: Boundary condition loss: 0.0024394819047302008\n","\tBefore adaption: PDE loss: 0.01983967050909996\n","\tBefore adaption: Data loss: 0.010233322158455849\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1653, 0.1279, 0.4200, 0.2868], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006639902901428691\n","\t\tAfter adaption: Boundary condition loss: 0.00040332844974431834\n","\t\tAfter adaption: PDE loss: 0.00833218650831017\n","\t\tAfter adaption: Data loss: 0.0029345404528052115\n","\n","\tTesting: Initial condition loss: 0.006387387402355671\n","\tTesting: Boundary condition loss: 0.0008752129506319761\n","\tTesting: PDE loss: 0.018650107085704803\n","\tTesting: Data loss: 0.007909771986305714\n","\n","Epoch 185\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007542270235717297\n","\tBefore adaption: Boundary condition loss: 0.0007330456865020096\n","\tBefore adaption: PDE loss: 0.018596606329083443\n","\tBefore adaption: Data loss: 0.007821557112038136\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1501, 0.1279, 0.4329, 0.2891], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009644007975005447\n","\t\tAfter adaption: Boundary condition loss: 0.00011003819977656642\n","\t\tAfter adaption: PDE loss: 0.008051259880112516\n","\t\tAfter adaption: Data loss: 0.0022610580030731522\n","\n","\tTesting: Initial condition loss: 0.011518730781972408\n","\tTesting: Boundary condition loss: 0.0003242296807002276\n","\tTesting: PDE loss: 0.01752489246428013\n","\tTesting: Data loss: 0.006530205253511667\n","\n","Epoch 186\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012095446698367596\n","\tBefore adaption: Boundary condition loss: 0.0002885541180148721\n","\tBefore adaption: PDE loss: 0.017472365871071815\n","\tBefore adaption: Data loss: 0.006479447707533836\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1218, 0.1389, 0.4578, 0.2815], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016798167483533964\n","\t\tAfter adaption: Boundary condition loss: 3.5153425027652566e-05\n","\t\tAfter adaption: PDE loss: 0.007999027726829592\n","\t\tAfter adaption: Data loss: 0.0018238567082148054\n","\n","\tTesting: Initial condition loss: 0.018239909783005714\n","\tTesting: Boundary condition loss: 0.0007296798285096884\n","\tTesting: PDE loss: 0.016525866463780403\n","\tTesting: Data loss: 0.006171672139316797\n","\n","Epoch 187\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018101420253515244\n","\tBefore adaption: Boundary condition loss: 0.0007339373114518821\n","\tBefore adaption: PDE loss: 0.01648346707224846\n","\tBefore adaption: Data loss: 0.006150910165160894\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0843, 0.1752, 0.4804, 0.2600], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031716381436460573\n","\t\tAfter adaption: Boundary condition loss: 6.190688790247476e-05\n","\t\tAfter adaption: PDE loss: 0.007919377708590244\n","\t\tAfter adaption: Data loss: 0.0015991885382639068\n","\n","\tTesting: Initial condition loss: 0.024870626628398895\n","\tTesting: Boundary condition loss: 0.0014766874955967069\n","\tTesting: PDE loss: 0.015680404379963875\n","\tTesting: Data loss: 0.006433132570236921\n","\n","Epoch 188\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02409476414322853\n","\tBefore adaption: Boundary condition loss: 0.0014724964275956154\n","\tBefore adaption: PDE loss: 0.015648672357201576\n","\tBefore adaption: Data loss: 0.006433352828025818\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0490, 0.2461, 0.4796, 0.2253], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005930447732361677\n","\t\tAfter adaption: Boundary condition loss: 7.211736060513537e-05\n","\t\tAfter adaption: PDE loss: 0.007504531484125998\n","\t\tAfter adaption: Data loss: 0.0014496266497459323\n","\n","\tTesting: Initial condition loss: 0.028983818367123604\n","\tTesting: Boundary condition loss: 0.0019197170622646809\n","\tTesting: PDE loss: 0.01514038722962141\n","\tTesting: Data loss: 0.006758681498467922\n","\n","Epoch 189\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02792457863688469\n","\tBefore adaption: Boundary condition loss: 0.0018992837285622954\n","\tBefore adaption: PDE loss: 0.015074332244694233\n","\tBefore adaption: Data loss: 0.006768811959773302\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0286, 0.3388, 0.4450, 0.1876], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009461620687462799\n","\t\tAfter adaption: Boundary condition loss: 5.439681993880535e-05\n","\t\tAfter adaption: PDE loss: 0.006707505049960667\n","\t\tAfter adaption: Data loss: 0.0012696216293264658\n","\n","\tTesting: Initial condition loss: 0.028429441154003143\n","\tTesting: Boundary condition loss: 0.0016565973637625575\n","\tTesting: PDE loss: 0.014989622868597507\n","\tTesting: Data loss: 0.006732173264026642\n","\n","Epoch 190\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027585333213210106\n","\tBefore adaption: Boundary condition loss: 0.001643627299927175\n","\tBefore adaption: PDE loss: 0.014912822283804417\n","\tBefore adaption: Data loss: 0.006738588213920593\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0242, 0.4239, 0.3931, 0.1588], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011692819818820635\n","\t\tAfter adaption: Boundary condition loss: 3.9779511511172794e-05\n","\t\tAfter adaption: PDE loss: 0.005861887151736384\n","\t\tAfter adaption: Data loss: 0.001070373326113259\n","\n","\tTesting: Initial condition loss: 0.022856390103697777\n","\tTesting: Boundary condition loss: 0.0008393513271585107\n","\tTesting: PDE loss: 0.015323678962886333\n","\tTesting: Data loss: 0.00643621850758791\n","\n","Epoch 191\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022749923169612885\n","\tBefore adaption: Boundary condition loss: 0.0008453961345367134\n","\tBefore adaption: PDE loss: 0.015269901603460312\n","\tBefore adaption: Data loss: 0.006424928084015846\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0265, 0.4817, 0.3490, 0.1428], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010959447233178581\n","\t\tAfter adaption: Boundary condition loss: 2.2383068862497948e-05\n","\t\tAfter adaption: PDE loss: 0.005328812648051029\n","\t\tAfter adaption: Data loss: 0.0009175623897362059\n","\n","\tTesting: Initial condition loss: 0.014743965119123459\n","\tTesting: Boundary condition loss: 0.0002543679147493094\n","\tTesting: PDE loss: 0.016227543354034424\n","\tTesting: Data loss: 0.006562404800206423\n","\n","Epoch 192\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0155332637950778\n","\tBefore adaption: Boundary condition loss: 0.00023359367332886904\n","\tBefore adaption: PDE loss: 0.016164660453796387\n","\tBefore adaption: Data loss: 0.006520647089928389\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0278, 0.5085, 0.3265, 0.1372], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007898821505471719\n","\t\tAfter adaption: Boundary condition loss: 6.499767891248596e-06\n","\t\tAfter adaption: PDE loss: 0.0052773852432620475\n","\t\tAfter adaption: Data loss: 0.0008945537037491008\n","\n","\tTesting: Initial condition loss: 0.007702571339905262\n","\tTesting: Boundary condition loss: 0.0008946461020968854\n","\tTesting: PDE loss: 0.017538415268063545\n","\tTesting: Data loss: 0.007948195561766624\n","\n","Epoch 193\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009257935918867588\n","\tBefore adaption: Boundary condition loss: 0.000753908243495971\n","\tBefore adaption: PDE loss: 0.017447547987103462\n","\tBefore adaption: Data loss: 0.007866325788199902\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0260, 0.5041, 0.3293, 0.1405], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004666590774330858\n","\t\tAfter adaption: Boundary condition loss: 1.9636722839613858e-05\n","\t\tAfter adaption: PDE loss: 0.005746207408033832\n","\t\tAfter adaption: Data loss: 0.0011055927485010713\n","\n","\tTesting: Initial condition loss: 0.004168893676251173\n","\tTesting: Boundary condition loss: 0.003271329915151\n","\tTesting: PDE loss: 0.018957218155264854\n","\tTesting: Data loss: 0.010861939750611782\n","\n","Epoch 194\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006073636934161186\n","\tBefore adaption: Boundary condition loss: 0.0029022509697824717\n","\tBefore adaption: PDE loss: 0.01890355348587036\n","\tBefore adaption: Data loss: 0.010734189301729202\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0243, 0.4651, 0.3558, 0.1548], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002824608843275202\n","\t\tAfter adaption: Boundary condition loss: 7.039542672929013e-05\n","\t\tAfter adaption: PDE loss: 0.006726541616501012\n","\t\tAfter adaption: Data loss: 0.0016621785924727346\n","\n","\tTesting: Initial condition loss: 0.004105397034436464\n","\tTesting: Boundary condition loss: 0.007005748338997364\n","\tTesting: PDE loss: 0.02030358649790287\n","\tTesting: Data loss: 0.0146611537784338\n","\n","Epoch 195\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005860826466232538\n","\tBefore adaption: Boundary condition loss: 0.0063636573031544685\n","\tBefore adaption: PDE loss: 0.020262915641069412\n","\tBefore adaption: Data loss: 0.01448951568454504\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0306, 0.3893, 0.3966, 0.1836], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022815026314822007\n","\t\tAfter adaption: Boundary condition loss: 0.0001946377283096287\n","\t\tAfter adaption: PDE loss: 0.008035351503273554\n","\t\tAfter adaption: Data loss: 0.0026599759998112873\n","\n","\tTesting: Initial condition loss: 0.005674461368471384\n","\tTesting: Boundary condition loss: 0.010630414821207523\n","\tTesting: PDE loss: 0.021368222311139107\n","\tTesting: Data loss: 0.018054693937301636\n","\n","Epoch 196\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007078975439071655\n","\tBefore adaption: Boundary condition loss: 0.009753750637173653\n","\tBefore adaption: PDE loss: 0.02129920944571495\n","\tBefore adaption: Data loss: 0.017850298434495926\n","tensor(0.0098, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0098, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0542, 0.2905, 0.4303, 0.2250], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020562397662775927\n","\t\tAfter adaption: Boundary condition loss: 0.0005289997418871296\n","\t\tAfter adaption: PDE loss: 0.00916550610991639\n","\t\tAfter adaption: Data loss: 0.004015807206721445\n","\n","\tTesting: Initial condition loss: 0.006852855905890465\n","\tTesting: Boundary condition loss: 0.012484119273722172\n","\tTesting: PDE loss: 0.021995455026626587\n","\tTesting: Data loss: 0.019702577963471413\n","\n","Epoch 197\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008014959283173084\n","\tBefore adaption: Boundary condition loss: 0.011480838991701603\n","\tBefore adaption: PDE loss: 0.02192249894142151\n","\tBefore adaption: Data loss: 0.019485630095005035\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0929, 0.2033, 0.4369, 0.2669], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016292546135862533\n","\t\tAfter adaption: Boundary condition loss: 0.0010667113023866328\n","\t\tAfter adaption: PDE loss: 0.009578967551444835\n","\t\tAfter adaption: Data loss: 0.0052000103824294715\n","\n","\tTesting: Initial condition loss: 0.006623107008635998\n","\tTesting: Boundary condition loss: 0.01166602224111557\n","\tTesting: PDE loss: 0.0222060177475214\n","\tTesting: Data loss: 0.018855473026633263\n","\n","Epoch 198\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007754415273666382\n","\tBefore adaption: Boundary condition loss: 0.010680649429559708\n","\tBefore adaption: PDE loss: 0.022181054577231407\n","\tBefore adaption: Data loss: 0.018650731071829796\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1314, 0.1525, 0.4199, 0.2962], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011825762101121636\n","\t\tAfter adaption: Boundary condition loss: 0.001403835196341449\n","\t\tAfter adaption: PDE loss: 0.00931298665659486\n","\t\tAfter adaption: Data loss: 0.005524285570147045\n","\n","\tTesting: Initial condition loss: 0.00515661621466279\n","\tTesting: Boundary condition loss: 0.008664191700518131\n","\tTesting: PDE loss: 0.022217977792024612\n","\tTesting: Data loss: 0.015791455283761024\n","\n","Epoch 199\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00646620849147439\n","\tBefore adaption: Boundary condition loss: 0.007834491319954395\n","\tBefore adaption: PDE loss: 0.02216256968677044\n","\tBefore adaption: Data loss: 0.015621562488377094\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1573, 0.1328, 0.3995, 0.3103], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008589833092525155\n","\t\tAfter adaption: Boundary condition loss: 0.001232747977903156\n","\t\tAfter adaption: PDE loss: 0.008853834704327136\n","\t\tAfter adaption: Data loss: 0.004847591932738954\n","\n","\tTesting: Initial condition loss: 0.0036333969328552485\n","\tTesting: Boundary condition loss: 0.005007581785321236\n","\tTesting: PDE loss: 0.02202581614255905\n","\tTesting: Data loss: 0.011720510199666023\n","\n","Epoch 200\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005158614832907915\n","\tBefore adaption: Boundary condition loss: 0.004425094462931156\n","\tBefore adaption: PDE loss: 0.022005736827850342\n","\tBefore adaption: Data loss: 0.01159717794507742\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1676, 0.1278, 0.3918, 0.3129], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006592222531101309\n","\t\tAfter adaption: Boundary condition loss: 0.0007415350037357531\n","\t\tAfter adaption: PDE loss: 0.008620820397847798\n","\t\tAfter adaption: Data loss: 0.003628536533711\n","\n","\tTesting: Initial condition loss: 0.0034816258121281862\n","\tTesting: Boundary condition loss: 0.0022245312575250864\n","\tTesting: PDE loss: 0.021770263090729713\n","\tTesting: Data loss: 0.008050195872783661\n","\n","Epoch 201\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005037633236497641\n","\tBefore adaption: Boundary condition loss: 0.0019008979434147477\n","\tBefore adaption: PDE loss: 0.021782606840133667\n","\tBefore adaption: Data loss: 0.007971496321260929\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1628, 0.1270, 0.4036, 0.3066], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006397934264792661\n","\t\tAfter adaption: Boundary condition loss: 0.0003094080493847659\n","\t\tAfter adaption: PDE loss: 0.008792522818753952\n","\t\tAfter adaption: Data loss: 0.0024438920346377194\n","\n","\tTesting: Initial condition loss: 0.005575668998062611\n","\tTesting: Boundary condition loss: 0.0010593105107545853\n","\tTesting: PDE loss: 0.02140709199011326\n","\tTesting: Data loss: 0.005675921216607094\n","\n","Epoch 202\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0068960124626755714\n","\tBefore adaption: Boundary condition loss: 0.0009409329504705966\n","\tBefore adaption: PDE loss: 0.021452007815241814\n","\tBefore adaption: Data loss: 0.005632487591356039\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1441, 0.1286, 0.4365, 0.2908], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008870251431994105\n","\t\tAfter adaption: Boundary condition loss: 0.0001355509575607147\n","\t\tAfter adaption: PDE loss: 0.009363508403280645\n","\t\tAfter adaption: Data loss: 0.0016380658960749384\n","\n","\tTesting: Initial condition loss: 0.009798168204724789\n","\tTesting: Boundary condition loss: 0.0012232701992616057\n","\tTesting: PDE loss: 0.020926987752318382\n","\tTesting: Data loss: 0.004736526869237423\n","\n","Epoch 203\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010740431025624275\n","\tBefore adaption: Boundary condition loss: 0.0012339865788817406\n","\tBefore adaption: PDE loss: 0.020893897861242294\n","\tBefore adaption: Data loss: 0.004719060845673084\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1140, 0.1385, 0.4846, 0.2629], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014871128512697496\n","\t\tAfter adaption: Boundary condition loss: 0.00014066266200926447\n","\t\tAfter adaption: PDE loss: 0.010125202946625507\n","\t\tAfter adaption: Data loss: 0.0012408726210289896\n","\n","\tTesting: Initial condition loss: 0.015357175841927528\n","\tTesting: Boundary condition loss: 0.0019961553625762463\n","\tTesting: PDE loss: 0.020057344809174538\n","\tTesting: Data loss: 0.004820419009774923\n","\n","Epoch 204\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01584456115961075\n","\tBefore adaption: Boundary condition loss: 0.0020680075976997614\n","\tBefore adaption: PDE loss: 0.020043548196554184\n","\tBefore adaption: Data loss: 0.0048208474181592464\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0799, 0.1677, 0.5297, 0.2227], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0026578049788837745\n","\t\tAfter adaption: Boundary condition loss: 0.00016518116486403776\n","\t\tAfter adaption: PDE loss: 0.010617210019062712\n","\t\tAfter adaption: Data loss: 0.0010734854908327732\n","\n","\tTesting: Initial condition loss: 0.020930176600813866\n","\tTesting: Boundary condition loss: 0.002695944858714938\n","\tTesting: PDE loss: 0.018917134031653404\n","\tTesting: Data loss: 0.005340988282114267\n","\n","Epoch 205\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021039245650172234\n","\tBefore adaption: Boundary condition loss: 0.0027760087978094816\n","\tBefore adaption: PDE loss: 0.01892094314098358\n","\tBefore adaption: Data loss: 0.0053541213274002075\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0541, 0.2238, 0.5441, 0.1780], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004708654103475101\n","\t\tAfter adaption: Boundary condition loss: 0.0001503000652685701\n","\t\tAfter adaption: PDE loss: 0.01029480916896464\n","\t\tAfter adaption: Data loss: 0.0009528081116694524\n","\n","\tTesting: Initial condition loss: 0.024769769981503487\n","\tTesting: Boundary condition loss: 0.0028375666588544846\n","\tTesting: PDE loss: 0.017696235328912735\n","\tTesting: Data loss: 0.005810660310089588\n","\n","Epoch 206\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024763911962509155\n","\tBefore adaption: Boundary condition loss: 0.0028963617514818907\n","\tBefore adaption: PDE loss: 0.01771456189453602\n","\tBefore adaption: Data loss: 0.0058302185498178005\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0446, 0.2977, 0.5153, 0.1424], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0073727643194378785\n","\t\tAfter adaption: Boundary condition loss: 0.000129112962769573\n","\t\tAfter adaption: PDE loss: 0.009128267258107588\n","\t\tAfter adaption: Data loss: 0.0008302383922169238\n","\n","\tTesting: Initial condition loss: 0.025229958817362785\n","\tTesting: Boundary condition loss: 0.0022321694996207952\n","\tTesting: PDE loss: 0.016669074073433876\n","\tTesting: Data loss: 0.0059966593980789185\n","\n","Epoch 207\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025376638397574425\n","\tBefore adaption: Boundary condition loss: 0.002265285002067685\n","\tBefore adaption: PDE loss: 0.016659695655107498\n","\tBefore adaption: Data loss: 0.006012219935655594\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0462, 0.3696, 0.4614, 0.1228], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00937836414433727\n","\t\tAfter adaption: Boundary condition loss: 0.00010466400325130202\n","\t\tAfter adaption: PDE loss: 0.00768726644357088\n","\t\tAfter adaption: Data loss: 0.0007383034954647781\n","\n","\tTesting: Initial condition loss: 0.021723348647356033\n","\tTesting: Boundary condition loss: 0.0011342369252815843\n","\tTesting: PDE loss: 0.01604505255818367\n","\tTesting: Data loss: 0.006106122862547636\n","\n","Epoch 208\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02224789373576641\n","\tBefore adaption: Boundary condition loss: 0.0011467315489426255\n","\tBefore adaption: PDE loss: 0.01604040339589119\n","\tBefore adaption: Data loss: 0.006102041341364384\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0489, 0.4252, 0.4097, 0.1162], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009460612744038617\n","\t\tAfter adaption: Boundary condition loss: 5.603940441142407e-05\n","\t\tAfter adaption: PDE loss: 0.006571096077326427\n","\t\tAfter adaption: Data loss: 0.0007092745125783165\n","\n","\tTesting: Initial condition loss: 0.015504450537264347\n","\tTesting: Boundary condition loss: 0.00031080649932846427\n","\tTesting: PDE loss: 0.01594662480056286\n","\tTesting: Data loss: 0.006820051930844784\n","\n","Epoch 209\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016573773697018623\n","\tBefore adaption: Boundary condition loss: 0.0002908107708208263\n","\tBefore adaption: PDE loss: 0.01593751646578312\n","\tBefore adaption: Data loss: 0.006778276525437832\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0469, 0.4594, 0.3755, 0.1182], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007614259981113524\n","\t\tAfter adaption: Boundary condition loss: 1.3629776628366364e-05\n","\t\tAfter adaption: PDE loss: 0.005985307008652998\n","\t\tAfter adaption: Data loss: 0.0008009693772826087\n","\n","\tTesting: Initial condition loss: 0.009247634559869766\n","\tTesting: Boundary condition loss: 0.0007033151923678815\n","\tTesting: PDE loss: 0.016320057213306427\n","\tTesting: Data loss: 0.008944308385252953\n","\n","Epoch 210\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010777435265481472\n","\tBefore adaption: Boundary condition loss: 0.0006189465057104826\n","\tBefore adaption: PDE loss: 0.0163443423807621\n","\tBefore adaption: Data loss: 0.008847170509397984\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0399, 0.4688, 0.3632, 0.1281], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005052098691815871\n","\t\tAfter adaption: Boundary condition loss: 2.471787586974411e-05\n","\t\tAfter adaption: PDE loss: 0.005935915710922006\n","\t\tAfter adaption: Data loss: 0.0011334945791219811\n","\n","\tTesting: Initial condition loss: 0.005199408624321222\n","\tTesting: Boundary condition loss: 0.003015244612470269\n","\tTesting: PDE loss: 0.017074597999453545\n","\tTesting: Data loss: 0.01278844103217125\n","\n","Epoch 211\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006994419731199741\n","\tBefore adaption: Boundary condition loss: 0.0028336006216704845\n","\tBefore adaption: PDE loss: 0.017086803913116455\n","\tBefore adaption: Data loss: 0.012624379247426987\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0323, 0.4469, 0.3704, 0.1504], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031257710421895906\n","\t\tAfter adaption: Boundary condition loss: 9.16181659031589e-05\n","\t\tAfter adaption: PDE loss: 0.006328789750640453\n","\t\tAfter adaption: Data loss: 0.0018984734890698622\n","\n","\tTesting: Initial condition loss: 0.003970688674598932\n","\tTesting: Boundary condition loss: 0.0070040239952504635\n","\tTesting: PDE loss: 0.017974337562918663\n","\tTesting: Data loss: 0.017689771950244904\n","\n","Epoch 212\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005740944296121597\n","\tBefore adaption: Boundary condition loss: 0.006691432558000088\n","\tBefore adaption: PDE loss: 0.0179690420627594\n","\tBefore adaption: Data loss: 0.017458245158195496\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0338, 0.3874, 0.3879, 0.1908], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022243169097458004\n","\t\tAfter adaption: Boundary condition loss: 0.0002263147531992549\n","\t\tAfter adaption: PDE loss: 0.006970538933775678\n","\t\tAfter adaption: Data loss: 0.003331224116212296\n","\n","\tTesting: Initial condition loss: 0.004503609612584114\n","\tTesting: Boundary condition loss: 0.01109334733337164\n","\tTesting: PDE loss: 0.018759168684482574\n","\tTesting: Data loss: 0.022100143134593964\n","\n","Epoch 213\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006091234274208546\n","\tBefore adaption: Boundary condition loss: 0.010664278641343117\n","\tBefore adaption: PDE loss: 0.018746593967080116\n","\tBefore adaption: Data loss: 0.021816473454236984\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0554, 0.2980, 0.3988, 0.2478], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001815262953288765\n","\t\tAfter adaption: Boundary condition loss: 0.0005906850697841064\n","\t\tAfter adaption: PDE loss: 0.007475802854447709\n","\t\tAfter adaption: Data loss: 0.005406479326375198\n","\n","\tTesting: Initial condition loss: 0.005193069577217102\n","\tTesting: Boundary condition loss: 0.013181942515075207\n","\tTesting: PDE loss: 0.019301196560263634\n","\tTesting: Data loss: 0.024167459458112717\n","\n","Epoch 214\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006614972837269306\n","\tBefore adaption: Boundary condition loss: 0.01268075592815876\n","\tBefore adaption: PDE loss: 0.019259367138147354\n","\tBefore adaption: Data loss: 0.023864222690463066\n","tensor(0.0127, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0127, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0955, 0.2089, 0.3898, 0.3058], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013821668860637716\n","\t\tAfter adaption: Boundary condition loss: 0.0012113330256874966\n","\t\tAfter adaption: PDE loss: 0.007506637379205362\n","\t\tAfter adaption: Data loss: 0.0072968138922370075\n","\n","\tTesting: Initial condition loss: 0.0050071533769369125\n","\tTesting: Boundary condition loss: 0.011990509927272797\n","\tTesting: PDE loss: 0.01955818571150303\n","\tTesting: Data loss: 0.022747348994016647\n","\n","Epoch 215\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00640740105882287\n","\tBefore adaption: Boundary condition loss: 0.011484029702842236\n","\tBefore adaption: PDE loss: 0.01952040195465088\n","\tBefore adaption: Data loss: 0.022466421127319336\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1374, 0.1485, 0.3668, 0.3472], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009516294586365226\n","\t\tAfter adaption: Boundary condition loss: 0.0015780382265312503\n","\t\tAfter adaption: PDE loss: 0.0071607332927444345\n","\t\tAfter adaption: Data loss: 0.007801118985023448\n","\n","\tTesting: Initial condition loss: 0.004084066953510046\n","\tTesting: Boundary condition loss: 0.008220064453780651\n","\tTesting: PDE loss: 0.019692312926054\n","\tTesting: Data loss: 0.01831517368555069\n","\n","Epoch 216\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005581897217780352\n","\tBefore adaption: Boundary condition loss: 0.007777190767228603\n","\tBefore adaption: PDE loss: 0.019669881090521812\n","\tBefore adaption: Data loss: 0.01809314265847206\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1661, 0.1192, 0.3467, 0.3680], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006654838784298416\n","\t\tAfter adaption: Boundary condition loss: 0.0012919886204101885\n","\t\tAfter adaption: PDE loss: 0.006819328854248977\n","\t\tAfter adaption: Data loss: 0.006657621052922201\n","\n","\tTesting: Initial condition loss: 0.0035143778659403324\n","\tTesting: Boundary condition loss: 0.004030333831906319\n","\tTesting: PDE loss: 0.01986347883939743\n","\tTesting: Data loss: 0.012757422402501106\n","\n","Epoch 217\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005088649224489927\n","\tBefore adaption: Boundary condition loss: 0.0037019699811935425\n","\tBefore adaption: PDE loss: 0.019896136596798897\n","\tBefore adaption: Data loss: 0.012610199861228466\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1770, 0.1092, 0.3415, 0.3723], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005557590044057563\n","\t\tAfter adaption: Boundary condition loss: 0.0006551454897424695\n","\t\tAfter adaption: PDE loss: 0.0067949828421757985\n","\t\tAfter adaption: Data loss: 0.004694645514335658\n","\n","\tTesting: Initial condition loss: 0.0045010787434875965\n","\tTesting: Boundary condition loss: 0.001326459227129817\n","\tTesting: PDE loss: 0.020188795402646065\n","\tTesting: Data loss: 0.00809630285948515\n","\n","Epoch 218\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006018769461661577\n","\tBefore adaption: Boundary condition loss: 0.0011488228337839246\n","\tBefore adaption: PDE loss: 0.020266355946660042\n","\tBefore adaption: Data loss: 0.008016061969101429\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1703, 0.1095, 0.3569, 0.3634], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006588745620137687\n","\t\tAfter adaption: Boundary condition loss: 0.00019558778324393252\n","\t\tAfter adaption: PDE loss: 0.007232170650798407\n","\t\tAfter adaption: Data loss: 0.002913223177399781\n","\n","\tTesting: Initial condition loss: 0.0076078493148088455\n","\tTesting: Boundary condition loss: 0.0007777870632708073\n","\tTesting: PDE loss: 0.02062445692718029\n","\tTesting: Data loss: 0.005414818413555622\n","\n","Epoch 219\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008862538263201714\n","\tBefore adaption: Boundary condition loss: 0.0007183253183029592\n","\tBefore adaption: PDE loss: 0.020708627998828888\n","\tBefore adaption: Data loss: 0.0053807818330824375\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1471, 0.1188, 0.3942, 0.3400], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010525634367549621\n","\t\tAfter adaption: Boundary condition loss: 0.00010564916693216715\n","\t\tAfter adaption: PDE loss: 0.008162922563300673\n","\t\tAfter adaption: Data loss: 0.0018293447869200475\n","\n","\tTesting: Initial condition loss: 0.012452755123376846\n","\tTesting: Boundary condition loss: 0.0017400281503796577\n","\tTesting: PDE loss: 0.020949356257915497\n","\tTesting: Data loss: 0.0046201590448617935\n","\n","Epoch 220\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013317368924617767\n","\tBefore adaption: Boundary condition loss: 0.0017620512517169118\n","\tBefore adaption: PDE loss: 0.021022602915763855\n","\tBefore adaption: Data loss: 0.004613347351551056\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1111, 0.1431, 0.4479, 0.2979], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019051392083584751\n","\t\tAfter adaption: Boundary condition loss: 0.00019580419636347919\n","\t\tAfter adaption: PDE loss: 0.009416570652332448\n","\t\tAfter adaption: Data loss: 0.0013742892643672329\n","\n","\tTesting: Initial condition loss: 0.017870139330625534\n","\tTesting: Boundary condition loss: 0.003188053611665964\n","\tTesting: PDE loss: 0.020996911451220512\n","\tTesting: Data loss: 0.0049524069763720036\n","\n","Epoch 221\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018320871517062187\n","\tBefore adaption: Boundary condition loss: 0.0032572823110967875\n","\tBefore adaption: PDE loss: 0.021068518981337547\n","\tBefore adaption: Data loss: 0.004960077814757824\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0739, 0.1903, 0.4973, 0.2384], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0034867049873223187\n","\t\tAfter adaption: Boundary condition loss: 0.00024087112829988187\n","\t\tAfter adaption: PDE loss: 0.010478014223065754\n","\t\tAfter adaption: Data loss: 0.0011825203644387522\n","\n","\tTesting: Initial condition loss: 0.022309081628918648\n","\tTesting: Boundary condition loss: 0.004214408341795206\n","\tTesting: PDE loss: 0.0207027867436409\n","\tTesting: Data loss: 0.005516777280718088\n","\n","Epoch 222\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022460289299488068\n","\tBefore adaption: Boundary condition loss: 0.004296871367841959\n","\tBefore adaption: PDE loss: 0.020800089463591576\n","\tBefore adaption: Data loss: 0.005532851908355951\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0527, 0.2571, 0.5130, 0.1772], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005774949704898666\n","\t\tAfter adaption: Boundary condition loss: 0.0002265864525154123\n","\t\tAfter adaption: PDE loss: 0.010670028725504615\n","\t\tAfter adaption: Data loss: 0.0009802481294517412\n","\n","\tTesting: Initial condition loss: 0.024058131501078606\n","\tTesting: Boundary condition loss: 0.004243575967848301\n","\tTesting: PDE loss: 0.020235473290085793\n","\tTesting: Data loss: 0.005666837096214294\n","\n","Epoch 223\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02419987879693508\n","\tBefore adaption: Boundary condition loss: 0.004317587707191706\n","\tBefore adaption: PDE loss: 0.020337538793683052\n","\tBefore adaption: Data loss: 0.005687901750206947\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0526, 0.3246, 0.4887, 0.1341], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007855578126097188\n","\t\tAfter adaption: Boundary condition loss: 0.00022714976359937357\n","\t\tAfter adaption: PDE loss: 0.009939337560699866\n","\t\tAfter adaption: Data loss: 0.0007625106141772296\n","\n","\tTesting: Initial condition loss: 0.022104235365986824\n","\tTesting: Boundary condition loss: 0.0032274520490318537\n","\tTesting: PDE loss: 0.019834747537970543\n","\tTesting: Data loss: 0.005232827737927437\n","\n","Epoch 224\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02258721925318241\n","\tBefore adaption: Boundary condition loss: 0.003283392172306776\n","\tBefore adaption: PDE loss: 0.019924433901906013\n","\tBefore adaption: Data loss: 0.005253536626696587\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0620, 0.3764, 0.4487, 0.1130], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008501571177144403\n","\t\tAfter adaption: Boundary condition loss: 0.00020342742302136422\n","\t\tAfter adaption: PDE loss: 0.008939779229174266\n","\t\tAfter adaption: Data loss: 0.000593494687596941\n","\n","\tTesting: Initial condition loss: 0.01708386465907097\n","\tTesting: Boundary condition loss: 0.0017172357765957713\n","\tTesting: PDE loss: 0.01966598629951477\n","\tTesting: Data loss: 0.004631003364920616\n","\n","Epoch 225\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018146932125091553\n","\tBefore adaption: Boundary condition loss: 0.0017434705514460802\n","\tBefore adaption: PDE loss: 0.01972668431699276\n","\tBefore adaption: Data loss: 0.004642032086849213\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0685, 0.4085, 0.4175, 0.1054], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007413855442259696\n","\t\tAfter adaption: Boundary condition loss: 0.00011940093388039786\n","\t\tAfter adaption: PDE loss: 0.008236639431281823\n","\t\tAfter adaption: Data loss: 0.000489415354270073\n","\n","\tTesting: Initial condition loss: 0.011166843585669994\n","\tTesting: Boundary condition loss: 0.0006314251804724336\n","\tTesting: PDE loss: 0.01971212588250637\n","\tTesting: Data loss: 0.004668484907597303\n","\n","Epoch 226\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012723224237561226\n","\tBefore adaption: Boundary condition loss: 0.0005985744064673781\n","\tBefore adaption: PDE loss: 0.019807055592536926\n","\tBefore adaption: Data loss: 0.004656574688851833\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0674, 0.4220, 0.4065, 0.1041], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005369772002781314\n","\t\tAfter adaption: Boundary condition loss: 4.036905423333293e-05\n","\t\tAfter adaption: PDE loss: 0.008050596311241283\n","\t\tAfter adaption: Data loss: 0.00048457227292139047\n","\n","\tTesting: Initial condition loss: 0.0065605430863797665\n","\tTesting: Boundary condition loss: 0.0008022415568120778\n","\tTesting: PDE loss: 0.019924860447645187\n","\tTesting: Data loss: 0.006054962519556284\n","\n","Epoch 227\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008417976088821888\n","\tBefore adaption: Boundary condition loss: 0.0006811374332755804\n","\tBefore adaption: PDE loss: 0.020065778866410255\n","\tBefore adaption: Data loss: 0.006006976589560509\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0592, 0.4160, 0.4178, 0.1071], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0035017140175191567\n","\t\tAfter adaption: Boundary condition loss: 4.02893935051049e-05\n","\t\tAfter adaption: PDE loss: 0.008383771750833425\n","\t\tAfter adaption: Data loss: 0.0006430750234587439\n","\n","\tTesting: Initial condition loss: 0.0043395645916461945\n","\tTesting: Boundary condition loss: 0.0026014826726168394\n","\tTesting: PDE loss: 0.020236527547240257\n","\tTesting: Data loss: 0.008959414437413216\n","\n","Epoch 228\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006242769304662943\n","\tBefore adaption: Boundary condition loss: 0.002347567118704319\n","\tBefore adaption: PDE loss: 0.020362408831715584\n","\tBefore adaption: Data loss: 0.008865727111697197\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0477, 0.3863, 0.4482, 0.1178], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002411816972454828\n","\t\tAfter adaption: Boundary condition loss: 0.00011193506230770551\n","\t\tAfter adaption: PDE loss: 0.00912600780099318\n","\t\tAfter adaption: Data loss: 0.00104439694457286\n","\n","\tTesting: Initial condition loss: 0.004161362070590258\n","\tTesting: Boundary condition loss: 0.005679740104824305\n","\tTesting: PDE loss: 0.020430678501725197\n","\tTesting: Data loss: 0.012892927043139935\n","\n","Epoch 229\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005932276137173176\n","\tBefore adaption: Boundary condition loss: 0.005291068460792303\n","\tBefore adaption: PDE loss: 0.020534729585051537\n","\tBefore adaption: Data loss: 0.012751217000186443\n","tensor(0.0053, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0053, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0420, 0.3305, 0.4847, 0.1428], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019605039400539693\n","\t\tAfter adaption: Boundary condition loss: 0.00022218873314112824\n","\t\tAfter adaption: PDE loss: 0.009953880644796492\n","\t\tAfter adaption: Data loss: 0.0018207684373734566\n","\n","\tTesting: Initial condition loss: 0.004866139031946659\n","\tTesting: Boundary condition loss: 0.00896293856203556\n","\tTesting: PDE loss: 0.02039523608982563\n","\tTesting: Data loss: 0.01690937764942646\n","\n","Epoch 230\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006480044685304165\n","\tBefore adaption: Boundary condition loss: 0.008488067425787449\n","\tBefore adaption: PDE loss: 0.02047429047524929\n","\tBefore adaption: Data loss: 0.016723748296499252\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0534, 0.2578, 0.5037, 0.1851], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001670597250099139\n","\t\tAfter adaption: Boundary condition loss: 0.0004535284482038947\n","\t\tAfter adaption: PDE loss: 0.010313040950687762\n","\t\tAfter adaption: Data loss: 0.0030948154852646023\n","\n","\tTesting: Initial condition loss: 0.005355577450245619\n","\tTesting: Boundary condition loss: 0.01119427103549242\n","\tTesting: PDE loss: 0.020089371129870415\n","\tTesting: Data loss: 0.019904455170035362\n","\n","Epoch 231\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006880893371999264\n","\tBefore adaption: Boundary condition loss: 0.010697600431740284\n","\tBefore adaption: PDE loss: 0.020128706470131874\n","\tBefore adaption: Data loss: 0.01968545652925968\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0839, 0.1917, 0.4881, 0.2363], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013194083479686283\n","\t\tAfter adaption: Boundary condition loss: 0.0008976129205056359\n","\t\tAfter adaption: PDE loss: 0.009824594122591037\n","\t\tAfter adaption: Data loss: 0.004650760288288148\n","\n","\tTesting: Initial condition loss: 0.005077206064015627\n","\tTesting: Boundary condition loss: 0.011388115584850311\n","\tTesting: PDE loss: 0.01952596940100193\n","\tTesting: Data loss: 0.0209148321300745\n","\n","Epoch 232\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006628151051700115\n","\tBefore adaption: Boundary condition loss: 0.010938931256532669\n","\tBefore adaption: PDE loss: 0.019563378766179085\n","\tBefore adaption: Data loss: 0.020679859444499016\n","tensor(0.0109, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0109, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1211, 0.1495, 0.4473, 0.2821], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009907922539508258\n","\t\tAfter adaption: Boundary condition loss: 0.0013251805008041165\n","\t\tAfter adaption: PDE loss: 0.008750937819520058\n","\t\tAfter adaption: Data loss: 0.005832994901759518\n","\n","\tTesting: Initial condition loss: 0.004269549623131752\n","\tTesting: Boundary condition loss: 0.00934984814375639\n","\tTesting: PDE loss: 0.01882217451930046\n","\tTesting: Data loss: 0.01950335130095482\n","\n","Epoch 233\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005916719790548086\n","\tBefore adaption: Boundary condition loss: 0.00900037307292223\n","\tBefore adaption: PDE loss: 0.01883530244231224\n","\tBefore adaption: Data loss: 0.019276998937129974\n","tensor(0.0090, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0090, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1513, 0.1288, 0.4047, 0.3153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007619519577129134\n","\t\tAfter adaption: Boundary condition loss: 0.0013613130348052273\n","\t\tAfter adaption: PDE loss: 0.007622619555914857\n","\t\tAfter adaption: Data loss: 0.0060774799066019465\n","\n","\tTesting: Initial condition loss: 0.0038694010581821203\n","\tTesting: Boundary condition loss: 0.005923485849052668\n","\tTesting: PDE loss: 0.018024027347564697\n","\tTesting: Data loss: 0.01618785783648491\n","\n","Epoch 234\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005596003495156765\n","\tBefore adaption: Boundary condition loss: 0.005693431943655014\n","\tBefore adaption: PDE loss: 0.018036188557744026\n","\tBefore adaption: Data loss: 0.01599469594657421\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1677, 0.1202, 0.3757, 0.3365], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006724453565340574\n","\t\tAfter adaption: Boundary condition loss: 0.0009547106053680214\n","\t\tAfter adaption: PDE loss: 0.006775656108531087\n","\t\tAfter adaption: Data loss: 0.005381865701387132\n","\n","\tTesting: Initial condition loss: 0.005089353304356337\n","\tTesting: Boundary condition loss: 0.002618620404973626\n","\tTesting: PDE loss: 0.01721152476966381\n","\tTesting: Data loss: 0.012235411442816257\n","\n","Epoch 235\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006787166930735111\n","\tBefore adaption: Boundary condition loss: 0.002498909831047058\n","\tBefore adaption: PDE loss: 0.01724456436932087\n","\tBefore adaption: Data loss: 0.01209190022200346\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1687, 0.1185, 0.3651, 0.3477], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008045526074615516\n","\t\tAfter adaption: Boundary condition loss: 0.0004215359022906737\n","\t\tAfter adaption: PDE loss: 0.00629631964193301\n","\t\tAfter adaption: Data loss: 0.004203779716633428\n","\n","\tTesting: Initial condition loss: 0.008765952661633492\n","\tTesting: Boundary condition loss: 0.0006540585891343653\n","\tTesting: PDE loss: 0.016527151688933372\n","\tTesting: Data loss: 0.008934042416512966\n","\n","Epoch 236\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010253206826746464\n","\tBefore adaption: Boundary condition loss: 0.0006061670719645917\n","\tBefore adaption: PDE loss: 0.016537608578801155\n","\tBefore adaption: Data loss: 0.00884412694722414\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1540, 0.1261, 0.3719, 0.3479], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012932376751461816\n","\t\tAfter adaption: Boundary condition loss: 9.334149430006968e-05\n","\t\tAfter adaption: PDE loss: 0.00615112953676473\n","\t\tAfter adaption: Data loss: 0.003077184608006305\n","\n","\tTesting: Initial condition loss: 0.014709633775055408\n","\tTesting: Boundary condition loss: 0.00019584335677791387\n","\tTesting: PDE loss: 0.016000093892216682\n","\tTesting: Data loss: 0.006961932871490717\n","\n","Epoch 237\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01583227515220642\n","\tBefore adaption: Boundary condition loss: 0.000173994354554452\n","\tBefore adaption: PDE loss: 0.015987632796168327\n","\tBefore adaption: Data loss: 0.006920535583049059\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1244, 0.1523, 0.3905, 0.3328], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0024110006251832827\n","\t\tAfter adaption: Boundary condition loss: 2.164317890294859e-05\n","\t\tAfter adaption: PDE loss: 0.006243180039735354\n","\t\tAfter adaption: Data loss: 0.0023033284377988396\n","\n","\tTesting: Initial condition loss: 0.021386073902249336\n","\tTesting: Boundary condition loss: 0.0007898168987594545\n","\tTesting: PDE loss: 0.015698038041591644\n","\tTesting: Data loss: 0.006245644297450781\n","\n","Epoch 238\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022157859057188034\n","\tBefore adaption: Boundary condition loss: 0.0007662016432732344\n","\tBefore adaption: PDE loss: 0.01567641831934452\n","\tBefore adaption: Data loss: 0.00624183239415288\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0847, 0.2093, 0.4085, 0.2976], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004636650499664253\n","\t\tAfter adaption: Boundary condition loss: 6.49090650947497e-05\n","\t\tAfter adaption: PDE loss: 0.0064032498353330004\n","\t\tAfter adaption: Data loss: 0.0018573521449193459\n","\n","\tTesting: Initial condition loss: 0.02640659362077713\n","\tTesting: Boundary condition loss: 0.001629403792321682\n","\tTesting: PDE loss: 0.015671947970986366\n","\tTesting: Data loss: 0.006180399097502232\n","\n","Epoch 239\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02695990540087223\n","\tBefore adaption: Boundary condition loss: 0.0015965065686032176\n","\tBefore adaption: PDE loss: 0.015651531517505646\n","\tBefore adaption: Data loss: 0.0062001231126487255\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0477, 0.2973, 0.4094, 0.2456], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008015835730719635\n","\t\tAfter adaption: Boundary condition loss: 7.621991897543284e-05\n","\t\tAfter adaption: PDE loss: 0.006407245570605166\n","\t\tAfter adaption: Data loss: 0.001522534086581803\n","\n","\tTesting: Initial condition loss: 0.027122635394334793\n","\tTesting: Boundary condition loss: 0.0019325041212141514\n","\tTesting: PDE loss: 0.01603345386683941\n","\tTesting: Data loss: 0.006027711555361748\n","\n","Epoch 240\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02773767150938511\n","\tBefore adaption: Boundary condition loss: 0.0019060863414779305\n","\tBefore adaption: PDE loss: 0.01600710302591324\n","\tBefore adaption: Data loss: 0.006055097561329603\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0270, 0.3923, 0.3880, 0.1927], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010882600915360158\n","\t\tAfter adaption: Boundary condition loss: 5.143363401394808e-05\n","\t\tAfter adaption: PDE loss: 0.006210033512195573\n","\t\tAfter adaption: Data loss: 0.001166943825823509\n","\n","\tTesting: Initial condition loss: 0.02252415008842945\n","\tTesting: Boundary condition loss: 0.0014199124416336417\n","\tTesting: PDE loss: 0.016847793012857437\n","\tTesting: Data loss: 0.005464770831167698\n","\n","Epoch 241\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02347823604941368\n","\tBefore adaption: Boundary condition loss: 0.0014148028567433357\n","\tBefore adaption: PDE loss: 0.01685757376253605\n","\tBefore adaption: Data loss: 0.005484487395733595\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0227, 0.4636, 0.3595, 0.1542], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010884697966261533\n","\t\tAfter adaption: Boundary condition loss: 3.2152293057980105e-05\n","\t\tAfter adaption: PDE loss: 0.006059883116438859\n","\t\tAfter adaption: Data loss: 0.0008456571769285583\n","\n","\tTesting: Initial condition loss: 0.014762461185455322\n","\tTesting: Boundary condition loss: 0.0006031614611856639\n","\tTesting: PDE loss: 0.01813361421227455\n","\tTesting: Data loss: 0.004952985793352127\n","\n","Epoch 242\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016191130504012108\n","\tBefore adaption: Boundary condition loss: 0.0005977873806841671\n","\tBefore adaption: PDE loss: 0.018182842060923576\n","\tBefore adaption: Data loss: 0.004952477291226387\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0251, 0.4985, 0.3439, 0.1325], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008071325382518748\n","\t\tAfter adaption: Boundary condition loss: 1.5017707130387411e-05\n","\t\tAfter adaption: PDE loss: 0.006252361260932528\n","\t\tAfter adaption: Data loss: 0.0006562737301992838\n","\n","\tTesting: Initial condition loss: 0.007820439524948597\n","\tTesting: Boundary condition loss: 0.0005108112236484885\n","\tTesting: PDE loss: 0.019698219373822212\n","\tTesting: Data loss: 0.005378962028771639\n","\n","Epoch 243\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009614966809749603\n","\tBefore adaption: Boundary condition loss: 0.00043773476500064135\n","\tBefore adaption: PDE loss: 0.019746262580156326\n","\tBefore adaption: Data loss: 0.005349000915884972\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0268, 0.4979, 0.3518, 0.1236], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0047869973558926655\n","\t\tAfter adaption: Boundary condition loss: 1.17422178474624e-05\n","\t\tAfter adaption: PDE loss: 0.006945845703887134\n","\t\tAfter adaption: Data loss: 0.0006608718043112475\n","\n","\tTesting: Initial condition loss: 0.004275990184396505\n","\tTesting: Boundary condition loss: 0.001909155398607254\n","\tTesting: PDE loss: 0.021273138001561165\n","\tTesting: Data loss: 0.007263531442731619\n","\n","Epoch 244\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006119995843619108\n","\tBefore adaption: Boundary condition loss: 0.0016834145644679666\n","\tBefore adaption: PDE loss: 0.021297134459018707\n","\tBefore adaption: Data loss: 0.007201223634183407\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0265, 0.4634, 0.3851, 0.1249], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002836109221988517\n","\t\tAfter adaption: Boundary condition loss: 4.46492072290484e-05\n","\t\tAfter adaption: PDE loss: 0.008202192698829752\n","\t\tAfter adaption: Data loss: 0.0008996390691273975\n","\n","\tTesting: Initial condition loss: 0.004093016032129526\n","\tTesting: Boundary condition loss: 0.004635136108845472\n","\tTesting: PDE loss: 0.022473536431789398\n","\tTesting: Data loss: 0.010343230329453945\n","\n","Epoch 245\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005756556522101164\n","\tBefore adaption: Boundary condition loss: 0.004206421785056591\n","\tBefore adaption: PDE loss: 0.022548751905560493\n","\tBefore adaption: Data loss: 0.010249834507703781\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0287, 0.3953, 0.4379, 0.1381], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022754816806343755\n","\t\tAfter adaption: Boundary condition loss: 0.00012080366852353811\n","\t\tAfter adaption: PDE loss: 0.00987422544871402\n","\t\tAfter adaption: Data loss: 0.001415400145593036\n","\n","\tTesting: Initial condition loss: 0.005629290826618671\n","\tTesting: Boundary condition loss: 0.0077027189545333385\n","\tTesting: PDE loss: 0.023207567632198334\n","\tTesting: Data loss: 0.013753819279372692\n","\n","Epoch 246\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006972996983677149\n","\tBefore adaption: Boundary condition loss: 0.007086530327796936\n","\tBefore adaption: PDE loss: 0.023292141035199165\n","\tBefore adaption: Data loss: 0.01363283395767212\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0414, 0.3036, 0.4899, 0.1651], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021168442536290497\n","\t\tAfter adaption: Boundary condition loss: 0.0002935261483773065\n","\t\tAfter adaption: PDE loss: 0.011411611141664186\n","\t\tAfter adaption: Data loss: 0.0022503459427742644\n","\n","\tTesting: Initial condition loss: 0.007036191411316395\n","\tTesting: Boundary condition loss: 0.009963304735720158\n","\tTesting: PDE loss: 0.02339823730289936\n","\tTesting: Data loss: 0.01652376540005207\n","\n","Epoch 247\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008098379708826542\n","\tBefore adaption: Boundary condition loss: 0.009241721592843533\n","\tBefore adaption: PDE loss: 0.023465596139431\n","\tBefore adaption: Data loss: 0.016380993649363518\n","tensor(0.0092, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0092, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0683, 0.2176, 0.5123, 0.2018], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017618817895226932\n","\t\tAfter adaption: Boundary condition loss: 0.0006313286594503048\n","\t\tAfter adaption: PDE loss: 0.012022597460262454\n","\t\tAfter adaption: Data loss: 0.0033053095965031734\n","\n","\tTesting: Initial condition loss: 0.007155272178351879\n","\tTesting: Boundary condition loss: 0.010596725158393383\n","\tTesting: PDE loss: 0.0230440404266119\n","\tTesting: Data loss: 0.017873823642730713\n","\n","Epoch 248\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008151824586093426\n","\tBefore adaption: Boundary condition loss: 0.009879088960587978\n","\tBefore adaption: PDE loss: 0.023103365674614906\n","\tBefore adaption: Data loss: 0.017718113958835602\n","tensor(0.0099, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0099, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1019, 0.1643, 0.4963, 0.2375], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013395141186694683\n","\t\tAfter adaption: Boundary condition loss: 0.0010064781618160047\n","\t\tAfter adaption: PDE loss: 0.011465926513118212\n","\t\tAfter adaption: Data loss: 0.0042082505519103995\n","\n","\tTesting: Initial condition loss: 0.005889843683689833\n","\tTesting: Boundary condition loss: 0.00933564081788063\n","\tTesting: PDE loss: 0.022317122668027878\n","\tTesting: Data loss: 0.01740792952477932\n","\n","Epoch 249\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007019103970378637\n","\tBefore adaption: Boundary condition loss: 0.00873158685863018\n","\tBefore adaption: PDE loss: 0.022328952327370644\n","\tBefore adaption: Data loss: 0.01725125126540661\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1304, 0.1426, 0.4621, 0.2649], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010008246518959372\n","\t\tAfter adaption: Boundary condition loss: 0.0011389302058139488\n","\t\tAfter adaption: PDE loss: 0.010317464025135885\n","\t\tAfter adaption: Data loss: 0.004570018629831128\n","\n","\tTesting: Initial condition loss: 0.004067159257829189\n","\tTesting: Boundary condition loss: 0.006667279172688723\n","\tTesting: PDE loss: 0.021275650709867477\n","\tTesting: Data loss: 0.01532584335654974\n","\n","Epoch 250\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0054118018597364426\n","\tBefore adaption: Boundary condition loss: 0.006240732502192259\n","\tBefore adaption: PDE loss: 0.02131805382668972\n","\tBefore adaption: Data loss: 0.01518023107200861\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1477, 0.1358, 0.4327, 0.2838], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007347556084776578\n","\t\tAfter adaption: Boundary condition loss: 0.0009215532327212834\n","\t\tAfter adaption: PDE loss: 0.009225355808058068\n","\t\tAfter adaption: Data loss: 0.004308372837946259\n","\n","\tTesting: Initial condition loss: 0.0030982547905296087\n","\tTesting: Boundary condition loss: 0.003643240313977003\n","\tTesting: PDE loss: 0.020134571939706802\n","\tTesting: Data loss: 0.012391026131808758\n","\n","Epoch 251\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004543663468211889\n","\tBefore adaption: Boundary condition loss: 0.003389656776562333\n","\tBefore adaption: PDE loss: 0.020147185772657394\n","\tBefore adaption: Data loss: 0.012266968376934528\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1522, 0.1318, 0.4196, 0.2964], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005988614420183007\n","\t\tAfter adaption: Boundary condition loss: 0.0005160629211366501\n","\t\tAfter adaption: PDE loss: 0.00845299789586472\n","\t\tAfter adaption: Data loss: 0.0036358041000976128\n","\n","\tTesting: Initial condition loss: 0.004240960814058781\n","\tTesting: Boundary condition loss: 0.0013241396518424153\n","\tTesting: PDE loss: 0.018962180241942406\n","\tTesting: Data loss: 0.009565060958266258\n","\n","Epoch 252\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005544742103666067\n","\tBefore adaption: Boundary condition loss: 0.0012055678525939584\n","\tBefore adaption: PDE loss: 0.01894996128976345\n","\tBefore adaption: Data loss: 0.00946821365505457\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1442, 0.1278, 0.4246, 0.3033], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007088949930882104\n","\t\tAfter adaption: Boundary condition loss: 0.00017389860177131376\n","\t\tAfter adaption: PDE loss: 0.008047016824675143\n","\t\tAfter adaption: Data loss: 0.0028713123644330714\n","\n","\tTesting: Initial condition loss: 0.007991672493517399\n","\tTesting: Boundary condition loss: 0.00026868144050240517\n","\tTesting: PDE loss: 0.017774634063243866\n","\tTesting: Data loss: 0.007559329271316528\n","\n","Epoch 253\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008956743404269218\n","\tBefore adaption: Boundary condition loss: 0.00022290748893283308\n","\tBefore adaption: PDE loss: 0.01780342310667038\n","\tBefore adaption: Data loss: 0.007491657510399818\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1238, 0.1289, 0.4450, 0.3022], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011549550384901941\n","\t\tAfter adaption: Boundary condition loss: 2.7596810148601038e-05\n","\t\tAfter adaption: PDE loss: 0.007922489512316699\n","\t\tAfter adaption: Data loss: 0.002264351351826328\n","\n","\tTesting: Initial condition loss: 0.013952425681054592\n","\tTesting: Boundary condition loss: 0.00036237708991393447\n","\tTesting: PDE loss: 0.016709554940462112\n","\tTesting: Data loss: 0.0066084424033761024\n","\n","Epoch 254\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014402307569980621\n","\tBefore adaption: Boundary condition loss: 0.00033440571860410273\n","\tBefore adaption: PDE loss: 0.016721654683351517\n","\tBefore adaption: Data loss: 0.006567505653947592\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0927, 0.1474, 0.4710, 0.2888], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021235275592772712\n","\t\tAfter adaption: Boundary condition loss: 3.099972982196813e-05\n","\t\tAfter adaption: PDE loss: 0.007876288930374446\n","\t\tAfter adaption: Data loss: 0.001896905451703263\n","\n","\tTesting: Initial condition loss: 0.020831802859902382\n","\tTesting: Boundary condition loss: 0.0010821112664416432\n","\tTesting: PDE loss: 0.015741335228085518\n","\tTesting: Data loss: 0.006511900573968887\n","\n","Epoch 255\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020718324929475784\n","\tBefore adaption: Boundary condition loss: 0.0010342762107029557\n","\tBefore adaption: PDE loss: 0.015737123787403107\n","\tBefore adaption: Data loss: 0.006493004038929939\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0581, 0.1981, 0.4840, 0.2598], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004104251125878917\n","\t\tAfter adaption: Boundary condition loss: 6.0062939838732936e-05\n","\t\tAfter adaption: PDE loss: 0.007616800559397022\n","\t\tAfter adaption: Data loss: 0.0016870616625861068\n","\n","\tTesting: Initial condition loss: 0.026533283293247223\n","\tTesting: Boundary condition loss: 0.0017731913831084967\n","\tTesting: PDE loss: 0.014925887808203697\n","\tTesting: Data loss: 0.006816249806433916\n","\n","Epoch 256\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026064997538924217\n","\tBefore adaption: Boundary condition loss: 0.001697805942967534\n","\tBefore adaption: PDE loss: 0.014909572899341583\n","\tBefore adaption: Data loss: 0.006811267230659723\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0322, 0.2821, 0.4654, 0.2202], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007354214100828752\n","\t\tAfter adaption: Boundary condition loss: 5.470113475899236e-05\n","\t\tAfter adaption: PDE loss: 0.006939232460400096\n","\t\tAfter adaption: Data loss: 0.00149991392163136\n","\n","\tTesting: Initial condition loss: 0.028476042672991753\n","\tTesting: Boundary condition loss: 0.0018667900003492832\n","\tTesting: PDE loss: 0.01442610565572977\n","\tTesting: Data loss: 0.007025345228612423\n","\n","Epoch 257\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028036871924996376\n","\tBefore adaption: Boundary condition loss: 0.0017839440843090415\n","\tBefore adaption: PDE loss: 0.01439304742962122\n","\tBefore adaption: Data loss: 0.00702274963259697\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0223, 0.3764, 0.4182, 0.1831], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010552723922814367\n","\t\tAfter adaption: Boundary condition loss: 3.9861485530710326e-05\n","\t\tAfter adaption: PDE loss: 0.0060190581842582015\n","\t\tAfter adaption: Data loss: 0.0012856952053550551\n","\n","\tTesting: Initial condition loss: 0.02508416958153248\n","\tTesting: Boundary condition loss: 0.0011978924740105867\n","\tTesting: PDE loss: 0.014360388740897179\n","\tTesting: Data loss: 0.006973592098802328\n","\n","Epoch 258\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025129040703177452\n","\tBefore adaption: Boundary condition loss: 0.0011414277832955122\n","\tBefore adaption: PDE loss: 0.014353950507938862\n","\tBefore adaption: Data loss: 0.006959073711186647\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0234, 0.4522, 0.3662, 0.1583], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011362272617057566\n","\t\tAfter adaption: Boundary condition loss: 2.6656123651906467e-05\n","\t\tAfter adaption: PDE loss: 0.005256731110762447\n","\t\tAfter adaption: Data loss: 0.001101395266704128\n","\n","\tTesting: Initial condition loss: 0.017568055540323257\n","\tTesting: Boundary condition loss: 0.0003165158268529922\n","\tTesting: PDE loss: 0.014851666986942291\n","\tTesting: Data loss: 0.007164977490901947\n","\n","Epoch 259\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01833247020840645\n","\tBefore adaption: Boundary condition loss: 0.0002933072973974049\n","\tBefore adaption: PDE loss: 0.014865080825984478\n","\tBefore adaption: Data loss: 0.007123957853764296\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0260, 0.4967, 0.3304, 0.1469], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009105196207023394\n","\t\tAfter adaption: Boundary condition loss: 7.629203480421957e-06\n","\t\tAfter adaption: PDE loss: 0.004911011882745203\n","\t\tAfter adaption: Data loss: 0.001046837208882025\n","\n","\tTesting: Initial condition loss: 0.00961434654891491\n","\tTesting: Boundary condition loss: 0.00032783899223431945\n","\tTesting: PDE loss: 0.015826309099793434\n","\tTesting: Data loss: 0.008542308583855629\n","\n","Epoch 260\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011061042547225952\n","\tBefore adaption: Boundary condition loss: 0.0002890281321015209\n","\tBefore adaption: PDE loss: 0.01583952270448208\n","\tBefore adaption: Data loss: 0.008463665843009949\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0255, 0.5080, 0.3187, 0.1477], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0056192542269203555\n","\t\tAfter adaption: Boundary condition loss: 7.38334064104012e-06\n","\t\tAfter adaption: PDE loss: 0.00504846102578444\n","\t\tAfter adaption: Data loss: 0.0012501400485067844\n","\n","\tTesting: Initial condition loss: 0.004663625732064247\n","\tTesting: Boundary condition loss: 0.002137722447514534\n","\tTesting: PDE loss: 0.017072735354304314\n","\tTesting: Data loss: 0.011678619310259819\n","\n","Epoch 261\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006419724319130182\n","\tBefore adaption: Boundary condition loss: 0.001999970292672515\n","\tBefore adaption: PDE loss: 0.017103413119912148\n","\tBefore adaption: Data loss: 0.011556827463209629\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0232, 0.4838, 0.3310, 0.1620], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031059025321389473\n","\t\tAfter adaption: Boundary condition loss: 4.635246623395363e-05\n","\t\tAfter adaption: PDE loss: 0.0056619148520501315\n","\t\tAfter adaption: Data loss: 0.0018719393961654969\n","\n","\tTesting: Initial condition loss: 0.003639436326920986\n","\tTesting: Boundary condition loss: 0.005677885375916958\n","\tTesting: PDE loss: 0.018343739211559296\n","\tTesting: Data loss: 0.016107844188809395\n","\n","Epoch 262\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005322146229445934\n","\tBefore adaption: Boundary condition loss: 0.005380428861826658\n","\tBefore adaption: PDE loss: 0.018381893634796143\n","\tBefore adaption: Data loss: 0.015943700447678566\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0260, 0.4194, 0.3608, 0.1938], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00223205281641915\n","\t\tAfter adaption: Boundary condition loss: 0.00013966820200192687\n","\t\tAfter adaption: PDE loss: 0.006632364442166055\n","\t\tAfter adaption: Data loss: 0.003090558035265115\n","\n","\tTesting: Initial condition loss: 0.005001075100153685\n","\tTesting: Boundary condition loss: 0.009577260352671146\n","\tTesting: PDE loss: 0.019364653155207634\n","\tTesting: Data loss: 0.02032850868999958\n","\n","Epoch 263\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006386731751263142\n","\tBefore adaption: Boundary condition loss: 0.009111154824495316\n","\tBefore adaption: PDE loss: 0.01942434534430504\n","\tBefore adaption: Data loss: 0.020131660625338554\n","tensor(0.0091, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0091, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0442, 0.3216, 0.3911, 0.2430], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020541262263631195\n","\t\tAfter adaption: Boundary condition loss: 0.0004027773167531721\n","\t\tAfter adaption: PDE loss: 0.0075975524278775845\n","\t\tAfter adaption: Data loss: 0.004892660466490302\n","\n","\tTesting: Initial condition loss: 0.006417301017791033\n","\tTesting: Boundary condition loss: 0.011825960129499435\n","\tTesting: PDE loss: 0.020094797015190125\n","\tTesting: Data loss: 0.02255829982459545\n","\n","Epoch 264\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007526974193751812\n","\tBefore adaption: Boundary condition loss: 0.01123848557472229\n","\tBefore adaption: PDE loss: 0.02012570947408676\n","\tBefore adaption: Data loss: 0.02234739065170288\n","tensor(0.0112, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0112, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0800, 0.2225, 0.4012, 0.2963], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016748739591277823\n","\t\tAfter adaption: Boundary condition loss: 0.0008991179984236556\n","\t\tAfter adaption: PDE loss: 0.008074762751269327\n","\t\tAfter adaption: Data loss: 0.006620721618210852\n","\n","\tTesting: Initial condition loss: 0.0063820998184382915\n","\tTesting: Boundary condition loss: 0.011193402111530304\n","\tTesting: PDE loss: 0.020488480105996132\n","\tTesting: Data loss: 0.021708259359002113\n","\n","Epoch 265\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007438625209033489\n","\tBefore adaption: Boundary condition loss: 0.010590443387627602\n","\tBefore adaption: PDE loss: 0.02052351087331772\n","\tBefore adaption: Data loss: 0.021506058052182198\n","tensor(0.0106, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0106, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1197, 0.1568, 0.3883, 0.3352], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011661183525292107\n","\t\tAfter adaption: Boundary condition loss: 0.0012678615375878368\n","\t\tAfter adaption: PDE loss: 0.00796935242573128\n","\t\tAfter adaption: Data loss: 0.0072091189299029615\n","\n","\tTesting: Initial condition loss: 0.004921587649732828\n","\tTesting: Boundary condition loss: 0.00808838102966547\n","\tTesting: PDE loss: 0.020640991628170013\n","\tTesting: Data loss: 0.01804041676223278\n","\n","Epoch 266\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006138631608337164\n","\tBefore adaption: Boundary condition loss: 0.007577996701002121\n","\tBefore adaption: PDE loss: 0.020716184750199318\n","\tBefore adaption: Data loss: 0.017867840826511383\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1483, 0.1280, 0.3697, 0.3540], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007856360862401241\n","\t\tAfter adaption: Boundary condition loss: 0.0011236190422688492\n","\t\tAfter adaption: PDE loss: 0.007658957366619207\n","\t\tAfter adaption: Data loss: 0.00632583672572301\n","\n","\tTesting: Initial condition loss: 0.003318984992802143\n","\tTesting: Boundary condition loss: 0.0043372707441449165\n","\tTesting: PDE loss: 0.02070852369070053\n","\tTesting: Data loss: 0.013057209551334381\n","\n","Epoch 267\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004754485562443733\n","\tBefore adaption: Boundary condition loss: 0.0039732991717755795\n","\tBefore adaption: PDE loss: 0.020806582644581795\n","\tBefore adaption: Data loss: 0.012925682589411736\n","tensor(0.0040, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0040, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1604, 0.1199, 0.3623, 0.3574], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005699061057234878\n","\t\tAfter adaption: Boundary condition loss: 0.000637389277486405\n","\t\tAfter adaption: PDE loss: 0.007538446418383626\n","\t\tAfter adaption: Data loss: 0.00461969050215372\n","\n","\tTesting: Initial condition loss: 0.003261502832174301\n","\tTesting: Boundary condition loss: 0.0015933847753331065\n","\tTesting: PDE loss: 0.020713720470666885\n","\tTesting: Data loss: 0.008568721823394299\n","\n","Epoch 268\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004773546010255814\n","\tBefore adaption: Boundary condition loss: 0.0013931355206295848\n","\tBefore adaption: PDE loss: 0.02078319899737835\n","\tBefore adaption: Data loss: 0.008479021489620209\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1567, 0.1189, 0.3747, 0.3496], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005677110281288281\n","\t\tAfter adaption: Boundary condition loss: 0.00021836922875991758\n","\t\tAfter adaption: PDE loss: 0.007787217066303321\n","\t\tAfter adaption: Data loss: 0.002964576015182152\n","\n","\tTesting: Initial condition loss: 0.005776390433311462\n","\tTesting: Boundary condition loss: 0.0006025939946994185\n","\tTesting: PDE loss: 0.020574243739247322\n","\tTesting: Data loss: 0.005705427378416061\n","\n","Epoch 269\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0071598561480641365\n","\tBefore adaption: Boundary condition loss: 0.000535386789124459\n","\tBefore adaption: PDE loss: 0.02064550668001175\n","\tBefore adaption: Data loss: 0.005654624197632074\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1383, 0.1218, 0.4094, 0.3305], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008721028080555759\n","\t\tAfter adaption: Boundary condition loss: 7.403111232632126e-05\n","\t\tAfter adaption: PDE loss: 0.008451769566921456\n","\t\tAfter adaption: Data loss: 0.001869099865647152\n","\n","\tTesting: Initial condition loss: 0.010718360543251038\n","\tTesting: Boundary condition loss: 0.0011258969316259027\n","\tTesting: PDE loss: 0.020239457488059998\n","\tTesting: Data loss: 0.004622729029506445\n","\n","Epoch 270\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011860192753374577\n","\tBefore adaption: Boundary condition loss: 0.0011412684107199311\n","\tBefore adaption: PDE loss: 0.020311817526817322\n","\tBefore adaption: Data loss: 0.004605694208294153\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1073, 0.1350, 0.4615, 0.2962], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016007498464741523\n","\t\tAfter adaption: Boundary condition loss: 0.00012248992448619494\n","\t\tAfter adaption: PDE loss: 0.009373695416218021\n","\t\tAfter adaption: Data loss: 0.001364270497961947\n","\n","\tTesting: Initial condition loss: 0.016915621235966682\n","\tTesting: Boundary condition loss: 0.002331408439204097\n","\tTesting: PDE loss: 0.019669486209750175\n","\tTesting: Data loss: 0.004762406460940838\n","\n","Epoch 271\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.017811859026551247\n","\tBefore adaption: Boundary condition loss: 0.002380841877311468\n","\tBefore adaption: PDE loss: 0.01972370594739914\n","\tBefore adaption: Data loss: 0.004770626779645681\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0723, 0.1716, 0.5110, 0.2450], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0030570287090348758\n","\t\tAfter adaption: Boundary condition loss: 0.0001722045528334112\n","\t\tAfter adaption: PDE loss: 0.010079394891484808\n","\t\tAfter adaption: Data loss: 0.0011688616598705588\n","\n","\tTesting: Initial condition loss: 0.02249927632510662\n","\tTesting: Boundary condition loss: 0.00330458115786314\n","\tTesting: PDE loss: 0.018870655447244644\n","\tTesting: Data loss: 0.005321444943547249\n","\n","Epoch 272\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023312944918870926\n","\tBefore adaption: Boundary condition loss: 0.0033547156490385532\n","\tBefore adaption: PDE loss: 0.018928900361061096\n","\tBefore adaption: Data loss: 0.005346463993191719\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0484, 0.2384, 0.5259, 0.1873], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005557239242019055\n","\t\tAfter adaption: Boundary condition loss: 0.00016251758130290595\n","\t\tAfter adaption: PDE loss: 0.009954893516425428\n","\t\tAfter adaption: Data loss: 0.001001231111060707\n","\n","\tTesting: Initial condition loss: 0.025388656184077263\n","\tTesting: Boundary condition loss: 0.0033985385671257973\n","\tTesting: PDE loss: 0.01804329641163349\n","\tTesting: Data loss: 0.005626136902719736\n","\n","Epoch 273\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026338528841733932\n","\tBefore adaption: Boundary condition loss: 0.0034412324894219637\n","\tBefore adaption: PDE loss: 0.01807876117527485\n","\tBefore adaption: Data loss: 0.005657936446368694\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0434, 0.3199, 0.4946, 0.1421], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008425193375633883\n","\t\tAfter adaption: Boundary condition loss: 0.0001492642646783189\n","\t\tAfter adaption: PDE loss: 0.008942203529604478\n","\t\tAfter adaption: Data loss: 0.0008040990517646431\n","\n","\tTesting: Initial condition loss: 0.023901252076029778\n","\tTesting: Boundary condition loss: 0.0024699196219444275\n","\tTesting: PDE loss: 0.01739911362528801\n","\tTesting: Data loss: 0.005408532917499542\n","\n","Epoch 274\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025219637900590897\n","\tBefore adaption: Boundary condition loss: 0.0025090533308684826\n","\tBefore adaption: PDE loss: 0.017436742782592773\n","\tBefore adaption: Data loss: 0.005433273501694202\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0491, 0.3913, 0.4419, 0.1177], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00986889954655555\n","\t\tAfter adaption: Boundary condition loss: 0.0001231729702233274\n","\t\tAfter adaption: PDE loss: 0.007704450043400913\n","\t\tAfter adaption: Data loss: 0.0006397074462687081\n","\n","\tTesting: Initial condition loss: 0.018317462876439095\n","\tTesting: Boundary condition loss: 0.0010553543688729405\n","\tTesting: PDE loss: 0.017145663499832153\n","\tTesting: Data loss: 0.00507366331294179\n","\n","Epoch 275\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020128073170781136\n","\tBefore adaption: Boundary condition loss: 0.00108805182389915\n","\tBefore adaption: PDE loss: 0.017184309661388397\n","\tBefore adaption: Data loss: 0.005074765533208847\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0540, 0.4400, 0.3974, 0.1086], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00885671997527776\n","\t\tAfter adaption: Boundary condition loss: 5.8716980650417876e-05\n","\t\tAfter adaption: PDE loss: 0.006829541406503453\n","\t\tAfter adaption: Data loss: 0.0005510554321038729\n","\n","\tTesting: Initial condition loss: 0.011171231977641582\n","\tTesting: Boundary condition loss: 0.00024247015244327486\n","\tTesting: PDE loss: 0.017310163006186485\n","\tTesting: Data loss: 0.005600907374173403\n","\n","Epoch 276\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013430158607661724\n","\tBefore adaption: Boundary condition loss: 0.00022528540284838527\n","\tBefore adaption: PDE loss: 0.017339730635285378\n","\tBefore adaption: Data loss: 0.005563083104789257\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0525, 0.4640, 0.3755, 0.1080], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006231200890614859\n","\t\tAfter adaption: Boundary condition loss: 1.1830398383651104e-05\n","\t\tAfter adaption: PDE loss: 0.006510648286354318\n","\t\tAfter adaption: Data loss: 0.0006010374532127136\n","\n","\tTesting: Initial condition loss: 0.005727123003453016\n","\tTesting: Boundary condition loss: 0.0010447135427966714\n","\tTesting: PDE loss: 0.01774168759584427\n","\tTesting: Data loss: 0.00791136920452118\n","\n","Epoch 277\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008057095110416412\n","\tBefore adaption: Boundary condition loss: 0.0009209164418280125\n","\tBefore adaption: PDE loss: 0.017815088853240013\n","\tBefore adaption: Data loss: 0.007825679145753384\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0452, 0.4613, 0.3783, 0.1152], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0037171124840105407\n","\t\tAfter adaption: Boundary condition loss: 4.158963335956701e-05\n","\t\tAfter adaption: PDE loss: 0.006740114624084003\n","\t\tAfter adaption: Data loss: 0.0009011641712816344\n","\n","\tTesting: Initial condition loss: 0.003563462756574154\n","\tTesting: Boundary condition loss: 0.0037351930513978004\n","\tTesting: PDE loss: 0.018281035125255585\n","\tTesting: Data loss: 0.012162954546511173\n","\n","Epoch 278\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005624699406325817\n","\tBefore adaption: Boundary condition loss: 0.003461353713646531\n","\tBefore adaption: PDE loss: 0.018382741138339043\n","\tBefore adaption: Data loss: 0.012026084586977959\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0374, 0.4260, 0.4015, 0.1351], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002395853340761133\n","\t\tAfter adaption: Boundary condition loss: 0.0001294877755393293\n","\t\tAfter adaption: PDE loss: 0.007381468387077791\n","\t\tAfter adaption: Data loss: 0.0016246584795969108\n","\n","\tTesting: Initial condition loss: 0.004063444212079048\n","\tTesting: Boundary condition loss: 0.007666362449526787\n","\tTesting: PDE loss: 0.0187336727976799\n","\tTesting: Data loss: 0.017489442601799965\n","\n","Epoch 279\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005689362995326519\n","\tBefore adaption: Boundary condition loss: 0.007227088790386915\n","\tBefore adaption: PDE loss: 0.01883174292743206\n","\tBefore adaption: Data loss: 0.01730201207101345\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0401, 0.3538, 0.4306, 0.1755], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002013138903875437\n","\t\tAfter adaption: Boundary condition loss: 0.00028961147602174503\n","\t\tAfter adaption: PDE loss: 0.008109218647807585\n","\t\tAfter adaption: Data loss: 0.003035980227652242\n","\n","\tTesting: Initial condition loss: 0.005386691074818373\n","\tTesting: Boundary condition loss: 0.011389664374291897\n","\tTesting: PDE loss: 0.018936654552817345\n","\tTesting: Data loss: 0.022269031032919884\n","\n","Epoch 280\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006635465659201145\n","\tBefore adaption: Boundary condition loss: 0.010829376056790352\n","\tBefore adaption: PDE loss: 0.01901562139391899\n","\tBefore adaption: Data loss: 0.022040802985429764\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0636, 0.2604, 0.4408, 0.2352], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017276421887337337\n","\t\tAfter adaption: Boundary condition loss: 0.0006887452101589796\n","\t\tAfter adaption: PDE loss: 0.008382033055134934\n","\t\tAfter adaption: Data loss: 0.005184833202687881\n","\n","\tTesting: Initial condition loss: 0.005896556656807661\n","\tTesting: Boundary condition loss: 0.013103479519486427\n","\tTesting: PDE loss: 0.018850328400731087\n","\tTesting: Data loss: 0.024721356108784676\n","\n","Epoch 281\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006997361779212952\n","\tBefore adaption: Boundary condition loss: 0.012522857636213303\n","\tBefore adaption: PDE loss: 0.018922751769423485\n","\tBefore adaption: Data loss: 0.024471154436469078\n","tensor(0.0125, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0125, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1039, 0.1806, 0.4188, 0.2968], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012636759678541663\n","\t\tAfter adaption: Boundary condition loss: 0.00130053098560681\n","\t\tAfter adaption: PDE loss: 0.007924366581718193\n","\t\tAfter adaption: Data loss: 0.007262536016374002\n","\n","\tTesting: Initial condition loss: 0.005037243012338877\n","\tTesting: Boundary condition loss: 0.011788319796323776\n","\tTesting: PDE loss: 0.018535561859607697\n","\tTesting: Data loss: 0.023725753650069237\n","\n","Epoch 282\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006247275043278933\n","\tBefore adaption: Boundary condition loss: 0.011281698942184448\n","\tBefore adaption: PDE loss: 0.018591271713376045\n","\tBefore adaption: Data loss: 0.023481091484427452\n","tensor(0.0113, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0113, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1429, 0.1349, 0.3801, 0.3421], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008425122402758022\n","\t\tAfter adaption: Boundary condition loss: 0.001612639491087076\n","\t\tAfter adaption: PDE loss: 0.007065941666635962\n","\t\tAfter adaption: Data loss: 0.008033547925249865\n","\n","\tTesting: Initial condition loss: 0.003562691155821085\n","\tTesting: Boundary condition loss: 0.00812549889087677\n","\tTesting: PDE loss: 0.01807045191526413\n","\tTesting: Data loss: 0.019648868590593338\n","\n","Epoch 283\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005029122345149517\n","\tBefore adaption: Boundary condition loss: 0.007757831830531359\n","\tBefore adaption: PDE loss: 0.01813371852040291\n","\tBefore adaption: Data loss: 0.019436728209257126\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1681, 0.1157, 0.3477, 0.3685], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005817346938661924\n","\t\tAfter adaption: Boundary condition loss: 0.0013043500681389787\n","\t\tAfter adaption: PDE loss: 0.006304674326547293\n","\t\tAfter adaption: Data loss: 0.007162753575717783\n","\n","\tTesting: Initial condition loss: 0.003079058136790991\n","\tTesting: Boundary condition loss: 0.004038095939904451\n","\tTesting: PDE loss: 0.017626937478780746\n","\tTesting: Data loss: 0.014229685068130493\n","\n","Epoch 284\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004745388403534889\n","\tBefore adaption: Boundary condition loss: 0.0038165608420968056\n","\tBefore adaption: PDE loss: 0.01769072562456131\n","\tBefore adaption: Data loss: 0.014066912233829498\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1769, 0.1091, 0.3333, 0.3807], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005176512580819959\n","\t\tAfter adaption: Boundary condition loss: 0.0006753275242096367\n","\t\tAfter adaption: PDE loss: 0.005896291329422201\n","\t\tAfter adaption: Data loss: 0.0053548464567034606\n","\n","\tTesting: Initial condition loss: 0.005038197617977858\n","\tTesting: Boundary condition loss: 0.001153795514255762\n","\tTesting: PDE loss: 0.01734016276896\n","\tTesting: Data loss: 0.009437807835638523\n","\n","Epoch 285\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006702646613121033\n","\tBefore adaption: Boundary condition loss: 0.0010544590186327696\n","\tBefore adaption: PDE loss: 0.01738765463232994\n","\tBefore adaption: Data loss: 0.00933096557855606\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1701, 0.1091, 0.3398, 0.3810], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007314337779339665\n","\t\tAfter adaption: Boundary condition loss: 0.00017934072181337283\n","\t\tAfter adaption: PDE loss: 0.005908742599637216\n","\t\tAfter adaption: Data loss: 0.003554829801758276\n","\n","\tTesting: Initial condition loss: 0.009869500994682312\n","\tTesting: Boundary condition loss: 0.00013440563634503633\n","\tTesting: PDE loss: 0.017220890149474144\n","\tTesting: Data loss: 0.006447982974350452\n","\n","Epoch 286\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011285683140158653\n","\tBefore adaption: Boundary condition loss: 0.00010683857544790953\n","\tBefore adaption: PDE loss: 0.017241448163986206\n","\tBefore adaption: Data loss: 0.006393734831362963\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1471, 0.1200, 0.3663, 0.3666], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013542990502762242\n","\t\tAfter adaption: Boundary condition loss: 1.571687509764941e-05\n","\t\tAfter adaption: PDE loss: 0.006315523063637477\n","\t\tAfter adaption: Data loss: 0.0023438843232768632\n","\n","\tTesting: Initial condition loss: 0.01673167757689953\n","\tTesting: Boundary condition loss: 0.00069512112531811\n","\tTesting: PDE loss: 0.017173947766423225\n","\tTesting: Data loss: 0.005365296266973019\n","\n","Epoch 287\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01771625503897667\n","\tBefore adaption: Boundary condition loss: 0.0006916041602380574\n","\tBefore adaption: PDE loss: 0.017209716141223907\n","\tBefore adaption: Data loss: 0.0053559839725494385\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1093, 0.1548, 0.4052, 0.3308], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0027416133662211337\n","\t\tAfter adaption: Boundary condition loss: 7.556896126635366e-05\n","\t\tAfter adaption: PDE loss: 0.006973257047518274\n","\t\tAfter adaption: Data loss: 0.00177170189363818\n","\n","\tTesting: Initial condition loss: 0.023675553500652313\n","\tTesting: Boundary condition loss: 0.0019364116014912724\n","\tTesting: PDE loss: 0.017161894589662552\n","\tTesting: Data loss: 0.0055079213343560696\n","\n","Epoch 288\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024258188903331757\n","\tBefore adaption: Boundary condition loss: 0.0019298434490337968\n","\tBefore adaption: PDE loss: 0.01720678061246872\n","\tBefore adaption: Data loss: 0.005533149931579828\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0667, 0.2261, 0.4359, 0.2713], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005485154323644954\n","\t\tAfter adaption: Boundary condition loss: 0.0001287936325560545\n","\t\tAfter adaption: PDE loss: 0.007499931127775013\n","\t\tAfter adaption: Data loss: 0.001501008752800757\n","\n","\tTesting: Initial condition loss: 0.027991361916065216\n","\tTesting: Boundary condition loss: 0.002831332152709365\n","\tTesting: PDE loss: 0.017218435183167458\n","\tTesting: Data loss: 0.005892756395041943\n","\n","Epoch 289\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028433775529265404\n","\tBefore adaption: Boundary condition loss: 0.002821718342602253\n","\tBefore adaption: PDE loss: 0.017263995483517647\n","\tBefore adaption: Data loss: 0.005937391426414251\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0380, 0.3240, 0.4343, 0.2036], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00921385559703088\n","\t\tAfter adaption: Boundary condition loss: 0.00010733746667192774\n","\t\tAfter adaption: PDE loss: 0.007498015574804007\n","\t\tAfter adaption: Data loss: 0.0012088448672404597\n","\n","\tTesting: Initial condition loss: 0.027332551777362823\n","\tTesting: Boundary condition loss: 0.0027184493374079466\n","\tTesting: PDE loss: 0.01749345473945141\n","\tTesting: Data loss: 0.005732789635658264\n","\n","Epoch 290\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02796316146850586\n","\tBefore adaption: Boundary condition loss: 0.002718135714530945\n","\tBefore adaption: PDE loss: 0.01754341833293438\n","\tBefore adaption: Data loss: 0.005780335981398821\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0309, 0.4134, 0.4035, 0.1521], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01156126477422065\n","\t\tAfter adaption: Boundary condition loss: 8.391985716597604e-05\n","\t\tAfter adaption: PDE loss: 0.00707952034104345\n","\t\tAfter adaption: Data loss: 0.0008794008770602545\n","\n","\tTesting: Initial condition loss: 0.0214830469340086\n","\tTesting: Boundary condition loss: 0.0016708949115127325\n","\tTesting: PDE loss: 0.01809675246477127\n","\tTesting: Data loss: 0.004961343016475439\n","\n","Epoch 291\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022588998079299927\n","\tBefore adaption: Boundary condition loss: 0.0016892330022528768\n","\tBefore adaption: PDE loss: 0.0181720033288002\n","\tBefore adaption: Data loss: 0.004994601011276245\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0354, 0.4700, 0.3704, 0.1242], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010616661685124252\n","\t\tAfter adaption: Boundary condition loss: 5.9828189720786916e-05\n","\t\tAfter adaption: PDE loss: 0.006730657896665548\n","\t\tAfter adaption: Data loss: 0.0006203479367571068\n","\n","\tTesting: Initial condition loss: 0.013219514861702919\n","\tTesting: Boundary condition loss: 0.000574306643102318\n","\tTesting: PDE loss: 0.019054368138313293\n","\tTesting: Data loss: 0.004368833266198635\n","\n","Epoch 292\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01495229173451662\n","\tBefore adaption: Boundary condition loss: 0.0005816927296109498\n","\tBefore adaption: PDE loss: 0.019143424928188324\n","\tBefore adaption: Data loss: 0.004372337833046913\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0401, 0.4923, 0.3554, 0.1122], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007360314507004504\n","\t\tAfter adaption: Boundary condition loss: 2.3305717061272503e-05\n","\t\tAfter adaption: PDE loss: 0.006804198911447281\n","\t\tAfter adaption: Data loss: 0.000490788369882293\n","\n","\tTesting: Initial condition loss: 0.00656915595754981\n","\tTesting: Boundary condition loss: 0.0005500058177858591\n","\tTesting: PDE loss: 0.020162908360362053\n","\tTesting: Data loss: 0.0049992892891168594\n","\n","Epoch 293\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008600673638284206\n","\tBefore adaption: Boundary condition loss: 0.00047243107110261917\n","\tBefore adaption: PDE loss: 0.020280390977859497\n","\tBefore adaption: Data loss: 0.0049628522247076035\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0399, 0.4848, 0.3662, 0.1091], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004169416091491718\n","\t\tAfter adaption: Boundary condition loss: 1.886555291628962e-05\n","\t\tAfter adaption: PDE loss: 0.007426158225233213\n","\t\tAfter adaption: Data loss: 0.0005415201754793394\n","\n","\tTesting: Initial condition loss: 0.0035928210709244013\n","\tTesting: Boundary condition loss: 0.002222602255642414\n","\tTesting: PDE loss: 0.021231286227703094\n","\tTesting: Data loss: 0.007371016312390566\n","\n","Epoch 294\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005522698629647493\n","\tBefore adaption: Boundary condition loss: 0.001971831079572439\n","\tBefore adaption: PDE loss: 0.021378202363848686\n","\tBefore adaption: Data loss: 0.007291019894182682\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0361, 0.4473, 0.4030, 0.1136], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002470274864561388\n","\t\tAfter adaption: Boundary condition loss: 7.123355397840052e-05\n","\t\tAfter adaption: PDE loss: 0.00861500470851271\n","\t\tAfter adaption: Data loss: 0.0008282491093393382\n","\n","\tTesting: Initial condition loss: 0.004013606812804937\n","\tTesting: Boundary condition loss: 0.00529511971399188\n","\tTesting: PDE loss: 0.022044913843274117\n","\tTesting: Data loss: 0.011131849139928818\n","\n","Epoch 295\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005560340825468302\n","\tBefore adaption: Boundary condition loss: 0.004837617743760347\n","\tBefore adaption: PDE loss: 0.022172732278704643\n","\tBefore adaption: Data loss: 0.01101086288690567\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0352, 0.3774, 0.4575, 0.1299], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020982060080891045\n","\t\tAfter adaption: Boundary condition loss: 0.00017044728908610258\n","\t\tAfter adaption: PDE loss: 0.010144728954202042\n","\t\tAfter adaption: Data loss: 0.0014301155490856097\n","\n","\tTesting: Initial condition loss: 0.005970857571810484\n","\tTesting: Boundary condition loss: 0.008739875629544258\n","\tTesting: PDE loss: 0.02234501577913761\n","\tTesting: Data loss: 0.01529738400131464\n","\n","Epoch 296\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007050630636513233\n","\tBefore adaption: Boundary condition loss: 0.008082243613898754\n","\tBefore adaption: PDE loss: 0.022483356297016144\n","\tBefore adaption: Data loss: 0.015139895491302013\n","tensor(0.0081, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0081, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0476, 0.2852, 0.5045, 0.1627], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002010702528805275\n","\t\tAfter adaption: Boundary condition loss: 0.0003849928744244381\n","\t\tAfter adaption: PDE loss: 0.011342031978576486\n","\t\tAfter adaption: Data loss: 0.0024635842347532546\n","\n","\tTesting: Initial condition loss: 0.007528703194111586\n","\tTesting: Boundary condition loss: 0.01134831178933382\n","\tTesting: PDE loss: 0.022158736363053322\n","\tTesting: Data loss: 0.018735246732831\n","\n","Epoch 297\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008270333521068096\n","\tBefore adaption: Boundary condition loss: 0.010576455853879452\n","\tBefore adaption: PDE loss: 0.022290004417300224\n","\tBefore adaption: Data loss: 0.018548695370554924\n","tensor(0.0106, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0106, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0775, 0.2024, 0.5124, 0.2078], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001673585678309385\n","\t\tAfter adaption: Boundary condition loss: 0.0008192430812148005\n","\t\tAfter adaption: PDE loss: 0.011420801337627288\n","\t\tAfter adaption: Data loss: 0.0038545540539365844\n","\n","\tTesting: Initial condition loss: 0.007572985719889402\n","\tTesting: Boundary condition loss: 0.012196719646453857\n","\tTesting: PDE loss: 0.021572278812527657\n","\tTesting: Data loss: 0.020468994975090027\n","\n","Epoch 298\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0082623939961195\n","\tBefore adaption: Boundary condition loss: 0.011428380385041237\n","\tBefore adaption: PDE loss: 0.02167525328695774\n","\tBefore adaption: Data loss: 0.02026505582034588\n","tensor(0.0114, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0114, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1145, 0.1545, 0.4795, 0.2515], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012762218627869915\n","\t\tAfter adaption: Boundary condition loss: 0.0013088986230347444\n","\t\tAfter adaption: PDE loss: 0.010393974251420487\n","\t\tAfter adaption: Data loss: 0.005096172676509823\n","\n","\tTesting: Initial condition loss: 0.006070203613489866\n","\tTesting: Boundary condition loss: 0.010922402143478394\n","\tTesting: PDE loss: 0.0206771157681942\n","\tTesting: Data loss: 0.0199346374720335\n","\n","Epoch 299\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006988442037254572\n","\tBefore adaption: Boundary condition loss: 0.010270485654473305\n","\tBefore adaption: PDE loss: 0.020781228318810463\n","\tBefore adaption: Data loss: 0.019728809595108032\n","tensor(0.0103, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0103, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1454, 0.1365, 0.4334, 0.2847], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009542026880780377\n","\t\tAfter adaption: Boundary condition loss: 0.0014930988247369276\n","\t\tAfter adaption: PDE loss: 0.00900576231683415\n","\t\tAfter adaption: Data loss: 0.005617218573159734\n","\n","\tTesting: Initial condition loss: 0.003995539154857397\n","\tTesting: Boundary condition loss: 0.008005967363715172\n","\tTesting: PDE loss: 0.019663983955979347\n","\tTesting: Data loss: 0.01733122207224369\n","\n","Epoch 300\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005280714016407728\n","\tBefore adaption: Boundary condition loss: 0.00752959493547678\n","\tBefore adaption: PDE loss: 0.01972794160246849\n","\tBefore adaption: Data loss: 0.017139794304966927\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1641, 0.1312, 0.3972, 0.3076], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006926908353649306\n","\t\tAfter adaption: Boundary condition loss: 0.0012356876119242264\n","\t\tAfter adaption: PDE loss: 0.007835029033629164\n","\t\tAfter adaption: Data loss: 0.0052715397835845475\n","\n","\tTesting: Initial condition loss: 0.0029348405078053474\n","\tTesting: Boundary condition loss: 0.004583288915455341\n","\tTesting: PDE loss: 0.01857321336865425\n","\tTesting: Data loss: 0.013617581687867641\n","\n","Epoch 301\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004529778845608234\n","\tBefore adaption: Boundary condition loss: 0.004289817996323109\n","\tBefore adaption: PDE loss: 0.01862240768969059\n","\tBefore adaption: Data loss: 0.013454481028020382\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1701, 0.1273, 0.3799, 0.3227], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005768605996811347\n","\t\tAfter adaption: Boundary condition loss: 0.0007297811568720031\n","\t\tAfter adaption: PDE loss: 0.00707385060519602\n","\t\tAfter adaption: Data loss: 0.004341424730957162\n","\n","\tTesting: Initial condition loss: 0.004263259936124086\n","\tTesting: Boundary condition loss: 0.0017963415011763573\n","\tTesting: PDE loss: 0.01754048280417919\n","\tTesting: Data loss: 0.010018564760684967\n","\n","Epoch 302\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0060080052353441715\n","\tBefore adaption: Boundary condition loss: 0.0016634257044643164\n","\tBefore adaption: PDE loss: 0.017565906047821045\n","\tBefore adaption: Data loss: 0.009893334470689297\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1635, 0.1236, 0.3823, 0.3306], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007425995829762972\n","\t\tAfter adaption: Boundary condition loss: 0.0002720220504031638\n","\t\tAfter adaption: PDE loss: 0.006714774159757456\n","\t\tAfter adaption: Data loss: 0.0032707872103817474\n","\n","\tTesting: Initial condition loss: 0.008546591736376286\n","\tTesting: Boundary condition loss: 0.0003107377851847559\n","\tTesting: PDE loss: 0.01660149171948433\n","\tTesting: Data loss: 0.0074381278827786446\n","\n","Epoch 303\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010208787396550179\n","\tBefore adaption: Boundary condition loss: 0.00027235460584051907\n","\tBefore adaption: PDE loss: 0.016618231311440468\n","\tBefore adaption: Data loss: 0.007355550769716501\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1435, 0.1268, 0.4013, 0.3284], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012940023176199913\n","\t\tAfter adaption: Boundary condition loss: 3.909349505469946e-05\n","\t\tAfter adaption: PDE loss: 0.006669284009360318\n","\t\tAfter adaption: Data loss: 0.00241544323523402\n","\n","\tTesting: Initial condition loss: 0.015264850109815598\n","\tTesting: Boundary condition loss: 0.00011374090536264703\n","\tTesting: PDE loss: 0.01576199196279049\n","\tTesting: Data loss: 0.006193932145833969\n","\n","Epoch 304\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016639942303299904\n","\tBefore adaption: Boundary condition loss: 0.00010959814244415611\n","\tBefore adaption: PDE loss: 0.015787776559591293\n","\tBefore adaption: Data loss: 0.006151983514428139\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1102, 0.1515, 0.4282, 0.3101], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0025208581335528064\n","\t\tAfter adaption: Boundary condition loss: 1.2081918129975059e-05\n","\t\tAfter adaption: PDE loss: 0.006760468965757081\n","\t\tAfter adaption: Data loss: 0.0019074714524915323\n","\n","\tTesting: Initial condition loss: 0.0228678360581398\n","\tTesting: Boundary condition loss: 0.0007107971468940377\n","\tTesting: PDE loss: 0.015041671693325043\n","\tTesting: Data loss: 0.00604582903906703\n","\n","Epoch 305\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02391430363059044\n","\tBefore adaption: Boundary condition loss: 0.0007017875323072076\n","\tBefore adaption: PDE loss: 0.015051574446260929\n","\tBefore adaption: Data loss: 0.0060378992930054665\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0697, 0.2146, 0.4442, 0.2715], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005131541452440224\n","\t\tAfter adaption: Boundary condition loss: 4.892599353087727e-05\n","\t\tAfter adaption: PDE loss: 0.006685951966048739\n","\t\tAfter adaption: Data loss: 0.0016392911371229675\n","\n","\tTesting: Initial condition loss: 0.028731761500239372\n","\tTesting: Boundary condition loss: 0.0013648964231833816\n","\tTesting: PDE loss: 0.014502950012683868\n","\tTesting: Data loss: 0.006358663085848093\n","\n","Epoch 306\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029580315575003624\n","\tBefore adaption: Boundary condition loss: 0.0013442476047202945\n","\tBefore adaption: PDE loss: 0.014496656134724617\n","\tBefore adaption: Data loss: 0.006372441072016954\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0361, 0.3146, 0.4292, 0.2201], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009306272280169375\n","\t\tAfter adaption: Boundary condition loss: 4.853208149151697e-05\n","\t\tAfter adaption: PDE loss: 0.0062224831679457615\n","\t\tAfter adaption: Data loss: 0.0014022565963527883\n","\n","\tTesting: Initial condition loss: 0.029785485938191414\n","\tTesting: Boundary condition loss: 0.0014371414436027408\n","\tTesting: PDE loss: 0.014306345023214817\n","\tTesting: Data loss: 0.00644182413816452\n","\n","Epoch 307\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030746955424547195\n","\tBefore adaption: Boundary condition loss: 0.0014169869245961308\n","\tBefore adaption: PDE loss: 0.014298558235168457\n","\tBefore adaption: Data loss: 0.0064596268348395824\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0199, 0.4198, 0.3864, 0.1740], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012906147318944211\n","\t\tAfter adaption: Boundary condition loss: 2.8167456691864796e-05\n","\t\tAfter adaption: PDE loss: 0.005524894931619371\n","\t\tAfter adaption: Data loss: 0.001123796950320663\n","\n","\tTesting: Initial condition loss: 0.02472839504480362\n","\tTesting: Boundary condition loss: 0.0008096559322439134\n","\tTesting: PDE loss: 0.014636949636042118\n","\tTesting: Data loss: 0.006119991187006235\n","\n","Epoch 308\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026141565293073654\n","\tBefore adaption: Boundary condition loss: 0.0008046398870646954\n","\tBefore adaption: PDE loss: 0.014607541263103485\n","\tBefore adaption: Data loss: 0.006120477803051472\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0172, 0.4971, 0.3410, 0.1448], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012994042986986816\n","\t\tAfter adaption: Boundary condition loss: 1.3834605450990177e-05\n","\t\tAfter adaption: PDE loss: 0.004980825657507577\n","\t\tAfter adaption: Data loss: 0.0008860337960762338\n","\n","\tTesting: Initial condition loss: 0.01588246040046215\n","\tTesting: Boundary condition loss: 0.0001298171846428886\n","\tTesting: PDE loss: 0.01548461802303791\n","\tTesting: Data loss: 0.00609639473259449\n","\n","Epoch 309\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01783689856529236\n","\tBefore adaption: Boundary condition loss: 0.00013019036850892007\n","\tBefore adaption: PDE loss: 0.01547314878553152\n","\tBefore adaption: Data loss: 0.006060149986296892\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0185, 0.5366, 0.3134, 0.1315], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009571878714639681\n","\t\tAfter adaption: Boundary condition loss: 2.405997157716538e-06\n","\t\tAfter adaption: PDE loss: 0.004849530064358537\n","\t\tAfter adaption: Data loss: 0.0007967264206308623\n","\n","\tTesting: Initial condition loss: 0.007777629420161247\n","\tTesting: Boundary condition loss: 0.0004974045441485941\n","\tTesting: PDE loss: 0.016744136810302734\n","\tTesting: Data loss: 0.0074989693239331245\n","\n","Epoch 310\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009993516840040684\n","\tBefore adaption: Boundary condition loss: 0.00043164193630218506\n","\tBefore adaption: PDE loss: 0.016743749380111694\n","\tBefore adaption: Data loss: 0.007413623388856649\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0185, 0.5398, 0.3110, 0.1306], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005394801186631257\n","\t\tAfter adaption: Boundary condition loss: 7.987429395831812e-06\n","\t\tAfter adaption: PDE loss: 0.0052076547465322596\n","\t\tAfter adaption: Data loss: 0.000968546212519218\n","\n","\tTesting: Initial condition loss: 0.0036879016552120447\n","\tTesting: Boundary condition loss: 0.0026414019521325827\n","\tTesting: PDE loss: 0.018151987344026566\n","\tTesting: Data loss: 0.010900354944169521\n","\n","Epoch 311\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0056772087700665\n","\tBefore adaption: Boundary condition loss: 0.0024003437720239162\n","\tBefore adaption: PDE loss: 0.01818247325718403\n","\tBefore adaption: Data loss: 0.010760579258203506\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0182, 0.5048, 0.3338, 0.1432], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002865861305857101\n","\t\tAfter adaption: Boundary condition loss: 4.3741977244251125e-05\n","\t\tAfter adaption: PDE loss: 0.0060696617954692006\n","\t\tAfter adaption: Data loss: 0.0015404423565789987\n","\n","\tTesting: Initial condition loss: 0.003768851747736335\n","\tTesting: Boundary condition loss: 0.006251143757253885\n","\tTesting: PDE loss: 0.019474660977721214\n","\tTesting: Data loss: 0.01572241261601448\n","\n","Epoch 312\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005244608968496323\n","\tBefore adaption: Boundary condition loss: 0.005783017259091139\n","\tBefore adaption: PDE loss: 0.019504353404045105\n","\tBefore adaption: Data loss: 0.01553176436573267\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0245, 0.4270, 0.3746, 0.1739], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022393135469818736\n","\t\tAfter adaption: Boundary condition loss: 0.0001416106741058937\n","\t\tAfter adaption: PDE loss: 0.007306917744817995\n","\t\tAfter adaption: Data loss: 0.0027010977397518027\n","\n","\tTesting: Initial condition loss: 0.005942381918430328\n","\tTesting: Boundary condition loss: 0.01008491963148117\n","\tTesting: PDE loss: 0.02047644555568695\n","\tTesting: Data loss: 0.02043994329869747\n","\n","Epoch 313\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006854300387203693\n","\tBefore adaption: Boundary condition loss: 0.009403322823345661\n","\tBefore adaption: PDE loss: 0.020486023277044296\n","\tBefore adaption: Data loss: 0.020208366215229034\n","tensor(0.0094, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0094, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0466, 0.3166, 0.4127, 0.2240], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002170395850149221\n","\t\tAfter adaption: Boundary condition loss: 0.00043844635708612065\n","\t\tAfter adaption: PDE loss: 0.008454105616961518\n","\t\tAfter adaption: Data loss: 0.004527662885046868\n","\n","\tTesting: Initial condition loss: 0.007696965709328651\n","\tTesting: Boundary condition loss: 0.012425201945006847\n","\tTesting: PDE loss: 0.021036271005868912\n","\tTesting: Data loss: 0.023318639025092125\n","\n","Epoch 314\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008242523297667503\n","\tBefore adaption: Boundary condition loss: 0.011617278680205345\n","\tBefore adaption: PDE loss: 0.021034248173236847\n","\tBefore adaption: Data loss: 0.023064376786351204\n","tensor(0.0116, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0116, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0848, 0.2128, 0.4222, 0.2801], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017542947488721921\n","\t\tAfter adaption: Boundary condition loss: 0.0009847644094505164\n","\t\tAfter adaption: PDE loss: 0.00888170760484938\n","\t\tAfter adaption: Data loss: 0.0064614401723456436\n","\n","\tTesting: Initial condition loss: 0.007613217458128929\n","\tTesting: Boundary condition loss: 0.012128784321248531\n","\tTesting: PDE loss: 0.02122359536588192\n","\tTesting: Data loss: 0.023206189274787903\n","\n","Epoch 315\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008112923242151737\n","\tBefore adaption: Boundary condition loss: 0.011327991262078285\n","\tBefore adaption: PDE loss: 0.021231262013316154\n","\tBefore adaption: Data loss: 0.022952724248170853\n","tensor(0.0113, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0113, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1242, 0.1508, 0.4022, 0.3227], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012237355943593943\n","\t\tAfter adaption: Boundary condition loss: 0.0014072280176037073\n","\t\tAfter adaption: PDE loss: 0.008539646750719712\n","\t\tAfter adaption: Data loss: 0.007407207744841133\n","\n","\tTesting: Initial condition loss: 0.0057824524119496346\n","\tTesting: Boundary condition loss: 0.009372600354254246\n","\tTesting: PDE loss: 0.021176116541028023\n","\tTesting: Data loss: 0.02011725679039955\n","\n","Epoch 316\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006509752478450537\n","\tBefore adaption: Boundary condition loss: 0.00870139803737402\n","\tBefore adaption: PDE loss: 0.0211808942258358\n","\tBefore adaption: Data loss: 0.01988808624446392\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1515, 0.1275, 0.3753, 0.3458], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008298662030654646\n","\t\tAfter adaption: Boundary condition loss: 0.0013179302293049881\n","\t\tAfter adaption: PDE loss: 0.007948758100958478\n","\t\tAfter adaption: Data loss: 0.006876859440787657\n","\n","\tTesting: Initial condition loss: 0.003519034245982766\n","\tTesting: Boundary condition loss: 0.0055815852247178555\n","\tTesting: PDE loss: 0.020994866266846657\n","\tTesting: Data loss: 0.015278133563697338\n","\n","Epoch 317\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004567605443298817\n","\tBefore adaption: Boundary condition loss: 0.005108673125505447\n","\tBefore adaption: PDE loss: 0.021008113399147987\n","\tBefore adaption: Data loss: 0.015089834108948708\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1633, 0.1219, 0.3605, 0.3544], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005565801188772177\n","\t\tAfter adaption: Boundary condition loss: 0.0008340528693955157\n","\t\tAfter adaption: PDE loss: 0.00757338945969869\n","\t\tAfter adaption: Data loss: 0.005347619471194222\n","\n","\tTesting: Initial condition loss: 0.002599384170025587\n","\tTesting: Boundary condition loss: 0.0023737289011478424\n","\tTesting: PDE loss: 0.020733892917633057\n","\tTesting: Data loss: 0.010421681217849255\n","\n","Epoch 318\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0038224016316235065\n","\tBefore adaption: Boundary condition loss: 0.002105058403685689\n","\tBefore adaption: PDE loss: 0.020790264010429382\n","\tBefore adaption: Data loss: 0.010282162576913834\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1611, 0.1196, 0.3661, 0.3532], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004572799516813677\n","\t\tAfter adaption: Boundary condition loss: 0.00033907068162353004\n","\t\tAfter adaption: PDE loss: 0.007611479409746051\n","\t\tAfter adaption: Data loss: 0.003631517188574026\n","\n","\tTesting: Initial condition loss: 0.004218535032123327\n","\tTesting: Boundary condition loss: 0.0006285980925895274\n","\tTesting: PDE loss: 0.020455386489629745\n","\tTesting: Data loss: 0.00686122989282012\n","\n","Epoch 319\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005372677464038134\n","\tBefore adaption: Boundary condition loss: 0.000532095436938107\n","\tBefore adaption: PDE loss: 0.020521942526102066\n","\tBefore adaption: Data loss: 0.006771129090338945\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1457, 0.1172, 0.3947, 0.3423], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000629776777356276\n","\t\tAfter adaption: Boundary condition loss: 7.755108065385274e-05\n","\t\tAfter adaption: PDE loss: 0.008099725625550143\n","\t\tAfter adaption: Data loss: 0.0023180873750285485\n","\n","\tTesting: Initial condition loss: 0.008576136082410812\n","\tTesting: Boundary condition loss: 0.00045505311572924256\n","\tTesting: PDE loss: 0.02010371908545494\n","\tTesting: Data loss: 0.005047914572060108\n","\n","Epoch 320\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009377913549542427\n","\tBefore adaption: Boundary condition loss: 0.00046282022958621383\n","\tBefore adaption: PDE loss: 0.02014324814081192\n","\tBefore adaption: Data loss: 0.00500255823135376\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1177, 0.1203, 0.4440, 0.3179], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011285249718185292\n","\t\tAfter adaption: Boundary condition loss: 5.449451641037369e-05\n","\t\tAfter adaption: PDE loss: 0.008944564415646138\n","\t\tAfter adaption: Data loss: 0.0015901579984716906\n","\n","\tTesting: Initial condition loss: 0.014824306592345238\n","\tTesting: Boundary condition loss: 0.0012912900419905782\n","\tTesting: PDE loss: 0.01960042119026184\n","\tTesting: Data loss: 0.004705504048615694\n","\n","Epoch 321\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01515933871269226\n","\tBefore adaption: Boundary condition loss: 0.001344284974038601\n","\tBefore adaption: PDE loss: 0.01956685446202755\n","\tBefore adaption: Data loss: 0.0046968781389296055\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0816, 0.1431, 0.5002, 0.2751], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002168860881482916\n","\t\tAfter adaption: Boundary condition loss: 0.00010967148044483696\n","\t\tAfter adaption: PDE loss: 0.00978739140054077\n","\t\tAfter adaption: Data loss: 0.0012923118001404773\n","\n","\tTesting: Initial condition loss: 0.021513888612389565\n","\tTesting: Boundary condition loss: 0.002354959025979042\n","\tTesting: PDE loss: 0.018847782164812088\n","\tTesting: Data loss: 0.005177756305783987\n","\n","Epoch 322\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02145272120833397\n","\tBefore adaption: Boundary condition loss: 0.002410853747278452\n","\tBefore adaption: PDE loss: 0.018781786784529686\n","\tBefore adaption: Data loss: 0.00519565911963582\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0498, 0.1998, 0.5322, 0.2182], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004285524222232199\n","\t\tAfter adaption: Boundary condition loss: 0.00012010143912961508\n","\t\tAfter adaption: PDE loss: 0.009996592721381986\n","\t\tAfter adaption: Data loss: 0.001133523839358889\n","\n","\tTesting: Initial condition loss: 0.026666821911931038\n","\tTesting: Boundary condition loss: 0.002959570847451687\n","\tTesting: PDE loss: 0.0179432462900877\n","\tTesting: Data loss: 0.005751439370214939\n","\n","Epoch 323\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02650322951376438\n","\tBefore adaption: Boundary condition loss: 0.0029997907113283873\n","\tBefore adaption: PDE loss: 0.01786131039261818\n","\tBefore adaption: Data loss: 0.005785243585705757\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0354, 0.2848, 0.5150, 0.1648], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007547990633431508\n","\t\tAfter adaption: Boundary condition loss: 0.00010609611255048161\n","\t\tAfter adaption: PDE loss: 0.009199217764848827\n","\t\tAfter adaption: Data loss: 0.000953412663270866\n","\n","\tTesting: Initial condition loss: 0.02812476083636284\n","\tTesting: Boundary condition loss: 0.0026935602072626352\n","\tTesting: PDE loss: 0.01713782735168934\n","\tTesting: Data loss: 0.005890292581170797\n","\n","Epoch 324\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028203796595335007\n","\tBefore adaption: Boundary condition loss: 0.0027212502900511026\n","\tBefore adaption: PDE loss: 0.017052164301276207\n","\tBefore adaption: Data loss: 0.005927175283432007\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0369, 0.3710, 0.4614, 0.1307], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010462956671955433\n","\t\tAfter adaption: Boundary condition loss: 0.00010043912319214779\n","\t\tAfter adaption: PDE loss: 0.00786784705573188\n","\t\tAfter adaption: Data loss: 0.0007747704565671712\n","\n","\tTesting: Initial condition loss: 0.024693142622709274\n","\tTesting: Boundary condition loss: 0.0016306033357977867\n","\tTesting: PDE loss: 0.016645878553390503\n","\tTesting: Data loss: 0.005531603936105967\n","\n","Epoch 325\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0253854189068079\n","\tBefore adaption: Boundary condition loss: 0.001654751948080957\n","\tBefore adaption: PDE loss: 0.01659010909497738\n","\tBefore adaption: Data loss: 0.005555097013711929\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0431, 0.4367, 0.4049, 0.1153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011086261136009804\n","\t\tAfter adaption: Boundary condition loss: 7.129566906302909e-05\n","\t\tAfter adaption: PDE loss: 0.00671684930074669\n","\t\tAfter adaption: Data loss: 0.0006406470223196388\n","\n","\tTesting: Initial condition loss: 0.01759536936879158\n","\tTesting: Boundary condition loss: 0.00044868022087030113\n","\tTesting: PDE loss: 0.016653697937726974\n","\tTesting: Data loss: 0.005293446127325296\n","\n","Epoch 326\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01904911920428276\n","\tBefore adaption: Boundary condition loss: 0.00046727922745049\n","\tBefore adaption: PDE loss: 0.016601059585809708\n","\tBefore adaption: Data loss: 0.005283487495034933\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0455, 0.4768, 0.3669, 0.1109], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009082585040748617\n","\t\tAfter adaption: Boundary condition loss: 2.123935353595805e-05\n","\t\tAfter adaption: PDE loss: 0.006090101049743904\n","\t\tAfter adaption: Data loss: 0.0005859295420622351\n","\n","\tTesting: Initial condition loss: 0.00996567215770483\n","\tTesting: Boundary condition loss: 0.00016648003656882793\n","\tTesting: PDE loss: 0.01710858941078186\n","\tTesting: Data loss: 0.0061996630392968655\n","\n","Epoch 327\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012035823427140713\n","\tBefore adaption: Boundary condition loss: 0.00013679849507752806\n","\tBefore adaption: PDE loss: 0.017053505405783653\n","\tBefore adaption: Data loss: 0.006137125194072723\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0418, 0.4914, 0.3538, 0.1130], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005914536325952653\n","\t\tAfter adaption: Boundary condition loss: 5.713171068609482e-06\n","\t\tAfter adaption: PDE loss: 0.006033848082225278\n","\t\tAfter adaption: Data loss: 0.0006935364249474179\n","\n","\tTesting: Initial condition loss: 0.004880319815129042\n","\tTesting: Boundary condition loss: 0.001565587823279202\n","\tTesting: PDE loss: 0.017850510776042938\n","\tTesting: Data loss: 0.008991424925625324\n","\n","Epoch 328\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00706503028050065\n","\tBefore adaption: Boundary condition loss: 0.0014143794542178512\n","\tBefore adaption: PDE loss: 0.0177984070032835\n","\tBefore adaption: Data loss: 0.008863436989486217\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0342, 0.4773, 0.3654, 0.1231], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00337183379463522\n","\t\tAfter adaption: Boundary condition loss: 4.843310092413202e-05\n","\t\tAfter adaption: PDE loss: 0.006503353955889487\n","\t\tAfter adaption: Data loss: 0.0010911773451070482\n","\n","\tTesting: Initial condition loss: 0.0034062578342854977\n","\tTesting: Boundary condition loss: 0.0046805329620838165\n","\tTesting: PDE loss: 0.01865939050912857\n","\tTesting: Data loss: 0.01355726271867752\n","\n","Epoch 329\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005215797573328018\n","\tBefore adaption: Boundary condition loss: 0.004344499204307795\n","\tBefore adaption: PDE loss: 0.018610602244734764\n","\tBefore adaption: Data loss: 0.013362283818423748\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0297, 0.4267, 0.3958, 0.1478], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002225651773833593\n","\t\tAfter adaption: Boundary condition loss: 0.00012921165129539658\n","\t\tAfter adaption: PDE loss: 0.007365825173952686\n","\t\tAfter adaption: Data loss: 0.001974387333700412\n","\n","\tTesting: Initial condition loss: 0.004432837013155222\n","\tTesting: Boundary condition loss: 0.008690818212926388\n","\tTesting: PDE loss: 0.019315946847200394\n","\tTesting: Data loss: 0.01886022463440895\n","\n","Epoch 330\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005746475420892239\n","\tBefore adaption: Boundary condition loss: 0.008176766335964203\n","\tBefore adaption: PDE loss: 0.019271114841103554\n","\tBefore adaption: Data loss: 0.01860557124018669\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0396, 0.3392, 0.4277, 0.1935], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019492432864486272\n","\t\tAfter adaption: Boundary condition loss: 0.0003235696639185306\n","\t\tAfter adaption: PDE loss: 0.00824272947976414\n","\t\tAfter adaption: Data loss: 0.0036001144286770645\n","\n","\tTesting: Initial condition loss: 0.006062017288058996\n","\tTesting: Boundary condition loss: 0.012155430391430855\n","\tTesting: PDE loss: 0.019728560000658035\n","\tTesting: Data loss: 0.023263532668352127\n","\n","Epoch 331\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00693728169426322\n","\tBefore adaption: Boundary condition loss: 0.01151758711785078\n","\tBefore adaption: PDE loss: 0.01962772011756897\n","\tBefore adaption: Data loss: 0.022966114804148674\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0708, 0.2392, 0.4354, 0.2546], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016591235594025408\n","\t\tAfter adaption: Boundary condition loss: 0.0008160010925135132\n","\t\tAfter adaption: PDE loss: 0.008545020856728366\n","\t\tAfter adaption: Data loss: 0.0058480061390322035\n","\n","\tTesting: Initial condition loss: 0.006666580215096474\n","\tTesting: Boundary condition loss: 0.01353405974805355\n","\tTesting: PDE loss: 0.019775519147515297\n","\tTesting: Data loss: 0.02515888772904873\n","\n","Epoch 332\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0073690833523869514\n","\tBefore adaption: Boundary condition loss: 0.012861416675150394\n","\tBefore adaption: PDE loss: 0.01967652700841427\n","\tBefore adaption: Data loss: 0.02484249882400036\n","tensor(0.0129, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0129, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1138, 0.1644, 0.4107, 0.3110], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012116707724501184\n","\t\tAfter adaption: Boundary condition loss: 0.0014636044616054122\n","\t\tAfter adaption: PDE loss: 0.008081912526216138\n","\t\tAfter adaption: Data loss: 0.007726928282482831\n","\n","\tTesting: Initial condition loss: 0.005726708564907312\n","\tTesting: Boundary condition loss: 0.012099710293114185\n","\tTesting: PDE loss: 0.019571801647543907\n","\tTesting: Data loss: 0.02371971681714058\n","\n","Epoch 333\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006567453034222126\n","\tBefore adaption: Boundary condition loss: 0.0114853885024786\n","\tBefore adaption: PDE loss: 0.01947103813290596\n","\tBefore adaption: Data loss: 0.023414604365825653\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1507, 0.1271, 0.3735, 0.3487], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008347030579515536\n","\t\tAfter adaption: Boundary condition loss: 0.001730770280027832\n","\t\tAfter adaption: PDE loss: 0.007273043718473299\n","\t\tAfter adaption: Data loss: 0.00816416385600068\n","\n","\tTesting: Initial condition loss: 0.003968348726630211\n","\tTesting: Boundary condition loss: 0.008528249338269234\n","\tTesting: PDE loss: 0.01918412372469902\n","\tTesting: Data loss: 0.019474847242236137\n","\n","Epoch 334\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0051811872981488705\n","\tBefore adaption: Boundary condition loss: 0.008047639392316341\n","\tBefore adaption: PDE loss: 0.019110508263111115\n","\tBefore adaption: Data loss: 0.019209520891308784\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1728, 0.1136, 0.3451, 0.3685], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005887710772382489\n","\t\tAfter adaption: Boundary condition loss: 0.0013904374858283535\n","\t\tAfter adaption: PDE loss: 0.006594162327965546\n","\t\tAfter adaption: Data loss: 0.007079350366875847\n","\n","\tTesting: Initial condition loss: 0.0029420219361782074\n","\tTesting: Boundary condition loss: 0.00453136395663023\n","\tTesting: PDE loss: 0.018787438049912453\n","\tTesting: Data loss: 0.014049826189875603\n","\n","Epoch 335\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004552774131298065\n","\tBefore adaption: Boundary condition loss: 0.004205112345516682\n","\tBefore adaption: PDE loss: 0.018714886158704758\n","\tBefore adaption: Data loss: 0.013845302164554596\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1796, 0.1096, 0.3348, 0.3760], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004990255673771951\n","\t\tAfter adaption: Boundary condition loss: 0.0007551533297415043\n","\t\tAfter adaption: PDE loss: 0.006266622830428769\n","\t\tAfter adaption: Data loss: 0.00520533406918501\n","\n","\tTesting: Initial condition loss: 0.0041235205717384815\n","\tTesting: Boundary condition loss: 0.0015346260042861104\n","\tTesting: PDE loss: 0.018421214073896408\n","\tTesting: Data loss: 0.009226838126778603\n","\n","Epoch 336\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005984514486044645\n","\tBefore adaption: Boundary condition loss: 0.0013736255932599306\n","\tBefore adaption: PDE loss: 0.01836383156478405\n","\tBefore adaption: Data loss: 0.009092996828258038\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1721, 0.1095, 0.3454, 0.3730], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000655060565481783\n","\t\tAfter adaption: Boundary condition loss: 0.0002364055169475925\n","\t\tAfter adaption: PDE loss: 0.006343450864034908\n","\t\tAfter adaption: Data loss: 0.0033917375501060065\n","\n","\tTesting: Initial condition loss: 0.008199854753911495\n","\tTesting: Boundary condition loss: 0.00024202378699555993\n","\tTesting: PDE loss: 0.018082235008478165\n","\tTesting: Data loss: 0.006137581542134285\n","\n","Epoch 337\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010052729398012161\n","\tBefore adaption: Boundary condition loss: 0.0002094935771310702\n","\tBefore adaption: PDE loss: 0.018048450350761414\n","\tBefore adaption: Data loss: 0.0060726189985871315\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1499, 0.1170, 0.3763, 0.3568], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011765688892545706\n","\t\tAfter adaption: Boundary condition loss: 3.139762803623001e-05\n","\t\tAfter adaption: PDE loss: 0.006791013613098646\n","\t\tAfter adaption: Data loss: 0.0021668341665178428\n","\n","\tTesting: Initial condition loss: 0.014634992927312851\n","\tTesting: Boundary condition loss: 0.0004948098212480545\n","\tTesting: PDE loss: 0.017779240384697914\n","\tTesting: Data loss: 0.004963396117091179\n","\n","Epoch 338\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016256634145975113\n","\tBefore adaption: Boundary condition loss: 0.0005400656955316663\n","\tBefore adaption: PDE loss: 0.017747562378644943\n","\tBefore adaption: Data loss: 0.004956493154168129\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1135, 0.1450, 0.4203, 0.3212], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002357522984077632\n","\t\tAfter adaption: Boundary condition loss: 6.131593931234213e-05\n","\t\tAfter adaption: PDE loss: 0.007458632180488496\n","\t\tAfter adaption: Data loss: 0.0015919466683230927\n","\n","\tTesting: Initial condition loss: 0.021799389272928238\n","\tTesting: Boundary condition loss: 0.0015501438174396753\n","\tTesting: PDE loss: 0.017465481534600258\n","\tTesting: Data loss: 0.0051300716586411\n","\n","Epoch 339\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023167844861745834\n","\tBefore adaption: Boundary condition loss: 0.0016395151615142822\n","\tBefore adaption: PDE loss: 0.017433468252420425\n","\tBefore adaption: Data loss: 0.005164729431271553\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0713, 0.2085, 0.4564, 0.2637], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004831062786974699\n","\t\tAfter adaption: Boundary condition loss: 0.00011691041365885204\n","\t\tAfter adaption: PDE loss: 0.00795711729210905\n","\t\tAfter adaption: Data loss: 0.001362144108775764\n","\n","\tTesting: Initial condition loss: 0.02731996588408947\n","\tTesting: Boundary condition loss: 0.002525894669815898\n","\tTesting: PDE loss: 0.017197972163558006\n","\tTesting: Data loss: 0.005707249976694584\n","\n","Epoch 340\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028511863201856613\n","\tBefore adaption: Boundary condition loss: 0.002637210302054882\n","\tBefore adaption: PDE loss: 0.01716441847383976\n","\tBefore adaption: Data loss: 0.005766141694039106\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0404, 0.3040, 0.4575, 0.1981], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008668621079608248\n","\t\tAfter adaption: Boundary condition loss: 0.0001064115286475539\n","\t\tAfter adaption: PDE loss: 0.0078523665606409\n","\t\tAfter adaption: Data loss: 0.0011424733308366024\n","\n","\tTesting: Initial condition loss: 0.028571754693984985\n","\tTesting: Boundary condition loss: 0.0027343430556356907\n","\tTesting: PDE loss: 0.017156779766082764\n","\tTesting: Data loss: 0.00583935622125864\n","\n","Epoch 341\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029812511056661606\n","\tBefore adaption: Boundary condition loss: 0.0028530156705528498\n","\tBefore adaption: PDE loss: 0.017115119844675064\n","\tBefore adaption: Data loss: 0.005904459860175848\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0304, 0.3996, 0.4223, 0.1477], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011913732897133537\n","\t\tAfter adaption: Boundary condition loss: 8.685081197110775e-05\n","\t\tAfter adaption: PDE loss: 0.007227008234972203\n","\t\tAfter adaption: Data loss: 0.0008719551972246158\n","\n","\tTesting: Initial condition loss: 0.024397866800427437\n","\tTesting: Boundary condition loss: 0.0020181285217404366\n","\tTesting: PDE loss: 0.0175181832164526\n","\tTesting: Data loss: 0.0052383593283593655\n","\n","Epoch 342\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025923123583197594\n","\tBefore adaption: Boundary condition loss: 0.002129805274307728\n","\tBefore adaption: PDE loss: 0.017474910244345665\n","\tBefore adaption: Data loss: 0.0052905878983438015\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0341, 0.4667, 0.3786, 0.1205], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012098568268568713\n","\t\tAfter adaption: Boundary condition loss: 7.261204719588094e-05\n","\t\tAfter adaption: PDE loss: 0.006616871776981287\n","\t\tAfter adaption: Data loss: 0.0006377653778876183\n","\n","\tTesting: Initial condition loss: 0.016554102301597595\n","\tTesting: Boundary condition loss: 0.0009046515333466232\n","\tTesting: PDE loss: 0.018333984538912773\n","\tTesting: Data loss: 0.004491492174565792\n","\n","Epoch 343\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018446529284119606\n","\tBefore adaption: Boundary condition loss: 0.0009814653312787414\n","\tBefore adaption: PDE loss: 0.018283352255821228\n","\tBefore adaption: Data loss: 0.0045109898783266544\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0396, 0.4999, 0.3511, 0.1094], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009220958525959114\n","\t\tAfter adaption: Boundary condition loss: 3.8852988271765394e-05\n","\t\tAfter adaption: PDE loss: 0.006420174182774251\n","\t\tAfter adaption: Data loss: 0.000493454767255517\n","\n","\tTesting: Initial condition loss: 0.008758574724197388\n","\tTesting: Boundary condition loss: 0.00037205376429483294\n","\tTesting: PDE loss: 0.0194570142775774\n","\tTesting: Data loss: 0.0047133928164839745\n","\n","Epoch 344\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010847361758351326\n","\tBefore adaption: Boundary condition loss: 0.0003583059005904943\n","\tBefore adaption: PDE loss: 0.01940924860537052\n","\tBefore adaption: Data loss: 0.004682495724409819\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0409, 0.5032, 0.3495, 0.1064], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0054581734400236765\n","\t\tAfter adaption: Boundary condition loss: 1.4662336106233917e-05\n","\t\tAfter adaption: PDE loss: 0.006782935143180347\n","\t\tAfter adaption: Data loss: 0.0004983555855732713\n","\n","\tTesting: Initial condition loss: 0.004091437440365553\n","\tTesting: Boundary condition loss: 0.0012713895412161946\n","\tTesting: PDE loss: 0.020653136074543\n","\tTesting: Data loss: 0.006722377147525549\n","\n","Epoch 345\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005992180667817593\n","\tBefore adaption: Boundary condition loss: 0.0010795703856274486\n","\tBefore adaption: PDE loss: 0.02059457264840603\n","\tBefore adaption: Data loss: 0.006632255855947733\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0376, 0.4770, 0.3756, 0.1098], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0028580091692927178\n","\t\tAfter adaption: Boundary condition loss: 4.061946083948688e-05\n","\t\tAfter adaption: PDE loss: 0.007735039728300191\n","\t\tAfter adaption: Data loss: 0.0007284302804996392\n","\n","\tTesting: Initial condition loss: 0.003222608007490635\n","\tTesting: Boundary condition loss: 0.003697989508509636\n","\tTesting: PDE loss: 0.021636435762047768\n","\tTesting: Data loss: 0.01045176014304161\n","\n","Epoch 346\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004652090836316347\n","\tBefore adaption: Boundary condition loss: 0.0032773942220956087\n","\tBefore adaption: PDE loss: 0.021573258563876152\n","\tBefore adaption: Data loss: 0.010301775299012661\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0339, 0.4169, 0.4254, 0.1238], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019394304071652525\n","\t\tAfter adaption: Boundary condition loss: 0.00011112089083365376\n","\t\tAfter adaption: PDE loss: 0.0091779497071119\n","\t\tAfter adaption: Data loss: 0.001275034080679726\n","\n","\tTesting: Initial condition loss: 0.0046930331736803055\n","\tTesting: Boundary condition loss: 0.006930194329470396\n","\tTesting: PDE loss: 0.022168800234794617\n","\tTesting: Data loss: 0.015027427114546299\n","\n","Epoch 347\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005607725586742163\n","\tBefore adaption: Boundary condition loss: 0.006304354872554541\n","\tBefore adaption: PDE loss: 0.022116810083389282\n","\tBefore adaption: Data loss: 0.014822065830230713\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0387, 0.3252, 0.4809, 0.1552], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00182363851087298\n","\t\tAfter adaption: Boundary condition loss: 0.00024375196743890362\n","\t\tAfter adaption: PDE loss: 0.010636462904627659\n","\t\tAfter adaption: Data loss: 0.0023005697046518904\n","\n","\tTesting: Initial condition loss: 0.006476478185504675\n","\tTesting: Boundary condition loss: 0.00986592285335064\n","\tTesting: PDE loss: 0.022178487852215767\n","\tTesting: Data loss: 0.019231431186199188\n","\n","Epoch 348\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007013940252363682\n","\tBefore adaption: Boundary condition loss: 0.009102920070290565\n","\tBefore adaption: PDE loss: 0.02216983027756214\n","\tBefore adaption: Data loss: 0.018982097506523132\n","tensor(0.0091, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0091, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0599, 0.2270, 0.5088, 0.2043], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015924403514224739\n","\t\tAfter adaption: Boundary condition loss: 0.000544959565525474\n","\t\tAfter adaption: PDE loss: 0.011280223609756976\n","\t\tAfter adaption: Data loss: 0.0038777446007751295\n","\n","\tTesting: Initial condition loss: 0.007143978960812092\n","\tTesting: Boundary condition loss: 0.011462816968560219\n","\tTesting: PDE loss: 0.021791839972138405\n","\tTesting: Data loss: 0.021925223991274834\n","\n","Epoch 349\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007532448973506689\n","\tBefore adaption: Boundary condition loss: 0.010672241449356079\n","\tBefore adaption: PDE loss: 0.021772032603621483\n","\tBefore adaption: Data loss: 0.021647918969392776\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0934, 0.1582, 0.4913, 0.2572], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011914794060596905\n","\t\tAfter adaption: Boundary condition loss: 0.000996454686048212\n","\t\tAfter adaption: PDE loss: 0.010696004246336498\n","\t\tAfter adaption: Data loss: 0.005567384361962148\n","\n","\tTesting: Initial condition loss: 0.006243463139981031\n","\tTesting: Boundary condition loss: 0.011060967110097408\n","\tTesting: PDE loss: 0.021075667813420296\n","\tTesting: Data loss: 0.02230716310441494\n","\n","Epoch 350\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006731017492711544\n","\tBefore adaption: Boundary condition loss: 0.010355615988373756\n","\tBefore adaption: PDE loss: 0.02107136882841587\n","\tBefore adaption: Data loss: 0.02202184870839119\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1259, 0.1273, 0.4475, 0.2994], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008567966539136179\n","\t\tAfter adaption: Boundary condition loss: 0.0013032905527359\n","\t\tAfter adaption: PDE loss: 0.0094294385404728\n","\t\tAfter adaption: Data loss: 0.006592360099340663\n","\n","\tTesting: Initial condition loss: 0.004324857611209154\n","\tTesting: Boundary condition loss: 0.00878265593200922\n","\tTesting: PDE loss: 0.02020762301981449\n","\tTesting: Data loss: 0.020263008773326874\n","\n","Epoch 351\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005073282867670059\n","\tBefore adaption: Boundary condition loss: 0.008229261264204979\n","\tBefore adaption: PDE loss: 0.020177077502012253\n","\tBefore adaption: Data loss: 0.019992874935269356\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1483, 0.1178, 0.4060, 0.3279], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005974864744682341\n","\t\tAfter adaption: Boundary condition loss: 0.001220729961482755\n","\t\tAfter adaption: PDE loss: 0.008191203178418826\n","\t\tAfter adaption: Data loss: 0.006556117292143047\n","\n","\tTesting: Initial condition loss: 0.002694972325116396\n","\tTesting: Boundary condition loss: 0.00553930876776576\n","\tTesting: PDE loss: 0.019272908568382263\n","\tTesting: Data loss: 0.016528287902474403\n","\n","Epoch 352\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003740056650713086\n","\tBefore adaption: Boundary condition loss: 0.00516023812815547\n","\tBefore adaption: PDE loss: 0.01920211687684059\n","\tBefore adaption: Data loss: 0.016294192522764206\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1587, 0.1136, 0.3813, 0.3464], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004247249502504317\n","\t\tAfter adaption: Boundary condition loss: 0.0008191094213988423\n","\t\tAfter adaption: PDE loss: 0.007321031595227439\n","\t\tAfter adaption: Data loss: 0.005644996193277546\n","\n","\tTesting: Initial condition loss: 0.002860330045223236\n","\tTesting: Boundary condition loss: 0.002513028448447585\n","\tTesting: PDE loss: 0.018316734582185745\n","\tTesting: Data loss: 0.012341312132775784\n","\n","Epoch 353\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004019164480268955\n","\tBefore adaption: Boundary condition loss: 0.0022998193744570017\n","\tBefore adaption: PDE loss: 0.018268227577209473\n","\tBefore adaption: Data loss: 0.012156850658357143\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1572, 0.1086, 0.3769, 0.3573], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00043667275342339896\n","\t\tAfter adaption: Boundary condition loss: 0.0003614300763366547\n","\t\tAfter adaption: PDE loss: 0.006884834170663697\n","\t\tAfter adaption: Data loss: 0.004343904670839284\n","\n","\tTesting: Initial condition loss: 0.005748221185058355\n","\tTesting: Boundary condition loss: 0.0006028052303008735\n","\tTesting: PDE loss: 0.017471056431531906\n","\tTesting: Data loss: 0.008845719508826733\n","\n","Epoch 354\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006767162587493658\n","\tBefore adaption: Boundary condition loss: 0.0005193671095184982\n","\tBefore adaption: PDE loss: 0.01740623265504837\n","\tBefore adaption: Data loss: 0.008716784417629242\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1432, 0.1057, 0.3919, 0.3593], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007150579552599754\n","\t\tAfter adaption: Boundary condition loss: 7.437191324705937e-05\n","\t\tAfter adaption: PDE loss: 0.00682082222870893\n","\t\tAfter adaption: Data loss: 0.0031317301412329217\n","\n","\tTesting: Initial condition loss: 0.011289711110293865\n","\tTesting: Boundary condition loss: 4.699049168266356e-05\n","\tTesting: PDE loss: 0.016713513061404228\n","\tTesting: Data loss: 0.006669533438980579\n","\n","Epoch 355\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011988955549895763\n","\tBefore adaption: Boundary condition loss: 4.738078496302478e-05\n","\tBefore adaption: PDE loss: 0.016653649508953094\n","\tBefore adaption: Data loss: 0.006593546364456415\n","tensor(4.7381e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(4.7381e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1164, 0.1154, 0.4212, 0.3470], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001383265523723963\n","\t\tAfter adaption: Boundary condition loss: 5.515263906712374e-06\n","\t\tAfter adaption: PDE loss: 0.0070150270957741985\n","\t\tAfter adaption: Data loss: 0.002287880659440896\n","\n","\tTesting: Initial condition loss: 0.018593518063426018\n","\tTesting: Boundary condition loss: 0.000516263535246253\n","\tTesting: PDE loss: 0.016025524586439133\n","\tTesting: Data loss: 0.005829392001032829\n","\n","Epoch 356\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018852759152650833\n","\tBefore adaption: Boundary condition loss: 0.0005569977220147848\n","\tBefore adaption: PDE loss: 0.015968099236488342\n","\tBefore adaption: Data loss: 0.005798627156764269\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0800, 0.1554, 0.4511, 0.3136], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0029293000067165845\n","\t\tAfter adaption: Boundary condition loss: 4.453281545791696e-05\n","\t\tAfter adaption: PDE loss: 0.007203504164003267\n","\t\tAfter adaption: Data loss: 0.0018181711166902045\n","\n","\tTesting: Initial condition loss: 0.025846676900982857\n","\tTesting: Boundary condition loss: 0.0013846727088093758\n","\tTesting: PDE loss: 0.015400674194097519\n","\tTesting: Data loss: 0.005897515453398228\n","\n","Epoch 357\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025803092867136\n","\tBefore adaption: Boundary condition loss: 0.0014436233323067427\n","\tBefore adaption: PDE loss: 0.015351693145930767\n","\tBefore adaption: Data loss: 0.005900116637349129\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0449, 0.2375, 0.4581, 0.2594], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006129320006239293\n","\t\tAfter adaption: Boundary condition loss: 6.486606805114598e-05\n","\t\tAfter adaption: PDE loss: 0.0070329517700095595\n","\t\tAfter adaption: Data loss: 0.0015305057694608715\n","\n","\tTesting: Initial condition loss: 0.030449748039245605\n","\tTesting: Boundary condition loss: 0.001981662819162011\n","\tTesting: PDE loss: 0.014944232068955898\n","\tTesting: Data loss: 0.006197797600179911\n","\n","Epoch 358\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030455196276307106\n","\tBefore adaption: Boundary condition loss: 0.0020501213148236275\n","\tBefore adaption: PDE loss: 0.014915558509528637\n","\tBefore adaption: Data loss: 0.006220128387212753\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0249, 0.3457, 0.4287, 0.2007], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010527677691330868\n","\t\tAfter adaption: Boundary condition loss: 5.113278853267047e-05\n","\t\tAfter adaption: PDE loss: 0.006394446724849469\n","\t\tAfter adaption: Data loss: 0.001248199399543418\n","\n","\tTesting: Initial condition loss: 0.029949821531772614\n","\tTesting: Boundary condition loss: 0.0018446859903633595\n","\tTesting: PDE loss: 0.01486816257238388\n","\tTesting: Data loss: 0.006134458817541599\n","\n","Epoch 359\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03041849099099636\n","\tBefore adaption: Boundary condition loss: 0.0019202269613742828\n","\tBefore adaption: PDE loss: 0.01482642162591219\n","\tBefore adaption: Data loss: 0.006160374265164137\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0218, 0.4429, 0.3787, 0.1567], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01347192768144227\n","\t\tAfter adaption: Boundary condition loss: 4.181280795250501e-05\n","\t\tAfter adaption: PDE loss: 0.005614247265193393\n","\t\tAfter adaption: Data loss: 0.0009651685357208589\n","\n","\tTesting: Initial condition loss: 0.02389213629066944\n","\tTesting: Boundary condition loss: 0.00103076605591923\n","\tTesting: PDE loss: 0.015279345214366913\n","\tTesting: Data loss: 0.005675935652107\n","\n","Epoch 360\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0251515693962574\n","\tBefore adaption: Boundary condition loss: 0.001103456481359899\n","\tBefore adaption: PDE loss: 0.015254141762852669\n","\tBefore adaption: Data loss: 0.005686083342880011\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0259, 0.5069, 0.3350, 0.1322], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012748857686448598\n","\t\tAfter adaption: Boundary condition loss: 2.8626819520440272e-05\n","\t\tAfter adaption: PDE loss: 0.005109788435956811\n","\t\tAfter adaption: Data loss: 0.0007516922819791246\n","\n","\tTesting: Initial condition loss: 0.014918151311576366\n","\tTesting: Boundary condition loss: 0.00024031885550357401\n","\tTesting: PDE loss: 0.016256969422101974\n","\tTesting: Data loss: 0.0055561005137860775\n","\n","Epoch 361\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016917353495955467\n","\tBefore adaption: Boundary condition loss: 0.0002715708687901497\n","\tBefore adaption: PDE loss: 0.01620662584900856\n","\tBefore adaption: Data loss: 0.005528524052351713\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0290, 0.5361, 0.3129, 0.1220], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009069712784754545\n","\t\tAfter adaption: Boundary condition loss: 7.876949749197436e-06\n","\t\tAfter adaption: PDE loss: 0.005070264577422428\n","\t\tAfter adaption: Data loss: 0.0006746150049466671\n","\n","\tTesting: Initial condition loss: 0.007219378836452961\n","\tTesting: Boundary condition loss: 0.0004772554384544492\n","\tTesting: PDE loss: 0.017591187730431557\n","\tTesting: Data loss: 0.00680440803989768\n","\n","Epoch 362\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009550544433295727\n","\tBefore adaption: Boundary condition loss: 0.0003896528505720198\n","\tBefore adaption: PDE loss: 0.017562398687005043\n","\tBefore adaption: Data loss: 0.006721757352352142\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0281, 0.5331, 0.3168, 0.1221], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005091202598719666\n","\t\tAfter adaption: Boundary condition loss: 1.0947471892585306e-05\n","\t\tAfter adaption: PDE loss: 0.005563215554404355\n","\t\tAfter adaption: Data loss: 0.0008204305790903692\n","\n","\tTesting: Initial condition loss: 0.0036629445385187864\n","\tTesting: Boundary condition loss: 0.0024258550256490707\n","\tTesting: PDE loss: 0.019086770713329315\n","\tTesting: Data loss: 0.009918248280882835\n","\n","Epoch 363\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005710321944206953\n","\tBefore adaption: Boundary condition loss: 0.002130012260749936\n","\tBefore adaption: PDE loss: 0.01905478723347187\n","\tBefore adaption: Data loss: 0.009772763587534428\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0252, 0.4950, 0.3465, 0.1334], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002826406651022988\n","\t\tAfter adaption: Boundary condition loss: 5.37345730725559e-05\n","\t\tAfter adaption: PDE loss: 0.006601533837695118\n","\t\tAfter adaption: Data loss: 0.0013032740394394477\n","\n","\tTesting: Initial condition loss: 0.004151731263846159\n","\tTesting: Boundary condition loss: 0.005815234966576099\n","\tTesting: PDE loss: 0.02039923146367073\n","\tTesting: Data loss: 0.01440002117305994\n","\n","Epoch 364\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005525368265807629\n","\tBefore adaption: Boundary condition loss: 0.005274172406643629\n","\tBefore adaption: PDE loss: 0.02038183994591236\n","\tBefore adaption: Data loss: 0.014193577691912651\n","tensor(0.0053, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0053, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0276, 0.4171, 0.3942, 0.1610], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0023047654040227183\n","\t\tAfter adaption: Boundary condition loss: 0.00014581525441454093\n","\t\tAfter adaption: PDE loss: 0.008034351209775194\n","\t\tAfter adaption: Data loss: 0.002285687790460533\n","\n","\tTesting: Initial condition loss: 0.0066010733135044575\n","\tTesting: Boundary condition loss: 0.009516366757452488\n","\tTesting: PDE loss: 0.021376317366957664\n","\tTesting: Data loss: 0.01896904781460762\n","\n","Epoch 365\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007279085461050272\n","\tBefore adaption: Boundary condition loss: 0.008741911500692368\n","\tBefore adaption: PDE loss: 0.021297236904501915\n","\tBefore adaption: Data loss: 0.018712470307946205\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0453, 0.3104, 0.4372, 0.2071], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022595121058657007\n","\t\tAfter adaption: Boundary condition loss: 0.0003960882994295009\n","\t\tAfter adaption: PDE loss: 0.009311200948756596\n","\t\tAfter adaption: Data loss: 0.0038749184409689053\n","\n","\tTesting: Initial condition loss: 0.008637342602014542\n","\tTesting: Boundary condition loss: 0.012094743549823761\n","\tTesting: PDE loss: 0.021812405437231064\n","\tTesting: Data loss: 0.022170674055814743\n","\n","Epoch 366\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008871074765920639\n","\tBefore adaption: Boundary condition loss: 0.011174009181559086\n","\tBefore adaption: PDE loss: 0.021742604672908783\n","\tBefore adaption: Data loss: 0.021881969645619392\n","tensor(0.0112, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0112, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0796, 0.2128, 0.4475, 0.2601], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001887831389761013\n","\t\tAfter adaption: Boundary condition loss: 0.0008892008867409217\n","\t\tAfter adaption: PDE loss: 0.00973024718290375\n","\t\tAfter adaption: Data loss: 0.005691386340328271\n","\n","\tTesting: Initial condition loss: 0.008889865130186081\n","\tTesting: Boundary condition loss: 0.01245100237429142\n","\tTesting: PDE loss: 0.02184552513062954\n","\tTesting: Data loss: 0.022933876141905785\n","\n","Epoch 367\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009036267176270485\n","\tBefore adaption: Boundary condition loss: 0.011519999243319035\n","\tBefore adaption: PDE loss: 0.021769050508737564\n","\tBefore adaption: Data loss: 0.02263643778860569\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0115, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1174, 0.1564, 0.4240, 0.3021], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014135450083425725\n","\t\tAfter adaption: Boundary condition loss: 0.001352852767684604\n","\t\tAfter adaption: PDE loss: 0.009230046786100668\n","\t\tAfter adaption: Data loss: 0.00683927958525739\n","\n","\tTesting: Initial condition loss: 0.007254128344357014\n","\tTesting: Boundary condition loss: 0.010450953617691994\n","\tTesting: PDE loss: 0.02157178521156311\n","\tTesting: Data loss: 0.02098711207509041\n","\n","Epoch 368\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00765802850946784\n","\tBefore adaption: Boundary condition loss: 0.009634530171751976\n","\tBefore adaption: PDE loss: 0.021494172513484955\n","\tBefore adaption: Data loss: 0.020705899223685265\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1456, 0.1365, 0.3908, 0.3270], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00104539164235038\n","\t\tAfter adaption: Boundary condition loss: 0.001403149254910547\n","\t\tAfter adaption: PDE loss: 0.00840096413631797\n","\t\tAfter adaption: Data loss: 0.006770923874764524\n","\n","\tTesting: Initial condition loss: 0.004750854801386595\n","\tTesting: Boundary condition loss: 0.007048660423606634\n","\tTesting: PDE loss: 0.021072065457701683\n","\tTesting: Data loss: 0.01704520173370838\n","\n","Epoch 369\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005646534264087677\n","\tBefore adaption: Boundary condition loss: 0.006420818157494068\n","\tBefore adaption: PDE loss: 0.021011946722865105\n","\tBefore adaption: Data loss: 0.016802091151475906\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1601, 0.1325, 0.3684, 0.3390], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007481877149879524\n","\t\tAfter adaption: Boundary condition loss: 0.0010278451339387985\n","\t\tAfter adaption: PDE loss: 0.007741215725491763\n","\t\tAfter adaption: Data loss: 0.005695843830002758\n","\n","\tTesting: Initial condition loss: 0.003016088390722871\n","\tTesting: Boundary condition loss: 0.0036470936611294746\n","\tTesting: PDE loss: 0.020430047065019608\n","\tTesting: Data loss: 0.012468026950955391\n","\n","Epoch 370\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004455253016203642\n","\tBefore adaption: Boundary condition loss: 0.0032247307244688272\n","\tBefore adaption: PDE loss: 0.020396007224917412\n","\tBefore adaption: Data loss: 0.01227827649563551\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1615, 0.1309, 0.3649, 0.3427], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005831940442215695\n","\t\tAfter adaption: Boundary condition loss: 0.0005208815793333284\n","\t\tAfter adaption: PDE loss: 0.007442697967378851\n","\t\tAfter adaption: Data loss: 0.004207308578271316\n","\n","\tTesting: Initial condition loss: 0.003476531943306327\n","\tTesting: Boundary condition loss: 0.001288590137846768\n","\tTesting: PDE loss: 0.019736990332603455\n","\tTesting: Data loss: 0.008560162037611008\n","\n","Epoch 371\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005266289226710796\n","\tBefore adaption: Boundary condition loss: 0.0010719223646447062\n","\tBefore adaption: PDE loss: 0.01971433125436306\n","\tBefore adaption: Data loss: 0.008430872112512589\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1508, 0.1281, 0.3823, 0.3388], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006747800392371839\n","\t\tAfter adaption: Boundary condition loss: 0.0001616431684945832\n","\t\tAfter adaption: PDE loss: 0.007535815982973514\n","\t\tAfter adaption: Data loss: 0.0028565458496275275\n","\n","\tTesting: Initial condition loss: 0.0066957008093595505\n","\tTesting: Boundary condition loss: 0.00041052192682400346\n","\tTesting: PDE loss: 0.018995830789208412\n","\tTesting: Data loss: 0.006067244801670313\n","\n","Epoch 372\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008567663840949535\n","\tBefore adaption: Boundary condition loss: 0.00036298399209044874\n","\tBefore adaption: PDE loss: 0.018979545682668686\n","\tBefore adaption: Data loss: 0.0059955124743282795\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1279, 0.1287, 0.4189, 0.3245], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011024277690060188\n","\t\tAfter adaption: Boundary condition loss: 4.642810290929337e-05\n","\t\tAfter adaption: PDE loss: 0.007951223367053407\n","\t\tAfter adaption: Data loss: 0.0019454449721243083\n","\n","\tTesting: Initial condition loss: 0.012225639075040817\n","\tTesting: Boundary condition loss: 0.0007323503959923983\n","\tTesting: PDE loss: 0.018221084028482437\n","\tTesting: Data loss: 0.005061245057731867\n","\n","Epoch 373\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013973255641758442\n","\tBefore adaption: Boundary condition loss: 0.0007996638305485249\n","\tBefore adaption: PDE loss: 0.018188027665019035\n","\tBefore adaption: Data loss: 0.005038367118686438\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0950, 0.1448, 0.4658, 0.2944], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002023938430491713\n","\t\tAfter adaption: Boundary condition loss: 7.593683632305757e-05\n","\t\tAfter adaption: PDE loss: 0.008472752894916861\n","\t\tAfter adaption: Data loss: 0.0014830573692714564\n","\n","\tTesting: Initial condition loss: 0.018836379051208496\n","\tTesting: Boundary condition loss: 0.0016095995670184493\n","\tTesting: PDE loss: 0.017364943400025368\n","\tTesting: Data loss: 0.005122584290802479\n","\n","Epoch 374\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02037365734577179\n","\tBefore adaption: Boundary condition loss: 0.0017445668345317245\n","\tBefore adaption: PDE loss: 0.017347782850265503\n","\tBefore adaption: Data loss: 0.005138243082910776\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0604, 0.1928, 0.5000, 0.2468], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003928077590295826\n","\t\tAfter adaption: Boundary condition loss: 0.00010539203356071925\n","\t\tAfter adaption: PDE loss: 0.008673116700116232\n","\t\tAfter adaption: Data loss: 0.0012682778731392833\n","\n","\tTesting: Initial condition loss: 0.024689245969057083\n","\tTesting: Boundary condition loss: 0.0023955749347805977\n","\tTesting: PDE loss: 0.016533920541405678\n","\tTesting: Data loss: 0.005625702906399965\n","\n","Epoch 375\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02611328661441803\n","\tBefore adaption: Boundary condition loss: 0.0025579738430678844\n","\tBefore adaption: PDE loss: 0.01650269143283367\n","\tBefore adaption: Data loss: 0.0056661502458155155\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0376, 0.2751, 0.4946, 0.1927], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007184019411545453\n","\t\tAfter adaption: Boundary condition loss: 9.628862825081552e-05\n","\t\tAfter adaption: PDE loss: 0.008161573941451398\n","\t\tAfter adaption: Data loss: 0.0010917951342376375\n","\n","\tTesting: Initial condition loss: 0.027580421417951584\n","\tTesting: Boundary condition loss: 0.002587708877399564\n","\tTesting: PDE loss: 0.015858309343457222\n","\tTesting: Data loss: 0.0059595066122710705\n","\n","Epoch 376\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029041985049843788\n","\tBefore adaption: Boundary condition loss: 0.0027471305802464485\n","\tBefore adaption: PDE loss: 0.015844393521547318\n","\tBefore adaption: Data loss: 0.006008697208017111\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0324, 0.3682, 0.4495, 0.1499], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01069255965092128\n","\t\tAfter adaption: Boundary condition loss: 8.896383707688128e-05\n","\t\tAfter adaption: PDE loss: 0.007122298691420606\n","\t\tAfter adaption: Data loss: 0.0009008489121594467\n","\n","\tTesting: Initial condition loss: 0.025841426104307175\n","\tTesting: Boundary condition loss: 0.002007493283599615\n","\tTesting: PDE loss: 0.015572628006339073\n","\tTesting: Data loss: 0.0058317165821790695\n","\n","Epoch 377\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027575548738241196\n","\tBefore adaption: Boundary condition loss: 0.0021415511146187782\n","\tBefore adaption: PDE loss: 0.01554158702492714\n","\tBefore adaption: Data loss: 0.005870400462299585\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0372, 0.4439, 0.3930, 0.1260], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012240944674885592\n","\t\tAfter adaption: Boundary condition loss: 7.95704850186473e-05\n","\t\tAfter adaption: PDE loss: 0.006107364269134722\n","\t\tAfter adaption: Data loss: 0.0007394904266712373\n","\n","\tTesting: Initial condition loss: 0.01982015185058117\n","\tTesting: Boundary condition loss: 0.0009771093027666211\n","\tTesting: PDE loss: 0.015767553821206093\n","\tTesting: Data loss: 0.005565606523305178\n","\n","Epoch 378\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021933987736701965\n","\tBefore adaption: Boundary condition loss: 0.0010636054212227464\n","\tBefore adaption: PDE loss: 0.01572422683238983\n","\tBefore adaption: Data loss: 0.005572597961872816\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0419, 0.4916, 0.3501, 0.1163], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010783624706125605\n","\t\tAfter adaption: Boundary condition loss: 4.4600079801843376e-05\n","\t\tAfter adaption: PDE loss: 0.00550487226463662\n","\t\tAfter adaption: Data loss: 0.0006483067772385091\n","\n","\tTesting: Initial condition loss: 0.012085044756531715\n","\tTesting: Boundary condition loss: 0.0002546845644246787\n","\tTesting: PDE loss: 0.01643742062151432\n","\tTesting: Data loss: 0.006044629495590925\n","\n","Epoch 379\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014486521482467651\n","\tBefore adaption: Boundary condition loss: 0.000257493753451854\n","\tBefore adaption: PDE loss: 0.016374148428440094\n","\tBefore adaption: Data loss: 0.005998524837195873\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0419, 0.5115, 0.3310, 0.1155], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007410554763789271\n","\t\tAfter adaption: Boundary condition loss: 1.0797205080760657e-05\n","\t\tAfter adaption: PDE loss: 0.005419636417541817\n","\t\tAfter adaption: Data loss: 0.0006930231042355097\n","\n","\tTesting: Initial condition loss: 0.00592454569414258\n","\tTesting: Boundary condition loss: 0.0007000082987360656\n","\tTesting: PDE loss: 0.017391594126820564\n","\tTesting: Data loss: 0.008151205256581306\n","\n","Epoch 380\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008297475054860115\n","\tBefore adaption: Boundary condition loss: 0.0005725916707888246\n","\tBefore adaption: PDE loss: 0.01734672673046589\n","\tBefore adaption: Data loss: 0.008038697764277458\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0370, 0.5028, 0.3374, 0.1228], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00417218005019718\n","\t\tAfter adaption: Boundary condition loss: 2.117750108875652e-05\n","\t\tAfter adaption: PDE loss: 0.0058522130114118534\n","\t\tAfter adaption: Data loss: 0.0009873304764381273\n","\n","\tTesting: Initial condition loss: 0.003236177610233426\n","\tTesting: Boundary condition loss: 0.0027340990491211414\n","\tTesting: PDE loss: 0.018462995067238808\n","\tTesting: Data loss: 0.012093644589185715\n","\n","Epoch 381\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005160362459719181\n","\tBefore adaption: Boundary condition loss: 0.0024327412247657776\n","\tBefore adaption: PDE loss: 0.018409591168165207\n","\tBefore adaption: Data loss: 0.011909234337508678\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0308, 0.4597, 0.3667, 0.1428], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0023724200610616133\n","\t\tAfter adaption: Boundary condition loss: 7.484574428884645e-05\n","\t\tAfter adaption: PDE loss: 0.006749878656232278\n","\t\tAfter adaption: Data loss: 0.001701169987415901\n","\n","\tTesting: Initial condition loss: 0.003652111627161503\n","\tTesting: Boundary condition loss: 0.0059075974859297276\n","\tTesting: PDE loss: 0.019339285790920258\n","\tTesting: Data loss: 0.017124362289905548\n","\n","Epoch 382\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004928221460431814\n","\tBefore adaption: Boundary condition loss: 0.005430121440440416\n","\tBefore adaption: PDE loss: 0.019272109493613243\n","\tBefore adaption: Data loss: 0.01687464490532875\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0316, 0.3783, 0.4074, 0.1827], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001864282175549296\n","\t\tAfter adaption: Boundary condition loss: 0.00017158068272386635\n","\t\tAfter adaption: PDE loss: 0.007852326452734924\n","\t\tAfter adaption: Data loss: 0.003082486382888022\n","\n","\tTesting: Initial condition loss: 0.0053168474696576595\n","\tTesting: Boundary condition loss: 0.009073012508451939\n","\tTesting: PDE loss: 0.01984216645359993\n","\tTesting: Data loss: 0.021830519661307335\n","\n","Epoch 383\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006005005445331335\n","\tBefore adaption: Boundary condition loss: 0.008458031341433525\n","\tBefore adaption: PDE loss: 0.01980411820113659\n","\tBefore adaption: Data loss: 0.0215307604521513\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0488, 0.2738, 0.4355, 0.2419], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016440258436535048\n","\t\tAfter adaption: Boundary condition loss: 0.0004124657618382568\n","\t\tAfter adaption: PDE loss: 0.008625656657839875\n","\t\tAfter adaption: Data loss: 0.005208485511041301\n","\n","\tTesting: Initial condition loss: 0.00642461609095335\n","\tTesting: Boundary condition loss: 0.010949300602078438\n","\tTesting: PDE loss: 0.020031604915857315\n","\tTesting: Data loss: 0.024693718180060387\n","\n","Epoch 384\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006784324999898672\n","\tBefore adaption: Boundary condition loss: 0.01026872731745243\n","\tBefore adaption: PDE loss: 0.019983060657978058\n","\tBefore adaption: Data loss: 0.024367239326238632\n","tensor(0.0103, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0103, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0811, 0.1836, 0.4311, 0.3042], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001245738860924162\n","\t\tAfter adaption: Boundary condition loss: 0.000832395874219289\n","\t\tAfter adaption: PDE loss: 0.008615204638494729\n","\t\tAfter adaption: Data loss: 0.007412342894670299\n","\n","\tTesting: Initial condition loss: 0.006046564783900976\n","\tTesting: Boundary condition loss: 0.01063294056802988\n","\tTesting: PDE loss: 0.01994805783033371\n","\tTesting: Data loss: 0.024674847722053528\n","\n","Epoch 385\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006410121917724609\n","\tBefore adaption: Boundary condition loss: 0.009978296235203743\n","\tBefore adaption: PDE loss: 0.019886843860149384\n","\tBefore adaption: Data loss: 0.024349292740225792\n","tensor(0.0100, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0100, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1152, 0.1321, 0.4020, 0.3508], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008467159059386641\n","\t\tAfter adaption: Boundary condition loss: 0.001149066091588093\n","\t\tAfter adaption: PDE loss: 0.007994199657485577\n","\t\tAfter adaption: Data loss: 0.00854096392713628\n","\n","\tTesting: Initial condition loss: 0.004423275124281645\n","\tTesting: Boundary condition loss: 0.00826904084533453\n","\tTesting: PDE loss: 0.01966019533574581\n","\tTesting: Data loss: 0.02175864949822426\n","\n","Epoch 386\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005076456815004349\n","\tBefore adaption: Boundary condition loss: 0.007721399888396263\n","\tBefore adaption: PDE loss: 0.01962423324584961\n","\tBefore adaption: Data loss: 0.021462244912981987\n","tensor(0.0077, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0077, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1394, 0.1116, 0.3712, 0.3777], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005667353840730371\n","\t\tAfter adaption: Boundary condition loss: 0.001076720739148079\n","\t\tAfter adaption: PDE loss: 0.007284448430776331\n","\t\tAfter adaption: Data loss: 0.008106653880127752\n","\n","\tTesting: Initial condition loss: 0.0027083968743681908\n","\tTesting: Boundary condition loss: 0.004993936512619257\n","\tTesting: PDE loss: 0.019297704100608826\n","\tTesting: Data loss: 0.017012005671858788\n","\n","Epoch 387\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037934686988592148\n","\tBefore adaption: Boundary condition loss: 0.004590607713907957\n","\tBefore adaption: PDE loss: 0.019294997677206993\n","\tBefore adaption: Data loss: 0.016767581924796104\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1505, 0.1049, 0.3542, 0.3904], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00039811687329704867\n","\t\tAfter adaption: Boundary condition loss: 0.0006906662771358765\n","\t\tAfter adaption: PDE loss: 0.006834756401209109\n","\t\tAfter adaption: Data loss: 0.006545653825516087\n","\n","\tTesting: Initial condition loss: 0.002343646716326475\n","\tTesting: Boundary condition loss: 0.002115669660270214\n","\tTesting: PDE loss: 0.018942616879940033\n","\tTesting: Data loss: 0.012005845084786415\n","\n","Epoch 388\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003815260250121355\n","\tBefore adaption: Boundary condition loss: 0.0018733651377260685\n","\tBefore adaption: PDE loss: 0.018969841301441193\n","\tBefore adaption: Data loss: 0.011823898181319237\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1485, 0.1016, 0.3570, 0.3929], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003877553609436099\n","\t\tAfter adaption: Boundary condition loss: 0.00027826001791831484\n","\t\tAfter adaption: PDE loss: 0.006771335437918533\n","\t\tAfter adaption: Data loss: 0.004645367865833219\n","\n","\tTesting: Initial condition loss: 0.004410553257912397\n","\tTesting: Boundary condition loss: 0.0005152725498192012\n","\tTesting: PDE loss: 0.01862696371972561\n","\tTesting: Data loss: 0.008042975328862667\n","\n","Epoch 389\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005996793508529663\n","\tBefore adaption: Boundary condition loss: 0.00041686813347041607\n","\tBefore adaption: PDE loss: 0.018672112375497818\n","\tBefore adaption: Data loss: 0.007924500852823257\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1341, 0.1008, 0.3806, 0.3846], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006042176414649813\n","\t\tAfter adaption: Boundary condition loss: 5.5886816545356524e-05\n","\t\tAfter adaption: PDE loss: 0.007106420651733219\n","\t\tAfter adaption: Data loss: 0.0030476790815090107\n","\n","\tTesting: Initial condition loss: 0.008982811123132706\n","\tTesting: Boundary condition loss: 0.00030775635968893766\n","\tTesting: PDE loss: 0.018349362537264824\n","\tTesting: Data loss: 0.005719325505197048\n","\n","Epoch 390\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010450120083987713\n","\tBefore adaption: Boundary condition loss: 0.00032618397381156683\n","\tBefore adaption: PDE loss: 0.018370505422353745\n","\tBefore adaption: Data loss: 0.005658842157572508\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1076, 0.1098, 0.4222, 0.3604], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011478083615093554\n","\t\tAfter adaption: Boundary condition loss: 3.509505883376186e-05\n","\t\tAfter adaption: PDE loss: 0.007756283091268392\n","\t\tAfter adaption: Data loss: 0.002039198671297691\n","\n","\tTesting: Initial condition loss: 0.015279785729944706\n","\tTesting: Boundary condition loss: 0.0010523408418521285\n","\tTesting: PDE loss: 0.018013430759310722\n","\tTesting: Data loss: 0.004929889924824238\n","\n","Epoch 391\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016494005918502808\n","\tBefore adaption: Boundary condition loss: 0.0011550363851711154\n","\tBefore adaption: PDE loss: 0.01800757832825184\n","\tBefore adaption: Data loss: 0.004916377365589142\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0737, 0.1438, 0.4686, 0.3140], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002371432027865891\n","\t\tAfter adaption: Boundary condition loss: 8.508663657265905e-05\n","\t\tAfter adaption: PDE loss: 0.008437804567132707\n","\t\tAfter adaption: Data loss: 0.0015436882288458087\n","\n","\tTesting: Initial condition loss: 0.021816596388816833\n","\tTesting: Boundary condition loss: 0.0020828298293054104\n","\tTesting: PDE loss: 0.017558805644512177\n","\tTesting: Data loss: 0.005115716252475977\n","\n","Epoch 392\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022849466651678085\n","\tBefore adaption: Boundary condition loss: 0.0022360337898135185\n","\tBefore adaption: PDE loss: 0.017567934468388557\n","\tBefore adaption: Data loss: 0.0051363869570195675\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0442, 0.2142, 0.4930, 0.2487], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004894536996165083\n","\t\tAfter adaption: Boundary condition loss: 9.875021269610579e-05\n","\t\tAfter adaption: PDE loss: 0.008660474033159987\n","\t\tAfter adaption: Data loss: 0.001277204515636287\n","\n","\tTesting: Initial condition loss: 0.026594990864396095\n","\tTesting: Boundary condition loss: 0.002786112017929554\n","\tTesting: PDE loss: 0.017115337774157524\n","\tTesting: Data loss: 0.005551671143621206\n","\n","Epoch 393\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027658093720674515\n","\tBefore adaption: Boundary condition loss: 0.0029629888013005257\n","\tBefore adaption: PDE loss: 0.01711573638021946\n","\tBefore adaption: Data loss: 0.005593796726316214\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0312, 0.3094, 0.4754, 0.1840], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008558375570141835\n","\t\tAfter adaption: Boundary condition loss: 9.237736586996143e-05\n","\t\tAfter adaption: PDE loss: 0.008136910311423\n","\t\tAfter adaption: Data loss: 0.0010291617043575025\n","\n","\tTesting: Initial condition loss: 0.027582425624132156\n","\tTesting: Boundary condition loss: 0.0027478442061692476\n","\tTesting: PDE loss: 0.016825305297970772\n","\tTesting: Data loss: 0.005622903350740671\n","\n","Epoch 394\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0289086252450943\n","\tBefore adaption: Boundary condition loss: 0.002921093488112092\n","\tBefore adaption: PDE loss: 0.01683976501226425\n","\tBefore adaption: Data loss: 0.005671243648976088\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0339, 0.3984, 0.4283, 0.1395], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011517453123248348\n","\t\tAfter adaption: Boundary condition loss: 9.893654384910882e-05\n","\t\tAfter adaption: PDE loss: 0.007211796812377986\n","\t\tAfter adaption: Data loss: 0.0007909186677978329\n","\n","\tTesting: Initial condition loss: 0.023928921669721603\n","\tTesting: Boundary condition loss: 0.001951528829522431\n","\tTesting: PDE loss: 0.016881007701158524\n","\tTesting: Data loss: 0.005168909672647715\n","\n","Epoch 395\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02570950984954834\n","\tBefore adaption: Boundary condition loss: 0.0020943223498761654\n","\tBefore adaption: PDE loss: 0.016887949779629707\n","\tBefore adaption: Data loss: 0.005206199362874031\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0416, 0.4609, 0.3807, 0.1168], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01184947586611976\n","\t\tAfter adaption: Boundary condition loss: 8.709437829037349e-05\n","\t\tAfter adaption: PDE loss: 0.006429157299703061\n","\t\tAfter adaption: Data loss: 0.0006081899175992486\n","\n","\tTesting: Initial condition loss: 0.016903391107916832\n","\tTesting: Boundary condition loss: 0.0008665233617648482\n","\tTesting: PDE loss: 0.0173586905002594\n","\tTesting: Data loss: 0.004676160868257284\n","\n","Epoch 396\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.019142482429742813\n","\tBefore adaption: Boundary condition loss: 0.0009518021834082901\n","\tBefore adaption: PDE loss: 0.01735866442322731\n","\tBefore adaption: Data loss: 0.004684457555413246\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0462, 0.4947, 0.3513, 0.1078], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009469496299501933\n","\t\tAfter adaption: Boundary condition loss: 4.3993421277296946e-05\n","\t\tAfter adaption: PDE loss: 0.006097700591565752\n","\t\tAfter adaption: Data loss: 0.0005050627220641481\n","\n","\tTesting: Initial condition loss: 0.00947960652410984\n","\tTesting: Boundary condition loss: 0.0002971681533381343\n","\tTesting: PDE loss: 0.018183410167694092\n","\tTesting: Data loss: 0.005054706707596779\n","\n","Epoch 397\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01198495551943779\n","\tBefore adaption: Boundary condition loss: 0.0002814085455611348\n","\tBefore adaption: PDE loss: 0.01818656548857689\n","\tBefore adaption: Data loss: 0.005017289891839027\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0451, 0.5022, 0.3464, 0.1062], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006019435028584736\n","\t\tAfter adaption: Boundary condition loss: 1.269388772609949e-05\n","\t\tAfter adaption: PDE loss: 0.006300473290684536\n","\t\tAfter adaption: Data loss: 0.0005328691415345143\n","\n","\tTesting: Initial condition loss: 0.00455677742138505\n","\tTesting: Boundary condition loss: 0.0009658046183176339\n","\tTesting: PDE loss: 0.019183676689863205\n","\tTesting: Data loss: 0.007039028685539961\n","\n","Epoch 398\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006882925983518362\n","\tBefore adaption: Boundary condition loss: 0.0008066652808338404\n","\tBefore adaption: PDE loss: 0.019201412796974182\n","\tBefore adaption: Data loss: 0.006944432854652405\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0392, 0.4823, 0.3673, 0.1113], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003319595751968791\n","\t\tAfter adaption: Boundary condition loss: 3.1592538092784535e-05\n","\t\tAfter adaption: PDE loss: 0.0070519792714675384\n","\t\tAfter adaption: Data loss: 0.0007727597212289915\n","\n","\tTesting: Initial condition loss: 0.0031401803717017174\n","\tTesting: Boundary condition loss: 0.0031197378411889076\n","\tTesting: PDE loss: 0.0201317947357893\n","\tTesting: Data loss: 0.010670235380530357\n","\n","Epoch 399\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00495541887357831\n","\tBefore adaption: Boundary condition loss: 0.0027854889631271362\n","\tBefore adaption: PDE loss: 0.020149368792772293\n","\tBefore adaption: Data loss: 0.010515346191823483\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0327, 0.4295, 0.4102, 0.1276], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002128146560008651\n","\t\tAfter adaption: Boundary condition loss: 9.111716449038128e-05\n","\t\tAfter adaption: PDE loss: 0.008265567994549255\n","\t\tAfter adaption: Data loss: 0.0013419180123562294\n","\n","\tTesting: Initial condition loss: 0.004286132287234068\n","\tTesting: Boundary condition loss: 0.006216287612915039\n","\tTesting: PDE loss: 0.02074183151125908\n","\tTesting: Data loss: 0.015218927524983883\n","\n","Epoch 400\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005458789877593517\n","\tBefore adaption: Boundary condition loss: 0.005705178249627352\n","\tBefore adaption: PDE loss: 0.020785825327038765\n","\tBefore adaption: Data loss: 0.0150084113702178\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0346, 0.3437, 0.4596, 0.1621], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001876180712435453\n","\t\tAfter adaption: Boundary condition loss: 0.00019765446670613195\n","\t\tAfter adaption: PDE loss: 0.009553015235730862\n","\t\tAfter adaption: Data loss: 0.0024323112474801257\n","\n","\tTesting: Initial condition loss: 0.0061825113371014595\n","\tTesting: Boundary condition loss: 0.009231277741491795\n","\tTesting: PDE loss: 0.021011169999837875\n","\tTesting: Data loss: 0.0195439625531435\n","\n","Epoch 401\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0067904433235526085\n","\tBefore adaption: Boundary condition loss: 0.008580021560192108\n","\tBefore adaption: PDE loss: 0.021017657592892647\n","\tBefore adaption: Data loss: 0.01928889751434326\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0535, 0.2459, 0.4863, 0.2143], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001669836568124361\n","\t\tAfter adaption: Boundary condition loss: 0.00045911901600773476\n","\t\tAfter adaption: PDE loss: 0.01022047281317259\n","\t\tAfter adaption: Data loss: 0.004133599270557132\n","\n","\tTesting: Initial condition loss: 0.007290317211300135\n","\tTesting: Boundary condition loss: 0.011090257205069065\n","\tTesting: PDE loss: 0.0208604633808136\n","\tTesting: Data loss: 0.02247343398630619\n","\n","Epoch 402\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007595609873533249\n","\tBefore adaption: Boundary condition loss: 0.010382406413555145\n","\tBefore adaption: PDE loss: 0.020882979035377502\n","\tBefore adaption: Data loss: 0.022189412266016006\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0863, 0.1714, 0.4723, 0.2699], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013017648744553857\n","\t\tAfter adaption: Boundary condition loss: 0.000896310405421\n","\t\tAfter adaption: PDE loss: 0.009863834361262548\n","\t\tAfter adaption: Data loss: 0.005989980915919988\n","\n","\tTesting: Initial condition loss: 0.006881864741444588\n","\tTesting: Boundary condition loss: 0.011067233979701996\n","\tTesting: PDE loss: 0.020426452159881592\n","\tTesting: Data loss: 0.023126015439629555\n","\n","Epoch 403\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007229303475469351\n","\tBefore adaption: Boundary condition loss: 0.010395067743957043\n","\tBefore adaption: PDE loss: 0.020445963367819786\n","\tBefore adaption: Data loss: 0.02283339761197567\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1198, 0.1342, 0.4325, 0.3135], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009703860658167946\n","\t\tAfter adaption: Boundary condition loss: 0.0012451711955614954\n","\t\tAfter adaption: PDE loss: 0.008842866507830631\n","\t\tAfter adaption: Data loss: 0.0071579518646892725\n","\n","\tTesting: Initial condition loss: 0.005203240551054478\n","\tTesting: Boundary condition loss: 0.009141400456428528\n","\tTesting: PDE loss: 0.01980811171233654\n","\tTesting: Data loss: 0.021286172792315483\n","\n","Epoch 404\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005904878489673138\n","\tBefore adaption: Boundary condition loss: 0.008579331450164318\n","\tBefore adaption: PDE loss: 0.019815146923065186\n","\tBefore adaption: Data loss: 0.02100788615643978\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1439, 0.1218, 0.3927, 0.3417], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000718956010255038\n","\t\tAfter adaption: Boundary condition loss: 0.0012347286131045461\n","\t\tAfter adaption: PDE loss: 0.007780750631833232\n","\t\tAfter adaption: Data loss: 0.007177506943361766\n","\n","\tTesting: Initial condition loss: 0.0033331080339848995\n","\tTesting: Boundary condition loss: 0.006083160173147917\n","\tTesting: PDE loss: 0.019075628370046616\n","\tTesting: Data loss: 0.017589187249541283\n","\n","Epoch 405\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004543832968920469\n","\tBefore adaption: Boundary condition loss: 0.0056719910353422165\n","\tBefore adaption: PDE loss: 0.019072653725743294\n","\tBefore adaption: Data loss: 0.017345910891890526\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1559, 0.1178, 0.3677, 0.3585], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005353153321342473\n","\t\tAfter adaption: Boundary condition loss: 0.0008844424975712448\n","\t\tAfter adaption: PDE loss: 0.007013658846850465\n","\t\tAfter adaption: Data loss: 0.006218909305718787\n","\n","\tTesting: Initial condition loss: 0.002687612781301141\n","\tTesting: Boundary condition loss: 0.0030516469851136208\n","\tTesting: PDE loss: 0.01828417368233204\n","\tTesting: Data loss: 0.013229617848992348\n","\n","Epoch 406\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004359641578048468\n","\tBefore adaption: Boundary condition loss: 0.0027918138075619936\n","\tBefore adaption: PDE loss: 0.018276818096637726\n","\tBefore adaption: Data loss: 0.013035994954407215\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1560, 0.1147, 0.3620, 0.3673], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004999727007272228\n","\t\tAfter adaption: Boundary condition loss: 0.00043550181421681396\n","\t\tAfter adaption: PDE loss: 0.006616865971372595\n","\t\tAfter adaption: Data loss: 0.004787981926711483\n","\n","\tTesting: Initial condition loss: 0.004358773585408926\n","\tTesting: Boundary condition loss: 0.0009619991760700941\n","\tTesting: PDE loss: 0.017504911869764328\n","\tTesting: Data loss: 0.009396555833518505\n","\n","Epoch 407\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0063366973772645\n","\tBefore adaption: Boundary condition loss: 0.0008317332249134779\n","\tBefore adaption: PDE loss: 0.017488788813352585\n","\tBefore adaption: Data loss: 0.009259470738470554\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1442, 0.1129, 0.3754, 0.3675], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007156904588107075\n","\t\tAfter adaption: Boundary condition loss: 0.00011990214464565886\n","\t\tAfter adaption: PDE loss: 0.00656480606315884\n","\t\tAfter adaption: Data loss: 0.003403081547229472\n","\n","\tTesting: Initial condition loss: 0.008612423203885555\n","\tTesting: Boundary condition loss: 0.00016031900304369628\n","\tTesting: PDE loss: 0.016763705760240555\n","\tTesting: Data loss: 0.0068182931281626225\n","\n","Epoch 408\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010709069669246674\n","\tBefore adaption: Boundary condition loss: 0.00012937696010340005\n","\tBefore adaption: PDE loss: 0.016755370423197746\n","\tBefore adaption: Data loss: 0.006737513467669487\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1202, 0.1206, 0.4043, 0.3549], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012917588814931765\n","\t\tAfter adaption: Boundary condition loss: 1.554840000461068e-05\n","\t\tAfter adaption: PDE loss: 0.006774042550094226\n","\t\tAfter adaption: Data loss: 0.0023911908761591973\n","\n","\tTesting: Initial condition loss: 0.014849122613668442\n","\tTesting: Boundary condition loss: 0.00040222969255410135\n","\tTesting: PDE loss: 0.01609986461699009\n","\tTesting: Data loss: 0.005629583727568388\n","\n","Epoch 409\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01687607727944851\n","\tBefore adaption: Boundary condition loss: 0.00044573014019988477\n","\tBefore adaption: PDE loss: 0.01607609912753105\n","\tBefore adaption: Data loss: 0.005597730167210102\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0863, 0.1527, 0.4381, 0.3229], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0025764392997071495\n","\t\tAfter adaption: Boundary condition loss: 3.8457767348293896e-05\n","\t\tAfter adaption: PDE loss: 0.007043418757607558\n","\t\tAfter adaption: Data loss: 0.0018076268488415024\n","\n","\tTesting: Initial condition loss: 0.02166474424302578\n","\tTesting: Boundary condition loss: 0.0011611718218773603\n","\tTesting: PDE loss: 0.01549371238797903\n","\tTesting: Data loss: 0.0054845730774104595\n","\n","Epoch 410\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023527152836322784\n","\tBefore adaption: Boundary condition loss: 0.0012530636740848422\n","\tBefore adaption: PDE loss: 0.015479851514101028\n","\tBefore adaption: Data loss: 0.005490048322826624\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0513, 0.2227, 0.4558, 0.2702], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005238817863087477\n","\t\tAfter adaption: Boundary condition loss: 6.429697491159179e-05\n","\t\tAfter adaption: PDE loss: 0.007056490254142998\n","\t\tAfter adaption: Data loss: 0.001483228729132116\n","\n","\tTesting: Initial condition loss: 0.02692866325378418\n","\tTesting: Boundary condition loss: 0.0018547874642536044\n","\tTesting: PDE loss: 0.015064890496432781\n","\tTesting: Data loss: 0.005765165667980909\n","\n","Epoch 411\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028674542903900146\n","\tBefore adaption: Boundary condition loss: 0.001972704427316785\n","\tBefore adaption: PDE loss: 0.01504063792526722\n","\tBefore adaption: Data loss: 0.005794574972242117\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0285, 0.3229, 0.4392, 0.2095], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009258736532302225\n","\t\tAfter adaption: Boundary condition loss: 5.6163713739618424e-05\n","\t\tAfter adaption: PDE loss: 0.00660511713243843\n","\t\tAfter adaption: Data loss: 0.0012138908042361115\n","\n","\tTesting: Initial condition loss: 0.028256261721253395\n","\tTesting: Boundary condition loss: 0.002014993689954281\n","\tTesting: PDE loss: 0.014931216835975647\n","\tTesting: Data loss: 0.0058438400737941265\n","\n","Epoch 412\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03011643886566162\n","\tBefore adaption: Boundary condition loss: 0.0021395436488091946\n","\tBefore adaption: PDE loss: 0.014913350343704224\n","\tBefore adaption: Data loss: 0.005879996344447136\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0227, 0.4213, 0.3953, 0.1607], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012688210455456954\n","\t\tAfter adaption: Boundary condition loss: 4.84643754608911e-05\n","\t\tAfter adaption: PDE loss: 0.0058953290775540425\n","\t\tAfter adaption: Data loss: 0.0009451353500315329\n","\n","\tTesting: Initial condition loss: 0.024466609582304955\n","\tTesting: Boundary condition loss: 0.0015054011018946767\n","\tTesting: PDE loss: 0.015239509753882885\n","\tTesting: Data loss: 0.005481300875544548\n","\n","Epoch 413\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02673390507698059\n","\tBefore adaption: Boundary condition loss: 0.0016146136913448572\n","\tBefore adaption: PDE loss: 0.015239210799336433\n","\tBefore adaption: Data loss: 0.005505391862243414\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0266, 0.4917, 0.3499, 0.1319], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013143862867110499\n","\t\tAfter adaption: Boundary condition loss: 4.2884293729463466e-05\n","\t\tAfter adaption: PDE loss: 0.00533236395718818\n","\t\tAfter adaption: Data loss: 0.000726016584326487\n","\n","\tTesting: Initial condition loss: 0.016985556110739708\n","\tTesting: Boundary condition loss: 0.0006748015293851495\n","\tTesting: PDE loss: 0.01604449190199375\n","\tTesting: Data loss: 0.005125403869897127\n","\n","Epoch 414\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.019674688577651978\n","\tBefore adaption: Boundary condition loss: 0.0007405803189612925\n","\tBefore adaption: PDE loss: 0.016050156205892563\n","\tBefore adaption: Data loss: 0.005119438748806715\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0311, 0.5285, 0.3219, 0.1185], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010397280734311315\n","\t\tAfter adaption: Boundary condition loss: 2.3064547017541596e-05\n","\t\tAfter adaption: PDE loss: 0.005165795937752554\n","\t\tAfter adaption: Data loss: 0.0006068729029673093\n","\n","\tTesting: Initial condition loss: 0.009226527065038681\n","\tTesting: Boundary condition loss: 0.0002583489113021642\n","\tTesting: PDE loss: 0.01724686101078987\n","\tTesting: Data loss: 0.005695951636880636\n","\n","Epoch 415\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011888368055224419\n","\tBefore adaption: Boundary condition loss: 0.00023893405159469694\n","\tBefore adaption: PDE loss: 0.01726677268743515\n","\tBefore adaption: Data loss: 0.005643903277814388\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0320, 0.5344, 0.3183, 0.1153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006352927931707462\n","\t\tAfter adaption: Boundary condition loss: 7.653844030862667e-06\n","\t\tAfter adaption: PDE loss: 0.005495852378896191\n","\t\tAfter adaption: Data loss: 0.0006507082538227904\n","\n","\tTesting: Initial condition loss: 0.00417457427829504\n","\tTesting: Boundary condition loss: 0.0010069162817671895\n","\tTesting: PDE loss: 0.018635515123605728\n","\tTesting: Data loss: 0.00792871043086052\n","\n","Epoch 416\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006413895636796951\n","\tBefore adaption: Boundary condition loss: 0.0008528285543434322\n","\tBefore adaption: PDE loss: 0.018676459789276123\n","\tBefore adaption: Data loss: 0.007821924984455109\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0291, 0.5086, 0.3409, 0.1213], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0032622824551730416\n","\t\tAfter adaption: Boundary condition loss: 2.4836809360547374e-05\n","\t\tAfter adaption: PDE loss: 0.006366922601243191\n","\t\tAfter adaption: Data loss: 0.0009491383851637186\n","\n","\tTesting: Initial condition loss: 0.0029143961146473885\n","\tTesting: Boundary condition loss: 0.003180146450176835\n","\tTesting: PDE loss: 0.019935237243771553\n","\tTesting: Data loss: 0.011795513331890106\n","\n","Epoch 417\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004485727287828922\n","\tBefore adaption: Boundary condition loss: 0.0028424845077097416\n","\tBefore adaption: PDE loss: 0.01997816376388073\n","\tBefore adaption: Data loss: 0.011632708832621574\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0263, 0.4462, 0.3865, 0.1410], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002001380913098497\n","\t\tAfter adaption: Boundary condition loss: 7.471740431577743e-05\n","\t\tAfter adaption: PDE loss: 0.007722083611618164\n","\t\tAfter adaption: Data loss: 0.0016404584950373557\n","\n","\tTesting: Initial condition loss: 0.004340069368481636\n","\tTesting: Boundary condition loss: 0.006154035218060017\n","\tTesting: PDE loss: 0.020882004871964455\n","\tTesting: Data loss: 0.016418954357504845\n","\n","Epoch 418\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005175941623747349\n","\tBefore adaption: Boundary condition loss: 0.0056247408501803875\n","\tBefore adaption: PDE loss: 0.020936258137226105\n","\tBefore adaption: Data loss: 0.016206158325076103\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0317, 0.3486, 0.4396, 0.1801], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001804403109603935\n","\t\tAfter adaption: Boundary condition loss: 0.00017830819382694954\n","\t\tAfter adaption: PDE loss: 0.009204075637902567\n","\t\tAfter adaption: Data loss: 0.002918110659638371\n","\n","\tTesting: Initial condition loss: 0.006387500092387199\n","\tTesting: Boundary condition loss: 0.00884774886071682\n","\tTesting: PDE loss: 0.02136218175292015\n","\tTesting: Data loss: 0.020516248419880867\n","\n","Epoch 419\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006649068556725979\n","\tBefore adaption: Boundary condition loss: 0.008173901587724686\n","\tBefore adaption: PDE loss: 0.021431270986795425\n","\tBefore adaption: Data loss: 0.020266428589820862\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0522, 0.2413, 0.4711, 0.2354], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016046395114966835\n","\t\tAfter adaption: Boundary condition loss: 0.00042679551458849697\n","\t\tAfter adaption: PDE loss: 0.01009597486365165\n","\t\tAfter adaption: Data loss: 0.004770032377350469\n","\n","\tTesting: Initial condition loss: 0.007420719135552645\n","\tTesting: Boundary condition loss: 0.010239508002996445\n","\tTesting: PDE loss: 0.021437864750623703\n","\tTesting: Data loss: 0.022926650941371918\n","\n","Epoch 420\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00741001358255744\n","\tBefore adaption: Boundary condition loss: 0.009509716182947159\n","\tBefore adaption: PDE loss: 0.021492455154657364\n","\tBefore adaption: Data loss: 0.022656165063381195\n","tensor(0.0095, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0095, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0836, 0.1630, 0.4633, 0.2902], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012077934451623445\n","\t\tAfter adaption: Boundary condition loss: 0.0007946813287441344\n","\t\tAfter adaption: PDE loss: 0.009956398737440485\n","\t\tAfter adaption: Data loss: 0.006574568029100959\n","\n","\tTesting: Initial condition loss: 0.0067749470472335815\n","\tTesting: Boundary condition loss: 0.009781593456864357\n","\tTesting: PDE loss: 0.021174753084778786\n","\tTesting: Data loss: 0.02293124422430992\n","\n","Epoch 421\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006837180815637112\n","\tBefore adaption: Boundary condition loss: 0.009096474386751652\n","\tBefore adaption: PDE loss: 0.02120933309197426\n","\tBefore adaption: Data loss: 0.022659597918391228\n","tensor(0.0091, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0091, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1133, 0.1264, 0.4303, 0.3299], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008643926561706266\n","\t\tAfter adaption: Boundary condition loss: 0.0010310708876725052\n","\t\tAfter adaption: PDE loss: 0.009126665733099318\n","\t\tAfter adaption: Data loss: 0.007475682788308549\n","\n","\tTesting: Initial condition loss: 0.004827923607081175\n","\tTesting: Boundary condition loss: 0.007665757555514574\n","\tTesting: PDE loss: 0.020652705803513527\n","\tTesting: Data loss: 0.0205560140311718\n","\n","Epoch 422\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0052546844817698\n","\tBefore adaption: Boundary condition loss: 0.007104760501533747\n","\tBefore adaption: PDE loss: 0.02070614881813526\n","\tBefore adaption: Data loss: 0.020303189754486084\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1334, 0.1156, 0.3975, 0.3536], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006074340618617014\n","\t\tAfter adaption: Boundary condition loss: 0.0009476088029402593\n","\t\tAfter adaption: PDE loss: 0.00822968246047634\n","\t\tAfter adaption: Data loss: 0.007178669667737032\n","\n","\tTesting: Initial condition loss: 0.002768645528703928\n","\tTesting: Boundary condition loss: 0.004750857129693031\n","\tTesting: PDE loss: 0.02002846635878086\n","\tTesting: Data loss: 0.01659967191517353\n","\n","Epoch 423\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036665252409875393\n","\tBefore adaption: Boundary condition loss: 0.004354608245193958\n","\tBefore adaption: PDE loss: 0.020057901740074158\n","\tBefore adaption: Data loss: 0.01638202741742134\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1418, 0.1124, 0.3795, 0.3664], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004120808408756951\n","\t\tAfter adaption: Boundary condition loss: 0.0006173388164515843\n","\t\tAfter adaption: PDE loss: 0.0076111898956675\n","\t\tAfter adaption: Data loss: 0.006002081493569008\n","\n","\tTesting: Initial condition loss: 0.0020480984821915627\n","\tTesting: Boundary condition loss: 0.0021380495745688677\n","\tTesting: PDE loss: 0.01933564990758896\n","\tTesting: Data loss: 0.012266278266906738\n","\n","Epoch 424\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003329442348331213\n","\tBefore adaption: Boundary condition loss: 0.001903971773572266\n","\tBefore adaption: PDE loss: 0.019345704466104507\n","\tBefore adaption: Data loss: 0.01209493912756443\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1389, 0.1083, 0.3811, 0.3716], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00036069532459267144\n","\t\tAfter adaption: Boundary condition loss: 0.00026454683229776727\n","\t\tAfter adaption: PDE loss: 0.007372239895218404\n","\t\tAfter adaption: Data loss: 0.004494976868488714\n","\n","\tTesting: Initial condition loss: 0.003687522606924176\n","\tTesting: Boundary condition loss: 0.0005688657402060926\n","\tTesting: PDE loss: 0.01862083375453949\n","\tTesting: Data loss: 0.008632342331111431\n","\n","Epoch 425\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005154249258339405\n","\tBefore adaption: Boundary condition loss: 0.0004732286906801164\n","\tBefore adaption: PDE loss: 0.01862029917538166\n","\tBefore adaption: Data loss: 0.008511227555572987\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1252, 0.1038, 0.4026, 0.3685], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005347903344201657\n","\t\tAfter adaption: Boundary condition loss: 5.92422727969438e-05\n","\t\tAfter adaption: PDE loss: 0.007495848314303922\n","\t\tAfter adaption: Data loss: 0.0031363189648886125\n","\n","\tTesting: Initial condition loss: 0.00793665274977684\n","\tTesting: Boundary condition loss: 0.00023249551304616034\n","\tTesting: PDE loss: 0.017872175201773643\n","\tTesting: Data loss: 0.006285306066274643\n","\n","Epoch 426\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009334016591310501\n","\tBefore adaption: Boundary condition loss: 0.0002387561253271997\n","\tBefore adaption: PDE loss: 0.017894640564918518\n","\tBefore adaption: Data loss: 0.006212310865521431\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1010, 0.1068, 0.4402, 0.3521], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009964964920816154\n","\t\tAfter adaption: Boundary condition loss: 2.4112878509888366e-05\n","\t\tAfter adaption: PDE loss: 0.007876375364564456\n","\t\tAfter adaption: Data loss: 0.0021873148915979275\n","\n","\tTesting: Initial condition loss: 0.014115062542259693\n","\tTesting: Boundary condition loss: 0.0007597074145451188\n","\tTesting: PDE loss: 0.01711748167872429\n","\tTesting: Data loss: 0.005265795160084963\n","\n","Epoch 427\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015335801057517529\n","\tBefore adaption: Boundary condition loss: 0.0008379787905141711\n","\tBefore adaption: PDE loss: 0.01714165508747101\n","\tBefore adaption: Data loss: 0.005234194919466972\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0700, 0.1331, 0.4809, 0.3160], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020406930625234704\n","\t\tAfter adaption: Boundary condition loss: 5.8692741480198604e-05\n","\t\tAfter adaption: PDE loss: 0.008243616702193172\n","\t\tAfter adaption: Data loss: 0.0016539023903572782\n","\n","\tTesting: Initial condition loss: 0.02097226493060589\n","\tTesting: Boundary condition loss: 0.001617808942683041\n","\tTesting: PDE loss: 0.016346924006938934\n","\tTesting: Data loss: 0.005218754522502422\n","\n","Epoch 428\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02204630896449089\n","\tBefore adaption: Boundary condition loss: 0.00173849833663553\n","\tBefore adaption: PDE loss: 0.01636875979602337\n","\tBefore adaption: Data loss: 0.0052197761833667755\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0419, 0.1978, 0.5000, 0.2602], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004361608964032896\n","\t\tAfter adaption: Boundary condition loss: 7.292924065646144e-05\n","\t\tAfter adaption: PDE loss: 0.008185161955299763\n","\t\tAfter adaption: Data loss: 0.0013579972325862633\n","\n","\tTesting: Initial condition loss: 0.026698408648371696\n","\tTesting: Boundary condition loss: 0.002291975310072303\n","\tTesting: PDE loss: 0.015619713813066483\n","\tTesting: Data loss: 0.00557914050295949\n","\n","Epoch 429\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02769864723086357\n","\tBefore adaption: Boundary condition loss: 0.0024294450413435698\n","\tBefore adaption: PDE loss: 0.015649667009711266\n","\tBefore adaption: Data loss: 0.005601632408797741\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0024, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0278, 0.2952, 0.4778, 0.1992], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008176055635336743\n","\t\tAfter adaption: Boundary condition loss: 6.743843487350563e-05\n","\t\tAfter adaption: PDE loss: 0.0074780892505293545\n","\t\tAfter adaption: Data loss: 0.0011159500706728104\n","\n","\tTesting: Initial condition loss: 0.02896551601588726\n","\tTesting: Boundary condition loss: 0.0023752092383801937\n","\tTesting: PDE loss: 0.015132597647607327\n","\tTesting: Data loss: 0.005772021133452654\n","\n","Epoch 430\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030145730823278427\n","\tBefore adaption: Boundary condition loss: 0.002509055659174919\n","\tBefore adaption: PDE loss: 0.015153218060731888\n","\tBefore adaption: Data loss: 0.005802714265882969\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0283, 0.3945, 0.4246, 0.1525], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011892969903003921\n","\t\tAfter adaption: Boundary condition loss: 7.110476529902748e-05\n","\t\tAfter adaption: PDE loss: 0.006434504612147768\n","\t\tAfter adaption: Data loss: 0.000885001118401688\n","\n","\tTesting: Initial condition loss: 0.026330703869462013\n","\tTesting: Boundary condition loss: 0.001754782977513969\n","\tTesting: PDE loss: 0.015050841495394707\n","\tTesting: Data loss: 0.0055344561114907265\n","\n","Epoch 431\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02794838510453701\n","\tBefore adaption: Boundary condition loss: 0.0018685684772208333\n","\tBefore adaption: PDE loss: 0.015063205733895302\n","\tBefore adaption: Data loss: 0.0055575380101799965\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0348, 0.4699, 0.3692, 0.1261], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013132650356707807\n","\t\tAfter adaption: Boundary condition loss: 6.507811986506144e-05\n","\t\tAfter adaption: PDE loss: 0.005561642740461395\n","\t\tAfter adaption: Data loss: 0.0007005953084775904\n","\n","\tTesting: Initial condition loss: 0.019503498449921608\n","\tTesting: Boundary condition loss: 0.0007858614553697407\n","\tTesting: PDE loss: 0.015454494394361973\n","\tTesting: Data loss: 0.005222478415817022\n","\n","Epoch 432\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02168426476418972\n","\tBefore adaption: Boundary condition loss: 0.0008595011313445866\n","\tBefore adaption: PDE loss: 0.01545687299221754\n","\tBefore adaption: Data loss: 0.005221223458647728\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0392, 0.5148, 0.3315, 0.1145], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011162911235615242\n","\t\tAfter adaption: Boundary condition loss: 3.3688610757862e-05\n","\t\tAfter adaption: PDE loss: 0.0051240825963404955\n","\t\tAfter adaption: Data loss: 0.000597844340086015\n","\n","\tTesting: Initial condition loss: 0.011418339796364307\n","\tTesting: Boundary condition loss: 0.00018652308790478855\n","\tTesting: PDE loss: 0.01629139482975006\n","\tTesting: Data loss: 0.005704496521502733\n","\n","Epoch 433\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013921086676418781\n","\tBefore adaption: Boundary condition loss: 0.00018687073315959424\n","\tBefore adaption: PDE loss: 0.01631668023765087\n","\tBefore adaption: Data loss: 0.005661619361490011\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0385, 0.5309, 0.3183, 0.1123], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007391384323734792\n","\t\tAfter adaption: Boundary condition loss: 7.200659698275552e-06\n","\t\tAfter adaption: PDE loss: 0.00519285994984478\n","\t\tAfter adaption: Data loss: 0.000635593015753879\n","\n","\tTesting: Initial condition loss: 0.005345863755792379\n","\tTesting: Boundary condition loss: 0.0007388419471681118\n","\tTesting: PDE loss: 0.017455752938985825\n","\tTesting: Data loss: 0.007802770007401705\n","\n","Epoch 434\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0076965936459600925\n","\tBefore adaption: Boundary condition loss: 0.0006394478841684759\n","\tBefore adaption: PDE loss: 0.017485367134213448\n","\tBefore adaption: Data loss: 0.007706266362220049\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0335, 0.5173, 0.3307, 0.1186], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003981355789899941\n","\t\tAfter adaption: Boundary condition loss: 2.1390063360038716e-05\n","\t\tAfter adaption: PDE loss: 0.005781714193603597\n","\t\tAfter adaption: Data loss: 0.0009139691093450084\n","\n","\tTesting: Initial condition loss: 0.0030031129717826843\n","\tTesting: Boundary condition loss: 0.002896243939176202\n","\tTesting: PDE loss: 0.0186877753585577\n","\tTesting: Data loss: 0.011670934967696667\n","\n","Epoch 435\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004841129295527935\n","\tBefore adaption: Boundary condition loss: 0.0026620286516845226\n","\tBefore adaption: PDE loss: 0.018711701035499573\n","\tBefore adaption: Data loss: 0.01151584554463625\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0280, 0.4675, 0.3664, 0.1381], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022633803512747885\n","\t\tAfter adaption: Boundary condition loss: 7.44194398590935e-05\n","\t\tAfter adaption: PDE loss: 0.006856418641541156\n","\t\tAfter adaption: Data loss: 0.001590202988725116\n","\n","\tTesting: Initial condition loss: 0.0038728343788534403\n","\tTesting: Boundary condition loss: 0.0061565302312374115\n","\tTesting: PDE loss: 0.01972193457186222\n","\tTesting: Data loss: 0.016559777781367302\n","\n","Epoch 436\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004996401257812977\n","\tBefore adaption: Boundary condition loss: 0.00575721962377429\n","\tBefore adaption: PDE loss: 0.01972530037164688\n","\tBefore adaption: Data loss: 0.016350505873560905\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0309, 0.3785, 0.4132, 0.1774], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018909304593574664\n","\t\tAfter adaption: Boundary condition loss: 0.00017806628130712852\n","\t\tAfter adaption: PDE loss: 0.008149840630953096\n","\t\tAfter adaption: Data loss: 0.002901318441107214\n","\n","\tTesting: Initial condition loss: 0.00601808400824666\n","\tTesting: Boundary condition loss: 0.009394947439432144\n","\tTesting: PDE loss: 0.02037958800792694\n","\tTesting: Data loss: 0.021138271316885948\n","\n","Epoch 437\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006467435508966446\n","\tBefore adaption: Boundary condition loss: 0.008849896490573883\n","\tBefore adaption: PDE loss: 0.0203773882240057\n","\tBefore adaption: Data loss: 0.02088625729084015\n","tensor(0.0088, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0088, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0512, 0.2691, 0.4444, 0.2354], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017400737058427004\n","\t\tAfter adaption: Boundary condition loss: 0.00045308428154668974\n","\t\tAfter adaption: PDE loss: 0.009055109013437106\n","\t\tAfter adaption: Data loss: 0.0049162316233747295\n","\n","\tTesting: Initial condition loss: 0.007497113663703203\n","\tTesting: Boundary condition loss: 0.011375479400157928\n","\tTesting: PDE loss: 0.020637650042772293\n","\tTesting: Data loss: 0.024024583399295807\n","\n","Epoch 438\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007557747419923544\n","\tBefore adaption: Boundary condition loss: 0.010750935412943363\n","\tBefore adaption: PDE loss: 0.02063983678817749\n","\tBefore adaption: Data loss: 0.023747555911540985\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0108, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0859, 0.1798, 0.4395, 0.2948], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013589613994721894\n","\t\tAfter adaption: Boundary condition loss: 0.0009231046037148923\n","\t\tAfter adaption: PDE loss: 0.009071704601236187\n","\t\tAfter adaption: Data loss: 0.007000841602229751\n","\n","\tTesting: Initial condition loss: 0.007300460711121559\n","\tTesting: Boundary condition loss: 0.011278948746621609\n","\tTesting: PDE loss: 0.020565573126077652\n","\tTesting: Data loss: 0.024281829595565796\n","\n","Epoch 439\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007347469683736563\n","\tBefore adaption: Boundary condition loss: 0.010670695453882217\n","\tBefore adaption: PDE loss: 0.020570918917655945\n","\tBefore adaption: Data loss: 0.024001892656087875\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0107, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1207, 0.1329, 0.4084, 0.3380], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009763215297173973\n","\t\tAfter adaption: Boundary condition loss: 0.0012884083065383372\n","\t\tAfter adaption: PDE loss: 0.008401384048795863\n","\t\tAfter adaption: Data loss: 0.008111866306618667\n","\n","\tTesting: Initial condition loss: 0.005547483917325735\n","\tTesting: Boundary condition loss: 0.009162001311779022\n","\tTesting: PDE loss: 0.0202495027333498\n","\tTesting: Data loss: 0.02182036265730858\n","\n","Epoch 440\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005936009809374809\n","\tBefore adaption: Boundary condition loss: 0.008654431439936161\n","\tBefore adaption: PDE loss: 0.020254425704479218\n","\tBefore adaption: Data loss: 0.021560445427894592\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1452, 0.1171, 0.3754, 0.3623], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006951163032014695\n","\t\tAfter adaption: Boundary condition loss: 0.001256840883945044\n","\t\tAfter adaption: PDE loss: 0.007603280755100037\n","\t\tAfter adaption: Data loss: 0.007811014458247495\n","\n","\tTesting: Initial condition loss: 0.0033746755216270685\n","\tTesting: Boundary condition loss: 0.005948742851614952\n","\tTesting: PDE loss: 0.01977439410984516\n","\tTesting: Data loss: 0.017490101978182793\n","\n","Epoch 441\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004292283207178116\n","\tBefore adaption: Boundary condition loss: 0.0055867331102490425\n","\tBefore adaption: PDE loss: 0.01977156661450863\n","\tBefore adaption: Data loss: 0.017268475145101547\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1567, 0.1133, 0.3562, 0.3738], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000486279434669607\n","\t\tAfter adaption: Boundary condition loss: 0.0008756303182458429\n","\t\tAfter adaption: PDE loss: 0.007042290100645962\n","\t\tAfter adaption: Data loss: 0.006454812532756643\n","\n","\tTesting: Initial condition loss: 0.002303789369761944\n","\tTesting: Boundary condition loss: 0.002869407879188657\n","\tTesting: PDE loss: 0.019206373021006584\n","\tTesting: Data loss: 0.012652076780796051\n","\n","Epoch 442\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003742702305316925\n","\tBefore adaption: Boundary condition loss: 0.002651551039889455\n","\tBefore adaption: PDE loss: 0.01920301653444767\n","\tBefore adaption: Data loss: 0.012479870580136776\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1561, 0.1108, 0.3562, 0.3769], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00041468490257324316\n","\t\tAfter adaption: Boundary condition loss: 0.00041387217999364854\n","\t\tAfter adaption: PDE loss: 0.006840828813691972\n","\t\tAfter adaption: Data loss: 0.004703382954319141\n","\n","\tTesting: Initial condition loss: 0.003543120576068759\n","\tTesting: Boundary condition loss: 0.0008577533881179988\n","\tTesting: PDE loss: 0.01856628991663456\n","\tTesting: Data loss: 0.008555136620998383\n","\n","Epoch 443\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005354306660592556\n","\tBefore adaption: Boundary condition loss: 0.0007533423486165702\n","\tBefore adaption: PDE loss: 0.01857841946184635\n","\tBefore adaption: Data loss: 0.008436485193669796\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1437, 0.1083, 0.3766, 0.3715], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005797310445745305\n","\t\tAfter adaption: Boundary condition loss: 0.0001082325489714069\n","\t\tAfter adaption: PDE loss: 0.006996390087063902\n","\t\tAfter adaption: Data loss: 0.0031338951220083885\n","\n","\tTesting: Initial condition loss: 0.007435264997184277\n","\tTesting: Boundary condition loss: 0.00021186625235714018\n","\tTesting: PDE loss: 0.017917994409799576\n","\tTesting: Data loss: 0.005903252400457859\n","\n","Epoch 444\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009465498849749565\n","\tBefore adaption: Boundary condition loss: 0.00019259416148997843\n","\tBefore adaption: PDE loss: 0.017918137833476067\n","\tBefore adaption: Data loss: 0.005835540592670441\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1194, 0.1125, 0.4149, 0.3532], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010647478888017373\n","\t\tAfter adaption: Boundary condition loss: 2.29991293400219e-05\n","\t\tAfter adaption: PDE loss: 0.007434526918657482\n","\t\tAfter adaption: Data loss: 0.002060988584719278\n","\n","\tTesting: Initial condition loss: 0.013421306386590004\n","\tTesting: Boundary condition loss: 0.000581691914703697\n","\tTesting: PDE loss: 0.01725354604423046\n","\tTesting: Data loss: 0.004756715148687363\n","\n","Epoch 445\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015497824177145958\n","\tBefore adaption: Boundary condition loss: 0.0006354177603498101\n","\tBefore adaption: PDE loss: 0.01725092902779579\n","\tBefore adaption: Data loss: 0.004732958506792784\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0858, 0.1385, 0.4604, 0.3153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021458511149213062\n","\t\tAfter adaption: Boundary condition loss: 5.450694438413468e-05\n","\t\tAfter adaption: PDE loss: 0.007942710382595378\n","\t\tAfter adaption: Data loss: 0.0014924668108001293\n","\n","\tTesting: Initial condition loss: 0.02034749835729599\n","\tTesting: Boundary condition loss: 0.0014041796093806624\n","\tTesting: PDE loss: 0.016583122313022614\n","\tTesting: Data loss: 0.0047068968415260315\n","\n","Epoch 446\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022246379405260086\n","\tBefore adaption: Boundary condition loss: 0.0015124230412766337\n","\tBefore adaption: PDE loss: 0.01658497005701065\n","\tBefore adaption: Data loss: 0.004717555362731218\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0518, 0.2022, 0.4890, 0.2570], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0044991856149972816\n","\t\tAfter adaption: Boundary condition loss: 7.830068215151247e-05\n","\t\tAfter adaption: PDE loss: 0.008109798164397566\n","\t\tAfter adaption: Data loss: 0.0012124106101456197\n","\n","\tTesting: Initial condition loss: 0.0261843204498291\n","\tTesting: Boundary condition loss: 0.002127961255609989\n","\tTesting: PDE loss: 0.015997815877199173\n","\tTesting: Data loss: 0.005117447581142187\n","\n","Epoch 447\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027924682945013046\n","\tBefore adaption: Boundary condition loss: 0.0022673688363283873\n","\tBefore adaption: PDE loss: 0.01599685288965702\n","\tBefore adaption: Data loss: 0.005150978919118643\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0306, 0.2999, 0.4768, 0.1927], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008374143507308762\n","\t\tAfter adaption: Boundary condition loss: 6.935872159917533e-05\n","\t\tAfter adaption: PDE loss: 0.007627492935102712\n","\t\tAfter adaption: Data loss: 0.0009926681778092282\n","\n","\tTesting: Initial condition loss: 0.02860298939049244\n","\tTesting: Boundary condition loss: 0.002314009703695774\n","\tTesting: PDE loss: 0.01565415970981121\n","\tTesting: Data loss: 0.005338903050869703\n","\n","Epoch 448\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030391013249754906\n","\tBefore adaption: Boundary condition loss: 0.002457743976265192\n","\tBefore adaption: PDE loss: 0.015632368624210358\n","\tBefore adaption: Data loss: 0.005381502211093903\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0267, 0.4004, 0.4293, 0.1436], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012169728037525711\n","\t\tAfter adaption: Boundary condition loss: 6.55261806414843e-05\n","\t\tAfter adaption: PDE loss: 0.006711644631686386\n","\t\tAfter adaption: Data loss: 0.0007725549102173981\n","\n","\tTesting: Initial condition loss: 0.026102006435394287\n","\tTesting: Boundary condition loss: 0.0018107055220752954\n","\tTesting: PDE loss: 0.015700869262218475\n","\tTesting: Data loss: 0.005044936202466488\n","\n","Epoch 449\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028078347444534302\n","\tBefore adaption: Boundary condition loss: 0.0019306184258311987\n","\tBefore adaption: PDE loss: 0.01568830944597721\n","\tBefore adaption: Data loss: 0.005080353934317827\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0319, 0.4759, 0.3759, 0.1164], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013363459290260662\n","\t\tAfter adaption: Boundary condition loss: 6.149059297529922e-05\n","\t\tAfter adaption: PDE loss: 0.005896472230346904\n","\t\tAfter adaption: Data loss: 0.0005911679851601304\n","\n","\tTesting: Initial condition loss: 0.019336938858032227\n","\tTesting: Boundary condition loss: 0.0009043128229677677\n","\tTesting: PDE loss: 0.016256650909781456\n","\tTesting: Data loss: 0.00456693721935153\n","\n","Epoch 450\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02169126644730568\n","\tBefore adaption: Boundary condition loss: 0.0009769489988684654\n","\tBefore adaption: PDE loss: 0.01623225398361683\n","\tBefore adaption: Data loss: 0.004578212276101112\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0368, 0.5192, 0.3392, 0.1048], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011262889030151513\n","\t\tAfter adaption: Boundary condition loss: 3.595358327317969e-05\n","\t\tAfter adaption: PDE loss: 0.005506007646812218\n","\t\tAfter adaption: Data loss: 0.00047961396449933965\n","\n","\tTesting: Initial condition loss: 0.011282924562692642\n","\tTesting: Boundary condition loss: 0.0002745769452303648\n","\tTesting: PDE loss: 0.017244206741452217\n","\tTesting: Data loss: 0.004789307247847319\n","\n","Epoch 451\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013856908306479454\n","\tBefore adaption: Boundary condition loss: 0.00027783610858023167\n","\tBefore adaption: PDE loss: 0.01721540093421936\n","\tBefore adaption: Data loss: 0.0047609638422727585\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0374, 0.5332, 0.3276, 0.1018], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007388108070561533\n","\t\tAfter adaption: Boundary condition loss: 1.038874713029998e-05\n","\t\tAfter adaption: PDE loss: 0.005639748319123077\n","\t\tAfter adaption: Data loss: 0.0004848455314036924\n","\n","\tTesting: Initial condition loss: 0.005256164353340864\n","\tTesting: Boundary condition loss: 0.0006352943019010127\n","\tTesting: PDE loss: 0.018493788316845894\n","\tTesting: Data loss: 0.006569391582161188\n","\n","Epoch 452\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007541725877672434\n","\tBefore adaption: Boundary condition loss: 0.0005498297396115959\n","\tBefore adaption: PDE loss: 0.01847258023917675\n","\tBefore adaption: Data loss: 0.006490170024335384\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0336, 0.5178, 0.3428, 0.1059], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003904867460334386\n","\t\tAfter adaption: Boundary condition loss: 1.8460272829565163e-05\n","\t\tAfter adaption: PDE loss: 0.006331553092177489\n","\t\tAfter adaption: Data loss: 0.0006873266595957524\n","\n","\tTesting: Initial condition loss: 0.002844490110874176\n","\tTesting: Boundary condition loss: 0.0023956806398928165\n","\tTesting: PDE loss: 0.019755544140934944\n","\tTesting: Data loss: 0.010140021331608295\n","\n","Epoch 453\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004562161862850189\n","\tBefore adaption: Boundary condition loss: 0.0021990202367305756\n","\tBefore adaption: PDE loss: 0.0197345819324255\n","\tBefore adaption: Data loss: 0.010004774667322636\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0285, 0.4674, 0.3831, 0.1210], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021324363529720133\n","\t\tAfter adaption: Boundary condition loss: 6.267409259447553e-05\n","\t\tAfter adaption: PDE loss: 0.007559980093333215\n","\t\tAfter adaption: Data loss: 0.001210558137868154\n","\n","\tTesting: Initial condition loss: 0.0036096363328397274\n","\tTesting: Boundary condition loss: 0.005246711894869804\n","\tTesting: PDE loss: 0.02072359062731266\n","\tTesting: Data loss: 0.01487098727375269\n","\n","Epoch 454\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004620057996362448\n","\tBefore adaption: Boundary condition loss: 0.004904942121356726\n","\tBefore adaption: PDE loss: 0.020710764452815056\n","\tBefore adaption: Data loss: 0.014683135785162449\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0297, 0.3787, 0.4370, 0.1547], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017495894833248532\n","\t\tAfter adaption: Boundary condition loss: 0.00014560482240738172\n","\t\tAfter adaption: PDE loss: 0.009049960226068042\n","\t\tAfter adaption: Data loss: 0.002270765144522686\n","\n","\tTesting: Initial condition loss: 0.005690460093319416\n","\tTesting: Boundary condition loss: 0.008243540301918983\n","\tTesting: PDE loss: 0.021249601617455482\n","\tTesting: Data loss: 0.019571498036384583\n","\n","Epoch 455\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00606175372377038\n","\tBefore adaption: Boundary condition loss: 0.007765995804220438\n","\tBefore adaption: PDE loss: 0.021239817142486572\n","\tBefore adaption: Data loss: 0.01934013143181801\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0459, 0.2692, 0.4761, 0.2088], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016318352149058029\n","\t\tAfter adaption: Boundary condition loss: 0.00035653294124227906\n","\t\tAfter adaption: PDE loss: 0.010111739690426013\n","\t\tAfter adaption: Data loss: 0.004038484579882665\n","\n","\tTesting: Initial condition loss: 0.007244554348289967\n","\tTesting: Boundary condition loss: 0.010299097746610641\n","\tTesting: PDE loss: 0.021317915990948677\n","\tTesting: Data loss: 0.02299528382718563\n","\n","Epoch 456\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007219997234642506\n","\tBefore adaption: Boundary condition loss: 0.009745728224515915\n","\tBefore adaption: PDE loss: 0.0213177353143692\n","\tBefore adaption: Data loss: 0.02273501828312874\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0766, 0.1786, 0.4751, 0.2697], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012896682969792768\n","\t\tAfter adaption: Boundary condition loss: 0.0007463159748518139\n","\t\tAfter adaption: PDE loss: 0.010127915578163131\n","\t\tAfter adaption: Data loss: 0.006131704440868946\n","\n","\tTesting: Initial condition loss: 0.007242655847221613\n","\tTesting: Boundary condition loss: 0.010649971663951874\n","\tTesting: PDE loss: 0.021027449518442154\n","\tTesting: Data loss: 0.024184616282582283\n","\n","Epoch 457\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007157029118388891\n","\tBefore adaption: Boundary condition loss: 0.010110832750797272\n","\tBefore adaption: PDE loss: 0.02103315480053425\n","\tBefore adaption: Data loss: 0.02391323819756508\n","tensor(0.0101, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0101, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1095, 0.1304, 0.4414, 0.3187], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009335606073943188\n","\t\tAfter adaption: Boundary condition loss: 0.0011067638808783462\n","\t\tAfter adaption: PDE loss: 0.009284268061301764\n","\t\tAfter adaption: Data loss: 0.007620809902856343\n","\n","\tTesting: Initial condition loss: 0.005673313979059458\n","\tTesting: Boundary condition loss: 0.009147579781711102\n","\tTesting: PDE loss: 0.020502576604485512\n","\tTesting: Data loss: 0.022797420620918274\n","\n","Epoch 458\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005856169853359461\n","\tBefore adaption: Boundary condition loss: 0.00870063528418541\n","\tBefore adaption: PDE loss: 0.020505953580141068\n","\tBefore adaption: Data loss: 0.022534627467393875\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1340, 0.1143, 0.4016, 0.3501], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006693652138703426\n","\t\tAfter adaption: Boundary condition loss: 0.0011663191178597622\n","\t\tAfter adaption: PDE loss: 0.008234253038767275\n","\t\tAfter adaption: Data loss: 0.007889256163071384\n","\n","\tTesting: Initial condition loss: 0.0034562470391392708\n","\tTesting: Boundary condition loss: 0.006411305628716946\n","\tTesting: PDE loss: 0.019820470362901688\n","\tTesting: Data loss: 0.01931404508650303\n","\n","Epoch 459\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004107183776795864\n","\tBefore adaption: Boundary condition loss: 0.006091609597206116\n","\tBefore adaption: PDE loss: 0.019817853346467018\n","\tBefore adaption: Data loss: 0.0190782118588686\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1472, 0.1103, 0.3740, 0.3685], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00045315243319919577\n","\t\tAfter adaption: Boundary condition loss: 0.0008964744214333719\n","\t\tAfter adaption: PDE loss: 0.007412555813654052\n","\t\tAfter adaption: Data loss: 0.007029719476326812\n","\n","\tTesting: Initial condition loss: 0.0020207560155540705\n","\tTesting: Boundary condition loss: 0.0035202959552407265\n","\tTesting: PDE loss: 0.01907719485461712\n","\tTesting: Data loss: 0.014836171641945839\n","\n","Epoch 460\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0031597663182765245\n","\tBefore adaption: Boundary condition loss: 0.003317218506708741\n","\tBefore adaption: PDE loss: 0.019058413803577423\n","\tBefore adaption: Data loss: 0.0146414153277874\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1492, 0.1069, 0.3654, 0.3785], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00033783338956572083\n","\t\tAfter adaption: Boundary condition loss: 0.0004948549836311535\n","\t\tAfter adaption: PDE loss: 0.006963892420873373\n","\t\tAfter adaption: Data loss: 0.005541887822655401\n","\n","\tTesting: Initial condition loss: 0.002681541256606579\n","\tTesting: Boundary condition loss: 0.0013564404798671603\n","\tTesting: PDE loss: 0.01828860305249691\n","\tTesting: Data loss: 0.01057271845638752\n","\n","Epoch 461\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004128928296267986\n","\tBefore adaption: Boundary condition loss: 0.0012419578852131963\n","\tBefore adaption: PDE loss: 0.01827646978199482\n","\tBefore adaption: Data loss: 0.01042668055742979\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1406, 0.1018, 0.3766, 0.3810], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000420364115750464\n","\t\tAfter adaption: Boundary condition loss: 0.00017457518527612813\n","\t\tAfter adaption: PDE loss: 0.006882899033586855\n","\t\tAfter adaption: Data loss: 0.003972845629462831\n","\n","\tTesting: Initial condition loss: 0.0060218158178031445\n","\tTesting: Boundary condition loss: 0.00030060423887334764\n","\tTesting: PDE loss: 0.017512552440166473\n","\tTesting: Data loss: 0.0073762256652116776\n","\n","Epoch 462\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007515336386859417\n","\tBefore adaption: Boundary condition loss: 0.0002545100578572601\n","\tBefore adaption: PDE loss: 0.017506228759884834\n","\tBefore adaption: Data loss: 0.007280345074832439\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1212, 0.1004, 0.4059, 0.3726], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007543922085149808\n","\t\tAfter adaption: Boundary condition loss: 3.0837358234340964e-05\n","\t\tAfter adaption: PDE loss: 0.007105274345332655\n","\t\tAfter adaption: Data loss: 0.0027125444627703415\n","\n","\tTesting: Initial condition loss: 0.01173675712198019\n","\tTesting: Boundary condition loss: 0.000233232305618003\n","\tTesting: PDE loss: 0.01675397902727127\n","\tTesting: Data loss: 0.005568585824221373\n","\n","Epoch 463\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013109728693962097\n","\tBefore adaption: Boundary condition loss: 0.0002512591308914125\n","\tBefore adaption: PDE loss: 0.01674603670835495\n","\tBefore adaption: Data loss: 0.005517807323485613\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0918, 0.1160, 0.4458, 0.3464], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015208011263646195\n","\t\tAfter adaption: Boundary condition loss: 2.3072062887096008e-05\n","\t\tAfter adaption: PDE loss: 0.007465013364465\n","\t\tAfter adaption: Data loss: 0.001911316269556548\n","\n","\tTesting: Initial condition loss: 0.0187530480325222\n","\tTesting: Boundary condition loss: 0.0007945492397993803\n","\tTesting: PDE loss: 0.01602095551788807\n","\tTesting: Data loss: 0.004992078058421612\n","\n","Epoch 464\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0200066938996315\n","\tBefore adaption: Boundary condition loss: 0.0008601674344390631\n","\tBefore adaption: PDE loss: 0.016010195016860962\n","\tBefore adaption: Data loss: 0.004978208802640438\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0582, 0.1672, 0.4773, 0.2973], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0033450196826871276\n","\t\tAfter adaption: Boundary condition loss: 5.010088942808265e-05\n","\t\tAfter adaption: PDE loss: 0.007641735088861007\n","\t\tAfter adaption: Data loss: 0.0014797969379726121\n","\n","\tTesting: Initial condition loss: 0.02549060620367527\n","\tTesting: Boundary condition loss: 0.0015140809118747711\n","\tTesting: PDE loss: 0.01535639539361\n","\tTesting: Data loss: 0.005173053126782179\n","\n","Epoch 465\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026652157306671143\n","\tBefore adaption: Boundary condition loss: 0.0016133198514580727\n","\tBefore adaption: PDE loss: 0.015336844138801098\n","\tBefore adaption: Data loss: 0.0051857102662324905\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0321, 0.2601, 0.4754, 0.2324], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006931367095464651\n","\t\tAfter adaption: Boundary condition loss: 5.186522171899908e-05\n","\t\tAfter adaption: PDE loss: 0.007290612364343504\n","\t\tAfter adaption: Data loss: 0.001205252144660691\n","\n","\tTesting: Initial condition loss: 0.029675299301743507\n","\tTesting: Boundary condition loss: 0.0019410417880862951\n","\tTesting: PDE loss: 0.014888770878314972\n","\tTesting: Data loss: 0.005486270412802696\n","\n","Epoch 466\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03093145415186882\n","\tBefore adaption: Boundary condition loss: 0.002055375836789608\n","\tBefore adaption: PDE loss: 0.014858510345220566\n","\tBefore adaption: Data loss: 0.005513931158930063\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0219, 0.3703, 0.4348, 0.1730], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011453835497634393\n","\t\tAfter adaption: Boundary condition loss: 4.4971898315791525e-05\n","\t\tAfter adaption: PDE loss: 0.006460398496965641\n","\t\tAfter adaption: Data loss: 0.0009540631709174628\n","\n","\tTesting: Initial condition loss: 0.029199952259659767\n","\tTesting: Boundary condition loss: 0.0017901418032124639\n","\tTesting: PDE loss: 0.014781991019845009\n","\tTesting: Data loss: 0.005422145593911409\n","\n","Epoch 467\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03075609728693962\n","\tBefore adaption: Boundary condition loss: 0.0018994641723111272\n","\tBefore adaption: PDE loss: 0.014751981012523174\n","\tBefore adaption: Data loss: 0.005450565367937088\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0237, 0.4630, 0.3791, 0.1342], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014240745179631822\n","\t\tAfter adaption: Boundary condition loss: 4.506114959439481e-05\n","\t\tAfter adaption: PDE loss: 0.005592530055165809\n","\t\tAfter adaption: Data loss: 0.0007311996756105276\n","\n","\tTesting: Initial condition loss: 0.023680077865719795\n","\tTesting: Boundary condition loss: 0.0011199249420315027\n","\tTesting: PDE loss: 0.01516874972730875\n","\tTesting: Data loss: 0.004987971391528845\n","\n","Epoch 468\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025716856122016907\n","\tBefore adaption: Boundary condition loss: 0.0012022452428936958\n","\tBefore adaption: PDE loss: 0.015136693604290485\n","\tBefore adaption: Data loss: 0.005001564044505358\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0287, 0.5226, 0.3341, 0.1146], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013439656460804483\n","\t\tAfter adaption: Boundary condition loss: 3.4532997325833566e-05\n","\t\tAfter adaption: PDE loss: 0.00505727822930273\n","\t\tAfter adaption: Data loss: 0.0005730180322402825\n","\n","\tTesting: Initial condition loss: 0.015296589583158493\n","\tTesting: Boundary condition loss: 0.0004111301968805492\n","\tTesting: PDE loss: 0.016055714339017868\n","\tTesting: Data loss: 0.00485099945217371\n","\n","Epoch 469\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.017720110714435577\n","\tBefore adaption: Boundary condition loss: 0.00044078807695768774\n","\tBefore adaption: PDE loss: 0.016024472191929817\n","\tBefore adaption: Data loss: 0.004833537619560957\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0313, 0.5498, 0.3118, 0.1071], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009742550095168298\n","\t\tAfter adaption: Boundary condition loss: 1.3785529993698936e-05\n","\t\tAfter adaption: PDE loss: 0.004997007957295104\n","\t\tAfter adaption: Data loss: 0.000517609745465322\n","\n","\tTesting: Initial condition loss: 0.007554096169769764\n","\tTesting: Boundary condition loss: 0.0003851823857985437\n","\tTesting: PDE loss: 0.017338965088129044\n","\tTesting: Data loss: 0.005959023721516132\n","\n","Epoch 470\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009984535165131092\n","\tBefore adaption: Boundary condition loss: 0.0003301133692730218\n","\tBefore adaption: PDE loss: 0.01730974018573761\n","\tBefore adaption: Data loss: 0.005897624883800745\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0299, 0.5468, 0.3156, 0.1078], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00545910909741072\n","\t\tAfter adaption: Boundary condition loss: 9.871940259852075e-06\n","\t\tAfter adaption: PDE loss: 0.00546262791855508\n","\t\tAfter adaption: Data loss: 0.0006355131613940323\n","\n","\tTesting: Initial condition loss: 0.0032797553576529026\n","\tTesting: Boundary condition loss: 0.001588429557159543\n","\tTesting: PDE loss: 0.01878836378455162\n","\tTesting: Data loss: 0.008884532377123833\n","\n","Epoch 471\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0052675651386380196\n","\tBefore adaption: Boundary condition loss: 0.0014272240223363042\n","\tBefore adaption: PDE loss: 0.018746107816696167\n","\tBefore adaption: Data loss: 0.008771824650466442\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0262, 0.5098, 0.3457, 0.1182], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002685486172824685\n","\t\tAfter adaption: Boundary condition loss: 3.746285199787019e-05\n","\t\tAfter adaption: PDE loss: 0.006480925719433372\n","\t\tAfter adaption: Data loss: 0.0010369561786504583\n","\n","\tTesting: Initial condition loss: 0.0029716207645833492\n","\tTesting: Boundary condition loss: 0.004096504300832748\n","\tTesting: PDE loss: 0.02005760744214058\n","\tTesting: Data loss: 0.013328983448445797\n","\n","Epoch 472\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004255793988704681\n","\tBefore adaption: Boundary condition loss: 0.0037955131847411394\n","\tBefore adaption: PDE loss: 0.02002253197133541\n","\tBefore adaption: Data loss: 0.013165827840566635\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0256, 0.4327, 0.3967, 0.1450], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001841631024896069\n","\t\tAfter adaption: Boundary condition loss: 9.733838513626791e-05\n","\t\tAfter adaption: PDE loss: 0.007942231807742022\n","\t\tAfter adaption: Data loss: 0.0019084446892685912\n","\n","\tTesting: Initial condition loss: 0.005067033693194389\n","\tTesting: Boundary condition loss: 0.007259898353368044\n","\tTesting: PDE loss: 0.02096405439078808\n","\tTesting: Data loss: 0.0182404313236475\n","\n","Epoch 473\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005570721812546253\n","\tBefore adaption: Boundary condition loss: 0.00679908087477088\n","\tBefore adaption: PDE loss: 0.02091737650334835\n","\tBefore adaption: Data loss: 0.018032317981123924\n","tensor(0.0068, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0068, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0369, 0.3226, 0.4474, 0.1932], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017968824186949184\n","\t\tAfter adaption: Boundary condition loss: 0.0002508643992432922\n","\t\tAfter adaption: PDE loss: 0.0093580668916935\n","\t\tAfter adaption: Data loss: 0.00348316257609103\n","\n","\tTesting: Initial condition loss: 0.007388110738247633\n","\tTesting: Boundary condition loss: 0.009916167706251144\n","\tTesting: PDE loss: 0.021388499066233635\n","\tTesting: Data loss: 0.022295305505394936\n","\n","Epoch 474\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007265905849635601\n","\tBefore adaption: Boundary condition loss: 0.009327337145805359\n","\tBefore adaption: PDE loss: 0.021356703713536263\n","\tBefore adaption: Data loss: 0.022053822875022888\n","tensor(0.0093, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0093, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0642, 0.2146, 0.4668, 0.2544], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015590931709876777\n","\t\tAfter adaption: Boundary condition loss: 0.0005987129272119727\n","\t\tAfter adaption: PDE loss: 0.009969636183696583\n","\t\tAfter adaption: Data loss: 0.00561090756783568\n","\n","\tTesting: Initial condition loss: 0.008338052779436111\n","\tTesting: Boundary condition loss: 0.011066065169870853\n","\tTesting: PDE loss: 0.02141573466360569\n","\tTesting: Data loss: 0.024360761046409607\n","\n","Epoch 475\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00795839261263609\n","\tBefore adaption: Boundary condition loss: 0.010432165116071701\n","\tBefore adaption: PDE loss: 0.021376021206378937\n","\tBefore adaption: Data loss: 0.024101970717310905\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0104, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0984, 0.1467, 0.4465, 0.3084], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001167636110585198\n","\t\tAfter adaption: Boundary condition loss: 0.0010266339152052012\n","\t\tAfter adaption: PDE loss: 0.009544510857036358\n","\t\tAfter adaption: Data loss: 0.007432234686836485\n","\n","\tTesting: Initial condition loss: 0.007407661061733961\n","\tTesting: Boundary condition loss: 0.010249477811157703\n","\tTesting: PDE loss: 0.021124709397554398\n","\tTesting: Data loss: 0.02383914776146412\n","\n","Epoch 476\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0071742297150194645\n","\tBefore adaption: Boundary condition loss: 0.009677675552666187\n","\tBefore adaption: PDE loss: 0.021092940121889114\n","\tBefore adaption: Data loss: 0.0235820934176445\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1268, 0.1209, 0.4086, 0.3437], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008674039292452367\n","\t\tAfter adaption: Boundary condition loss: 0.0012271089247627614\n","\t\tAfter adaption: PDE loss: 0.008618802075896893\n","\t\tAfter adaption: Data loss: 0.008104826829791165\n","\n","\tTesting: Initial condition loss: 0.005137737840414047\n","\tTesting: Boundary condition loss: 0.00785782840102911\n","\tTesting: PDE loss: 0.020648591220378876\n","\tTesting: Data loss: 0.0209317896515131\n","\n","Epoch 477\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0053719282150268555\n","\tBefore adaption: Boundary condition loss: 0.007411247584968805\n","\tBefore adaption: PDE loss: 0.020602766424417496\n","\tBefore adaption: Data loss: 0.020694797858595848\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1440, 0.1159, 0.3769, 0.3632], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006226578617241292\n","\t\tAfter adaption: Boundary condition loss: 0.0010673931241547165\n","\t\tAfter adaption: PDE loss: 0.007764245938079241\n","\t\tAfter adaption: Data loss: 0.007516605433746686\n","\n","\tTesting: Initial condition loss: 0.0028363477904349566\n","\tTesting: Boundary condition loss: 0.004866955801844597\n","\tTesting: PDE loss: 0.020016871392726898\n","\tTesting: Data loss: 0.01657705195248127\n","\n","Epoch 478\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036423790734261274\n","\tBefore adaption: Boundary condition loss: 0.004555187653750181\n","\tBefore adaption: PDE loss: 0.01999206468462944\n","\tBefore adaption: Data loss: 0.016375526785850525\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1501, 0.1146, 0.3622, 0.3731], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000417577710017523\n","\t\tAfter adaption: Boundary condition loss: 0.0006837295670271451\n","\t\tAfter adaption: PDE loss: 0.007240987491786349\n","\t\tAfter adaption: Data loss: 0.006109110142405687\n","\n","\tTesting: Initial condition loss: 0.0019675821531563997\n","\tTesting: Boundary condition loss: 0.0023176155518740416\n","\tTesting: PDE loss: 0.019323350861668587\n","\tTesting: Data loss: 0.012010766193270683\n","\n","Epoch 479\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0032614797819405794\n","\tBefore adaption: Boundary condition loss: 0.0021214731968939304\n","\tBefore adaption: PDE loss: 0.019304852932691574\n","\tBefore adaption: Data loss: 0.011854126118123531\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1458, 0.1106, 0.3676, 0.3761], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003606790394001586\n","\t\tAfter adaption: Boundary condition loss: 0.0003092431741537191\n","\t\tAfter adaption: PDE loss: 0.0070957507484446306\n","\t\tAfter adaption: Data loss: 0.004458112747865062\n","\n","\tTesting: Initial condition loss: 0.003514630254358053\n","\tTesting: Boundary condition loss: 0.0007641374249942601\n","\tTesting: PDE loss: 0.018599314615130424\n","\tTesting: Data loss: 0.008254418149590492\n","\n","Epoch 480\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005049433559179306\n","\tBefore adaption: Boundary condition loss: 0.0006644400418736041\n","\tBefore adaption: PDE loss: 0.018595505505800247\n","\tBefore adaption: Data loss: 0.008145212195813656\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1312, 0.1052, 0.3928, 0.3708], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005310894438398534\n","\t\tAfter adaption: Boundary condition loss: 8.71977130382277e-05\n","\t\tAfter adaption: PDE loss: 0.0073047982286244244\n","\t\tAfter adaption: Data loss: 0.0030199261106954034\n","\n","\tTesting: Initial condition loss: 0.007670700084418058\n","\tTesting: Boundary condition loss: 0.00028255232609808445\n","\tTesting: PDE loss: 0.01787484996020794\n","\tTesting: Data loss: 0.005827026441693306\n","\n","Epoch 481\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00914676208049059\n","\tBefore adaption: Boundary condition loss: 0.0002625810739118606\n","\tBefore adaption: PDE loss: 0.0178608950227499\n","\tBefore adaption: Data loss: 0.005763139110058546\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1066, 0.1069, 0.4346, 0.3519], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009778172468076383\n","\t\tAfter adaption: Boundary condition loss: 2.799056631203465e-05\n","\t\tAfter adaption: PDE loss: 0.007762168104778423\n","\t\tAfter adaption: Data loss: 0.0020280992302898833\n","\n","\tTesting: Initial condition loss: 0.013781527057290077\n","\tTesting: Boundary condition loss: 0.0005880246753804386\n","\tTesting: PDE loss: 0.017083631828427315\n","\tTesting: Data loss: 0.004742217715829611\n","\n","Epoch 482\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01508332509547472\n","\tBefore adaption: Boundary condition loss: 0.0006353326607495546\n","\tBefore adaption: PDE loss: 0.017094839364290237\n","\tBefore adaption: Data loss: 0.0047166235744953156\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0748, 0.1319, 0.4802, 0.3130], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019896919643480233\n","\t\tAfter adaption: Boundary condition loss: 4.7532634309554614e-05\n","\t\tAfter adaption: PDE loss: 0.008209337577909485\n","\t\tAfter adaption: Data loss: 0.0014765291183851564\n","\n","\tTesting: Initial condition loss: 0.02071668766438961\n","\tTesting: Boundary condition loss: 0.0012709617149084806\n","\tTesting: PDE loss: 0.016283055767416954\n","\tTesting: Data loss: 0.004658664111047983\n","\n","Epoch 483\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021831762045621872\n","\tBefore adaption: Boundary condition loss: 0.0013654195936396718\n","\tBefore adaption: PDE loss: 0.0162995345890522\n","\tBefore adaption: Data loss: 0.004662405699491501\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0447, 0.1965, 0.5043, 0.2544], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004290539099744062\n","\t\tAfter adaption: Boundary condition loss: 6.109258222918133e-05\n","\t\tAfter adaption: PDE loss: 0.00822030711497636\n","\t\tAfter adaption: Data loss: 0.001186124900691383\n","\n","\tTesting: Initial condition loss: 0.02680603414773941\n","\tTesting: Boundary condition loss: 0.0018907597986981273\n","\tTesting: PDE loss: 0.01556120254099369\n","\tTesting: Data loss: 0.005044927820563316\n","\n","Epoch 484\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02775341272354126\n","\tBefore adaption: Boundary condition loss: 0.0020120027475059032\n","\tBefore adaption: PDE loss: 0.015567026101052761\n","\tBefore adaption: Data loss: 0.005067854654043913\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0275, 0.2960, 0.4853, 0.1912], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008215137876276866\n","\t\tAfter adaption: Boundary condition loss: 5.529128254434376e-05\n","\t\tAfter adaption: PDE loss: 0.007554649246263022\n","\t\tAfter adaption: Data loss: 0.0009690561073024268\n","\n","\tTesting: Initial condition loss: 0.029735462740063667\n","\tTesting: Boundary condition loss: 0.002082565799355507\n","\tTesting: PDE loss: 0.015059705823659897\n","\tTesting: Data loss: 0.0053202370181679726\n","\n","Epoch 485\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030800918117165565\n","\tBefore adaption: Boundary condition loss: 0.002207648241892457\n","\tBefore adaption: PDE loss: 0.015056712552905083\n","\tBefore adaption: Data loss: 0.005351897329092026\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0250, 0.3993, 0.4323, 0.1435], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012297617470693701\n","\t\tAfter adaption: Boundary condition loss: 5.5187658967753274e-05\n","\t\tAfter adaption: PDE loss: 0.006508655451007545\n","\t\tAfter adaption: Data loss: 0.0007678043966537045\n","\n","\tTesting: Initial condition loss: 0.027835160493850708\n","\tTesting: Boundary condition loss: 0.0016933099832385778\n","\tTesting: PDE loss: 0.01495408359915018\n","\tTesting: Data loss: 0.005142369773238897\n","\n","Epoch 486\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029304197058081627\n","\tBefore adaption: Boundary condition loss: 0.0018011085921898484\n","\tBefore adaption: PDE loss: 0.014954962767660618\n","\tBefore adaption: Data loss: 0.005169743672013283\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0297, 0.4789, 0.3746, 0.1169], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014032441279594673\n","\t\tAfter adaption: Boundary condition loss: 5.341949075277566e-05\n","\t\tAfter adaption: PDE loss: 0.005601566966150711\n","\t\tAfter adaption: Data loss: 0.0006044661310535004\n","\n","\tTesting: Initial condition loss: 0.02146710641682148\n","\tTesting: Boundary condition loss: 0.0009167377720586956\n","\tTesting: PDE loss: 0.015345588326454163\n","\tTesting: Data loss: 0.004739365540444851\n","\n","Epoch 487\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023478884249925613\n","\tBefore adaption: Boundary condition loss: 0.0009859942365437746\n","\tBefore adaption: PDE loss: 0.015348809771239758\n","\tBefore adaption: Data loss: 0.004747261293232441\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0339, 0.5272, 0.3335, 0.1054], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012378798097026095\n","\t\tAfter adaption: Boundary condition loss: 3.3400844075144366e-05\n","\t\tAfter adaption: PDE loss: 0.005118242519961667\n","\t\tAfter adaption: Data loss: 0.0005005110627169657\n","\n","\tTesting: Initial condition loss: 0.013273620046675205\n","\tTesting: Boundary condition loss: 0.0003194001328665763\n","\tTesting: PDE loss: 0.016176655888557434\n","\tTesting: Data loss: 0.004893449600785971\n","\n","Epoch 488\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015686940401792526\n","\tBefore adaption: Boundary condition loss: 0.0003278082876931876\n","\tBefore adaption: PDE loss: 0.016186200082302094\n","\tBefore adaption: Data loss: 0.0048667388036847115\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0343, 0.5465, 0.3167, 0.1025], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008572333471583295\n","\t\tAfter adaption: Boundary condition loss: 1.1255693983875398e-05\n","\t\tAfter adaption: PDE loss: 0.005125823481444635\n","\t\tAfter adaption: Data loss: 0.0004989473373906958\n","\n","\tTesting: Initial condition loss: 0.006469290237873793\n","\tTesting: Boundary condition loss: 0.0005654183914884925\n","\tTesting: PDE loss: 0.017321700230240822\n","\tTesting: Data loss: 0.006457083392888308\n","\n","Epoch 489\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00884211529046297\n","\tBefore adaption: Boundary condition loss: 0.0004833939019590616\n","\tBefore adaption: PDE loss: 0.01733299531042576\n","\tBefore adaption: Data loss: 0.006382031366229057\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0310, 0.5368, 0.3257, 0.1065], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004746710914399292\n","\t\tAfter adaption: Boundary condition loss: 1.4977332728305012e-05\n","\t\tAfter adaption: PDE loss: 0.00564567304010286\n","\t\tAfter adaption: Data loss: 0.0006794823458671368\n","\n","\tTesting: Initial condition loss: 0.0031168677378445864\n","\tTesting: Boundary condition loss: 0.002045110799372196\n","\tTesting: PDE loss: 0.018564997240900993\n","\tTesting: Data loss: 0.009783021174371243\n","\n","Epoch 490\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005037372000515461\n","\tBefore adaption: Boundary condition loss: 0.0018513948889449239\n","\tBefore adaption: PDE loss: 0.018562806770205498\n","\tBefore adaption: Data loss: 0.00965319573879242\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0265, 0.4930, 0.3596, 0.1209], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0024833879107054356\n","\t\tAfter adaption: Boundary condition loss: 4.90090334398075e-05\n","\t\tAfter adaption: PDE loss: 0.006675732048878179\n","\t\tAfter adaption: Data loss: 0.0011671307475997336\n","\n","\tTesting: Initial condition loss: 0.0032397538889199495\n","\tTesting: Boundary condition loss: 0.004612084943801165\n","\tTesting: PDE loss: 0.01965898461639881\n","\tTesting: Data loss: 0.01438838616013527\n","\n","Epoch 491\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004458453506231308\n","\tBefore adaption: Boundary condition loss: 0.004290001466870308\n","\tBefore adaption: PDE loss: 0.019643057137727737\n","\tBefore adaption: Data loss: 0.014207202941179276\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0271, 0.4096, 0.4099, 0.1533], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018261924149290786\n","\t\tAfter adaption: Boundary condition loss: 0.00011632257426803077\n","\t\tAfter adaption: PDE loss: 0.008052454227865097\n","\t\tAfter adaption: Data loss: 0.0021785861956442115\n","\n","\tTesting: Initial condition loss: 0.005276756826788187\n","\tTesting: Boundary condition loss: 0.007610863074660301\n","\tTesting: PDE loss: 0.020401878282427788\n","\tTesting: Data loss: 0.019198141992092133\n","\n","Epoch 492\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005718640051782131\n","\tBefore adaption: Boundary condition loss: 0.007145801559090614\n","\tBefore adaption: PDE loss: 0.020393408834934235\n","\tBefore adaption: Data loss: 0.018977012485265732\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0413, 0.2988, 0.4527, 0.2072], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017085250806904483\n","\t\tAfter adaption: Boundary condition loss: 0.0002949172234350041\n","\t\tAfter adaption: PDE loss: 0.009233033775522514\n","\t\tAfter adaption: Data loss: 0.003932381193019596\n","\n","\tTesting: Initial condition loss: 0.007270126137882471\n","\tTesting: Boundary condition loss: 0.009980659931898117\n","\tTesting: PDE loss: 0.020750224590301514\n","\tTesting: Data loss: 0.022986475378274918\n","\n","Epoch 493\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007146754767745733\n","\tBefore adaption: Boundary condition loss: 0.009405073709785938\n","\tBefore adaption: PDE loss: 0.02073156274855137\n","\tBefore adaption: Data loss: 0.02273561619222164\n","tensor(0.0094, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0094, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0705, 0.1985, 0.4606, 0.2704], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001418868485089208\n","\t\tAfter adaption: Boundary condition loss: 0.0006628670554924837\n","\t\tAfter adaption: PDE loss: 0.009548459287639819\n","\t\tAfter adaption: Data loss: 0.006147956422521842\n","\n","\tTesting: Initial condition loss: 0.007890342734754086\n","\tTesting: Boundary condition loss: 0.010811734944581985\n","\tTesting: PDE loss: 0.020735152065753937\n","\tTesting: Data loss: 0.024678662419319153\n","\n","Epoch 494\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0075622862204909325\n","\tBefore adaption: Boundary condition loss: 0.010203775949776173\n","\tBefore adaption: PDE loss: 0.020720211789011955\n","\tBefore adaption: Data loss: 0.024413898587226868\n","tensor(0.0102, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0102, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1039, 0.1398, 0.4335, 0.3227], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010574936084770104\n","\t\tAfter adaption: Boundary condition loss: 0.0010604730641541275\n","\t\tAfter adaption: PDE loss: 0.008982288893930962\n","\t\tAfter adaption: Data loss: 0.007879067297785602\n","\n","\tTesting: Initial condition loss: 0.006801059935241938\n","\tTesting: Boundary condition loss: 0.009748206473886967\n","\tTesting: PDE loss: 0.02047298476099968\n","\tTesting: Data loss: 0.02376369573175907\n","\n","Epoch 495\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006642626132816076\n","\tBefore adaption: Boundary condition loss: 0.009202155284583569\n","\tBefore adaption: PDE loss: 0.02044650726020336\n","\tBefore adaption: Data loss: 0.023504581302404404\n","tensor(0.0092, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0092, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1301, 0.1183, 0.3957, 0.3560], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007857788967322058\n","\t\tAfter adaption: Boundary condition loss: 0.0011971718588349878\n","\t\tAfter adaption: PDE loss: 0.008089742615839723\n","\t\tAfter adaption: Data loss: 0.008366584582819712\n","\n","\tTesting: Initial condition loss: 0.004613135941326618\n","\tTesting: Boundary condition loss: 0.007277167867869139\n","\tTesting: PDE loss: 0.02002692222595215\n","\tTesting: Data loss: 0.020563121885061264\n","\n","Epoch 496\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00492530781775713\n","\tBefore adaption: Boundary condition loss: 0.006846098694950342\n","\tBefore adaption: PDE loss: 0.0200064554810524\n","\tBefore adaption: Data loss: 0.020327886566519737\n","tensor(0.0068, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0068, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1450, 0.1136, 0.3672, 0.3742], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005593873089770772\n","\t\tAfter adaption: Boundary condition loss: 0.0009927526108901737\n","\t\tAfter adaption: PDE loss: 0.007346529873716582\n","\t\tAfter adaption: Data loss: 0.007606853585515794\n","\n","\tTesting: Initial condition loss: 0.002585049020126462\n","\tTesting: Boundary condition loss: 0.004401798825711012\n","\tTesting: PDE loss: 0.019488027319312096\n","\tTesting: Data loss: 0.01608196087181568\n","\n","Epoch 497\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003504529595375061\n","\tBefore adaption: Boundary condition loss: 0.004096253775060177\n","\tBefore adaption: PDE loss: 0.019453035667538643\n","\tBefore adaption: Data loss: 0.01588505506515503\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1491, 0.1115, 0.3563, 0.3831], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003905861864084965\n","\t\tAfter adaption: Boundary condition loss: 0.0006108058800798448\n","\t\tAfter adaption: PDE loss: 0.00693115021691525\n","\t\tAfter adaption: Data loss: 0.006086088670767278\n","\n","\tTesting: Initial condition loss: 0.0020738306920975447\n","\tTesting: Boundary condition loss: 0.0020387712866067886\n","\tTesting: PDE loss: 0.018892496824264526\n","\tTesting: Data loss: 0.011538772843778133\n","\n","Epoch 498\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0035062574315816164\n","\tBefore adaption: Boundary condition loss: 0.0018423352157697082\n","\tBefore adaption: PDE loss: 0.018845172598958015\n","\tBefore adaption: Data loss: 0.011387749575078487\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1431, 0.1072, 0.3649, 0.3848], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003759264182254448\n","\t\tAfter adaption: Boundary condition loss: 0.00026368217271411883\n","\t\tAfter adaption: PDE loss: 0.006875873363579672\n","\t\tAfter adaption: Data loss: 0.004381992540492366\n","\n","\tTesting: Initial condition loss: 0.003915191162377596\n","\tTesting: Boundary condition loss: 0.0006558565655723214\n","\tTesting: PDE loss: 0.018260391429066658\n","\tTesting: Data loss: 0.00788904819637537\n","\n","Epoch 499\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005641508381813765\n","\tBefore adaption: Boundary condition loss: 0.0005569319473579526\n","\tBefore adaption: PDE loss: 0.01822992041707039\n","\tBefore adaption: Data loss: 0.007785364054143429\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1271, 0.1032, 0.3927, 0.3771], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005821467626458513\n","\t\tAfter adaption: Boundary condition loss: 7.077079744280174e-05\n","\t\tAfter adaption: PDE loss: 0.007158094042581504\n","\t\tAfter adaption: Data loss: 0.002935712278714275\n","\n","\tTesting: Initial condition loss: 0.008208555169403553\n","\tTesting: Boundary condition loss: 0.00030443843570537865\n","\tTesting: PDE loss: 0.01761920005083084\n","\tTesting: Data loss: 0.005589203909039497\n","\n","Epoch 500\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009952859953045845\n","\tBefore adaption: Boundary condition loss: 0.0002913656644523144\n","\tBefore adaption: PDE loss: 0.01760183461010456\n","\tBefore adaption: Data loss: 0.005529075860977173\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1013, 0.1088, 0.4356, 0.3543], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010827395921604822\n","\t\tAfter adaption: Boundary condition loss: 2.950167552832732e-05\n","\t\tAfter adaption: PDE loss: 0.007668093137164105\n","\t\tAfter adaption: Data loss: 0.001959052206136849\n","\n","\tTesting: Initial condition loss: 0.014285258017480373\n","\tTesting: Boundary condition loss: 0.0006863237358629704\n","\tTesting: PDE loss: 0.016937172040343285\n","\tTesting: Data loss: 0.004612790886312723\n","\n","Epoch 501\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01597585342824459\n","\tBefore adaption: Boundary condition loss: 0.0007420314941555262\n","\tBefore adaption: PDE loss: 0.016909614205360413\n","\tBefore adaption: Data loss: 0.004588339943438768\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0695, 0.1403, 0.4798, 0.3104], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022415734930893187\n","\t\tAfter adaption: Boundary condition loss: 5.155192873915909e-05\n","\t\tAfter adaption: PDE loss: 0.00811372285573972\n","\t\tAfter adaption: Data loss: 0.0014241593816032752\n","\n","\tTesting: Initial condition loss: 0.0210369061678648\n","\tTesting: Boundary condition loss: 0.0013908392284065485\n","\tTesting: PDE loss: 0.016217326745390892\n","\tTesting: Data loss: 0.00459258584305644\n","\n","Epoch 502\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022554347291588783\n","\tBefore adaption: Boundary condition loss: 0.0014939535176381469\n","\tBefore adaption: PDE loss: 0.01620696298778057\n","\tBefore adaption: Data loss: 0.00459476700052619\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0413, 0.2116, 0.4994, 0.2477], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004773023759945585\n","\t\tAfter adaption: Boundary condition loss: 6.168579590817859e-05\n","\t\tAfter adaption: PDE loss: 0.008093490540855567\n","\t\tAfter adaption: Data loss: 0.0011381359826144633\n","\n","\tTesting: Initial condition loss: 0.02667517215013504\n","\tTesting: Boundary condition loss: 0.0019719477277249098\n","\tTesting: PDE loss: 0.015571927651762962\n","\tTesting: Data loss: 0.004974736366420984\n","\n","Epoch 503\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028110932558774948\n","\tBefore adaption: Boundary condition loss: 0.0021000823471695185\n","\tBefore adaption: PDE loss: 0.0155599694699049\n","\tBefore adaption: Data loss: 0.00499417120590806\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0267, 0.3129, 0.4765, 0.1839], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008795001534645802\n","\t\tAfter adaption: Boundary condition loss: 5.615179440122672e-05\n","\t\tAfter adaption: PDE loss: 0.007414849777337424\n","\t\tAfter adaption: Data loss: 0.0009182306941650426\n","\n","\tTesting: Initial condition loss: 0.02901359274983406\n","\tTesting: Boundary condition loss: 0.0021092272363603115\n","\tTesting: PDE loss: 0.015191508457064629\n","\tTesting: Data loss: 0.005186928901821375\n","\n","Epoch 504\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03054114803671837\n","\tBefore adaption: Boundary condition loss: 0.0022406571079045534\n","\tBefore adaption: PDE loss: 0.015167320147156715\n","\tBefore adaption: Data loss: 0.0052136811427772045\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0260, 0.4125, 0.4237, 0.1378], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012597565167473878\n","\t\tAfter adaption: Boundary condition loss: 5.824279416129038e-05\n","\t\tAfter adaption: PDE loss: 0.00642668456428811\n","\t\tAfter adaption: Data loss: 0.0007184895654904891\n","\n","\tTesting: Initial condition loss: 0.026662034913897514\n","\tTesting: Boundary condition loss: 0.001690124860033393\n","\tTesting: PDE loss: 0.01520195510238409\n","\tTesting: Data loss: 0.004942949861288071\n","\n","Epoch 505\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028466353192925453\n","\tBefore adaption: Boundary condition loss: 0.0018052199156954885\n","\tBefore adaption: PDE loss: 0.015193385072052479\n","\tBefore adaption: Data loss: 0.004965369589626789\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0312, 0.4863, 0.3695, 0.1130], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013843678921706203\n","\t\tAfter adaption: Boundary condition loss: 5.625053061255623e-05\n","\t\tAfter adaption: PDE loss: 0.0056136808904446635\n","\t\tAfter adaption: Data loss: 0.000561288716926616\n","\n","\tTesting: Initial condition loss: 0.020214855670928955\n","\tTesting: Boundary condition loss: 0.0009231476578861475\n","\tTesting: PDE loss: 0.01572412997484207\n","\tTesting: Data loss: 0.004519815556704998\n","\n","Epoch 506\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022349342703819275\n","\tBefore adaption: Boundary condition loss: 0.0009955938439816236\n","\tBefore adaption: PDE loss: 0.015702687203884125\n","\tBefore adaption: Data loss: 0.0045248037204146385\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0353, 0.5294, 0.3328, 0.1025], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01183136551992086\n","\t\tAfter adaption: Boundary condition loss: 3.5139751375033525e-05\n","\t\tAfter adaption: PDE loss: 0.005225407105832206\n","\t\tAfter adaption: Data loss: 0.00046401792877583857\n","\n","\tTesting: Initial condition loss: 0.01220991276204586\n","\tTesting: Boundary condition loss: 0.0003572063578758389\n","\tTesting: PDE loss: 0.016674654558300972\n","\tTesting: Data loss: 0.004694389179348946\n","\n","Epoch 507\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014646594412624836\n","\tBefore adaption: Boundary condition loss: 0.00036226349766366184\n","\tBefore adaption: PDE loss: 0.016642393544316292\n","\tBefore adaption: Data loss: 0.004668311215937138\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0356, 0.5440, 0.3205, 0.1000], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007967082243702106\n","\t\tAfter adaption: Boundary condition loss: 1.288221256552922e-05\n","\t\tAfter adaption: PDE loss: 0.005333117596629452\n","\t\tAfter adaption: Data loss: 0.0004669763341525043\n","\n","\tTesting: Initial condition loss: 0.005831788759678602\n","\tTesting: Boundary condition loss: 0.0006139430915936828\n","\tTesting: PDE loss: 0.017873920500278473\n","\tTesting: Data loss: 0.006266757380217314\n","\n","Epoch 508\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008165597915649414\n","\tBefore adaption: Boundary condition loss: 0.0005225866916589439\n","\tBefore adaption: PDE loss: 0.017853418365120888\n","\tBefore adaption: Data loss: 0.006197001319378614\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0320, 0.5300, 0.3340, 0.1040], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004327369184796536\n","\t\tAfter adaption: Boundary condition loss: 1.67372376503176e-05\n","\t\tAfter adaption: PDE loss: 0.005963410718006522\n","\t\tAfter adaption: Data loss: 0.0006444890539194704\n","\n","\tTesting: Initial condition loss: 0.0028922909405082464\n","\tTesting: Boundary condition loss: 0.0020020201336592436\n","\tTesting: PDE loss: 0.019105669111013412\n","\tTesting: Data loss: 0.009515173733234406\n","\n","Epoch 509\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004732217639684677\n","\tBefore adaption: Boundary condition loss: 0.0018016473622992635\n","\tBefore adaption: PDE loss: 0.019080644473433495\n","\tBefore adaption: Data loss: 0.009395157918334007\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0274, 0.4818, 0.3726, 0.1183], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002279912096507993\n","\t\tAfter adaption: Boundary condition loss: 4.937836599038646e-05\n","\t\tAfter adaption: PDE loss: 0.007108606804416943\n","\t\tAfter adaption: Data loss: 0.0011109904680376992\n","\n","\tTesting: Initial condition loss: 0.003202103078365326\n","\tTesting: Boundary condition loss: 0.004339166916906834\n","\tTesting: PDE loss: 0.020148223266005516\n","\tTesting: Data loss: 0.013976424932479858\n","\n","Epoch 510\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004298605024814606\n","\tBefore adaption: Boundary condition loss: 0.0040291384793818\n","\tBefore adaption: PDE loss: 0.020115453749895096\n","\tBefore adaption: Data loss: 0.013806807808578014\n","tensor(0.0040, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0040, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0277, 0.3955, 0.4266, 0.1502], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001700167619011725\n","\t\tAfter adaption: Boundary condition loss: 0.000111633356904778\n","\t\tAfter adaption: PDE loss: 0.008580368252687777\n","\t\tAfter adaption: Data loss: 0.0020740734817377366\n","\n","\tTesting: Initial condition loss: 0.005178561434149742\n","\tTesting: Boundary condition loss: 0.007009298074990511\n","\tTesting: PDE loss: 0.020821068435907364\n","\tTesting: Data loss: 0.018634889274835587\n","\n","Epoch 511\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005530809983611107\n","\tBefore adaption: Boundary condition loss: 0.006595166865736246\n","\tBefore adaption: PDE loss: 0.020771978422999382\n","\tBefore adaption: Data loss: 0.018421994522213936\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0406, 0.2852, 0.4709, 0.2033], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015775700689876597\n","\t\tAfter adaption: Boundary condition loss: 0.00026784954374698295\n","\t\tAfter adaption: PDE loss: 0.009781287571103695\n","\t\tAfter adaption: Data loss: 0.0037445475669161737\n","\n","\tTesting: Initial condition loss: 0.0070238905027508736\n","\tTesting: Boundary condition loss: 0.009156054817140102\n","\tTesting: PDE loss: 0.021087680011987686\n","\tTesting: Data loss: 0.022331641986966133\n","\n","Epoch 512\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0068614548072218895\n","\tBefore adaption: Boundary condition loss: 0.008658399805426598\n","\tBefore adaption: PDE loss: 0.021023692563176155\n","\tBefore adaption: Data loss: 0.022087395191192627\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0674, 0.1890, 0.4781, 0.2656], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012966186510362018\n","\t\tAfter adaption: Boundary condition loss: 0.0005831627181870056\n","\t\tAfter adaption: PDE loss: 0.010050475965546445\n","\t\tAfter adaption: Data loss: 0.005866883994698891\n","\n","\tTesting: Initial condition loss: 0.007565620820969343\n","\tTesting: Boundary condition loss: 0.009956576861441135\n","\tTesting: PDE loss: 0.02097318135201931\n","\tTesting: Data loss: 0.0241044033318758\n","\n","Epoch 513\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0072256773710250854\n","\tBefore adaption: Boundary condition loss: 0.009441629983484745\n","\tBefore adaption: PDE loss: 0.020918821915984154\n","\tBefore adaption: Data loss: 0.023845000192523003\n","tensor(0.0094, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0094, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0982, 0.1344, 0.4494, 0.3179], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009714570085379179\n","\t\tAfter adaption: Boundary condition loss: 0.0009275113621691279\n","\t\tAfter adaption: PDE loss: 0.009401478587158034\n","\t\tAfter adaption: Data loss: 0.007580123567821845\n","\n","\tTesting: Initial condition loss: 0.0065198359079658985\n","\tTesting: Boundary condition loss: 0.009090947918593884\n","\tTesting: PDE loss: 0.020614100620150566\n","\tTesting: Data loss: 0.023473303765058517\n","\n","Epoch 514\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006347569637000561\n","\tBefore adaption: Boundary condition loss: 0.008634915575385094\n","\tBefore adaption: PDE loss: 0.020558131858706474\n","\tBefore adaption: Data loss: 0.023217305541038513\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0086, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1228, 0.1152, 0.4098, 0.3522], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007310982795540042\n","\t\tAfter adaption: Boundary condition loss: 0.001060107321853185\n","\t\tAfter adaption: PDE loss: 0.008425592991320684\n","\t\tAfter adaption: Data loss: 0.008177365544200722\n","\n","\tTesting: Initial condition loss: 0.004427667241543531\n","\tTesting: Boundary condition loss: 0.006968829780817032\n","\tTesting: PDE loss: 0.020057860761880875\n","\tTesting: Data loss: 0.020665228366851807\n","\n","Epoch 515\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00472272140905261\n","\tBefore adaption: Boundary condition loss: 0.0066048516891896725\n","\tBefore adaption: PDE loss: 0.02001376822590828\n","\tBefore adaption: Data loss: 0.02043061889708042\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1372, 0.1111, 0.3795, 0.3723], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005246257454135216\n","\t\tAfter adaption: Boundary condition loss: 0.0009058767509844552\n","\t\tAfter adaption: PDE loss: 0.007595189668785171\n","\t\tAfter adaption: Data loss: 0.007605561005967708\n","\n","\tTesting: Initial condition loss: 0.002484896220266819\n","\tTesting: Boundary condition loss: 0.004404324572533369\n","\tTesting: PDE loss: 0.019404994323849678\n","\tTesting: Data loss: 0.016540296375751495\n","\n","Epoch 516\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003357252571731806\n","\tBefore adaption: Boundary condition loss: 0.004132733214646578\n","\tBefore adaption: PDE loss: 0.019359292462468147\n","\tBefore adaption: Data loss: 0.016340285539627075\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1417, 0.1088, 0.3663, 0.3832], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000365433083673167\n","\t\tAfter adaption: Boundary condition loss: 0.000585439168817158\n","\t\tAfter adaption: PDE loss: 0.007091507837522869\n","\t\tAfter adaption: Data loss: 0.006261297021867878\n","\n","\tTesting: Initial condition loss: 0.0019910470582544804\n","\tTesting: Boundary condition loss: 0.0021874941885471344\n","\tTesting: PDE loss: 0.018706537783145905\n","\tTesting: Data loss: 0.012194635346531868\n","\n","Epoch 517\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00331538962200284\n","\tBefore adaption: Boundary condition loss: 0.002001507207751274\n","\tBefore adaption: PDE loss: 0.01865563727915287\n","\tBefore adaption: Data loss: 0.012037031352519989\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1369, 0.1041, 0.3720, 0.3869], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000345286947610263\n","\t\tAfter adaption: Boundary condition loss: 0.0002739506073313254\n","\t\tAfter adaption: PDE loss: 0.006940758796041526\n","\t\tAfter adaption: Data loss: 0.004657545739878094\n","\n","\tTesting: Initial condition loss: 0.0037927667144685984\n","\tTesting: Boundary condition loss: 0.0007681892602704465\n","\tTesting: PDE loss: 0.01799064874649048\n","\tTesting: Data loss: 0.008548041805624962\n","\n","Epoch 518\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005290791392326355\n","\tBefore adaption: Boundary condition loss: 0.0006664453539997339\n","\tBefore adaption: PDE loss: 0.017944158986210823\n","\tBefore adaption: Data loss: 0.00843468215316534\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1227, 0.0994, 0.3962, 0.3817], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005259562170507246\n","\t\tAfter adaption: Boundary condition loss: 8.176756302227074e-05\n","\t\tAfter adaption: PDE loss: 0.007108908611927326\n","\t\tAfter adaption: Data loss: 0.0032197677646427147\n","\n","\tTesting: Initial condition loss: 0.008029461838304996\n","\tTesting: Boundary condition loss: 0.0002677499724086374\n","\tTesting: PDE loss: 0.017242886126041412\n","\tTesting: Data loss: 0.006102950312197208\n","\n","Epoch 519\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00945349596440792\n","\tBefore adaption: Boundary condition loss: 0.00024162689805962145\n","\tBefore adaption: PDE loss: 0.017221294343471527\n","\tBefore adaption: Data loss: 0.006031595170497894\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0992, 0.1037, 0.4347, 0.3623], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009805451544421776\n","\t\tAfter adaption: Boundary condition loss: 2.3981142519152407e-05\n","\t\tAfter adaption: PDE loss: 0.00748652293838584\n","\t\tAfter adaption: Data loss: 0.0021852671648101875\n","\n","\tTesting: Initial condition loss: 0.014086950570344925\n","\tTesting: Boundary condition loss: 0.00045937966206111014\n","\tTesting: PDE loss: 0.016502100974321365\n","\tTesting: Data loss: 0.004915609490126371\n","\n","Epoch 520\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015363315120339394\n","\tBefore adaption: Boundary condition loss: 0.0004971195594407618\n","\tBefore adaption: PDE loss: 0.01647195778787136\n","\tBefore adaption: Data loss: 0.00488008139654994\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0695, 0.1332, 0.4749, 0.3224], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020463059693041578\n","\t\tAfter adaption: Boundary condition loss: 3.4566626261397884e-05\n","\t\tAfter adaption: PDE loss: 0.007822864462434685\n","\t\tAfter adaption: Data loss: 0.0015731014653742664\n","\n","\tTesting: Initial condition loss: 0.020918121561408043\n","\tTesting: Boundary condition loss: 0.001013090368360281\n","\tTesting: PDE loss: 0.01575712114572525\n","\tTesting: Data loss: 0.004710962064564228\n","\n","Epoch 521\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022027630358934402\n","\tBefore adaption: Boundary condition loss: 0.0010979755315929651\n","\tBefore adaption: PDE loss: 0.015725089237093925\n","\tBefore adaption: Data loss: 0.00470288610085845\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0415, 0.2024, 0.4935, 0.2626], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004459413263676263\n","\t\tAfter adaption: Boundary condition loss: 4.555737611948698e-05\n","\t\tAfter adaption: PDE loss: 0.0077599023727356765\n","\t\tAfter adaption: Data loss: 0.0012349238608420565\n","\n","\tTesting: Initial condition loss: 0.026811111718416214\n","\tTesting: Boundary condition loss: 0.0015354498755186796\n","\tTesting: PDE loss: 0.015098066069185734\n","\tTesting: Data loss: 0.0049965474754571915\n","\n","Epoch 522\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027841750532388687\n","\tBefore adaption: Boundary condition loss: 0.0016459976322948933\n","\tBefore adaption: PDE loss: 0.015066291205585003\n","\tBefore adaption: Data loss: 0.005006786435842514\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0247, 0.3046, 0.4725, 0.1981], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008481398124302908\n","\t\tAfter adaption: Boundary condition loss: 4.0722954493302695e-05\n","\t\tAfter adaption: PDE loss: 0.007118551319364434\n","\t\tAfter adaption: Data loss: 0.000992086586218327\n","\n","\tTesting: Initial condition loss: 0.029541419818997383\n","\tTesting: Boundary condition loss: 0.0017142462311312556\n","\tTesting: PDE loss: 0.014698144048452377\n","\tTesting: Data loss: 0.005214225500822067\n","\n","Epoch 523\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030736127868294716\n","\tBefore adaption: Boundary condition loss: 0.0018311274470761418\n","\tBefore adaption: PDE loss: 0.01466398872435093\n","\tBefore adaption: Data loss: 0.005232572089880705\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0212, 0.4090, 0.4213, 0.1485], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012569972587239058\n","\t\tAfter adaption: Boundary condition loss: 3.883532805313805e-05\n","\t\tAfter adaption: PDE loss: 0.006178529537334232\n","\t\tAfter adaption: Data loss: 0.0007769685151281663\n","\n","\tTesting: Initial condition loss: 0.027601659297943115\n","\tTesting: Boundary condition loss: 0.0014267130754888058\n","\tTesting: PDE loss: 0.01471465453505516\n","\tTesting: Data loss: 0.005032471846789122\n","\n","Epoch 524\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029163623228669167\n","\tBefore adaption: Boundary condition loss: 0.001529499888420105\n","\tBefore adaption: PDE loss: 0.0146784083917737\n","\tBefore adaption: Data loss: 0.005046987906098366\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0246, 0.4888, 0.3668, 0.1198], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014255439947813402\n","\t\tAfter adaption: Boundary condition loss: 3.7665166120216113e-05\n","\t\tAfter adaption: PDE loss: 0.00538362173594194\n","\t\tAfter adaption: Data loss: 0.0006045964730705828\n","\n","\tTesting: Initial condition loss: 0.021336406469345093\n","\tTesting: Boundary condition loss: 0.0008163124439306557\n","\tTesting: PDE loss: 0.015237233601510525\n","\tTesting: Data loss: 0.004648575093597174\n","\n","Epoch 525\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023337610065937042\n","\tBefore adaption: Boundary condition loss: 0.000884561741258949\n","\tBefore adaption: PDE loss: 0.015193003229796886\n","\tBefore adaption: Data loss: 0.00464697415009141\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0283, 0.5367, 0.3284, 0.1066], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012526207132149364\n","\t\tAfter adaption: Boundary condition loss: 2.503381208632123e-05\n","\t\tAfter adaption: PDE loss: 0.004988777088636985\n","\t\tAfter adaption: Data loss: 0.0004953662330384806\n","\n","\tTesting: Initial condition loss: 0.01319900806993246\n","\tTesting: Boundary condition loss: 0.0003515696444083005\n","\tTesting: PDE loss: 0.01620960794389248\n","\tTesting: Data loss: 0.004778000526130199\n","\n","Epoch 526\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015543453395366669\n","\tBefore adaption: Boundary condition loss: 0.00035606740857474506\n","\tBefore adaption: PDE loss: 0.016157614067196846\n","\tBefore adaption: Data loss: 0.004747557919472456\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0291, 0.5546, 0.3137, 0.1026], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008621054637807839\n","\t\tAfter adaption: Boundary condition loss: 1.0363890337611958e-05\n","\t\tAfter adaption: PDE loss: 0.005067970637368932\n","\t\tAfter adaption: Data loss: 0.0004870649397024255\n","\n","\tTesting: Initial condition loss: 0.006407381501048803\n","\tTesting: Boundary condition loss: 0.0006088432855904102\n","\tTesting: PDE loss: 0.017461514100432396\n","\tTesting: Data loss: 0.0062317149713635445\n","\n","Epoch 527\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008747954852879047\n","\tBefore adaption: Boundary condition loss: 0.0005185228073969483\n","\tBefore adaption: PDE loss: 0.017425114288926125\n","\tBefore adaption: Data loss: 0.006162279285490513\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0268, 0.5428, 0.3246, 0.1058], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004748787367036064\n","\t\tAfter adaption: Boundary condition loss: 1.388149048396042e-05\n","\t\tAfter adaption: PDE loss: 0.005656523091864007\n","\t\tAfter adaption: Data loss: 0.0006517481064906881\n","\n","\tTesting: Initial condition loss: 0.0030416748486459255\n","\tTesting: Boundary condition loss: 0.0019353472162038088\n","\tTesting: PDE loss: 0.01877388171851635\n","\tTesting: Data loss: 0.009352082386612892\n","\n","Epoch 528\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004951088689267635\n","\tBefore adaption: Boundary condition loss: 0.0017241757595911622\n","\tBefore adaption: PDE loss: 0.018739134073257446\n","\tBefore adaption: Data loss: 0.009238437749445438\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0236, 0.4965, 0.3606, 0.1193], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002458038317297051\n","\t\tAfter adaption: Boundary condition loss: 4.075172965543461e-05\n","\t\tAfter adaption: PDE loss: 0.00675779412041307\n","\t\tAfter adaption: Data loss: 0.0011019183932879394\n","\n","\tTesting: Initial condition loss: 0.0031142120715230703\n","\tTesting: Boundary condition loss: 0.0042566112242639065\n","\tTesting: PDE loss: 0.01990036852657795\n","\tTesting: Data loss: 0.013732661493122578\n","\n","Epoch 529\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0042720152996480465\n","\tBefore adaption: Boundary condition loss: 0.00391189893707633\n","\tBefore adaption: PDE loss: 0.019869575276970863\n","\tBefore adaption: Data loss: 0.013575534336268902\n","tensor(0.0039, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0039, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0252, 0.4111, 0.4135, 0.1501], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017562775114421806\n","\t\tAfter adaption: Boundary condition loss: 9.865368467493965e-05\n","\t\tAfter adaption: PDE loss: 0.008216733532138339\n","\t\tAfter adaption: Data loss: 0.0020381665375617717\n","\n","\tTesting: Initial condition loss: 0.0050721182487905025\n","\tTesting: Boundary condition loss: 0.006982758641242981\n","\tTesting: PDE loss: 0.020674407482147217\n","\tTesting: Data loss: 0.018384814262390137\n","\n","Epoch 530\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005443149246275425\n","\tBefore adaption: Boundary condition loss: 0.0065049780532717705\n","\tBefore adaption: PDE loss: 0.02062467858195305\n","\tBefore adaption: Data loss: 0.018188660964369774\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0389, 0.2991, 0.4600, 0.2020], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001627827604740468\n","\t\tAfter adaption: Boundary condition loss: 0.00025321605466888797\n","\t\tAfter adaption: PDE loss: 0.00948800551495886\n","\t\tAfter adaption: Data loss: 0.00367377603764817\n","\n","\tTesting: Initial condition loss: 0.007045765407383442\n","\tTesting: Boundary condition loss: 0.009264152497053146\n","\tTesting: PDE loss: 0.0210120789706707\n","\tTesting: Data loss: 0.02215399220585823\n","\n","Epoch 531\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006837834604084492\n","\tBefore adaption: Boundary condition loss: 0.008668470196425915\n","\tBefore adaption: PDE loss: 0.0209758672863245\n","\tBefore adaption: Data loss: 0.02192864939570427\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0087, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0662, 0.1979, 0.4720, 0.2640], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013533106695611905\n","\t\tAfter adaption: Boundary condition loss: 0.0005736232153996994\n","\t\tAfter adaption: PDE loss: 0.009899724428166196\n","\t\tAfter adaption: Data loss: 0.005788139760740967\n","\n","\tTesting: Initial condition loss: 0.007774248719215393\n","\tTesting: Boundary condition loss: 0.010220584459602833\n","\tTesting: PDE loss: 0.020993493497371674\n","\tTesting: Data loss: 0.024066690355539322\n","\n","Epoch 532\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007354373577982187\n","\tBefore adaption: Boundary condition loss: 0.00958956964313984\n","\tBefore adaption: PDE loss: 0.020958993583917618\n","\tBefore adaption: Data loss: 0.02382691390812397\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0977, 0.1385, 0.4473, 0.3165], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00101849839079076\n","\t\tAfter adaption: Boundary condition loss: 0.0009368771815067137\n","\t\tAfter adaption: PDE loss: 0.009374252736614873\n","\t\tAfter adaption: Data loss: 0.007542340234958116\n","\n","\tTesting: Initial condition loss: 0.0068841311149299145\n","\tTesting: Boundary condition loss: 0.009481774643063545\n","\tTesting: PDE loss: 0.020715661346912384\n","\tTesting: Data loss: 0.023604827001690865\n","\n","Epoch 533\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006613119505345821\n","\tBefore adaption: Boundary condition loss: 0.008906972594559193\n","\tBefore adaption: PDE loss: 0.020678207278251648\n","\tBefore adaption: Data loss: 0.023367246612906456\n","tensor(0.0089, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0089, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1230, 0.1167, 0.4093, 0.3511], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007717598186084714\n","\t\tAfter adaption: Boundary condition loss: 0.0010953835647850843\n","\t\tAfter adaption: PDE loss: 0.008462814323801776\n","\t\tAfter adaption: Data loss: 0.008203201307619099\n","\n","\tTesting: Initial condition loss: 0.004849037155508995\n","\tTesting: Boundary condition loss: 0.007375235669314861\n","\tTesting: PDE loss: 0.020254747942090034\n","\tTesting: Data loss: 0.02094118669629097\n","\n","Epoch 534\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0050156740471720695\n","\tBefore adaption: Boundary condition loss: 0.00691833533346653\n","\tBefore adaption: PDE loss: 0.020217571407556534\n","\tBefore adaption: Data loss: 0.020721537992358208\n","tensor(0.0069, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0069, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1381, 0.1121, 0.3789, 0.3709], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005624872186262576\n","\t\tAfter adaption: Boundary condition loss: 0.0009555538328502661\n","\t\tAfter adaption: PDE loss: 0.007660012400205366\n","\t\tAfter adaption: Data loss: 0.007684705245891224\n","\n","\tTesting: Initial condition loss: 0.00276931026019156\n","\tTesting: Boundary condition loss: 0.004779541864991188\n","\tTesting: PDE loss: 0.01968931220471859\n","\tTesting: Data loss: 0.01688265986740589\n","\n","Epoch 535\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0035032492596656084\n","\tBefore adaption: Boundary condition loss: 0.004435388371348381\n","\tBefore adaption: PDE loss: 0.019642658531665802\n","\tBefore adaption: Data loss: 0.016694415360689163\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1433, 0.1103, 0.3651, 0.3814], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003865188971130128\n","\t\tAfter adaption: Boundary condition loss: 0.000635372956709924\n","\t\tAfter adaption: PDE loss: 0.007170764532333263\n","\t\tAfter adaption: Data loss: 0.006366526819568936\n","\n","\tTesting: Initial condition loss: 0.001906860270537436\n","\tTesting: Boundary condition loss: 0.0024630839470773935\n","\tTesting: PDE loss: 0.01906580477952957\n","\tTesting: Data loss: 0.012509072199463844\n","\n","Epoch 536\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003152300138026476\n","\tBefore adaption: Boundary condition loss: 0.002229925710707903\n","\tBefore adaption: PDE loss: 0.019009865820407867\n","\tBefore adaption: Data loss: 0.012358392588794231\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1391, 0.1059, 0.3701, 0.3849], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000333875119637625\n","\t\tAfter adaption: Boundary condition loss: 0.0003102528715632632\n","\t\tAfter adaption: PDE loss: 0.0070351930785846\n","\t\tAfter adaption: Data loss: 0.00475640446312689\n","\n","\tTesting: Initial condition loss: 0.0032151443883776665\n","\tTesting: Boundary condition loss: 0.0009450580109842122\n","\tTesting: PDE loss: 0.018419982865452766\n","\tTesting: Data loss: 0.008752175606787205\n","\n","Epoch 537\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00471074040979147\n","\tBefore adaption: Boundary condition loss: 0.0008204339537769556\n","\tBefore adaption: PDE loss: 0.018347257748246193\n","\tBefore adaption: Data loss: 0.008640834130346775\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1257, 0.1005, 0.3938, 0.3800], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004732603363425574\n","\t\tAfter adaption: Boundary condition loss: 0.0001031353608963399\n","\t\tAfter adaption: PDE loss: 0.007225661558189634\n","\t\tAfter adaption: Data loss: 0.0032835127779144747\n","\n","\tTesting: Initial condition loss: 0.006888456642627716\n","\tTesting: Boundary condition loss: 0.00033520610304549336\n","\tTesting: PDE loss: 0.017751365900039673\n","\tTesting: Data loss: 0.006145131774246693\n","\n","Epoch 538\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008357699029147625\n","\tBefore adaption: Boundary condition loss: 0.0002950462221633643\n","\tBefore adaption: PDE loss: 0.017674516886472702\n","\tBefore adaption: Data loss: 0.006071790121495724\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1031, 0.1018, 0.4332, 0.3619], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008504228737883252\n","\t\tAfter adaption: Boundary condition loss: 3.043375758959442e-05\n","\t\tAfter adaption: PDE loss: 0.0076570134668250515\n","\t\tAfter adaption: Data loss: 0.0021972234491860363\n","\n","\tTesting: Initial condition loss: 0.012453759089112282\n","\tTesting: Boundary condition loss: 0.0004242104187142104\n","\tTesting: PDE loss: 0.017035242170095444\n","\tTesting: Data loss: 0.004792574793100357\n","\n","Epoch 539\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013814590871334076\n","\tBefore adaption: Boundary condition loss: 0.0004522881645243615\n","\tBefore adaption: PDE loss: 0.016955584287643433\n","\tBefore adaption: Data loss: 0.004752403125166893\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0739, 0.1244, 0.4773, 0.3243], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017190143480524391\n","\t\tAfter adaption: Boundary condition loss: 3.343695542378963e-05\n","\t\tAfter adaption: PDE loss: 0.008093569929510616\n","\t\tAfter adaption: Data loss: 0.0015411907207460514\n","\n","\tTesting: Initial condition loss: 0.01897447556257248\n","\tTesting: Boundary condition loss: 0.0009137853048741817\n","\tTesting: PDE loss: 0.016249211505055428\n","\tTesting: Data loss: 0.004466362297534943\n","\n","Epoch 540\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020233966410160065\n","\tBefore adaption: Boundary condition loss: 0.000992064829915762\n","\tBefore adaption: PDE loss: 0.016203656792640686\n","\tBefore adaption: Data loss: 0.004453036468476057\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0453, 0.1844, 0.5037, 0.2666], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003730568579456057\n","\t\tAfter adaption: Boundary condition loss: 4.489441308426027e-05\n","\t\tAfter adaption: PDE loss: 0.008162490250824005\n","\t\tAfter adaption: Data loss: 0.0011873171787245397\n","\n","\tTesting: Initial condition loss: 0.025072215124964714\n","\tTesting: Boundary condition loss: 0.0014433253090828657\n","\tTesting: PDE loss: 0.015504362061619759\n","\tTesting: Data loss: 0.00472329230979085\n","\n","Epoch 541\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02633480168879032\n","\tBefore adaption: Boundary condition loss: 0.0015457492554560304\n","\tBefore adaption: PDE loss: 0.01546439342200756\n","\tBefore adaption: Data loss: 0.004729346372187138\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0267, 0.2801, 0.4913, 0.2020], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007375227844135959\n","\t\tAfter adaption: Boundary condition loss: 4.123713502470199e-05\n","\t\tAfter adaption: PDE loss: 0.007597051068084793\n","\t\tAfter adaption: Data loss: 0.0009553505666560432\n","\n","\tTesting: Initial condition loss: 0.028685932978987694\n","\tTesting: Boundary condition loss: 0.0016912496648728848\n","\tTesting: PDE loss: 0.014963588677346706\n","\tTesting: Data loss: 0.005022652912884951\n","\n","Epoch 542\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030063312500715256\n","\tBefore adaption: Boundary condition loss: 0.0018009254708886147\n","\tBefore adaption: PDE loss: 0.014922778122127056\n","\tBefore adaption: Data loss: 0.0050392188131809235\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0215, 0.3850, 0.4435, 0.1501], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011573096749190543\n","\t\tAfter adaption: Boundary condition loss: 3.873718856829726e-05\n","\t\tAfter adaption: PDE loss: 0.006617949849499767\n","\t\tAfter adaption: Data loss: 0.0007561494972139492\n","\n","\tTesting: Initial condition loss: 0.028111552819609642\n","\tTesting: Boundary condition loss: 0.001505278516560793\n","\tTesting: PDE loss: 0.014781409874558449\n","\tTesting: Data loss: 0.0049805003218352795\n","\n","Epoch 543\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029765641316771507\n","\tBefore adaption: Boundary condition loss: 0.0016070265555754304\n","\tBefore adaption: PDE loss: 0.0147470124065876\n","\tBefore adaption: Data loss: 0.0049964431673288345\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0242, 0.4703, 0.3864, 0.1191], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013998405949404448\n","\t\tAfter adaption: Boundary condition loss: 3.888477524415299e-05\n","\t\tAfter adaption: PDE loss: 0.005697993077799746\n","\t\tAfter adaption: Data loss: 0.0005952400986960318\n","\n","\tTesting: Initial condition loss: 0.023125195875763893\n","\tTesting: Boundary condition loss: 0.0009575283620506525\n","\tTesting: PDE loss: 0.015080890618264675\n","\tTesting: Data loss: 0.0046518403105437756\n","\n","Epoch 544\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02514035999774933\n","\tBefore adaption: Boundary condition loss: 0.0010359262814745307\n","\tBefore adaption: PDE loss: 0.015035968273878098\n","\tBefore adaption: Data loss: 0.004654936492443085\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0279, 0.5254, 0.3420, 0.1047], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013208587461554802\n","\t\tAfter adaption: Boundary condition loss: 2.8951958035284315e-05\n","\t\tAfter adaption: PDE loss: 0.005141749181989204\n","\t\tAfter adaption: Data loss: 0.00048734796723035186\n","\n","\tTesting: Initial condition loss: 0.015486088581383228\n","\tTesting: Boundary condition loss: 0.0004201423726044595\n","\tTesting: PDE loss: 0.015851400792598724\n","\tTesting: Data loss: 0.0046088807284832\n","\n","Epoch 545\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01779009960591793\n","\tBefore adaption: Boundary condition loss: 0.00044575537322089076\n","\tBefore adaption: PDE loss: 0.015813296660780907\n","\tBefore adaption: Data loss: 0.004587715957313776\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0292, 0.5511, 0.3197, 0.1000], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009803718130322698\n","\t\tAfter adaption: Boundary condition loss: 1.3030656929797995e-05\n","\t\tAfter adaption: PDE loss: 0.005056112527093743\n","\t\tAfter adaption: Data loss: 0.000458550478986908\n","\n","\tTesting: Initial condition loss: 0.008280273526906967\n","\tTesting: Boundary condition loss: 0.00042880576802417636\n","\tTesting: PDE loss: 0.01696099527180195\n","\tTesting: Data loss: 0.005656648427248001\n","\n","Epoch 546\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010626906529068947\n","\tBefore adaption: Boundary condition loss: 0.0003759181417990476\n","\tBefore adaption: PDE loss: 0.016895988956093788\n","\tBefore adaption: Data loss: 0.005601460114121437\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0273, 0.5483, 0.3225, 0.1019], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0058263028085576716\n","\t\tAfter adaption: Boundary condition loss: 1.026931661746508e-05\n","\t\tAfter adaption: PDE loss: 0.005449146737392208\n","\t\tAfter adaption: Data loss: 0.000570850582493136\n","\n","\tTesting: Initial condition loss: 0.0038006308022886515\n","\tTesting: Boundary condition loss: 0.0013680272968485951\n","\tTesting: PDE loss: 0.018170686438679695\n","\tTesting: Data loss: 0.008299246430397034\n","\n","Epoch 547\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005861442070454359\n","\tBefore adaption: Boundary condition loss: 0.001207699766382575\n","\tBefore adaption: PDE loss: 0.01812022738158703\n","\tBefore adaption: Data loss: 0.008202837780117989\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0238, 0.5132, 0.3503, 0.1126], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0030083297409107057\n","\t\tAfter adaption: Boundary condition loss: 2.877902672264527e-05\n","\t\tAfter adaption: PDE loss: 0.006348105217319523\n","\t\tAfter adaption: Data loss: 0.0009236154921253112\n","\n","\tTesting: Initial condition loss: 0.0027430446352809668\n","\tTesting: Boundary condition loss: 0.0032972791232168674\n","\tTesting: PDE loss: 0.01930072158575058\n","\tTesting: Data loss: 0.012364955618977547\n","\n","Epoch 548\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004194535315036774\n","\tBefore adaption: Boundary condition loss: 0.003008317667990923\n","\tBefore adaption: PDE loss: 0.01924874819815159\n","\tBefore adaption: Data loss: 0.012225241400301456\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0231, 0.4403, 0.3981, 0.1385], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018470164856989378\n","\t\tAfter adaption: Boundary condition loss: 6.941154279813401e-05\n","\t\tAfter adaption: PDE loss: 0.007662908327391942\n","\t\tAfter adaption: Data loss: 0.0016930582128487045\n","\n","\tTesting: Initial condition loss: 0.0041062962263822556\n","\tTesting: Boundary condition loss: 0.0058213709853589535\n","\tTesting: PDE loss: 0.020127074792981148\n","\tTesting: Data loss: 0.01705467700958252\n","\n","Epoch 549\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004809346981346607\n","\tBefore adaption: Boundary condition loss: 0.005408137571066618\n","\tBefore adaption: PDE loss: 0.0200947318226099\n","\tBefore adaption: Data loss: 0.016875702887773514\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0320, 0.3345, 0.4479, 0.1856], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016088725115142816\n","\t\tAfter adaption: Boundary condition loss: 0.0001728340667584756\n","\t\tAfter adaption: PDE loss: 0.009000614225784513\n","\t\tAfter adaption: Data loss: 0.0031321657705767987\n","\n","\tTesting: Initial condition loss: 0.006114686839282513\n","\tTesting: Boundary condition loss: 0.008184465579688549\n","\tTesting: PDE loss: 0.02060883492231369\n","\tTesting: Data loss: 0.021250762045383453\n","\n","Epoch 550\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006175993476063013\n","\tBefore adaption: Boundary condition loss: 0.007673102430999279\n","\tBefore adaption: PDE loss: 0.02056020312011242\n","\tBefore adaption: Data loss: 0.02103983424603939\n","tensor(0.0077, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0077, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0546, 0.2260, 0.4712, 0.2482], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013957478917640364\n","\t\tAfter adaption: Boundary condition loss: 0.0004188157560043602\n","\t\tAfter adaption: PDE loss: 0.009688797291091733\n","\t\tAfter adaption: Data loss: 0.005221695081744241\n","\n","\tTesting: Initial condition loss: 0.007323839236050844\n","\tTesting: Boundary condition loss: 0.009586959145963192\n","\tTesting: PDE loss: 0.0207050908356905\n","\tTesting: Data loss: 0.023895885795354843\n","\n","Epoch 551\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007034681737422943\n","\tBefore adaption: Boundary condition loss: 0.009018074721097946\n","\tBefore adaption: PDE loss: 0.020676735788583755\n","\tBefore adaption: Data loss: 0.0236658938229084\n","tensor(0.0090, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0090, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0849, 0.1520, 0.4559, 0.3072], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001069277896385935\n","\t\tAfter adaption: Boundary condition loss: 0.0007654959252270746\n","\t\tAfter adaption: PDE loss: 0.009427392230434001\n","\t\tAfter adaption: Data loss: 0.007269505646716482\n","\n","\tTesting: Initial condition loss: 0.007038875017315149\n","\tTesting: Boundary condition loss: 0.009453819133341312\n","\tTesting: PDE loss: 0.020543554797768593\n","\tTesting: Data loss: 0.024288145825266838\n","\n","Epoch 552\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006757468916475773\n","\tBefore adaption: Boundary condition loss: 0.008909241296350956\n","\tBefore adaption: PDE loss: 0.020509401336312294\n","\tBefore adaption: Data loss: 0.0240545105189085\n","tensor(0.0089, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0089, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1119, 0.1194, 0.4198, 0.3489], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008065956921734275\n","\t\tAfter adaption: Boundary condition loss: 0.0009972139011848319\n","\t\tAfter adaption: PDE loss: 0.008610114505104896\n","\t\tAfter adaption: Data loss: 0.008392447065691623\n","\n","\tTesting: Initial condition loss: 0.005414493847638369\n","\tTesting: Boundary condition loss: 0.00786494743078947\n","\tTesting: PDE loss: 0.02018730714917183\n","\tTesting: Data loss: 0.022350000217556953\n","\n","Epoch 553\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005466927774250507\n","\tBefore adaption: Boundary condition loss: 0.007404885720461607\n","\tBefore adaption: PDE loss: 0.02013859897851944\n","\tBefore adaption: Data loss: 0.022128650918602943\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1299, 0.1106, 0.3859, 0.3737], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006045128834375426\n","\t\tAfter adaption: Boundary condition loss: 0.0009616209355505686\n","\t\tAfter adaption: PDE loss: 0.007771053135276857\n","\t\tAfter adaption: Data loss: 0.008269076144832256\n","\n","\tTesting: Initial condition loss: 0.0033236711751669645\n","\tTesting: Boundary condition loss: 0.005509081296622753\n","\tTesting: PDE loss: 0.019681204110383987\n","\tTesting: Data loss: 0.018689561635255814\n","\n","Epoch 554\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003910570405423641\n","\tBefore adaption: Boundary condition loss: 0.005146305076777935\n","\tBefore adaption: PDE loss: 0.01963125355541706\n","\tBefore adaption: Data loss: 0.018493665382266045\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1380, 0.1086, 0.3662, 0.3872], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004247748792220502\n","\t\tAfter adaption: Boundary condition loss: 0.0007100735034471301\n","\t\tAfter adaption: PDE loss: 0.007189696142552771\n","\t\tAfter adaption: Data loss: 0.007160063069874115\n","\n","\tTesting: Initial condition loss: 0.001994282705709338\n","\tTesting: Boundary condition loss: 0.003153022611513734\n","\tTesting: PDE loss: 0.019091596826910973\n","\tTesting: Data loss: 0.014318229630589485\n","\n","Epoch 555\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0030943690799176693\n","\tBefore adaption: Boundary condition loss: 0.0029021722730249166\n","\tBefore adaption: PDE loss: 0.01903369650244713\n","\tBefore adaption: Data loss: 0.014155765064060688\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1370, 0.1054, 0.3646, 0.3930], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003261571695444833\n","\t\tAfter adaption: Boundary condition loss: 0.00039771758078562176\n","\t\tAfter adaption: PDE loss: 0.006939452672708338\n","\t\tAfter adaption: Data loss: 0.00556275244613163\n","\n","\tTesting: Initial condition loss: 0.0025223230477422476\n","\tTesting: Boundary condition loss: 0.0014039321104064584\n","\tTesting: PDE loss: 0.018456287682056427\n","\tTesting: Data loss: 0.010247101075947285\n","\n","Epoch 556\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00392140680924058\n","\tBefore adaption: Boundary condition loss: 0.001255629351362586\n","\tBefore adaption: PDE loss: 0.018391620367765427\n","\tBefore adaption: Data loss: 0.010121870785951614\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1273, 0.1002, 0.3814, 0.3911], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003928855808050793\n","\t\tAfter adaption: Boundary condition loss: 0.0001598951008516242\n","\t\tAfter adaption: PDE loss: 0.007014852570162303\n","\t\tAfter adaption: Data loss: 0.003958173425396617\n","\n","\tTesting: Initial condition loss: 0.0054274010471999645\n","\tTesting: Boundary condition loss: 0.0004920305218547583\n","\tTesting: PDE loss: 0.017784778028726578\n","\tTesting: Data loss: 0.007162163965404034\n","\n","Epoch 557\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006799262948334217\n","\tBefore adaption: Boundary condition loss: 0.0004288943891879171\n","\tBefore adaption: PDE loss: 0.017724379897117615\n","\tBefore adaption: Data loss: 0.007074813824146986\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1088, 0.0983, 0.4150, 0.3778], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006685878971389196\n","\t\tAfter adaption: Boundary condition loss: 4.666916389715241e-05\n","\t\tAfter adaption: PDE loss: 0.007355967536930234\n","\t\tAfter adaption: Data loss: 0.002673111733151641\n","\n","\tTesting: Initial condition loss: 0.010456806980073452\n","\tTesting: Boundary condition loss: 0.0003163382352795452\n","\tTesting: PDE loss: 0.01707608252763748\n","\tTesting: Data loss: 0.00532075809314847\n","\n","Epoch 558\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011636490933597088\n","\tBefore adaption: Boundary condition loss: 0.0003207449335604906\n","\tBefore adaption: PDE loss: 0.017024671658873558\n","\tBefore adaption: Data loss: 0.005267465487122536\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0827, 0.1119, 0.4581, 0.3473], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013023561214784154\n","\t\tAfter adaption: Boundary condition loss: 2.6525021832548052e-05\n","\t\tAfter adaption: PDE loss: 0.0077990192479098575\n","\t\tAfter adaption: Data loss: 0.0018292884018374944\n","\n","\tTesting: Initial condition loss: 0.016849398612976074\n","\tTesting: Boundary condition loss: 0.0006378442631103098\n","\tTesting: PDE loss: 0.016332760453224182\n","\tTesting: Data loss: 0.0046112919226288795\n","\n","Epoch 559\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01780758425593376\n","\tBefore adaption: Boundary condition loss: 0.0006950825336389244\n","\tBefore adaption: PDE loss: 0.016296230256557465\n","\tBefore adaption: Data loss: 0.004585995804518461\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0540, 0.1576, 0.4928, 0.2957], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002806196342269457\n","\t\tAfter adaption: Boundary condition loss: 3.7501299214160704e-05\n","\t\tAfter adaption: PDE loss: 0.008030041201089003\n","\t\tAfter adaption: Data loss: 0.0013561182776827161\n","\n","\tTesting: Initial condition loss: 0.023475175723433495\n","\tTesting: Boundary condition loss: 0.0011411182349547744\n","\tTesting: PDE loss: 0.015612974762916565\n","\tTesting: Data loss: 0.004669497720897198\n","\n","Epoch 560\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02417810633778572\n","\tBefore adaption: Boundary condition loss: 0.0012274704640731215\n","\tBefore adaption: PDE loss: 0.015572578646242619\n","\tBefore adaption: Data loss: 0.004665951244533062\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0314, 0.2423, 0.4956, 0.2307], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005859029662325758\n","\t\tAfter adaption: Boundary condition loss: 3.851548365727171e-05\n","\t\tAfter adaption: PDE loss: 0.007717237376831384\n","\t\tAfter adaption: Data loss: 0.001076566032504549\n","\n","\tTesting: Initial condition loss: 0.028330765664577484\n","\tTesting: Boundary condition loss: 0.001505382708273828\n","\tTesting: PDE loss: 0.015025382861495018\n","\tTesting: Data loss: 0.004979344084858894\n","\n","Epoch 561\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028990378603339195\n","\tBefore adaption: Boundary condition loss: 0.0016041792696341872\n","\tBefore adaption: PDE loss: 0.014995629899203777\n","\tBefore adaption: Data loss: 0.0049898154102265835\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0212, 0.3479, 0.4595, 0.1714], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0100851882717912\n","\t\tAfter adaption: Boundary condition loss: 3.405661906746282e-05\n","\t\tAfter adaption: PDE loss: 0.006890558060890694\n","\t\tAfter adaption: Data loss: 0.0008551787999601894\n","\n","\tTesting: Initial condition loss: 0.029453100636601448\n","\tTesting: Boundary condition loss: 0.001508314162492752\n","\tTesting: PDE loss: 0.014768505468964577\n","\tTesting: Data loss: 0.005060536786913872\n","\n","Epoch 562\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030307698994874954\n","\tBefore adaption: Boundary condition loss: 0.0016057370230555534\n","\tBefore adaption: PDE loss: 0.01473955251276493\n","\tBefore adaption: Data loss: 0.0050748297944664955\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0212, 0.4430, 0.4042, 0.1316], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013426551189737158\n","\t\tAfter adaption: Boundary condition loss: 3.400751860050771e-05\n","\t\tAfter adaption: PDE loss: 0.005957456452023757\n","\t\tAfter adaption: Data loss: 0.0006680070514202928\n","\n","\tTesting: Initial condition loss: 0.025968067348003387\n","\tTesting: Boundary condition loss: 0.0011186052579432726\n","\tTesting: PDE loss: 0.014971375465393066\n","\tTesting: Data loss: 0.004762823693454266\n","\n","Epoch 563\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027229562401771545\n","\tBefore adaption: Boundary condition loss: 0.0012014356907457113\n","\tBefore adaption: PDE loss: 0.014934984967112541\n","\tBefore adaption: Data loss: 0.004769558552652597\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0246, 0.5098, 0.3547, 0.1109], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013880463873304853\n","\t\tAfter adaption: Boundary condition loss: 2.9560489472957335e-05\n","\t\tAfter adaption: PDE loss: 0.005297938142130739\n","\t\tAfter adaption: Data loss: 0.0005289675067275463\n","\n","\tTesting: Initial condition loss: 0.018940649926662445\n","\tTesting: Boundary condition loss: 0.0005728669348172843\n","\tTesting: PDE loss: 0.0156332366168499\n","\tTesting: Data loss: 0.004459532909095287\n","\n","Epoch 564\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020687516778707504\n","\tBefore adaption: Boundary condition loss: 0.0006227944977581501\n","\tBefore adaption: PDE loss: 0.015603490173816681\n","\tBefore adaption: Data loss: 0.004448336083441973\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0269, 0.5459, 0.3249, 0.1023], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011294074513270495\n","\t\tAfter adaption: Boundary condition loss: 1.6747904350991304e-05\n","\t\tAfter adaption: PDE loss: 0.005069856765420841\n","\t\tAfter adaption: Data loss: 0.00045485760985267365\n","\n","\tTesting: Initial condition loss: 0.011050392873585224\n","\tTesting: Boundary condition loss: 0.0003342161071486771\n","\tTesting: PDE loss: 0.016684694215655327\n","\tTesting: Data loss: 0.004892041441053152\n","\n","Epoch 565\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013190487399697304\n","\tBefore adaption: Boundary condition loss: 0.00031911625410430133\n","\tBefore adaption: PDE loss: 0.01666191592812538\n","\tBefore adaption: Data loss: 0.004853817634284496\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0264, 0.5535, 0.3193, 0.1008], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007301001802125971\n","\t\tAfter adaption: Boundary condition loss: 8.413044128170111e-06\n","\t\tAfter adaption: PDE loss: 0.00532018305989016\n","\t\tAfter adaption: Data loss: 0.0004894062471423336\n","\n","\tTesting: Initial condition loss: 0.005200061947107315\n","\tTesting: Boundary condition loss: 0.0008342318469658494\n","\tTesting: PDE loss: 0.01794045977294445\n","\tTesting: Data loss: 0.006728938315063715\n","\n","Epoch 566\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007306970655918121\n","\tBefore adaption: Boundary condition loss: 0.0007241896819323301\n","\tBefore adaption: PDE loss: 0.01792171597480774\n","\tBefore adaption: Data loss: 0.006655559875071049\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0236, 0.5309, 0.3391, 0.1064], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0038793311749536017\n","\t\tAfter adaption: Boundary condition loss: 1.7088518322242223e-05\n","\t\tAfter adaption: PDE loss: 0.00607730367210422\n","\t\tAfter adaption: Data loss: 0.0007080982228907577\n","\n","\tTesting: Initial condition loss: 0.0027665672823786736\n","\tTesting: Boundary condition loss: 0.002265069168061018\n","\tTesting: PDE loss: 0.01914733089506626\n","\tTesting: Data loss: 0.010100294835865498\n","\n","Epoch 567\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0044568562880158424\n","\tBefore adaption: Boundary condition loss: 0.002028177259489894\n","\tBefore adaption: PDE loss: 0.019137021154165268\n","\tBefore adaption: Data loss: 0.009987544268369675\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0214, 0.4727, 0.3824, 0.1235], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021065840117780042\n","\t\tAfter adaption: Boundary condition loss: 4.343923572881175e-05\n","\t\tAfter adaption: PDE loss: 0.007317601204760122\n","\t\tAfter adaption: Data loss: 0.0012338727027532968\n","\n","\tTesting: Initial condition loss: 0.003300223732367158\n","\tTesting: Boundary condition loss: 0.004463699646294117\n","\tTesting: PDE loss: 0.020117180421948433\n","\tTesting: Data loss: 0.014472099021077156\n","\n","Epoch 568\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004256849177181721\n","\tBefore adaption: Boundary condition loss: 0.004079298581928015\n","\tBefore adaption: PDE loss: 0.020103201270103455\n","\tBefore adaption: Data loss: 0.014321972616016865\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0254, 0.3780, 0.4373, 0.1594], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016089141152932605\n","\t\tAfter adaption: Boundary condition loss: 0.0001036288107199773\n","\t\tAfter adaption: PDE loss: 0.008790262254975997\n","\t\tAfter adaption: Data loss: 0.0022826416639400338\n","\n","\tTesting: Initial condition loss: 0.005169264506548643\n","\tTesting: Boundary condition loss: 0.006884530186653137\n","\tTesting: PDE loss: 0.020734937861561775\n","\tTesting: Data loss: 0.018885109573602676\n","\n","Epoch 569\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005403077695518732\n","\tBefore adaption: Boundary condition loss: 0.006376355420798063\n","\tBefore adaption: PDE loss: 0.02069908380508423\n","\tBefore adaption: Data loss: 0.018702933564782143\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0415, 0.2662, 0.4774, 0.2149], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014380896815952323\n","\t\tAfter adaption: Boundary condition loss: 0.00026457419936731075\n","\t\tAfter adaption: PDE loss: 0.009881783261319261\n","\t\tAfter adaption: Data loss: 0.004020074913645838\n","\n","\tTesting: Initial condition loss: 0.0067938584834337234\n","\tTesting: Boundary condition loss: 0.008792627602815628\n","\tTesting: PDE loss: 0.020937127992510796\n","\tTesting: Data loss: 0.022302847355604172\n","\n","Epoch 570\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006543660070747137\n","\tBefore adaption: Boundary condition loss: 0.00818310584872961\n","\tBefore adaption: PDE loss: 0.020907945930957794\n","\tBefore adaption: Data loss: 0.02209692820906639\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0686, 0.1754, 0.4794, 0.2765], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011478925922291745\n","\t\tAfter adaption: Boundary condition loss: 0.0005613922912664297\n","\t\tAfter adaption: PDE loss: 0.010024046473409045\n","\t\tAfter adaption: Data loss: 0.006110644439839259\n","\n","\tTesting: Initial condition loss: 0.007201939821243286\n","\tTesting: Boundary condition loss: 0.00946036260575056\n","\tTesting: PDE loss: 0.02082584798336029\n","\tTesting: Data loss: 0.023880546912550926\n","\n","Epoch 571\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006794950924813747\n","\tBefore adaption: Boundary condition loss: 0.008830452337861061\n","\tBefore adaption: PDE loss: 0.020787058398127556\n","\tBefore adaption: Data loss: 0.02366427518427372\n","tensor(0.0088, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0088, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0973, 0.1271, 0.4492, 0.3264], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008637533537096052\n","\t\tAfter adaption: Boundary condition loss: 0.0008590196563044872\n","\t\tAfter adaption: PDE loss: 0.009337263844371828\n","\t\tAfter adaption: Data loss: 0.007724426515487298\n","\n","\tTesting: Initial condition loss: 0.006172259338200092\n","\tTesting: Boundary condition loss: 0.008609269745647907\n","\tTesting: PDE loss: 0.02047843486070633\n","\tTesting: Data loss: 0.023222070187330246\n","\n","Epoch 572\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00594682339578867\n","\tBefore adaption: Boundary condition loss: 0.008044371381402016\n","\tBefore adaption: PDE loss: 0.02042973041534424\n","\tBefore adaption: Data loss: 0.023009562864899635\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1192, 0.1110, 0.4108, 0.3590], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006598366180354557\n","\t\tAfter adaption: Boundary condition loss: 0.0009592555007093837\n","\t\tAfter adaption: PDE loss: 0.00839340540262701\n","\t\tAfter adaption: Data loss: 0.008259407028992223\n","\n","\tTesting: Initial condition loss: 0.004235715139657259\n","\tTesting: Boundary condition loss: 0.006611245684325695\n","\tTesting: PDE loss: 0.01995263621211052\n","\tTesting: Data loss: 0.020551243796944618\n","\n","Epoch 573\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004453941248357296\n","\tBefore adaption: Boundary condition loss: 0.0061567965894937515\n","\tBefore adaption: PDE loss: 0.019920237362384796\n","\tBefore adaption: Data loss: 0.0203559473156929\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1319, 0.1075, 0.3823, 0.3782], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00047885596816094007\n","\t\tAfter adaption: Boundary condition loss: 0.0008122644380739163\n","\t\tAfter adaption: PDE loss: 0.007615708138804329\n","\t\tAfter adaption: Data loss: 0.007699578542413996\n","\n","\tTesting: Initial condition loss: 0.0024396535009145737\n","\tTesting: Boundary condition loss: 0.004261388443410397\n","\tTesting: PDE loss: 0.01934143155813217\n","\tTesting: Data loss: 0.01663821004331112\n","\n","Epoch 574\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003210014896467328\n","\tBefore adaption: Boundary condition loss: 0.003925982862710953\n","\tBefore adaption: PDE loss: 0.019312800839543343\n","\tBefore adaption: Data loss: 0.016469871625304222\n","tensor(0.0039, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0039, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1356, 0.1051, 0.3704, 0.3889], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003373162385783614\n","\t\tAfter adaption: Boundary condition loss: 0.0005321962203909686\n","\t\tAfter adaption: PDE loss: 0.007154266808967992\n","\t\tAfter adaption: Data loss: 0.006405433098544738\n","\n","\tTesting: Initial condition loss: 0.0019333643140271306\n","\tTesting: Boundary condition loss: 0.002211951883509755\n","\tTesting: PDE loss: 0.018697824329137802\n","\tTesting: Data loss: 0.012466603890061378\n","\n","Epoch 575\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003165328176692128\n","\tBefore adaption: Boundary condition loss: 0.0020021579694002867\n","\tBefore adaption: PDE loss: 0.018652841448783875\n","\tBefore adaption: Data loss: 0.012329425662755966\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1306, 0.1002, 0.3767, 0.3925], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000317046965711504\n","\t\tAfter adaption: Boundary condition loss: 0.0002615095604485705\n","\t\tAfter adaption: PDE loss: 0.0070262370826322945\n","\t\tAfter adaption: Data loss: 0.004839780280567237\n","\n","\tTesting: Initial condition loss: 0.0035025200340896845\n","\tTesting: Boundary condition loss: 0.0008707756060175598\n","\tTesting: PDE loss: 0.01800549030303955\n","\tTesting: Data loss: 0.00886852853000164\n","\n","Epoch 576\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004958611447364092\n","\tBefore adaption: Boundary condition loss: 0.0007601466495543718\n","\tBefore adaption: PDE loss: 0.0179649218916893\n","\tBefore adaption: Data loss: 0.008764736354351044\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1170, 0.0952, 0.4005, 0.3873], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004722969783957447\n","\t\tAfter adaption: Boundary condition loss: 8.895712907960849e-05\n","\t\tAfter adaption: PDE loss: 0.007194255218131533\n","\t\tAfter adaption: Data loss: 0.0033942706964489593\n","\n","\tTesting: Initial condition loss: 0.007300402037799358\n","\tTesting: Boundary condition loss: 0.0002874421770684421\n","\tTesting: PDE loss: 0.01729508489370346\n","\tTesting: Data loss: 0.006330837495625019\n","\n","Epoch 577\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008754881098866463\n","\tBefore adaption: Boundary condition loss: 0.00025181384989991784\n","\tBefore adaption: PDE loss: 0.01725337840616703\n","\tBefore adaption: Data loss: 0.006258705165237188\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0950, 0.0989, 0.4380, 0.3681], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008655696785897262\n","\t\tAfter adaption: Boundary condition loss: 2.3927394758651606e-05\n","\t\tAfter adaption: PDE loss: 0.0075569115165426606\n","\t\tAfter adaption: Data loss: 0.0023039323905762106\n","\n","\tTesting: Initial condition loss: 0.012830228544771671\n","\tTesting: Boundary condition loss: 0.00031144250533543527\n","\tTesting: PDE loss: 0.016562024131417274\n","\tTesting: Data loss: 0.004955756478011608\n","\n","Epoch 578\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014225425198674202\n","\tBefore adaption: Boundary condition loss: 0.0003355334047228098\n","\tBefore adaption: PDE loss: 0.016511021181941032\n","\tBefore adaption: Data loss: 0.004911072552204132\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0672, 0.1259, 0.4777, 0.3292], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017911668317493361\n","\t\tAfter adaption: Boundary condition loss: 2.254355366231597e-05\n","\t\tAfter adaption: PDE loss: 0.007887351837690888\n","\t\tAfter adaption: Data loss: 0.0016167114770920502\n","\n","\tTesting: Initial condition loss: 0.019303955137729645\n","\tTesting: Boundary condition loss: 0.0007015070295892656\n","\tTesting: PDE loss: 0.015787122771143913\n","\tTesting: Data loss: 0.004548308439552784\n","\n","Epoch 579\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02057524025440216\n","\tBefore adaption: Boundary condition loss: 0.0007629600004293025\n","\tBefore adaption: PDE loss: 0.01575133204460144\n","\tBefore adaption: Data loss: 0.0045267255045473576\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0404, 0.1906, 0.4983, 0.2706], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0039223023524529435\n","\t\tAfter adaption: Boundary condition loss: 3.083420631414172e-05\n","\t\tAfter adaption: PDE loss: 0.00784897764283537\n","\t\tAfter adaption: Data loss: 0.001225149220277192\n","\n","\tTesting: Initial condition loss: 0.025148587301373482\n","\tTesting: Boundary condition loss: 0.001140774693340063\n","\tTesting: PDE loss: 0.015090052038431168\n","\tTesting: Data loss: 0.004706255160272121\n","\n","Epoch 580\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026446815580129623\n","\tBefore adaption: Boundary condition loss: 0.0012205936945974827\n","\tBefore adaption: PDE loss: 0.015058805234730244\n","\tBefore adaption: Data loss: 0.004701784811913967\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0230, 0.2892, 0.4820, 0.2058], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00764898160446696\n","\t\tAfter adaption: Boundary condition loss: 2.8086357335715025e-05\n","\t\tAfter adaption: PDE loss: 0.00725788814196538\n","\t\tAfter adaption: Data loss: 0.0009676194291352371\n","\n","\tTesting: Initial condition loss: 0.028492026031017303\n","\tTesting: Boundary condition loss: 0.0013591146562248468\n","\tTesting: PDE loss: 0.014619621448218822\n","\tTesting: Data loss: 0.004945061169564724\n","\n","Epoch 581\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029962783679366112\n","\tBefore adaption: Boundary condition loss: 0.0014472482725977898\n","\tBefore adaption: PDE loss: 0.014588440768420696\n","\tBefore adaption: Data loss: 0.004950011149048805\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0175, 0.3946, 0.4344, 0.1534], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011824572418401893\n","\t\tAfter adaption: Boundary condition loss: 2.5370616016048257e-05\n","\t\tAfter adaption: PDE loss: 0.006337013889384693\n","\t\tAfter adaption: Data loss: 0.0007595373573609683\n","\n","\tTesting: Initial condition loss: 0.027840174734592438\n","\tTesting: Boundary condition loss: 0.0012146711815148592\n","\tTesting: PDE loss: 0.014497325755655766\n","\tTesting: Data loss: 0.00490432046353817\n","\n","Epoch 582\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029604097828269005\n","\tBefore adaption: Boundary condition loss: 0.0012982962653040886\n","\tBefore adaption: PDE loss: 0.014469031244516373\n","\tBefore adaption: Data loss: 0.00490961316972971\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0193, 0.4796, 0.3796, 0.1215], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014198234467537044\n","\t\tAfter adaption: Boundary condition loss: 2.501614625519794e-05\n","\t\tAfter adaption: PDE loss: 0.0054923680168007406\n","\t\tAfter adaption: Data loss: 0.0005966795294129375\n","\n","\tTesting: Initial condition loss: 0.02297242358326912\n","\tTesting: Boundary condition loss: 0.0007770305965095758\n","\tTesting: PDE loss: 0.014820902608335018\n","\tTesting: Data loss: 0.004626415204256773\n","\n","Epoch 583\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02511841431260109\n","\tBefore adaption: Boundary condition loss: 0.0008414390031248331\n","\tBefore adaption: PDE loss: 0.01480183470994234\n","\tBefore adaption: Data loss: 0.004622269421815872\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0224, 0.5341, 0.3375, 0.1060], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013416593742186388\n","\t\tAfter adaption: Boundary condition loss: 1.883041011155835e-05\n","\t\tAfter adaption: PDE loss: 0.0049949587377572215\n","\t\tAfter adaption: Data loss: 0.0004901075292218164\n","\n","\tTesting: Initial condition loss: 0.015520759858191013\n","\tTesting: Boundary condition loss: 0.0003534276911523193\n","\tTesting: PDE loss: 0.01564033143222332\n","\tTesting: Data loss: 0.004627962596714497\n","\n","Epoch 584\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.017969811335206032\n","\tBefore adaption: Boundary condition loss: 0.00037584302481263876\n","\tBefore adaption: PDE loss: 0.015602566301822662\n","\tBefore adaption: Data loss: 0.004605242051184177\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0236, 0.5591, 0.3167, 0.1006], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010046186949628397\n","\t\tAfter adaption: Boundary condition loss: 8.881807423733767e-06\n","\t\tAfter adaption: PDE loss: 0.0049417811312412446\n","\t\tAfter adaption: Data loss: 0.00046319632158683835\n","\n","\tTesting: Initial condition loss: 0.008375486359000206\n","\tTesting: Boundary condition loss: 0.0004188590100966394\n","\tTesting: PDE loss: 0.016798673197627068\n","\tTesting: Data loss: 0.005651955958455801\n","\n","Epoch 585\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010866379365324974\n","\tBefore adaption: Boundary condition loss: 0.0003651473962236196\n","\tBefore adaption: PDE loss: 0.01674165017902851\n","\tBefore adaption: Data loss: 0.005601371638476849\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0223, 0.5552, 0.3203, 0.1023], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006032804344158617\n","\t\tAfter adaption: Boundary condition loss: 8.135573829780494e-06\n","\t\tAfter adaption: PDE loss: 0.005362119855147864\n","\t\tAfter adaption: Data loss: 0.0005727547942099945\n","\n","\tTesting: Initial condition loss: 0.003930207807570696\n","\tTesting: Boundary condition loss: 0.0013044257648289204\n","\tTesting: PDE loss: 0.01807592809200287\n","\tTesting: Data loss: 0.008195498026907444\n","\n","Epoch 586\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00602299626916647\n","\tBefore adaption: Boundary condition loss: 0.0011503436835482717\n","\tBefore adaption: PDE loss: 0.018022257834672928\n","\tBefore adaption: Data loss: 0.008109617978334427\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0198, 0.5190, 0.3483, 0.1129], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031260956153066383\n","\t\tAfter adaption: Boundary condition loss: 2.275856632122067e-05\n","\t\tAfter adaption: PDE loss: 0.0062777055865571845\n","\t\tAfter adaption: Data loss: 0.000915237499737646\n","\n","\tTesting: Initial condition loss: 0.002816753229126334\n","\tTesting: Boundary condition loss: 0.003091193037107587\n","\tTesting: PDE loss: 0.01925276778638363\n","\tTesting: Data loss: 0.01213256549090147\n","\n","Epoch 587\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004246886353939772\n","\tBefore adaption: Boundary condition loss: 0.0027966804336756468\n","\tBefore adaption: PDE loss: 0.019196083769202232\n","\tBefore adaption: Data loss: 0.012008868157863617\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0200, 0.4454, 0.3961, 0.1385], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018916031243155526\n","\t\tAfter adaption: Boundary condition loss: 5.60639873146974e-05\n","\t\tAfter adaption: PDE loss: 0.00760265033873865\n","\t\tAfter adaption: Data loss: 0.0016631270350173225\n","\n","\tTesting: Initial condition loss: 0.004080963786691427\n","\tTesting: Boundary condition loss: 0.005412475671619177\n","\tTesting: PDE loss: 0.02013368345797062\n","\tTesting: Data loss: 0.016709214076399803\n","\n","Epoch 588\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004733541049063206\n","\tBefore adaption: Boundary condition loss: 0.004976705182343721\n","\tBefore adaption: PDE loss: 0.02009224146604538\n","\tBefore adaption: Data loss: 0.01655156910419464\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0293, 0.3396, 0.4463, 0.1849], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016072764361320451\n","\t\tAfter adaption: Boundary condition loss: 0.00014556931287231927\n","\t\tAfter adaption: PDE loss: 0.008967690102755535\n","\t\tAfter adaption: Data loss: 0.003059938850622904\n","\n","\tTesting: Initial condition loss: 0.006037682294845581\n","\tTesting: Boundary condition loss: 0.007667431142181158\n","\tTesting: PDE loss: 0.020652366802096367\n","\tTesting: Data loss: 0.020866677165031433\n","\n","Epoch 589\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006048273295164108\n","\tBefore adaption: Boundary condition loss: 0.0071195573545992374\n","\tBefore adaption: PDE loss: 0.02059539407491684\n","\tBefore adaption: Data loss: 0.02068152278661728\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0509, 0.2305, 0.4719, 0.2467], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013943987603612853\n","\t\tAfter adaption: Boundary condition loss: 0.0003621153535707758\n","\t\tAfter adaption: PDE loss: 0.009718579639439864\n","\t\tAfter adaption: Data loss: 0.005102370048665704\n","\n","\tTesting: Initial condition loss: 0.007265858817845583\n","\tTesting: Boundary condition loss: 0.009059242904186249\n","\tTesting: PDE loss: 0.020780671387910843\n","\tTesting: Data loss: 0.023587297648191452\n","\n","Epoch 590\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006923647131770849\n","\tBefore adaption: Boundary condition loss: 0.00844962801784277\n","\tBefore adaption: PDE loss: 0.020730629563331604\n","\tBefore adaption: Data loss: 0.023384403437376022\n","tensor(0.0084, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0084, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0797, 0.1549, 0.4597, 0.3058], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010724372594302757\n","\t\tAfter adaption: Boundary condition loss: 0.0006732867553977599\n","\t\tAfter adaption: PDE loss: 0.009529257920381388\n","\t\tAfter adaption: Data loss: 0.007149829105531268\n","\n","\tTesting: Initial condition loss: 0.007066428195685148\n","\tTesting: Boundary condition loss: 0.009022407233715057\n","\tTesting: PDE loss: 0.020625978708267212\n","\tTesting: Data loss: 0.024177338927984238\n","\n","Epoch 591\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006712992675602436\n","\tBefore adaption: Boundary condition loss: 0.008433520793914795\n","\tBefore adaption: PDE loss: 0.020577028393745422\n","\tBefore adaption: Data loss: 0.023969341069459915\n","tensor(0.0084, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0084, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1056, 0.1206, 0.4254, 0.3483], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008096427441910446\n","\t\tAfter adaption: Boundary condition loss: 0.0008909512280890718\n","\t\tAfter adaption: PDE loss: 0.008754378033839579\n","\t\tAfter adaption: Data loss: 0.00834859805194821\n","\n","\tTesting: Initial condition loss: 0.005531060975044966\n","\tTesting: Boundary condition loss: 0.0075835734605789185\n","\tTesting: PDE loss: 0.02026369608938694\n","\tTesting: Data loss: 0.022511137649416924\n","\n","Epoch 592\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005483285989612341\n","\tBefore adaption: Boundary condition loss: 0.007082313299179077\n","\tBefore adaption: PDE loss: 0.020211581140756607\n","\tBefore adaption: Data loss: 0.022311579436063766\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1230, 0.1110, 0.3918, 0.3741], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006085206268258058\n","\t\tAfter adaption: Boundary condition loss: 0.0008714781319438097\n","\t\tAfter adaption: PDE loss: 0.00791936365984438\n","\t\tAfter adaption: Data loss: 0.008347865195673095\n","\n","\tTesting: Initial condition loss: 0.003457695245742798\n","\tTesting: Boundary condition loss: 0.00540258688852191\n","\tTesting: PDE loss: 0.01976209692656994\n","\tTesting: Data loss: 0.019107110798358917\n","\n","Epoch 593\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003921682946383953\n","\tBefore adaption: Boundary condition loss: 0.005009979475289583\n","\tBefore adaption: PDE loss: 0.019702691584825516\n","\tBefore adaption: Data loss: 0.01892736554145813\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1311, 0.1087, 0.3715, 0.3887], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004262574798924709\n","\t\tAfter adaption: Boundary condition loss: 0.0006567998697894356\n","\t\tAfter adaption: PDE loss: 0.007319648294871289\n","\t\tAfter adaption: Data loss: 0.0073571430946949\n","\n","\tTesting: Initial condition loss: 0.002007388509809971\n","\tTesting: Boundary condition loss: 0.0032113436609506607\n","\tTesting: PDE loss: 0.01915016397833824\n","\tTesting: Data loss: 0.014899076893925667\n","\n","Epoch 594\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0030015804804861546\n","\tBefore adaption: Boundary condition loss: 0.002940347185358405\n","\tBefore adaption: PDE loss: 0.01909540221095085\n","\tBefore adaption: Data loss: 0.014747156761586666\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1306, 0.1053, 0.3685, 0.3956], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003160249695161009\n","\t\tAfter adaption: Boundary condition loss: 0.0003841491724467409\n","\t\tAfter adaption: PDE loss: 0.007036188436794595\n","\t\tAfter adaption: Data loss: 0.0058338357828446145\n","\n","\tTesting: Initial condition loss: 0.0023026028648018837\n","\tTesting: Boundary condition loss: 0.0015246616676449776\n","\tTesting: PDE loss: 0.018480729311704636\n","\tTesting: Data loss: 0.010857908986508846\n","\n","Epoch 595\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003618548857048154\n","\tBefore adaption: Boundary condition loss: 0.001363367773592472\n","\tBefore adaption: PDE loss: 0.01841890998184681\n","\tBefore adaption: Data loss: 0.010737352073192596\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1220, 0.0995, 0.3834, 0.3950], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00036020295508258426\n","\t\tAfter adaption: Boundary condition loss: 0.00016632343012980595\n","\t\tAfter adaption: PDE loss: 0.007062165965106416\n","\t\tAfter adaption: Data loss: 0.004241709984821383\n","\n","\tTesting: Initial condition loss: 0.004909011535346508\n","\tTesting: Boundary condition loss: 0.0005578366108238697\n","\tTesting: PDE loss: 0.017788147553801537\n","\tTesting: Data loss: 0.007676362991333008\n","\n","Epoch 596\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006225524004548788\n","\tBefore adaption: Boundary condition loss: 0.0004822718328796327\n","\tBefore adaption: PDE loss: 0.017708076164126396\n","\tBefore adaption: Data loss: 0.007587582338601351\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1051, 0.0962, 0.4148, 0.3839], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005991238278817318\n","\t\tAfter adaption: Boundary condition loss: 5.068136782638059e-05\n","\t\tAfter adaption: PDE loss: 0.00734561816353018\n","\t\tAfter adaption: Data loss: 0.00291254580180719\n","\n","\tTesting: Initial condition loss: 0.00969691202044487\n","\tTesting: Boundary condition loss: 0.0002622337779030204\n","\tTesting: PDE loss: 0.01704992726445198\n","\tTesting: Data loss: 0.005653893109411001\n","\n","Epoch 597\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010750348679721355\n","\tBefore adaption: Boundary condition loss: 0.0002562102454248816\n","\tBefore adaption: PDE loss: 0.01697322353720665\n","\tBefore adaption: Data loss: 0.005595122929662466\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0809, 0.1067, 0.4562, 0.3562], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011468257868147232\n","\t\tAfter adaption: Boundary condition loss: 2.073201655752767e-05\n","\t\tAfter adaption: PDE loss: 0.007742644495041712\n","\t\tAfter adaption: Data loss: 0.0019931819038025117\n","\n","\tTesting: Initial condition loss: 0.01597347855567932\n","\tTesting: Boundary condition loss: 0.00045778893399983644\n","\tTesting: PDE loss: 0.01629110798239708\n","\tTesting: Data loss: 0.004745982121676207\n","\n","Epoch 598\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016693834215402603\n","\tBefore adaption: Boundary condition loss: 0.0004998433869332075\n","\tBefore adaption: PDE loss: 0.016209818422794342\n","\tBefore adaption: Data loss: 0.0047127059660851955\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0537, 0.1471, 0.4913, 0.3078], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0024558286253358232\n","\t\tAfter adaption: Boundary condition loss: 2.6859022832992107e-05\n","\t\tAfter adaption: PDE loss: 0.007964393568101934\n","\t\tAfter adaption: Data loss: 0.0014506815819148287\n","\n","\tTesting: Initial condition loss: 0.02267586812376976\n","\tTesting: Boundary condition loss: 0.0008706916705705225\n","\tTesting: PDE loss: 0.015537023544311523\n","\tTesting: Data loss: 0.004651676397770643\n","\n","Epoch 599\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023057516664266586\n","\tBefore adaption: Boundary condition loss: 0.000940647441893816\n","\tBefore adaption: PDE loss: 0.015455295331776142\n","\tBefore adaption: Data loss: 0.0046396078541874886\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0312, 0.2269, 0.4978, 0.2442], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005230879716336944\n","\t\tAfter adaption: Boundary condition loss: 2.934900945046097e-05\n","\t\tAfter adaption: PDE loss: 0.00769320730491773\n","\t\tAfter adaption: Data loss: 0.0011328299028659297\n","\n","\tTesting: Initial condition loss: 0.02798992395401001\n","\tTesting: Boundary condition loss: 0.0012156195007264614\n","\tTesting: PDE loss: 0.014909758232533932\n","\tTesting: Data loss: 0.004910909570753574\n","\n","Epoch 600\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028254026547074318\n","\tBefore adaption: Boundary condition loss: 0.0012944600312039256\n","\tBefore adaption: PDE loss: 0.014830161817371845\n","\tBefore adaption: Data loss: 0.004913428798317909\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0195, 0.3318, 0.4659, 0.1828], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009373981098214815\n","\t\tAfter adaption: Boundary condition loss: 2.520297761992401e-05\n","\t\tAfter adaption: PDE loss: 0.006909718142023125\n","\t\tAfter adaption: Data loss: 0.0008983294739747061\n","\n","\tTesting: Initial condition loss: 0.029950059950351715\n","\tTesting: Boundary condition loss: 0.0012703622924163938\n","\tTesting: PDE loss: 0.014579715207219124\n","\tTesting: Data loss: 0.005049220286309719\n","\n","Epoch 601\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030351728200912476\n","\tBefore adaption: Boundary condition loss: 0.0013481720816344023\n","\tBefore adaption: PDE loss: 0.014501066878437996\n","\tBefore adaption: Data loss: 0.005057925824075937\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0176, 0.4313, 0.4118, 0.1392], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013091318409802804\n","\t\tAfter adaption: Boundary condition loss: 2.37574397343742e-05\n","\t\tAfter adaption: PDE loss: 0.005971978969263681\n","\t\tAfter adaption: Data loss: 0.0007042003589627431\n","\n","\tTesting: Initial condition loss: 0.02741910144686699\n","\tTesting: Boundary condition loss: 0.0009720542002469301\n","\tTesting: PDE loss: 0.014683596789836884\n","\tTesting: Data loss: 0.004841760266572237\n","\n","Epoch 602\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028207266703248024\n","\tBefore adaption: Boundary condition loss: 0.001040284289047122\n","\tBefore adaption: PDE loss: 0.014598971232771873\n","\tBefore adaption: Data loss: 0.004846568219363689\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0201, 0.5045, 0.3603, 0.1151], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01423052209306477\n","\t\tAfter adaption: Boundary condition loss: 2.0861814611725676e-05\n","\t\tAfter adaption: PDE loss: 0.005260062880885821\n","\t\tAfter adaption: Data loss: 0.0005580518172949201\n","\n","\tTesting: Initial condition loss: 0.02099829725921154\n","\tTesting: Boundary condition loss: 0.0004959614016115665\n","\tTesting: PDE loss: 0.015257532708346844\n","\tTesting: Data loss: 0.0045351507142186165\n","\n","Epoch 603\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022331271320581436\n","\tBefore adaption: Boundary condition loss: 0.0005397456116043031\n","\tBefore adaption: PDE loss: 0.01518021710216999\n","\tBefore adaption: Data loss: 0.004526128061115742\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0221, 0.5470, 0.3265, 0.1044], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01221501554768301\n","\t\tAfter adaption: Boundary condition loss: 1.1944506152381212e-05\n","\t\tAfter adaption: PDE loss: 0.004956144478415131\n","\t\tAfter adaption: Data loss: 0.00047248858847906877\n","\n","\tTesting: Initial condition loss: 0.012946425937116146\n","\tTesting: Boundary condition loss: 0.0002272721758345142\n","\tTesting: PDE loss: 0.016285525634884834\n","\tTesting: Data loss: 0.004786991979926825\n","\n","Epoch 604\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014816301874816418\n","\tBefore adaption: Boundary condition loss: 0.00022469267423730344\n","\tBefore adaption: PDE loss: 0.016195518895983696\n","\tBefore adaption: Data loss: 0.004754598252475262\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0219, 0.5605, 0.3159, 0.1016], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00830509904790173\n","\t\tAfter adaption: Boundary condition loss: 4.916372099713939e-06\n","\t\tAfter adaption: PDE loss: 0.005116963778850233\n","\t\tAfter adaption: Data loss: 0.0004832197162190255\n","\n","\tTesting: Initial condition loss: 0.006378299091011286\n","\tTesting: Boundary condition loss: 0.0005744749796576798\n","\tTesting: PDE loss: 0.01755816489458084\n","\tTesting: Data loss: 0.006300713866949081\n","\n","Epoch 605\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008367939852178097\n","\tBefore adaption: Boundary condition loss: 0.0004978059441782534\n","\tBefore adaption: PDE loss: 0.01748231239616871\n","\tBefore adaption: Data loss: 0.006237073335796595\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0195, 0.5442, 0.3305, 0.1058], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00455416854336721\n","\t\tAfter adaption: Boundary condition loss: 9.716405709218809e-06\n","\t\tAfter adaption: PDE loss: 0.005777499834768997\n","\t\tAfter adaption: Data loss: 0.0006596599324960067\n","\n","\tTesting: Initial condition loss: 0.0030374936759471893\n","\tTesting: Boundary condition loss: 0.0017589688068255782\n","\tTesting: PDE loss: 0.018872402608394623\n","\tTesting: Data loss: 0.009343738667666912\n","\n","Epoch 606\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004729120526462793\n","\tBefore adaption: Boundary condition loss: 0.0015845670131966472\n","\tBefore adaption: PDE loss: 0.01878204196691513\n","\tBefore adaption: Data loss: 0.009243672713637352\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0173, 0.4930, 0.3693, 0.1204], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0023314853063388544\n","\t\tAfter adaption: Boundary condition loss: 2.7401810862497902e-05\n","\t\tAfter adaption: PDE loss: 0.006935769356768415\n","\t\tAfter adaption: Data loss: 0.0011131607981626737\n","\n","\tTesting: Initial condition loss: 0.0029192862566560507\n","\tTesting: Boundary condition loss: 0.0037150741554796696\n","\tTesting: PDE loss: 0.019937554374337196\n","\tTesting: Data loss: 0.013524518348276615\n","\n","Epoch 607\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003975026309490204\n","\tBefore adaption: Boundary condition loss: 0.003408673917874694\n","\tBefore adaption: PDE loss: 0.019848937168717384\n","\tBefore adaption: Data loss: 0.013389726169407368\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0200, 0.4039, 0.4236, 0.1525], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016055351005722083\n","\t\tAfter adaption: Boundary condition loss: 6.823998696190884e-05\n","\t\tAfter adaption: PDE loss: 0.00840768057287183\n","\t\tAfter adaption: Data loss: 0.0020418165989125195\n","\n","\tTesting: Initial condition loss: 0.004565051291137934\n","\tTesting: Boundary condition loss: 0.006033782847225666\n","\tTesting: PDE loss: 0.02063853107392788\n","\tTesting: Data loss: 0.017963223159313202\n","\n","Epoch 608\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004923985339701176\n","\tBefore adaption: Boundary condition loss: 0.005617343354970217\n","\tBefore adaption: PDE loss: 0.020554523915052414\n","\tBefore adaption: Data loss: 0.0177988950163126\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0336, 0.2912, 0.4702, 0.2050], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014337057624098301\n","\t\tAfter adaption: Boundary condition loss: 0.00018882727499529414\n","\t\tAfter adaption: PDE loss: 0.009664690453634193\n","\t\tAfter adaption: Data loss: 0.0036491151682583375\n","\n","\tTesting: Initial condition loss: 0.006330165546387434\n","\tTesting: Boundary condition loss: 0.008027912117540836\n","\tTesting: PDE loss: 0.02093803882598877\n","\tTesting: Data loss: 0.02163599245250225\n","\n","Epoch 609\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0061711883172392845\n","\tBefore adaption: Boundary condition loss: 0.007529722526669502\n","\tBefore adaption: PDE loss: 0.020860545337200165\n","\tBefore adaption: Data loss: 0.02144978754222393\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0589, 0.1912, 0.4827, 0.2673], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011797420343436782\n","\t\tAfter adaption: Boundary condition loss: 0.0004434798125545061\n","\t\tAfter adaption: PDE loss: 0.010068653786724726\n","\t\tAfter adaption: Data loss: 0.005732846667015721\n","\n","\tTesting: Initial condition loss: 0.007086318917572498\n","\tTesting: Boundary condition loss: 0.008991154842078686\n","\tTesting: PDE loss: 0.020899392664432526\n","\tTesting: Data loss: 0.023662278428673744\n","\n","Epoch 610\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006699337624013424\n","\tBefore adaption: Boundary condition loss: 0.00845940038561821\n","\tBefore adaption: PDE loss: 0.020828355103731155\n","\tBefore adaption: Data loss: 0.02346477098762989\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0085, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0877, 0.1325, 0.4591, 0.3207], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008876661841837055\n","\t\tAfter adaption: Boundary condition loss: 0.0007421295957745081\n","\t\tAfter adaption: PDE loss: 0.00956209570515158\n","\t\tAfter adaption: Data loss: 0.007524694189146169\n","\n","\tTesting: Initial condition loss: 0.006426198873668909\n","\tTesting: Boundary condition loss: 0.008513964712619781\n","\tTesting: PDE loss: 0.02058497443795204\n","\tTesting: Data loss: 0.023541845381259918\n","\n","Epoch 611\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0061307935975492\n","\tBefore adaption: Boundary condition loss: 0.008019950240850449\n","\tBefore adaption: PDE loss: 0.02053046226501465\n","\tBefore adaption: Data loss: 0.02334473840892315\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1111, 0.1107, 0.4215, 0.3567], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006785675545850601\n","\t\tAfter adaption: Boundary condition loss: 0.0008913665732342412\n","\t\tAfter adaption: PDE loss: 0.00865324457605118\n","\t\tAfter adaption: Data loss: 0.008326860616253784\n","\n","\tTesting: Initial condition loss: 0.004685563966631889\n","\tTesting: Boundary condition loss: 0.006787632126361132\n","\tTesting: PDE loss: 0.020103847607970238\n","\tTesting: Data loss: 0.021346868947148323\n","\n","Epoch 612\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004752247594296932\n","\tBefore adaption: Boundary condition loss: 0.006385918706655502\n","\tBefore adaption: PDE loss: 0.02005017362535\n","\tBefore adaption: Data loss: 0.021161526441574097\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1256, 0.1061, 0.3901, 0.3782], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005040283447809477\n","\t\tAfter adaption: Boundary condition loss: 0.0008020871264810125\n","\t\tAfter adaption: PDE loss: 0.007822321663363841\n","\t\tAfter adaption: Data loss: 0.008003267035758444\n","\n","\tTesting: Initial condition loss: 0.0027926939073950052\n","\tTesting: Boundary condition loss: 0.00450753653421998\n","\tTesting: PDE loss: 0.019517946988344193\n","\tTesting: Data loss: 0.017713434994220734\n","\n","Epoch 613\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0033617534209042788\n","\tBefore adaption: Boundary condition loss: 0.004207795485854149\n","\tBefore adaption: PDE loss: 0.01944638602435589\n","\tBefore adaption: Data loss: 0.017548922449350357\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1311, 0.1044, 0.3742, 0.3903], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00035087820866299405\n","\t\tAfter adaption: Boundary condition loss: 0.0005515564420915405\n","\t\tAfter adaption: PDE loss: 0.0072769026634395394\n","\t\tAfter adaption: Data loss: 0.006850103148503125\n","\n","\tTesting: Initial condition loss: 0.0018845386803150177\n","\tTesting: Boundary condition loss: 0.0024065906181931496\n","\tTesting: PDE loss: 0.018854212015867233\n","\tTesting: Data loss: 0.013574947603046894\n","\n","Epoch 614\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0029207183979451656\n","\tBefore adaption: Boundary condition loss: 0.0022161612287163734\n","\tBefore adaption: PDE loss: 0.01877056248486042\n","\tBefore adaption: Data loss: 0.013437197543680668\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1280, 0.1003, 0.3761, 0.3956], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002928670933187897\n","\t\tAfter adaption: Boundary condition loss: 0.00028359640276740477\n","\t\tAfter adaption: PDE loss: 0.00705980860777914\n","\t\tAfter adaption: Data loss: 0.005316420104631689\n","\n","\tTesting: Initial condition loss: 0.0028619093354791403\n","\tTesting: Boundary condition loss: 0.0009564163046889007\n","\tTesting: PDE loss: 0.018143683671951294\n","\tTesting: Data loss: 0.00980845745652914\n","\n","Epoch 615\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0041778008453547955\n","\tBefore adaption: Boundary condition loss: 0.0008567342301830649\n","\tBefore adaption: PDE loss: 0.018060311675071716\n","\tBefore adaption: Data loss: 0.009699671529233456\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1163, 0.0948, 0.3957, 0.3931], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003960453591120374\n","\t\tAfter adaption: Boundary condition loss: 9.967935060766904e-05\n","\t\tAfter adaption: PDE loss: 0.007147027383217462\n","\t\tAfter adaption: Data loss: 0.003813164650737236\n","\n","\tTesting: Initial condition loss: 0.006058648694306612\n","\tTesting: Boundary condition loss: 0.000254848477197811\n","\tTesting: PDE loss: 0.017409179359674454\n","\tTesting: Data loss: 0.006982673890888691\n","\n","Epoch 616\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007425122894346714\n","\tBefore adaption: Boundary condition loss: 0.00021937588462606072\n","\tBefore adaption: PDE loss: 0.01732998713850975\n","\tBefore adaption: Data loss: 0.00690292427316308\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0963, 0.0948, 0.4303, 0.3785], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007040770812935963\n","\t\tAfter adaption: Boundary condition loss: 2.113645326218829e-05\n","\t\tAfter adaption: PDE loss: 0.0074578575626709\n","\t\tAfter adaption: Data loss: 0.002612646002482087\n","\n","\tTesting: Initial condition loss: 0.011254284530878067\n","\tTesting: Boundary condition loss: 0.00018699838255997747\n","\tTesting: PDE loss: 0.016652686521410942\n","\tTesting: Data loss: 0.005294131115078926\n","\n","Epoch 617\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01247415505349636\n","\tBefore adaption: Boundary condition loss: 0.0001965878764167428\n","\tBefore adaption: PDE loss: 0.016576845198869705\n","\tBefore adaption: Data loss: 0.005240106023848057\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0698, 0.1138, 0.4709, 0.3455], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001419527181905252\n","\t\tAfter adaption: Boundary condition loss: 1.3721817766465326e-05\n","\t\tAfter adaption: PDE loss: 0.007805249285346116\n","\t\tAfter adaption: Data loss: 0.0018107178577945735\n","\n","\tTesting: Initial condition loss: 0.017720824107527733\n","\tTesting: Boundary condition loss: 0.0005192763055674732\n","\tTesting: PDE loss: 0.01587502285838127\n","\tTesting: Data loss: 0.004627530463039875\n","\n","Epoch 618\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01869102194905281\n","\tBefore adaption: Boundary condition loss: 0.00055403116857633\n","\tBefore adaption: PDE loss: 0.015801304951310158\n","\tBefore adaption: Data loss: 0.004595165606588125\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0425, 0.1677, 0.4981, 0.2917], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003134109555074468\n","\t\tAfter adaption: Boundary condition loss: 2.3548962361878235e-05\n","\t\tAfter adaption: PDE loss: 0.007870947821929111\n","\t\tAfter adaption: Data loss: 0.0013403863850186687\n","\n","\tTesting: Initial condition loss: 0.02400125376880169\n","\tTesting: Boundary condition loss: 0.0009682074887678027\n","\tTesting: PDE loss: 0.015159077942371368\n","\tTesting: Data loss: 0.0046484945341944695\n","\n","Epoch 619\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024882372468709946\n","\tBefore adaption: Boundary condition loss: 0.0010160764213651419\n","\tBefore adaption: PDE loss: 0.015073076821863651\n","\tBefore adaption: Data loss: 0.004632840398699045\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0230, 0.2594, 0.4913, 0.2263], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006454996459018447\n","\t\tAfter adaption: Boundary condition loss: 2.3319767957692103e-05\n","\t\tAfter adaption: PDE loss: 0.007405666436795455\n","\t\tAfter adaption: Data loss: 0.001048462539590009\n","\n","\tTesting: Initial condition loss: 0.02826172672212124\n","\tTesting: Boundary condition loss: 0.0012650953140109777\n","\tTesting: PDE loss: 0.01462479867041111\n","\tTesting: Data loss: 0.004889069590717554\n","\n","Epoch 620\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029245426878333092\n","\tBefore adaption: Boundary condition loss: 0.0013184802373871207\n","\tBefore adaption: PDE loss: 0.014532117173075676\n","\tBefore adaption: Data loss: 0.004883528687059879\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0154, 0.3669, 0.4492, 0.1684], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01073141143516897\n","\t\tAfter adaption: Boundary condition loss: 2.0323856287151938e-05\n","\t\tAfter adaption: PDE loss: 0.006527911979068911\n","\t\tAfter adaption: Data loss: 0.0008225622533587713\n","\n","\tTesting: Initial condition loss: 0.028791368007659912\n","\tTesting: Boundary condition loss: 0.0012271489249542356\n","\tTesting: PDE loss: 0.014399169944226742\n","\tTesting: Data loss: 0.00493896659463644\n","\n","Epoch 621\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030095398426055908\n","\tBefore adaption: Boundary condition loss: 0.001281169941648841\n","\tBefore adaption: PDE loss: 0.014314407482743263\n","\tBefore adaption: Data loss: 0.004935828968882561\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0164, 0.4601, 0.3934, 0.1302], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013845825361935156\n","\t\tAfter adaption: Boundary condition loss: 2.0997948154485395e-05\n","\t\tAfter adaption: PDE loss: 0.005630649849706255\n","\t\tAfter adaption: Data loss: 0.0006425962081914853\n","\n","\tTesting: Initial condition loss: 0.025063656270503998\n","\tTesting: Boundary condition loss: 0.0008578074630349874\n","\tTesting: PDE loss: 0.014598051086068153\n","\tTesting: Data loss: 0.004706816282123327\n","\n","Epoch 622\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026784131303429604\n","\tBefore adaption: Boundary condition loss: 0.0009050129447132349\n","\tBefore adaption: PDE loss: 0.014519740827381611\n","\tBefore adaption: Data loss: 0.004697724711149931\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0198, 0.5238, 0.3462, 0.1102], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014030681741413238\n","\t\tAfter adaption: Boundary condition loss: 1.792988046053099e-05\n","\t\tAfter adaption: PDE loss: 0.005026132596408186\n","\t\tAfter adaption: Data loss: 0.0005176253551913028\n","\n","\tTesting: Initial condition loss: 0.01815173216164112\n","\tTesting: Boundary condition loss: 0.0003984379000030458\n","\tTesting: PDE loss: 0.015246697701513767\n","\tTesting: Data loss: 0.004567602649331093\n","\n","Epoch 623\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020270302891731262\n","\tBefore adaption: Boundary condition loss: 0.00042532067163847387\n","\tBefore adaption: PDE loss: 0.015184562653303146\n","\tBefore adaption: Data loss: 0.00454447977244854\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0218, 0.5574, 0.3188, 0.1020], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011298497980942282\n","\t\tAfter adaption: Boundary condition loss: 9.27053758747404e-06\n","\t\tAfter adaption: PDE loss: 0.004841319486415457\n","\t\tAfter adaption: Data loss: 0.00046344541237347244\n","\n","\tTesting: Initial condition loss: 0.010551516897976398\n","\tTesting: Boundary condition loss: 0.00024608528474345803\n","\tTesting: PDE loss: 0.016307437792420387\n","\tTesting: Data loss: 0.005213415250182152\n","\n","Epoch 624\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012931394390761852\n","\tBefore adaption: Boundary condition loss: 0.00022617574722971767\n","\tBefore adaption: PDE loss: 0.016231002286076546\n","\tBefore adaption: Data loss: 0.0051686884835362434\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0212, 0.5623, 0.3151, 0.1014], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007270818362510598\n","\t\tAfter adaption: Boundary condition loss: 4.788854773686071e-06\n","\t\tAfter adaption: PDE loss: 0.005114981238591753\n","\t\tAfter adaption: Data loss: 0.0005242557220914619\n","\n","\tTesting: Initial condition loss: 0.005055652931332588\n","\tTesting: Boundary condition loss: 0.0007988959550857544\n","\tTesting: PDE loss: 0.01755852997303009\n","\tTesting: Data loss: 0.007236164528876543\n","\n","Epoch 625\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007221831474453211\n","\tBefore adaption: Boundary condition loss: 0.0006950853858143091\n","\tBefore adaption: PDE loss: 0.017481990158557892\n","\tBefore adaption: Data loss: 0.007163302507251501\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0187, 0.5364, 0.3360, 0.1089], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003873712212599524\n","\t\tAfter adaption: Boundary condition loss: 1.2982391540951471e-05\n","\t\tAfter adaption: PDE loss: 0.005874715748348567\n","\t\tAfter adaption: Data loss: 0.0007800071382580364\n","\n","\tTesting: Initial condition loss: 0.0028326769825071096\n","\tTesting: Boundary condition loss: 0.0022072952706366777\n","\tTesting: PDE loss: 0.018799297511577606\n","\tTesting: Data loss: 0.010719982907176018\n","\n","Epoch 626\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0044353012926876545\n","\tBefore adaption: Boundary condition loss: 0.0019911753479391336\n","\tBefore adaption: PDE loss: 0.018713433295488358\n","\tBefore adaption: Data loss: 0.010615560226142406\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0172, 0.4744, 0.3791, 0.1293], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002104314833245042\n","\t\tAfter adaption: Boundary condition loss: 3.430183941095541e-05\n","\t\tAfter adaption: PDE loss: 0.007093365052222697\n","\t\tAfter adaption: Data loss: 0.001372315003291942\n","\n","\tTesting: Initial condition loss: 0.0033958815038204193\n","\tTesting: Boundary condition loss: 0.004314673598855734\n","\tTesting: PDE loss: 0.019796287640929222\n","\tTesting: Data loss: 0.015111934393644333\n","\n","Epoch 627\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0042383261024951935\n","\tBefore adaption: Boundary condition loss: 0.003964453935623169\n","\tBefore adaption: PDE loss: 0.019712377339601517\n","\tBefore adaption: Data loss: 0.014977001585066319\n","tensor(0.0040, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0040, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0223, 0.3765, 0.4319, 0.1693], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015958861464428166\n","\t\tAfter adaption: Boundary condition loss: 8.844328797772842e-05\n","\t\tAfter adaption: PDE loss: 0.008513616671271318\n","\t\tAfter adaption: Data loss: 0.002535034880343818\n","\n","\tTesting: Initial condition loss: 0.00520855700597167\n","\tTesting: Boundary condition loss: 0.006567477714270353\n","\tTesting: PDE loss: 0.020421447232365608\n","\tTesting: Data loss: 0.0194479301571846\n","\n","Epoch 628\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005345678422600031\n","\tBefore adaption: Boundary condition loss: 0.006102282553911209\n","\tBefore adaption: PDE loss: 0.02035253494977951\n","\tBefore adaption: Data loss: 0.01928653009235859\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0392, 0.2635, 0.4691, 0.2281], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014087904544949508\n","\t\tAfter adaption: Boundary condition loss: 0.00023935037143566604\n","\t\tAfter adaption: PDE loss: 0.00954754160493917\n","\t\tAfter adaption: Data loss: 0.0043998402997418055\n","\n","\tTesting: Initial condition loss: 0.006741370540112257\n","\tTesting: Boundary condition loss: 0.008235972374677658\n","\tTesting: PDE loss: 0.020659465342760086\n","\tTesting: Data loss: 0.022709963843226433\n","\n","Epoch 629\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00642385333776474\n","\tBefore adaption: Boundary condition loss: 0.007710669655352831\n","\tBefore adaption: PDE loss: 0.020585862919688225\n","\tBefore adaption: Data loss: 0.022529447451233864\n","tensor(0.0077, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0077, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0659, 0.1735, 0.4699, 0.2907], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001114387473883898\n","\t\tAfter adaption: Boundary condition loss: 0.0005084083748682413\n","\t\tAfter adaption: PDE loss: 0.00967364691760476\n","\t\tAfter adaption: Data loss: 0.0065486473182516216\n","\n","\tTesting: Initial condition loss: 0.007069130428135395\n","\tTesting: Boundary condition loss: 0.008726635947823524\n","\tTesting: PDE loss: 0.02058575488626957\n","\tTesting: Data loss: 0.024106528609991074\n","\n","Epoch 630\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006635009311139584\n","\tBefore adaption: Boundary condition loss: 0.008201638236641884\n","\tBefore adaption: PDE loss: 0.02050788141787052\n","\tBefore adaption: Data loss: 0.023916464298963547\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0932, 0.1259, 0.4411, 0.3397], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008356156968421953\n","\t\tAfter adaption: Boundary condition loss: 0.0007644517695135492\n","\t\tAfter adaption: PDE loss: 0.0090466782675262\n","\t\tAfter adaption: Data loss: 0.008124910601032482\n","\n","\tTesting: Initial condition loss: 0.0060164108872413635\n","\tTesting: Boundary condition loss: 0.007858866825699806\n","\tTesting: PDE loss: 0.02027183212339878\n","\tTesting: Data loss: 0.023307854309678078\n","\n","Epoch 631\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005795939359813929\n","\tBefore adaption: Boundary condition loss: 0.00738845719024539\n","\tBefore adaption: PDE loss: 0.020200686529278755\n","\tBefore adaption: Data loss: 0.023119507357478142\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1136, 0.1099, 0.4055, 0.3709], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006371295538851567\n","\t\tAfter adaption: Boundary condition loss: 0.0008392024803155261\n","\t\tAfter adaption: PDE loss: 0.008192291862643393\n","\t\tAfter adaption: Data loss: 0.008576060598601403\n","\n","\tTesting: Initial condition loss: 0.004099714569747448\n","\tTesting: Boundary condition loss: 0.005994792096316814\n","\tTesting: PDE loss: 0.019805902615189552\n","\tTesting: Data loss: 0.020580999553203583\n","\n","Epoch 632\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004345531575381756\n","\tBefore adaption: Boundary condition loss: 0.005612548440694809\n","\tBefore adaption: PDE loss: 0.019736072048544884\n","\tBefore adaption: Data loss: 0.02040485478937626\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0056, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1250, 0.1065, 0.3796, 0.3890], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004627822743335324\n","\t\tAfter adaption: Boundary condition loss: 0.0007014039473634266\n","\t\tAfter adaption: PDE loss: 0.007491273528428375\n","\t\tAfter adaption: Data loss: 0.007936679416431633\n","\n","\tTesting: Initial condition loss: 0.002367603126913309\n","\tTesting: Boundary condition loss: 0.0038526093121618032\n","\tTesting: PDE loss: 0.019235605373978615\n","\tTesting: Data loss: 0.016691820695996284\n","\n","Epoch 633\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003146512433886528\n","\tBefore adaption: Boundary condition loss: 0.0035786652006208897\n","\tBefore adaption: PDE loss: 0.01916046068072319\n","\tBefore adaption: Data loss: 0.01653638854622841\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1277, 0.1041, 0.3697, 0.3985], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00032754430303628425\n","\t\tAfter adaption: Boundary condition loss: 0.00045699050884674886\n","\t\tAfter adaption: PDE loss: 0.007083181751085597\n","\t\tAfter adaption: Data loss: 0.006590191481319413\n","\n","\tTesting: Initial condition loss: 0.0019365862244740129\n","\tTesting: Boundary condition loss: 0.002040077233687043\n","\tTesting: PDE loss: 0.018604427576065063\n","\tTesting: Data loss: 0.012577504850924015\n","\n","Epoch 634\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0030869687907397747\n","\tBefore adaption: Boundary condition loss: 0.0018699828069657087\n","\tBefore adaption: PDE loss: 0.018529944121837616\n","\tBefore adaption: Data loss: 0.012447991408407688\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1224, 0.0992, 0.3773, 0.4011], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003062789416901747\n","\t\tAfter adaption: Boundary condition loss: 0.00022881631059930535\n","\t\tAfter adaption: PDE loss: 0.006990820007844317\n","\t\tAfter adaption: Data loss: 0.004993496630919201\n","\n","\tTesting: Initial condition loss: 0.003584214486181736\n","\tTesting: Boundary condition loss: 0.0008277677115984261\n","\tTesting: PDE loss: 0.01796543039381504\n","\tTesting: Data loss: 0.009024256840348244\n","\n","Epoch 635\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0047921775840222836\n","\tBefore adaption: Boundary condition loss: 0.0007378291338682175\n","\tBefore adaption: PDE loss: 0.017845528200268745\n","\tBefore adaption: Data loss: 0.008923008106648922\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1091, 0.0942, 0.4018, 0.3948], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00045149457705820264\n","\t\tAfter adaption: Boundary condition loss: 8.051667910145351e-05\n","\t\tAfter adaption: PDE loss: 0.007170655720579592\n","\t\tAfter adaption: Data loss: 0.003523163713959156\n","\n","\tTesting: Initial condition loss: 0.0074955434538424015\n","\tTesting: Boundary condition loss: 0.00025383001775480807\n","\tTesting: PDE loss: 0.017256198450922966\n","\tTesting: Data loss: 0.0064851148054003716\n","\n","Epoch 636\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008399484679102898\n","\tBefore adaption: Boundary condition loss: 0.00022871734108775854\n","\tBefore adaption: PDE loss: 0.01716187223792076\n","\tBefore adaption: Data loss: 0.006412282586097717\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0883, 0.0974, 0.4395, 0.3748], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008183339774065819\n","\t\tAfter adaption: Boundary condition loss: 2.0198834952769822e-05\n","\t\tAfter adaption: PDE loss: 0.0075421675109458184\n","\t\tAfter adaption: Data loss: 0.0024032417707300874\n","\n","\tTesting: Initial condition loss: 0.013212078250944614\n","\tTesting: Boundary condition loss: 0.0002281711931573227\n","\tTesting: PDE loss: 0.016535749658942223\n","\tTesting: Data loss: 0.005065969657152891\n","\n","Epoch 637\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013667638413608074\n","\tBefore adaption: Boundary condition loss: 0.00024729009601287544\n","\tBefore adaption: PDE loss: 0.016447661444544792\n","\tBefore adaption: Data loss: 0.005019885953515768\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0623, 0.1232, 0.4791, 0.3354], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016837864822267258\n","\t\tAfter adaption: Boundary condition loss: 1.5414016032578536e-05\n","\t\tAfter adaption: PDE loss: 0.007879984544859574\n","\t\tAfter adaption: Data loss: 0.0016835611719057068\n","\n","\tTesting: Initial condition loss: 0.01977388933300972\n","\tTesting: Boundary condition loss: 0.0005217582220211625\n","\tTesting: PDE loss: 0.015820810571312904\n","\tTesting: Data loss: 0.004598573315888643\n","\n","Epoch 638\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.019891025498509407\n","\tBefore adaption: Boundary condition loss: 0.0005679996102117002\n","\tBefore adaption: PDE loss: 0.015722420066595078\n","\tBefore adaption: Data loss: 0.004575112834572792\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0374, 0.1857, 0.5002, 0.2767], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0036933561042980663\n","\t\tAfter adaption: Boundary condition loss: 2.1230747956108932e-05\n","\t\tAfter adaption: PDE loss: 0.007864293562060736\n","\t\tAfter adaption: Data loss: 0.0012661440460955723\n","\n","\tTesting: Initial condition loss: 0.026014624163508415\n","\tTesting: Boundary condition loss: 0.0008913286146707833\n","\tTesting: PDE loss: 0.015151577070355415\n","\tTesting: Data loss: 0.004710329230874777\n","\n","Epoch 639\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02573312260210514\n","\tBefore adaption: Boundary condition loss: 0.0009524737833999097\n","\tBefore adaption: PDE loss: 0.015065912157297134\n","\tBefore adaption: Data loss: 0.0047035557217895985\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0207, 0.2823, 0.4854, 0.2116], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007264320717750686\n","\t\tAfter adaption: Boundary condition loss: 1.9697600795187642e-05\n","\t\tAfter adaption: PDE loss: 0.007313022137220491\n","\t\tAfter adaption: Data loss: 0.0009953796349683193\n","\n","\tTesting: Initial condition loss: 0.02984466962516308\n","\tTesting: Boundary condition loss: 0.0011103071738034487\n","\tTesting: PDE loss: 0.01469009555876255\n","\tTesting: Data loss: 0.004928900394588709\n","\n","Epoch 640\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029489755630493164\n","\tBefore adaption: Boundary condition loss: 0.0011770289856940508\n","\tBefore adaption: PDE loss: 0.014617602340877056\n","\tBefore adaption: Data loss: 0.004931553732603788\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0146, 0.3875, 0.4395, 0.1583], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011427576353100365\n","\t\tAfter adaption: Boundary condition loss: 1.7199867819801256e-05\n","\t\tAfter adaption: PDE loss: 0.00642502300022899\n","\t\tAfter adaption: Data loss: 0.0007808454533195105\n","\n","\tTesting: Initial condition loss: 0.029577123001217842\n","\tTesting: Boundary condition loss: 0.0010295829270035028\n","\tTesting: PDE loss: 0.014593781903386116\n","\tTesting: Data loss: 0.004880832973867655\n","\n","Epoch 641\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02951829694211483\n","\tBefore adaption: Boundary condition loss: 0.0010952777229249477\n","\tBefore adaption: PDE loss: 0.01452604215592146\n","\tBefore adaption: Data loss: 0.004884293302893639\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0155, 0.4742, 0.3853, 0.1250], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013996401875831982\n","\t\tAfter adaption: Boundary condition loss: 1.6951402965700387e-05\n","\t\tAfter adaption: PDE loss: 0.005597318643751434\n","\t\tAfter adaption: Data loss: 0.0006106969623376481\n","\n","\tTesting: Initial condition loss: 0.024941163137555122\n","\tTesting: Boundary condition loss: 0.0006801362615078688\n","\tTesting: PDE loss: 0.014946709387004375\n","\tTesting: Data loss: 0.0045624589547514915\n","\n","Epoch 642\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025509577244520187\n","\tBefore adaption: Boundary condition loss: 0.00073629105463624\n","\tBefore adaption: PDE loss: 0.01486811414361\n","\tBefore adaption: Data loss: 0.004558016546070576\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0181, 0.5311, 0.3426, 0.1082], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013546887081998683\n","\t\tAfter adaption: Boundary condition loss: 1.3345836830789686e-05\n","\t\tAfter adaption: PDE loss: 0.005094496837904109\n","\t\tAfter adaption: Data loss: 0.0004930734320433283\n","\n","\tTesting: Initial condition loss: 0.017485035583376884\n","\tTesting: Boundary condition loss: 0.00030002626590430737\n","\tTesting: PDE loss: 0.015713928267359734\n","\tTesting: Data loss: 0.004431656561791897\n","\n","Epoch 643\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018791284412145615\n","\tBefore adaption: Boundary condition loss: 0.0003318709786981344\n","\tBefore adaption: PDE loss: 0.015620431862771511\n","\tBefore adaption: Data loss: 0.004410779569298029\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0194, 0.5584, 0.3207, 0.1014], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010493303235216023\n","\t\tAfter adaption: Boundary condition loss: 6.445740852420093e-06\n","\t\tAfter adaption: PDE loss: 0.005010064622450207\n","\t\tAfter adaption: Data loss: 0.0004473683609341551\n","\n","\tTesting: Initial condition loss: 0.009921204298734665\n","\tTesting: Boundary condition loss: 0.00026245444314554334\n","\tTesting: PDE loss: 0.01678306795656681\n","\tTesting: Data loss: 0.005178096238523722\n","\n","Epoch 644\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011697588488459587\n","\tBefore adaption: Boundary condition loss: 0.00024379976093769073\n","\tBefore adaption: PDE loss: 0.0166934821754694\n","\tBefore adaption: Data loss: 0.005133987870067358\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0185, 0.5575, 0.3225, 0.1014], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006521408939869655\n","\t\tAfter adaption: Boundary condition loss: 4.519547680486692e-06\n","\t\tAfter adaption: PDE loss: 0.005384228906910587\n","\t\tAfter adaption: Data loss: 0.0005207236991966566\n","\n","\tTesting: Initial condition loss: 0.004575685132294893\n","\tTesting: Boundary condition loss: 0.0009261782397516072\n","\tTesting: PDE loss: 0.01797804795205593\n","\tTesting: Data loss: 0.007324842270463705\n","\n","Epoch 645\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006467130966484547\n","\tBefore adaption: Boundary condition loss: 0.0008226604550145566\n","\tBefore adaption: PDE loss: 0.017907021567225456\n","\tBefore adaption: Data loss: 0.007252981420606375\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0164, 0.5256, 0.3487, 0.1093], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003399121846795956\n","\t\tAfter adaption: Boundary condition loss: 1.3472898256001777e-05\n","\t\tAfter adaption: PDE loss: 0.0062447696763326946\n","\t\tAfter adaption: Data loss: 0.0007926773486496713\n","\n","\tTesting: Initial condition loss: 0.0025945764500647783\n","\tTesting: Boundary condition loss: 0.002395526273176074\n","\tTesting: PDE loss: 0.019126046448946\n","\tTesting: Data loss: 0.010875637643039227\n","\n","Epoch 646\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004057310521602631\n","\tBefore adaption: Boundary condition loss: 0.0021746638230979443\n","\tBefore adaption: PDE loss: 0.01904839277267456\n","\tBefore adaption: Data loss: 0.010774658061563969\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0161, 0.4574, 0.3960, 0.1305], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018559232041183808\n","\t\tAfter adaption: Boundary condition loss: 3.493513469615219e-05\n","\t\tAfter adaption: PDE loss: 0.007543099069354619\n","\t\tAfter adaption: Data loss: 0.00140621748815598\n","\n","\tTesting: Initial condition loss: 0.003259860910475254\n","\tTesting: Boundary condition loss: 0.004492755047976971\n","\tTesting: PDE loss: 0.019982552155852318\n","\tTesting: Data loss: 0.015246981754899025\n","\n","Epoch 647\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004012612160295248\n","\tBefore adaption: Boundary condition loss: 0.004147863015532494\n","\tBefore adaption: PDE loss: 0.01992550492286682\n","\tBefore adaption: Data loss: 0.015118810348212719\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0230, 0.3554, 0.4498, 0.1718], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001426143603730464\n","\t\tAfter adaption: Boundary condition loss: 9.55466032063438e-05\n","\t\tAfter adaption: PDE loss: 0.00896240092869864\n","\t\tAfter adaption: Data loss: 0.0025967147488636737\n","\n","\tTesting: Initial condition loss: 0.005045544356107712\n","\tTesting: Boundary condition loss: 0.006716773379594088\n","\tTesting: PDE loss: 0.02048940770328045\n","\tTesting: Data loss: 0.01949993520975113\n","\n","Epoch 648\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005098902620375156\n","\tBefore adaption: Boundary condition loss: 0.006255572661757469\n","\tBefore adaption: PDE loss: 0.020445361733436584\n","\tBefore adaption: Data loss: 0.019348565489053726\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0418, 0.2437, 0.4832, 0.2313], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012427055175497142\n","\t\tAfter adaption: Boundary condition loss: 0.00026161756082495707\n","\t\tAfter adaption: PDE loss: 0.00987922603813051\n","\t\tAfter adaption: Data loss: 0.004474485121951342\n","\n","\tTesting: Initial condition loss: 0.006506563629955053\n","\tTesting: Boundary condition loss: 0.008357471786439419\n","\tTesting: PDE loss: 0.020634545013308525\n","\tTesting: Data loss: 0.02265036851167679\n","\n","Epoch 649\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006104752421379089\n","\tBefore adaption: Boundary condition loss: 0.007830804213881493\n","\tBefore adaption: PDE loss: 0.020604921504855156\n","\tBefore adaption: Data loss: 0.02248360402882099\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0694, 0.1593, 0.4782, 0.2931], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009721923144833306\n","\t\tAfter adaption: Boundary condition loss: 0.0005434215214265099\n","\t\tAfter adaption: PDE loss: 0.009853753614620854\n","\t\tAfter adaption: Data loss: 0.006590604431909923\n","\n","\tTesting: Initial condition loss: 0.0067808968015015125\n","\tTesting: Boundary condition loss: 0.00879912544041872\n","\tTesting: PDE loss: 0.020494895055890083\n","\tTesting: Data loss: 0.023921890184283257\n","\n","Epoch 650\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006246635690331459\n","\tBefore adaption: Boundary condition loss: 0.008268201723694801\n","\tBefore adaption: PDE loss: 0.020481392741203308\n","\tBefore adaption: Data loss: 0.023749860003590584\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0966, 0.1170, 0.4454, 0.3411], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007308931276855486\n","\t\tAfter adaption: Boundary condition loss: 0.0007983521740231503\n","\t\tAfter adaption: PDE loss: 0.009122101524254257\n","\t\tAfter adaption: Data loss: 0.008099940438774567\n","\n","\tTesting: Initial condition loss: 0.005721379537135363\n","\tTesting: Boundary condition loss: 0.007824237458407879\n","\tTesting: PDE loss: 0.02017010562121868\n","\tTesting: Data loss: 0.022989511489868164\n","\n","Epoch 651\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005385155323892832\n","\tBefore adaption: Boundary condition loss: 0.0073505728505551815\n","\tBefore adaption: PDE loss: 0.020146863535046577\n","\tBefore adaption: Data loss: 0.022823160514235497\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0074, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1165, 0.1036, 0.4082, 0.3717], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005580808965141054\n","\t\tAfter adaption: Boundary condition loss: 0.0008562335886908183\n","\t\tAfter adaption: PDE loss: 0.008224430716819522\n","\t\tAfter adaption: Data loss: 0.00848239719723864\n","\n","\tTesting: Initial condition loss: 0.0038708471693098545\n","\tTesting: Boundary condition loss: 0.005819740239530802\n","\tTesting: PDE loss: 0.019743435084819794\n","\tTesting: Data loss: 0.020129859447479248\n","\n","Epoch 652\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004002979025244713\n","\tBefore adaption: Boundary condition loss: 0.005445306189358234\n","\tBefore adaption: PDE loss: 0.01967739872634411\n","\tBefore adaption: Data loss: 0.0199778750538826\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1273, 0.1010, 0.3822, 0.3895], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00040422481641136474\n","\t\tAfter adaption: Boundary condition loss: 0.0006934353867033854\n","\t\tAfter adaption: PDE loss: 0.007519802682440763\n","\t\tAfter adaption: Data loss: 0.007781761503609765\n","\n","\tTesting: Initial condition loss: 0.0022628584410995245\n","\tTesting: Boundary condition loss: 0.003544802078977227\n","\tTesting: PDE loss: 0.019217537716031075\n","\tTesting: Data loss: 0.01612536795437336\n","\n","Epoch 653\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002964565996080637\n","\tBefore adaption: Boundary condition loss: 0.003286602906882763\n","\tBefore adaption: PDE loss: 0.019141975790262222\n","\tBefore adaption: Data loss: 0.015994597226381302\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0033, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1294, 0.0988, 0.3729, 0.3989], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00029278586293793036\n","\t\tAfter adaption: Boundary condition loss: 0.0004251479999014231\n","\t\tAfter adaption: PDE loss: 0.007138851514371279\n","\t\tAfter adaption: Data loss: 0.006380850793897689\n","\n","\tTesting: Initial condition loss: 0.0019789403304457664\n","\tTesting: Boundary condition loss: 0.001692958758212626\n","\tTesting: PDE loss: 0.018667422235012054\n","\tTesting: Data loss: 0.01193972211331129\n","\n","Epoch 654\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0031700849067419767\n","\tBefore adaption: Boundary condition loss: 0.0015449130441993475\n","\tBefore adaption: PDE loss: 0.018567310646176338\n","\tBefore adaption: Data loss: 0.011834659613668919\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1228, 0.0943, 0.3819, 0.4010], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002989329289479471\n","\t\tAfter adaption: Boundary condition loss: 0.0001897855744605029\n","\t\tAfter adaption: PDE loss: 0.007090564568224847\n","\t\tAfter adaption: Data loss: 0.0047453664874772435\n","\n","\tTesting: Initial condition loss: 0.0037177265621721745\n","\tTesting: Boundary condition loss: 0.0005699432222172618\n","\tTesting: PDE loss: 0.018045373260974884\n","\tTesting: Data loss: 0.008384711109101772\n","\n","Epoch 655\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005218966398388147\n","\tBefore adaption: Boundary condition loss: 0.000511606631334871\n","\tBefore adaption: PDE loss: 0.017975779250264168\n","\tBefore adaption: Data loss: 0.008304581046104431\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1079, 0.0907, 0.4083, 0.3932], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004732593889382069\n","\t\tAfter adaption: Boundary condition loss: 5.518701240657622e-05\n","\t\tAfter adaption: PDE loss: 0.007339250437239704\n","\t\tAfter adaption: Data loss: 0.0032650588545866926\n","\n","\tTesting: Initial condition loss: 0.0076402840204536915\n","\tTesting: Boundary condition loss: 0.00020723517809528857\n","\tTesting: PDE loss: 0.017412904649972916\n","\tTesting: Data loss: 0.005918421316891909\n","\n","Epoch 656\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009224032051861286\n","\tBefore adaption: Boundary condition loss: 0.00021505594486370683\n","\tBefore adaption: PDE loss: 0.017340628430247307\n","\tBefore adaption: Data loss: 0.005861448124051094\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0850, 0.0972, 0.4477, 0.3700], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008968560620017606\n","\t\tAfter adaption: Boundary condition loss: 1.8285598575138462e-05\n","\t\tAfter adaption: PDE loss: 0.007764255012663283\n","\t\tAfter adaption: Data loss: 0.0021686940655977994\n","\n","\tTesting: Initial condition loss: 0.01336502656340599\n","\tTesting: Boundary condition loss: 0.00043277189251966774\n","\tTesting: PDE loss: 0.016729680821299553\n","\tTesting: Data loss: 0.004626964218914509\n","\n","Epoch 657\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014824013225734234\n","\tBefore adaption: Boundary condition loss: 0.00047990441089496017\n","\tBefore adaption: PDE loss: 0.01665244624018669\n","\tBefore adaption: Data loss: 0.0045913527719676495\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0578, 0.1292, 0.4873, 0.3257], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001915251381015844\n","\t\tAfter adaption: Boundary condition loss: 2.7753286122406607e-05\n","\t\tAfter adaption: PDE loss: 0.008114763438661653\n","\t\tAfter adaption: Data loss: 0.0014952568608161563\n","\n","\tTesting: Initial condition loss: 0.019865619018673897\n","\tTesting: Boundary condition loss: 0.0009434414096176624\n","\tTesting: PDE loss: 0.015988299623131752\n","\tTesting: Data loss: 0.004292398691177368\n","\n","Epoch 658\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021281614899635315\n","\tBefore adaption: Boundary condition loss: 0.001008054707199335\n","\tBefore adaption: PDE loss: 0.015899568796157837\n","\tBefore adaption: Data loss: 0.004274720326066017\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0340, 0.1992, 0.5047, 0.2621], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004240079484244758\n","\t\tAfter adaption: Boundary condition loss: 3.4250336657439704e-05\n","\t\tAfter adaption: PDE loss: 0.00802447933716377\n","\t\tAfter adaption: Data loss: 0.0011203545934280882\n","\n","\tTesting: Initial condition loss: 0.025519920513033867\n","\tTesting: Boundary condition loss: 0.0014299398753792048\n","\tTesting: PDE loss: 0.015309065580368042\n","\tTesting: Data loss: 0.004488691221922636\n","\n","Epoch 659\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027030954137444496\n","\tBefore adaption: Boundary condition loss: 0.0014992516953498125\n","\tBefore adaption: PDE loss: 0.015217024832963943\n","\tBefore adaption: Data loss: 0.0044839936308562756\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0210, 0.3005, 0.4835, 0.1950], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008123529890302081\n","\t\tAfter adaption: Boundary condition loss: 3.152528441040445e-05\n","\t\tAfter adaption: PDE loss: 0.0073571675981096325\n","\t\tAfter adaption: Data loss: 0.0008742118576366284\n","\n","\tTesting: Initial condition loss: 0.028491077944636345\n","\tTesting: Boundary condition loss: 0.0016162224346771836\n","\tTesting: PDE loss: 0.014840451069176197\n","\tTesting: Data loss: 0.004721125587821007\n","\n","Epoch 660\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03020472265779972\n","\tBefore adaption: Boundary condition loss: 0.0016836589202284813\n","\tBefore adaption: PDE loss: 0.01474019605666399\n","\tBefore adaption: Data loss: 0.0047227186150848866\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0194, 0.4044, 0.4329, 0.1433], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012214403373447452\n","\t\tAfter adaption: Boundary condition loss: 3.258098483714377e-05\n","\t\tAfter adaption: PDE loss: 0.006381347312869242\n","\t\tAfter adaption: Data loss: 0.0006769533950431065\n","\n","\tTesting: Initial condition loss: 0.027344876900315285\n","\tTesting: Boundary condition loss: 0.0013691504718735814\n","\tTesting: PDE loss: 0.014713090844452381\n","\tTesting: Data loss: 0.004668332636356354\n","\n","Epoch 661\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02934129908680916\n","\tBefore adaption: Boundary condition loss: 0.0014306750381365418\n","\tBefore adaption: PDE loss: 0.01461434829980135\n","\tBefore adaption: Data loss: 0.004668519366532564\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0231, 0.4857, 0.3779, 0.1133], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014250759029086625\n","\t\tAfter adaption: Boundary condition loss: 3.308581410106706e-05\n","\t\tAfter adaption: PDE loss: 0.005523062271358221\n","\t\tAfter adaption: Data loss: 0.0005287741462469881\n","\n","\tTesting: Initial condition loss: 0.02219032496213913\n","\tTesting: Boundary condition loss: 0.0008107592002488673\n","\tTesting: PDE loss: 0.015013602562248707\n","\tTesting: Data loss: 0.004449328873306513\n","\n","Epoch 662\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02445484697818756\n","\tBefore adaption: Boundary condition loss: 0.0008613054524175823\n","\tBefore adaption: PDE loss: 0.01491081714630127\n","\tBefore adaption: Data loss: 0.004440103191882372\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0267, 0.5367, 0.3372, 0.0994], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013125468270912693\n","\t\tAfter adaption: Boundary condition loss: 2.2978295202323004e-05\n","\t\tAfter adaption: PDE loss: 0.005027577218880087\n","\t\tAfter adaption: Data loss: 0.0004414450801746813\n","\n","\tTesting: Initial condition loss: 0.014831122010946274\n","\tTesting: Boundary condition loss: 0.00029349070973694324\n","\tTesting: PDE loss: 0.015698622912168503\n","\tTesting: Data loss: 0.004637214820832014\n","\n","Epoch 663\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.017302032560110092\n","\tBefore adaption: Boundary condition loss: 0.000322455249261111\n","\tBefore adaption: PDE loss: 0.015604998916387558\n","\tBefore adaption: Data loss: 0.004610792268067598\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0274, 0.5590, 0.3183, 0.0954], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009671749398288697\n","\t\tAfter adaption: Boundary condition loss: 8.82674881784433e-06\n","\t\tAfter adaption: PDE loss: 0.004966329202354825\n","\t\tAfter adaption: Data loss: 0.00043977178436218267\n","\n","\tTesting: Initial condition loss: 0.007943203672766685\n","\tTesting: Boundary condition loss: 0.00025399087462574244\n","\tTesting: PDE loss: 0.01663624309003353\n","\tTesting: Data loss: 0.005940707866102457\n","\n","Epoch 664\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01043359749019146\n","\tBefore adaption: Boundary condition loss: 0.00023570616031065583\n","\tBefore adaption: PDE loss: 0.016568100079894066\n","\tBefore adaption: Data loss: 0.005891910754144192\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0250, 0.5529, 0.3234, 0.0987], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00576920028411446\n","\t\tAfter adaption: Boundary condition loss: 5.885054803491773e-06\n","\t\tAfter adaption: PDE loss: 0.005357312294414067\n","\t\tAfter adaption: Data loss: 0.0005817466265216734\n","\n","\tTesting: Initial condition loss: 0.003808770328760147\n","\tTesting: Boundary condition loss: 0.0010280467104166746\n","\tTesting: PDE loss: 0.017649073153734207\n","\tTesting: Data loss: 0.008760850876569748\n","\n","Epoch 665\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005836102180182934\n","\tBefore adaption: Boundary condition loss: 0.0009298159857280552\n","\tBefore adaption: PDE loss: 0.017588214948773384\n","\tBefore adaption: Data loss: 0.008687594905495644\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0209, 0.5149, 0.3521, 0.1121], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0030047529962234534\n","\t\tAfter adaption: Boundary condition loss: 1.942153788300366e-05\n","\t\tAfter adaption: PDE loss: 0.006193611453316683\n","\t\tAfter adaption: Data loss: 0.0009739713922031672\n","\n","\tTesting: Initial condition loss: 0.002696976298466325\n","\tTesting: Boundary condition loss: 0.0026771854609251022\n","\tTesting: PDE loss: 0.018586864694952965\n","\tTesting: Data loss: 0.012897913344204426\n","\n","Epoch 666\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004059400409460068\n","\tBefore adaption: Boundary condition loss: 0.00248250225558877\n","\tBefore adaption: PDE loss: 0.01850462518632412\n","\tBefore adaption: Data loss: 0.012798107229173183\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0190, 0.4396, 0.3990, 0.1424], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017843316502574298\n","\t\tAfter adaption: Boundary condition loss: 4.7221548754015245e-05\n","\t\tAfter adaption: PDE loss: 0.007383539152664953\n","\t\tAfter adaption: Data loss: 0.0018226047770176822\n","\n","\tTesting: Initial condition loss: 0.0037472343537956476\n","\tTesting: Boundary condition loss: 0.004925226327031851\n","\tTesting: PDE loss: 0.01924617402255535\n","\tTesting: Data loss: 0.01758301630616188\n","\n","Epoch 667\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004372213501483202\n","\tBefore adaption: Boundary condition loss: 0.004623343702405691\n","\tBefore adaption: PDE loss: 0.019187334924936295\n","\tBefore adaption: Data loss: 0.01745717227458954\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0259, 0.3327, 0.4460, 0.1953], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0014546979305031474\n","\t\tAfter adaption: Boundary condition loss: 0.00011978114140721898\n","\t\tAfter adaption: PDE loss: 0.008558303452150395\n","\t\tAfter adaption: Data loss: 0.003410055012294453\n","\n","\tTesting: Initial condition loss: 0.005430746357887983\n","\tTesting: Boundary condition loss: 0.00705766212195158\n","\tTesting: PDE loss: 0.01959921605885029\n","\tTesting: Data loss: 0.021751057356595993\n","\n","Epoch 668\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005457176361232996\n","\tBefore adaption: Boundary condition loss: 0.006672480143606663\n","\tBefore adaption: PDE loss: 0.019565189257264137\n","\tBefore adaption: Data loss: 0.02160453423857689\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0458, 0.2239, 0.4665, 0.2638], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012217520887071423\n","\t\tAfter adaption: Boundary condition loss: 0.0003058544916260811\n","\t\tAfter adaption: PDE loss: 0.009127566520466882\n","\t\tAfter adaption: Data loss: 0.005698431301912739\n","\n","\tTesting: Initial condition loss: 0.006470170803368092\n","\tTesting: Boundary condition loss: 0.008316460996866226\n","\tTesting: PDE loss: 0.019698403775691986\n","\tTesting: Data loss: 0.024383079260587692\n","\n","Epoch 669\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0062036700546741486\n","\tBefore adaption: Boundary condition loss: 0.007898503914475441\n","\tBefore adaption: PDE loss: 0.019652973860502243\n","\tBefore adaption: Data loss: 0.024224350228905678\n","tensor(0.0079, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0079, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0736, 0.1485, 0.4504, 0.3274], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000921263498280868\n","\t\tAfter adaption: Boundary condition loss: 0.0005815808145489378\n","\t\tAfter adaption: PDE loss: 0.00885264797584263\n","\t\tAfter adaption: Data loss: 0.00793145774425742\n","\n","\tTesting: Initial condition loss: 0.006247388198971748\n","\tTesting: Boundary condition loss: 0.008175746537744999\n","\tTesting: PDE loss: 0.01956009678542614\n","\tTesting: Data loss: 0.02479124628007412\n","\n","Epoch 670\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006029223091900349\n","\tBefore adaption: Boundary condition loss: 0.0077808513306081295\n","\tBefore adaption: PDE loss: 0.019529111683368683\n","\tBefore adaption: Data loss: 0.02462981641292572\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0992, 0.1138, 0.4148, 0.3722], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006859144633912927\n","\t\tAfter adaption: Boundary condition loss: 0.0007721161116529067\n","\t\tAfter adaption: PDE loss: 0.008100719393651045\n","\t\tAfter adaption: Data loss: 0.009167210120624155\n","\n","\tTesting: Initial condition loss: 0.004875728860497475\n","\tTesting: Boundary condition loss: 0.006699531804770231\n","\tTesting: PDE loss: 0.019286684691905975\n","\tTesting: Data loss: 0.02289297617971897\n","\n","Epoch 671\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004990056157112122\n","\tBefore adaption: Boundary condition loss: 0.006371141877025366\n","\tBefore adaption: PDE loss: 0.01925087161362171\n","\tBefore adaption: Data loss: 0.022738423198461533\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1166, 0.1033, 0.3815, 0.3986], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005156106254943606\n","\t\tAfter adaption: Boundary condition loss: 0.0007425713252928937\n","\t\tAfter adaption: PDE loss: 0.0073448043339068405\n","\t\tAfter adaption: Data loss: 0.009063282338412203\n","\n","\tTesting: Initial condition loss: 0.0031036483123898506\n","\tTesting: Boundary condition loss: 0.00452939560636878\n","\tTesting: PDE loss: 0.018913747742772102\n","\tTesting: Data loss: 0.019264517351984978\n","\n","Epoch 672\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003707127645611763\n","\tBefore adaption: Boundary condition loss: 0.00429258868098259\n","\tBefore adaption: PDE loss: 0.018873561173677444\n","\tBefore adaption: Data loss: 0.019124839454889297\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1243, 0.1008, 0.3622, 0.4126], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003738134665943915\n","\t\tAfter adaption: Boundary condition loss: 0.0005336221033032493\n","\t\tAfter adaption: PDE loss: 0.0068367990860677555\n","\t\tAfter adaption: Data loss: 0.007891077801657228\n","\n","\tTesting: Initial condition loss: 0.0020171913783997297\n","\tTesting: Boundary condition loss: 0.0024713289458304644\n","\tTesting: PDE loss: 0.018486101180315018\n","\tTesting: Data loss: 0.014881676994264126\n","\n","Epoch 673\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0031149480491876602\n","\tBefore adaption: Boundary condition loss: 0.002319185994565487\n","\tBefore adaption: PDE loss: 0.018440034240484238\n","\tBefore adaption: Data loss: 0.014763317070901394\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1229, 0.0982, 0.3606, 0.4183], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00030599196970124273\n","\t\tAfter adaption: Boundary condition loss: 0.00028506852976973744\n","\t\tAfter adaption: PDE loss: 0.006649452586325411\n","\t\tAfter adaption: Data loss: 0.006174760294405602\n","\n","\tTesting: Initial condition loss: 0.0025946905370801687\n","\tTesting: Boundary condition loss: 0.0010211176704615355\n","\tTesting: PDE loss: 0.018043508753180504\n","\tTesting: Data loss: 0.010734849609434605\n","\n","Epoch 674\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00398936215788126\n","\tBefore adaption: Boundary condition loss: 0.0009430702193640172\n","\tBefore adaption: PDE loss: 0.01798083819448948\n","\tBefore adaption: Data loss: 0.010641228407621384\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1129, 0.0947, 0.3770, 0.4154], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00037773676978728664\n","\t\tAfter adaption: Boundary condition loss: 0.00010644585026152755\n","\t\tAfter adaption: PDE loss: 0.006779157383438754\n","\t\tAfter adaption: Data loss: 0.004420589536904364\n","\n","\tTesting: Initial condition loss: 0.005313791334629059\n","\tTesting: Boundary condition loss: 0.00029399277991615236\n","\tTesting: PDE loss: 0.017597639933228493\n","\tTesting: Data loss: 0.007514502853155136\n","\n","Epoch 675\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006696643773466349\n","\tBefore adaption: Boundary condition loss: 0.00027841218980029225\n","\tBefore adaption: PDE loss: 0.017519725486636162\n","\tBefore adaption: Data loss: 0.00744617311283946\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0946, 0.0951, 0.4099, 0.4004], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006369732261196448\n","\t\tAfter adaption: Boundary condition loss: 2.633133793305227e-05\n","\t\tAfter adaption: PDE loss: 0.007181417477488361\n","\t\tAfter adaption: Data loss: 0.002981447783002824\n","\n","\tTesting: Initial condition loss: 0.010081157088279724\n","\tTesting: Boundary condition loss: 0.0002483678690623492\n","\tTesting: PDE loss: 0.017092717811465263\n","\tTesting: Data loss: 0.005502578802406788\n","\n","Epoch 676\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011176271364092827\n","\tBefore adaption: Boundary condition loss: 0.0002701545017771423\n","\tBefore adaption: PDE loss: 0.01703246682882309\n","\tBefore adaption: Data loss: 0.00545767555013299\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0698, 0.1106, 0.4525, 0.3671], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012357396224302788\n","\t\tAfter adaption: Boundary condition loss: 1.8857852479928614e-05\n","\t\tAfter adaption: PDE loss: 0.007707190056549594\n","\t\tAfter adaption: Data loss: 0.002003663991249363\n","\n","\tTesting: Initial condition loss: 0.01610850729048252\n","\tTesting: Boundary condition loss: 0.0006639512721449137\n","\tTesting: PDE loss: 0.016584672033786774\n","\tTesting: Data loss: 0.004619470331817865\n","\n","Epoch 677\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016889365389943123\n","\tBefore adaption: Boundary condition loss: 0.0007043212535791099\n","\tBefore adaption: PDE loss: 0.016507336869835854\n","\tBefore adaption: Data loss: 0.004595986567437649\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0440, 0.1558, 0.4882, 0.3119], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0026321436187386354\n","\t\tAfter adaption: Boundary condition loss: 3.100575557507444e-05\n","\t\tAfter adaption: PDE loss: 0.008058611045203357\n","\t\tAfter adaption: Data loss: 0.0014337076415667364\n","\n","\tTesting: Initial condition loss: 0.02236267179250717\n","\tTesting: Boundary condition loss: 0.0012520909076556563\n","\tTesting: PDE loss: 0.01608332432806492\n","\tTesting: Data loss: 0.004534472245723009\n","\n","Epoch 678\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022795826196670532\n","\tBefore adaption: Boundary condition loss: 0.0013023033970966935\n","\tBefore adaption: PDE loss: 0.015982866287231445\n","\tBefore adaption: Data loss: 0.004529230762273073\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0255, 0.2369, 0.4949, 0.2426], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005399867297537042\n","\t\tAfter adaption: Boundary condition loss: 3.3263439928551565e-05\n","\t\tAfter adaption: PDE loss: 0.007910477886497229\n","\t\tAfter adaption: Data loss: 0.0010989870055082677\n","\n","\tTesting: Initial condition loss: 0.02721388451755047\n","\tTesting: Boundary condition loss: 0.0017266640206798911\n","\tTesting: PDE loss: 0.0156626608222723\n","\tTesting: Data loss: 0.004774761851876974\n","\n","Epoch 679\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02739882841706276\n","\tBefore adaption: Boundary condition loss: 0.001781111815944314\n","\tBefore adaption: PDE loss: 0.015567028895020485\n","\tBefore adaption: Data loss: 0.004782214295119047\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0191, 0.3369, 0.4653, 0.1787], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009229975745820115\n","\t\tAfter adaption: Boundary condition loss: 3.4094128175164705e-05\n","\t\tAfter adaption: PDE loss: 0.007242772031722596\n","\t\tAfter adaption: Data loss: 0.0008546736903639385\n","\n","\tTesting: Initial condition loss: 0.028974562883377075\n","\tTesting: Boundary condition loss: 0.0018655710155144334\n","\tTesting: PDE loss: 0.015486326068639755\n","\tTesting: Data loss: 0.004883126355707645\n","\n","Epoch 680\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02914596162736416\n","\tBefore adaption: Boundary condition loss: 0.0019211091566830873\n","\tBefore adaption: PDE loss: 0.01539176981896162\n","\tBefore adaption: Data loss: 0.0048965876922011375\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0218, 0.4276, 0.4157, 0.1349], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012464167543631253\n","\t\tAfter adaption: Boundary condition loss: 4.1916603337581e-05\n","\t\tAfter adaption: PDE loss: 0.00639773080445626\n","\t\tAfter adaption: Data loss: 0.000660427832047377\n","\n","\tTesting: Initial condition loss: 0.026646291837096214\n","\tTesting: Boundary condition loss: 0.0015867905458435416\n","\tTesting: PDE loss: 0.01567094214260578\n","\tTesting: Data loss: 0.004641139414161444\n","\n","Epoch 681\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027140790596604347\n","\tBefore adaption: Boundary condition loss: 0.0016405436908826232\n","\tBefore adaption: PDE loss: 0.01557591650635004\n","\tBefore adaption: Data loss: 0.004652323201298714\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0274, 0.4925, 0.3689, 0.1112], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013368027703823233\n","\t\tAfter adaption: Boundary condition loss: 4.495927806970897e-05\n","\t\tAfter adaption: PDE loss: 0.005745401724588832\n","\t\tAfter adaption: Data loss: 0.0005172752435852345\n","\n","\tTesting: Initial condition loss: 0.020748145878314972\n","\tTesting: Boundary condition loss: 0.0010165506973862648\n","\tTesting: PDE loss: 0.016264384612441063\n","\tTesting: Data loss: 0.004243458155542612\n","\n","Epoch 682\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021830353885889053\n","\tBefore adaption: Boundary condition loss: 0.001064170035533607\n","\tBefore adaption: PDE loss: 0.016170771792531013\n","\tBefore adaption: Data loss: 0.004244040697813034\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0315, 0.5292, 0.3388, 0.1006], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011552366125175595\n","\t\tAfter adaption: Boundary condition loss: 3.352963242931746e-05\n","\t\tAfter adaption: PDE loss: 0.0054779034829038386\n","\t\tAfter adaption: Data loss: 0.0004267400541743399\n","\n","\tTesting: Initial condition loss: 0.013387829065322876\n","\tTesting: Boundary condition loss: 0.00046155668678693473\n","\tTesting: PDE loss: 0.01719839870929718\n","\tTesting: Data loss: 0.0042468486353755\n","\n","Epoch 683\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015014052391052246\n","\tBefore adaption: Boundary condition loss: 0.0004941304214298725\n","\tBefore adaption: PDE loss: 0.01712276041507721\n","\tBefore adaption: Data loss: 0.004230752121657133\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0324, 0.5397, 0.3308, 0.0971], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00810290467795313\n","\t\tAfter adaption: Boundary condition loss: 1.601473415132053e-05\n","\t\tAfter adaption: PDE loss: 0.005663766480056505\n","\t\tAfter adaption: Data loss: 0.00041092304167117795\n","\n","\tTesting: Initial condition loss: 0.007000443059951067\n","\tTesting: Boundary condition loss: 0.0003010484215337783\n","\tTesting: PDE loss: 0.018357712775468826\n","\tTesting: Data loss: 0.005278246942907572\n","\n","Epoch 684\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008910703472793102\n","\tBefore adaption: Boundary condition loss: 0.0002941806160379201\n","\tBefore adaption: PDE loss: 0.018276719376444817\n","\tBefore adaption: Data loss: 0.005240753758698702\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0300, 0.5240, 0.3469, 0.0991], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00466906715270593\n","\t\tAfter adaption: Boundary condition loss: 8.823059053685692e-06\n","\t\tAfter adaption: PDE loss: 0.00634037893471518\n","\t\tAfter adaption: Data loss: 0.000519429750636634\n","\n","\tTesting: Initial condition loss: 0.0033339515794068575\n","\tTesting: Boundary condition loss: 0.0008409666479565203\n","\tTesting: PDE loss: 0.01951642520725727\n","\tTesting: Data loss: 0.007651861757040024\n","\n","Epoch 685\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005088125821202993\n","\tBefore adaption: Boundary condition loss: 0.0007644311990588903\n","\tBefore adaption: PDE loss: 0.01946488581597805\n","\tBefore adaption: Data loss: 0.007589774671941996\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0254, 0.4785, 0.3870, 0.1091], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00243463275178842\n","\t\tAfter adaption: Boundary condition loss: 1.940691072511242e-05\n","\t\tAfter adaption: PDE loss: 0.0075334850398328925\n","\t\tAfter adaption: Data loss: 0.0008279673474283046\n","\n","\tTesting: Initial condition loss: 0.0026321581099182367\n","\tTesting: Boundary condition loss: 0.0021137420553714037\n","\tTesting: PDE loss: 0.02051834762096405\n","\tTesting: Data loss: 0.011169033125042915\n","\n","Epoch 686\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0038017078768461943\n","\tBefore adaption: Boundary condition loss: 0.001943627605214715\n","\tBefore adaption: PDE loss: 0.02047167345881462\n","\tBefore adaption: Data loss: 0.011082305572926998\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0219, 0.4002, 0.4447, 0.1333], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015215021854687468\n","\t\tAfter adaption: Boundary condition loss: 4.248063073735618e-05\n","\t\tAfter adaption: PDE loss: 0.009103105755211133\n","\t\tAfter adaption: Data loss: 0.0014768232450930348\n","\n","\tTesting: Initial condition loss: 0.0038365533109754324\n","\tTesting: Boundary condition loss: 0.0039183939807116985\n","\tTesting: PDE loss: 0.021221188828349113\n","\tTesting: Data loss: 0.01517095323652029\n","\n","Epoch 687\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004280322231352329\n","\tBefore adaption: Boundary condition loss: 0.0036485898308455944\n","\tBefore adaption: PDE loss: 0.021155929192900658\n","\tBefore adaption: Data loss: 0.015061978250741959\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0249, 0.2983, 0.4999, 0.1769], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001276823500298871\n","\t\tAfter adaption: Boundary condition loss: 9.088550776346206e-05\n","\t\tAfter adaption: PDE loss: 0.01057546842243947\n","\t\tAfter adaption: Data loss: 0.0026645718550468373\n","\n","\tTesting: Initial condition loss: 0.005546675994992256\n","\tTesting: Boundary condition loss: 0.005755085963755846\n","\tTesting: PDE loss: 0.021493466570973396\n","\tTesting: Data loss: 0.01880675181746483\n","\n","Epoch 688\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005364343989640474\n","\tBefore adaption: Boundary condition loss: 0.0053965370170772076\n","\tBefore adaption: PDE loss: 0.021456405520439148\n","\tBefore adaption: Data loss: 0.018679820001125336\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0388, 0.2015, 0.5247, 0.2349], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001081170985403518\n","\t\tAfter adaption: Boundary condition loss: 0.0002096321419041512\n","\t\tAfter adaption: PDE loss: 0.011257885211555475\n","\t\tAfter adaption: Data loss: 0.004388262189891426\n","\n","\tTesting: Initial condition loss: 0.006603354122489691\n","\tTesting: Boundary condition loss: 0.0069992332719266415\n","\tTesting: PDE loss: 0.021424265578389168\n","\tTesting: Data loss: 0.0212690606713295\n","\n","Epoch 689\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006087211426347494\n","\tBefore adaption: Boundary condition loss: 0.006600356660783291\n","\tBefore adaption: PDE loss: 0.02137952856719494\n","\tBefore adaption: Data loss: 0.021129991859197617\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0609, 0.1386, 0.5093, 0.2913], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008434033131070358\n","\t\tAfter adaption: Boundary condition loss: 0.0004016461162903439\n","\t\tAfter adaption: PDE loss: 0.010889303276793154\n","\t\tAfter adaption: Data loss: 0.006154344036760043\n","\n","\tTesting: Initial condition loss: 0.006476429291069508\n","\tTesting: Boundary condition loss: 0.007156992331147194\n","\tTesting: PDE loss: 0.02105564810335636\n","\tTesting: Data loss: 0.02196829952299595\n","\n","Epoch 690\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005963335745036602\n","\tBefore adaption: Boundary condition loss: 0.00677100382745266\n","\tBefore adaption: PDE loss: 0.021008960902690887\n","\tBefore adaption: Data loss: 0.021824851632118225\n","tensor(0.0068, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0068, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0833, 0.1116, 0.4714, 0.3337], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006657832273894389\n","\t\tAfter adaption: Boundary condition loss: 0.0005636965199366166\n","\t\tAfter adaption: PDE loss: 0.00990436167369536\n","\t\tAfter adaption: Data loss: 0.007282233145339465\n","\n","\tTesting: Initial condition loss: 0.005242510233074427\n","\tTesting: Boundary condition loss: 0.0061306036077439785\n","\tTesting: PDE loss: 0.02046048827469349\n","\tTesting: Data loss: 0.020713813602924347\n","\n","Epoch 691\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005070027895271778\n","\tBefore adaption: Boundary condition loss: 0.005805023480206728\n","\tBefore adaption: PDE loss: 0.020417800173163414\n","\tBefore adaption: Data loss: 0.020574970170855522\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1002, 0.1049, 0.4338, 0.3611], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005316242762850727\n","\t\tAfter adaption: Boundary condition loss: 0.0005816545560132706\n","\t\tAfter adaption: PDE loss: 0.00885734858029946\n","\t\tAfter adaption: Data loss: 0.007430440477177829\n","\n","\tTesting: Initial condition loss: 0.003576227929443121\n","\tTesting: Boundary condition loss: 0.004308761563152075\n","\tTesting: PDE loss: 0.019611645489931107\n","\tTesting: Data loss: 0.017842942848801613\n","\n","Epoch 692\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003989731427282095\n","\tBefore adaption: Boundary condition loss: 0.004077249672263861\n","\tBefore adaption: PDE loss: 0.019575873389840126\n","\tBefore adaption: Data loss: 0.01771767996251583\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0041, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1095, 0.1039, 0.4091, 0.3776], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00041437630087497857\n","\t\tAfter adaption: Boundary condition loss: 0.0004465420194809579\n","\t\tAfter adaption: PDE loss: 0.00800754461046461\n","\t\tAfter adaption: Data loss: 0.0066896110560178005\n","\n","\tTesting: Initial condition loss: 0.0024916352704167366\n","\tTesting: Boundary condition loss: 0.00240117940120399\n","\tTesting: PDE loss: 0.018648438155651093\n","\tTesting: Data loss: 0.01414784137159586\n","\n","Epoch 693\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036595962010324\n","\tBefore adaption: Boundary condition loss: 0.0022612125612795353\n","\tBefore adaption: PDE loss: 0.018605483695864677\n","\tBefore adaption: Data loss: 0.014042813330888748\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1107, 0.1023, 0.4010, 0.3860], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003742186997158834\n","\t\tAfter adaption: Boundary condition loss: 0.00025023800333951997\n","\t\tAfter adaption: PDE loss: 0.007461421225789208\n","\t\tAfter adaption: Data loss: 0.005421145637935733\n","\n","\tTesting: Initial condition loss: 0.0030271823052316904\n","\tTesting: Boundary condition loss: 0.0009418880799785256\n","\tTesting: PDE loss: 0.017621587961912155\n","\tTesting: Data loss: 0.010509449988603592\n","\n","Epoch 694\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0049171457067132\n","\tBefore adaption: Boundary condition loss: 0.0008712054695934057\n","\tBefore adaption: PDE loss: 0.0175790935754776\n","\tBefore adaption: Data loss: 0.010427681729197502\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1035, 0.1005, 0.4095, 0.3865], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004939673123163931\n","\t\tAfter adaption: Boundary condition loss: 9.015560154871829e-05\n","\t\tAfter adaption: PDE loss: 0.007199398708017491\n","\t\tAfter adaption: Data loss: 0.0040304521585180116\n","\n","\tTesting: Initial condition loss: 0.005792033392935991\n","\tTesting: Boundary condition loss: 0.00020620852592401206\n","\tTesting: PDE loss: 0.016550125554203987\n","\tTesting: Data loss: 0.007608369924128056\n","\n","Epoch 695\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008306151255965233\n","\tBefore adaption: Boundary condition loss: 0.00019068390247412026\n","\tBefore adaption: PDE loss: 0.016521571204066277\n","\tBefore adaption: Data loss: 0.007549813948571682\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0879, 0.1048, 0.4316, 0.3757], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008705833772880005\n","\t\tAfter adaption: Boundary condition loss: 1.6756102434790342e-05\n","\t\tAfter adaption: PDE loss: 0.007131225800140792\n","\t\tAfter adaption: Data loss: 0.0028363365097829355\n","\n","\tTesting: Initial condition loss: 0.010639773681759834\n","\tTesting: Boundary condition loss: 0.00015247408009599894\n","\tTesting: PDE loss: 0.015545187518000603\n","\tTesting: Data loss: 0.00576768396422267\n","\n","Epoch 696\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013640704564750195\n","\tBefore adaption: Boundary condition loss: 0.00016408086230512708\n","\tBefore adaption: PDE loss: 0.015507638454437256\n","\tBefore adaption: Data loss: 0.005730489268898964\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0653, 0.1283, 0.4586, 0.3478], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017505039314578371\n","\t\tAfter adaption: Boundary condition loss: 1.0717791105175718e-05\n","\t\tAfter adaption: PDE loss: 0.00711135164824977\n","\t\tAfter adaption: Data loss: 0.0019929452202443296\n","\n","\tTesting: Initial condition loss: 0.016814520582556725\n","\tTesting: Boundary condition loss: 0.0005471868207678199\n","\tTesting: PDE loss: 0.014636671170592308\n","\tTesting: Data loss: 0.0049566361121833324\n","\n","Epoch 697\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020146716386079788\n","\tBefore adaption: Boundary condition loss: 0.0005641473107971251\n","\tBefore adaption: PDE loss: 0.014581562019884586\n","\tBefore adaption: Data loss: 0.0049377246759831905\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0408, 0.1862, 0.4737, 0.2992], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0037520742092686994\n","\t\tAfter adaption: Boundary condition loss: 2.302511556233451e-05\n","\t\tAfter adaption: PDE loss: 0.006907479309019281\n","\t\tAfter adaption: Data loss: 0.0014775397948373055\n","\n","\tTesting: Initial condition loss: 0.022900400683283806\n","\tTesting: Boundary condition loss: 0.0010710355127230287\n","\tTesting: PDE loss: 0.01387273333966732\n","\tTesting: Data loss: 0.00486677186563611\n","\n","Epoch 698\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026403699070215225\n","\tBefore adaption: Boundary condition loss: 0.0010828233789652586\n","\tBefore adaption: PDE loss: 0.013825244270265102\n","\tBefore adaption: Data loss: 0.004861727822571993\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0225, 0.2812, 0.4595, 0.2368], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007425384945361207\n","\t\tAfter adaption: Boundary condition loss: 2.4342720598651735e-05\n","\t\tAfter adaption: PDE loss: 0.006352210081167001\n","\t\tAfter adaption: Data loss: 0.0011513990010087313\n","\n","\tTesting: Initial condition loss: 0.026844460517168045\n","\tTesting: Boundary condition loss: 0.0013955984031781554\n","\tTesting: PDE loss: 0.013390649110078812\n","\tTesting: Data loss: 0.005025976337492466\n","\n","Epoch 699\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030494023114442825\n","\tBefore adaption: Boundary condition loss: 0.0014019017107784748\n","\tBefore adaption: PDE loss: 0.01333565078675747\n","\tBefore adaption: Data loss: 0.005028955172747374\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0153, 0.3910, 0.4154, 0.1784], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011922980876317952\n","\t\tAfter adaption: Boundary condition loss: 2.144302844349452e-05\n","\t\tAfter adaption: PDE loss: 0.00553903788997864\n","\t\tAfter adaption: Data loss: 0.0008969362140842195\n","\n","\tTesting: Initial condition loss: 0.026831181719899178\n","\tTesting: Boundary condition loss: 0.001296497299335897\n","\tTesting: PDE loss: 0.01327871810644865\n","\tTesting: Data loss: 0.005033801309764385\n","\n","Epoch 700\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030637163668870926\n","\tBefore adaption: Boundary condition loss: 0.0013033432187512517\n","\tBefore adaption: PDE loss: 0.013231800869107246\n","\tBefore adaption: Data loss: 0.005037363152951002\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0167, 0.4847, 0.3610, 0.1375], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014851106826503464\n","\t\tAfter adaption: Boundary condition loss: 2.1712482258603445e-05\n","\t\tAfter adaption: PDE loss: 0.00477733626982181\n","\t\tAfter adaption: Data loss: 0.0006928869257465236\n","\n","\tTesting: Initial condition loss: 0.022435929626226425\n","\tTesting: Boundary condition loss: 0.0007995018968358636\n","\tTesting: PDE loss: 0.013630388304591179\n","\tTesting: Data loss: 0.0048965453170239925\n","\n","Epoch 701\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02633856236934662\n","\tBefore adaption: Boundary condition loss: 0.0008120610727928579\n","\tBefore adaption: PDE loss: 0.01359244342893362\n","\tBefore adaption: Data loss: 0.0048926942981779575\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0203, 0.5469, 0.3175, 0.1153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01440389014003724\n","\t\tAfter adaption: Boundary condition loss: 1.6522228908424963e-05\n","\t\tAfter adaption: PDE loss: 0.004315396990282778\n","\t\tAfter adaption: Data loss: 0.0005640990274423544\n","\n","\tTesting: Initial condition loss: 0.015238179825246334\n","\tTesting: Boundary condition loss: 0.00023664206673856825\n","\tTesting: PDE loss: 0.014464748091995716\n","\tTesting: Data loss: 0.005160716827958822\n","\n","Epoch 702\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01899632252752781\n","\tBefore adaption: Boundary condition loss: 0.000251982914051041\n","\tBefore adaption: PDE loss: 0.01442691683769226\n","\tBefore adaption: Data loss: 0.005141707602888346\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0222, 0.5766, 0.2948, 0.1064], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010952900919701958\n","\t\tAfter adaption: Boundary condition loss: 5.595154587184899e-06\n","\t\tAfter adaption: PDE loss: 0.004252660610959919\n","\t\tAfter adaption: Data loss: 0.0005472965232269112\n","\n","\tTesting: Initial condition loss: 0.008123443461954594\n","\tTesting: Boundary condition loss: 0.0001283263845834881\n","\tTesting: PDE loss: 0.01568976230919361\n","\tTesting: Data loss: 0.006631775759160519\n","\n","Epoch 703\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01128404401242733\n","\tBefore adaption: Boundary condition loss: 0.00012160701589891687\n","\tBefore adaption: PDE loss: 0.015661107376217842\n","\tBefore adaption: Data loss: 0.006590839475393295\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0210, 0.5751, 0.2959, 0.1080], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006489408131747893\n","\t\tAfter adaption: Boundary condition loss: 2.552630982822404e-06\n","\t\tAfter adaption: PDE loss: 0.004634532237358928\n","\t\tAfter adaption: Data loss: 0.0007117235807381298\n","\n","\tTesting: Initial condition loss: 0.003612725529819727\n","\tTesting: Boundary condition loss: 0.0009241912048310041\n","\tTesting: PDE loss: 0.017131991684436798\n","\tTesting: Data loss: 0.009827339090406895\n","\n","Epoch 704\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005821003578603268\n","\tBefore adaption: Boundary condition loss: 0.0008522344869561493\n","\tBefore adaption: PDE loss: 0.017103131860494614\n","\tBefore adaption: Data loss: 0.009759997949004173\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0178, 0.5388, 0.3213, 0.1221], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031361813376082444\n","\t\tAfter adaption: Boundary condition loss: 1.5168710166613896e-05\n","\t\tAfter adaption: PDE loss: 0.005495769026168417\n","\t\tAfter adaption: Data loss: 0.001191695751300424\n","\n","\tTesting: Initial condition loss: 0.0025996544864028692\n","\tTesting: Boundary condition loss: 0.0027279756031930447\n","\tTesting: PDE loss: 0.018470296636223793\n","\tTesting: Data loss: 0.014506001025438309\n","\n","Epoch 705\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037273361813277006\n","\tBefore adaption: Boundary condition loss: 0.002564180176705122\n","\tBefore adaption: PDE loss: 0.018446722999215126\n","\tBefore adaption: Data loss: 0.014411515556275845\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0166, 0.4611, 0.3667, 0.1557], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017185147504532314\n","\t\tAfter adaption: Boundary condition loss: 4.2445925582141656e-05\n","\t\tAfter adaption: PDE loss: 0.0067645680585699565\n","\t\tAfter adaption: Data loss: 0.002243597283585977\n","\n","\tTesting: Initial condition loss: 0.0039045752491801977\n","\tTesting: Boundary condition loss: 0.005075118038803339\n","\tTesting: PDE loss: 0.019540008157491684\n","\tTesting: Data loss: 0.019648699089884758\n","\n","Epoch 706\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004041908774524927\n","\tBefore adaption: Boundary condition loss: 0.004803455900400877\n","\tBefore adaption: PDE loss: 0.019491860643029213\n","\tBefore adaption: Data loss: 0.019530203193426132\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0241, 0.3467, 0.4154, 0.2139], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001401139657100587\n","\t\tAfter adaption: Boundary condition loss: 0.00011587531225930202\n","\t\tAfter adaption: PDE loss: 0.008096159453563977\n","\t\tAfter adaption: Data loss: 0.004176776417864035\n","\n","\tTesting: Initial condition loss: 0.0057132914662361145\n","\tTesting: Boundary condition loss: 0.007081484422087669\n","\tTesting: PDE loss: 0.020225320011377335\n","\tTesting: Data loss: 0.023924628272652626\n","\n","Epoch 707\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0051481109112501144\n","\tBefore adaption: Boundary condition loss: 0.0067280251532793045\n","\tBefore adaption: PDE loss: 0.020165491849184036\n","\tBefore adaption: Data loss: 0.023789184167981148\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0445, 0.2271, 0.4411, 0.2872], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001169249539417037\n","\t\tAfter adaption: Boundary condition loss: 0.0002995503763369707\n","\t\tAfter adaption: PDE loss: 0.008895372086087837\n","\t\tAfter adaption: Data loss: 0.006833119068299544\n","\n","\tTesting: Initial condition loss: 0.0065413061529397964\n","\tTesting: Boundary condition loss: 0.00790528953075409\n","\tTesting: PDE loss: 0.020510194823145866\n","\tTesting: Data loss: 0.026185328140854836\n","\n","Epoch 708\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0057023861445486546\n","\tBefore adaption: Boundary condition loss: 0.007525175344198942\n","\tBefore adaption: PDE loss: 0.020475106313824654\n","\tBefore adaption: Data loss: 0.026041699573397636\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0717, 0.1428, 0.4327, 0.3528], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000814449302672107\n","\t\tAfter adaption: Boundary condition loss: 0.0005398869508764365\n","\t\tAfter adaption: PDE loss: 0.008858869966380184\n","\t\tAfter adaption: Data loss: 0.009186579621901208\n","\n","\tTesting: Initial condition loss: 0.005846611689776182\n","\tTesting: Boundary condition loss: 0.007215894293040037\n","\tTesting: PDE loss: 0.020515521988272667\n","\tTesting: Data loss: 0.025833042338490486\n","\n","Epoch 709\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005139470100402832\n","\tBefore adaption: Boundary condition loss: 0.006872640922665596\n","\tBefore adaption: PDE loss: 0.020497502759099007\n","\tBefore adaption: Data loss: 0.025690479204058647\n","tensor(0.0069, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0069, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0952, 0.1034, 0.4052, 0.3962], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005316599695575498\n","\t\tAfter adaption: Boundary condition loss: 0.000654044311239819\n","\t\tAfter adaption: PDE loss: 0.008305508769102476\n","\t\tAfter adaption: Data loss: 0.010178332271987469\n","\n","\tTesting: Initial condition loss: 0.003987006843090057\n","\tTesting: Boundary condition loss: 0.005357956513762474\n","\tTesting: PDE loss: 0.02034158445894718\n","\tTesting: Data loss: 0.023036761209368706\n","\n","Epoch 710\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003713928861543536\n","\tBefore adaption: Boundary condition loss: 0.005096641834825277\n","\tBefore adaption: PDE loss: 0.020302321761846542\n","\tBefore adaption: Data loss: 0.0229032002389431\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0051, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1092, 0.0911, 0.3798, 0.4198], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003382366733313986\n","\t\tAfter adaption: Boundary condition loss: 0.0005568049520788636\n","\t\tAfter adaption: PDE loss: 0.0077118129526373745\n","\t\tAfter adaption: Data loss: 0.009615430879681539\n","\n","\tTesting: Initial condition loss: 0.0019829447846859694\n","\tTesting: Boundary condition loss: 0.0031419575680047274\n","\tTesting: PDE loss: 0.02001979574561119\n","\tTesting: Data loss: 0.0186464861035347\n","\n","Epoch 711\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0022639669477939606\n","\tBefore adaption: Boundary condition loss: 0.0029715020209550858\n","\tBefore adaption: PDE loss: 0.01995965465903282\n","\tBefore adaption: Data loss: 0.0185273177921772\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1134, 0.0868, 0.3688, 0.4311], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0001964130916202994\n","\t\tAfter adaption: Boundary condition loss: 0.0003368742664963521\n","\t\tAfter adaption: PDE loss: 0.00736024018775338\n","\t\tAfter adaption: Data loss: 0.007987486463802282\n","\n","\tTesting: Initial condition loss: 0.0011046906001865864\n","\tTesting: Boundary condition loss: 0.0013421234907582402\n","\tTesting: PDE loss: 0.019581662490963936\n","\tTesting: Data loss: 0.013819687068462372\n","\n","Epoch 712\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0018513161921873689\n","\tBefore adaption: Boundary condition loss: 0.0012469306821003556\n","\tBefore adaption: PDE loss: 0.019512029364705086\n","\tBefore adaption: Data loss: 0.013717475347220898\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1083, 0.0815, 0.3762, 0.4340], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00015088618777807527\n","\t\tAfter adaption: Boundary condition loss: 0.00013506321704030157\n","\t\tAfter adaption: PDE loss: 0.007340012630954893\n","\t\tAfter adaption: Data loss: 0.005953416058191676\n","\n","\tTesting: Initial condition loss: 0.0022864702623337507\n","\tTesting: Boundary condition loss: 0.00031952225253917277\n","\tTesting: PDE loss: 0.019064506515860558\n","\tTesting: Data loss: 0.009573442861437798\n","\n","Epoch 713\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0032682567834854126\n","\tBefore adaption: Boundary condition loss: 0.00029044836992397904\n","\tBefore adaption: PDE loss: 0.01899312622845173\n","\tBefore adaption: Data loss: 0.009490543976426125\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0948, 0.0747, 0.4030, 0.4275], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00024406572349117413\n","\t\tAfter adaption: Boundary condition loss: 2.7547265463376943e-05\n","\t\tAfter adaption: PDE loss: 0.0076533474132563705\n","\t\tAfter adaption: Data loss: 0.0040574418119384914\n","\n","\tTesting: Initial condition loss: 0.005902207922190428\n","\tTesting: Boundary condition loss: 6.621186912525445e-05\n","\tTesting: PDE loss: 0.01846969500184059\n","\tTesting: Data loss: 0.006513065658509731\n","\n","Epoch 714\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0067826686426997185\n","\tBefore adaption: Boundary condition loss: 7.294821989489719e-05\n","\tBefore adaption: PDE loss: 0.018398918211460114\n","\tBefore adaption: Data loss: 0.006450182758271694\n","tensor(7.2948e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(7.2948e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0741, 0.0730, 0.4466, 0.4063], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004953840300914273\n","\t\tAfter adaption: Boundary condition loss: 5.406912096686144e-06\n","\t\tAfter adaption: PDE loss: 0.008216041316880994\n","\t\tAfter adaption: Data loss: 0.00262066364884798\n","\n","\tTesting: Initial condition loss: 0.01164654828608036\n","\tTesting: Boundary condition loss: 0.0004112541791982949\n","\tTesting: PDE loss: 0.017822202295064926\n","\tTesting: Data loss: 0.0047994512133300304\n","\n","Epoch 715\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012166904285550117\n","\tBefore adaption: Boundary condition loss: 0.00043363735312595963\n","\tBefore adaption: PDE loss: 0.01773122139275074\n","\tBefore adaption: Data loss: 0.004755367059260607\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0494, 0.0913, 0.4963, 0.3630], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011110032165286424\n","\t\tAfter adaption: Boundary condition loss: 2.1432596606050428e-05\n","\t\tAfter adaption: PDE loss: 0.008799827669410629\n","\t\tAfter adaption: Data loss: 0.0017260605449355908\n","\n","\tTesting: Initial condition loss: 0.018683375790715218\n","\tTesting: Boundary condition loss: 0.0010886047966778278\n","\tTesting: PDE loss: 0.01708132214844227\n","\tTesting: Data loss: 0.004248577635735273\n","\n","Epoch 716\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018800634890794754\n","\tBefore adaption: Boundary condition loss: 0.0011145705357193947\n","\tBefore adaption: PDE loss: 0.016987355425953865\n","\tBefore adaption: Data loss: 0.004221727140247822\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0280, 0.1472, 0.5289, 0.2959], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0027677982355015776\n","\t\tAfter adaption: Boundary condition loss: 3.1249022113441475e-05\n","\t\tAfter adaption: PDE loss: 0.008984290633316688\n","\t\tAfter adaption: Data loss: 0.0012490549202586261\n","\n","\tTesting: Initial condition loss: 0.025745220482349396\n","\tTesting: Boundary condition loss: 0.0017784344963729382\n","\tTesting: PDE loss: 0.016295533627271652\n","\tTesting: Data loss: 0.004443669226020575\n","\n","Epoch 717\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025555888190865517\n","\tBefore adaption: Boundary condition loss: 0.001802846440114081\n","\tBefore adaption: PDE loss: 0.016220280900597572\n","\tBefore adaption: Data loss: 0.004431486129760742\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0179, 0.2432, 0.5198, 0.2191], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006215741475240249\n","\t\tAfter adaption: Boundary condition loss: 3.2301244590486626e-05\n","\t\tAfter adaption: PDE loss: 0.008430903114430845\n","\t\tAfter adaption: Data loss: 0.0009708765932446672\n","\n","\tTesting: Initial condition loss: 0.030825961381196976\n","\tTesting: Boundary condition loss: 0.0021679713390767574\n","\tTesting: PDE loss: 0.015660559758543968\n","\tTesting: Data loss: 0.004827039781957865\n","\n","Epoch 718\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03063230589032173\n","\tBefore adaption: Boundary condition loss: 0.002190830884501338\n","\tBefore adaption: PDE loss: 0.015576347708702087\n","\tBefore adaption: Data loss: 0.004824917297810316\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0198, 0.3543, 0.4699, 0.1561], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01085194915593314\n","\t\tAfter adaption: Boundary condition loss: 4.3290329921432304e-05\n","\t\tAfter adaption: PDE loss: 0.007319240020823967\n","\t\tAfter adaption: Data loss: 0.0007530760650677044\n","\n","\tTesting: Initial condition loss: 0.031957246363162994\n","\tTesting: Boundary condition loss: 0.0020369940903037786\n","\tTesting: PDE loss: 0.015329658053815365\n","\tTesting: Data loss: 0.004892922006547451\n","\n","Epoch 719\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03205745667219162\n","\tBefore adaption: Boundary condition loss: 0.0020612908992916346\n","\tBefore adaption: PDE loss: 0.015249032527208328\n","\tBefore adaption: Data loss: 0.004895615857094526\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0021, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0268, 0.4493, 0.4059, 0.1180], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014402711740144132\n","\t\tAfter adaption: Boundary condition loss: 5.532923142066992e-05\n","\t\tAfter adaption: PDE loss: 0.0061896910344703794\n","\t\tAfter adaption: Data loss: 0.0005775482724224008\n","\n","\tTesting: Initial condition loss: 0.02831285074353218\n","\tTesting: Boundary condition loss: 0.0014056609943509102\n","\tTesting: PDE loss: 0.015426508150994778\n","\tTesting: Data loss: 0.004493535030633211\n","\n","Epoch 720\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029000332579016685\n","\tBefore adaption: Boundary condition loss: 0.0014336464228108525\n","\tBefore adaption: PDE loss: 0.015351301059126854\n","\tBefore adaption: Data loss: 0.004495491273701191\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0328, 0.5147, 0.3528, 0.0998], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01492534699551256\n","\t\tAfter adaption: Boundary condition loss: 4.703238009436988e-05\n","\t\tAfter adaption: PDE loss: 0.005415196922030755\n","\t\tAfter adaption: Data loss: 0.0004485635664849464\n","\n","\tTesting: Initial condition loss: 0.020892515778541565\n","\tTesting: Boundary condition loss: 0.0005967633915133774\n","\tTesting: PDE loss: 0.01600177399814129\n","\tTesting: Data loss: 0.004010673612356186\n","\n","Epoch 721\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022322313860058784\n","\tBefore adaption: Boundary condition loss: 0.0006230760482139885\n","\tBefore adaption: PDE loss: 0.015930762514472008\n","\tBefore adaption: Data loss: 0.00400516064837575\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0348, 0.5512, 0.3214, 0.0926], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01230380492918737\n","\t\tAfter adaption: Boundary condition loss: 2.1704739666597632e-05\n","\t\tAfter adaption: PDE loss: 0.0051199127363769515\n","\t\tAfter adaption: Data loss: 0.00037084219251583994\n","\n","\tTesting: Initial condition loss: 0.012516376562416553\n","\tTesting: Boundary condition loss: 0.00010767264029709622\n","\tTesting: PDE loss: 0.016951769590377808\n","\tTesting: Data loss: 0.004203504882752895\n","\n","Epoch 722\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014479699544608593\n","\tBefore adaption: Boundary condition loss: 0.00011789892596425489\n","\tBefore adaption: PDE loss: 0.016885822638869286\n","\tBefore adaption: Data loss: 0.004184666555374861\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0326, 0.5614, 0.3149, 0.0911], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008129535586538054\n","\t\tAfter adaption: Boundary condition loss: 3.8450007292580656e-06\n","\t\tAfter adaption: PDE loss: 0.0053168605647647355\n","\t\tAfter adaption: Data loss: 0.00038110665628129724\n","\n","\tTesting: Initial condition loss: 0.005956545006483793\n","\tTesting: Boundary condition loss: 0.00040169022395275533\n","\tTesting: PDE loss: 0.018105819821357727\n","\tTesting: Data loss: 0.005789716728031635\n","\n","Epoch 723\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008084902539849281\n","\tBefore adaption: Boundary condition loss: 0.0003610833373386413\n","\tBefore adaption: PDE loss: 0.01805347390472889\n","\tBefore adaption: Data loss: 0.0057510677725076675\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0272, 0.5438, 0.3342, 0.0948], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004396735405148198\n","\t\tAfter adaption: Boundary condition loss: 9.818179256824634e-06\n","\t\tAfter adaption: PDE loss: 0.006033291808358282\n","\t\tAfter adaption: Data loss: 0.0005451917875902515\n","\n","\tTesting: Initial condition loss: 0.0028040988836437464\n","\tTesting: Boundary condition loss: 0.0016855745343491435\n","\tTesting: PDE loss: 0.019301211461424828\n","\tTesting: Data loss: 0.008991471491754055\n","\n","Epoch 724\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00453242938965559\n","\tBefore adaption: Boundary condition loss: 0.0015513243852183223\n","\tBefore adaption: PDE loss: 0.019245514646172523\n","\tBefore adaption: Data loss: 0.008929459378123283\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0213, 0.4920, 0.3783, 0.1083], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022298220891249537\n","\t\tAfter adaption: Boundary condition loss: 3.311625253564602e-05\n","\t\tAfter adaption: PDE loss: 0.007281198412690651\n","\t\tAfter adaption: Data loss: 0.0009675054799607749\n","\n","\tTesting: Initial condition loss: 0.0028400958981364965\n","\tTesting: Boundary condition loss: 0.0038650536444038153\n","\tTesting: PDE loss: 0.02030078135430813\n","\tTesting: Data loss: 0.01340293139219284\n","\n","Epoch 725\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0038409805856645107\n","\tBefore adaption: Boundary condition loss: 0.003606508718803525\n","\tBefore adaption: PDE loss: 0.02027912624180317\n","\tBefore adaption: Data loss: 0.013316759839653969\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0209, 0.4013, 0.4376, 0.1401], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015415093679278413\n","\t\tAfter adaption: Boundary condition loss: 7.54665820008555e-05\n","\t\tAfter adaption: PDE loss: 0.008874721446281661\n","\t\tAfter adaption: Data loss: 0.0018658644362105662\n","\n","\tTesting: Initial condition loss: 0.0047062174417078495\n","\tTesting: Boundary condition loss: 0.006492635700851679\n","\tTesting: PDE loss: 0.020959699526429176\n","\tTesting: Data loss: 0.018130037933588028\n","\n","Epoch 726\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004958522506058216\n","\tBefore adaption: Boundary condition loss: 0.006099034566432238\n","\tBefore adaption: PDE loss: 0.020937426015734673\n","\tBefore adaption: Data loss: 0.018023893237113953\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0336, 0.2860, 0.4859, 0.1945], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001418245137332901\n","\t\tAfter adaption: Boundary condition loss: 0.00020517654610202526\n","\t\tAfter adaption: PDE loss: 0.01017261018979147\n","\t\tAfter adaption: Data loss: 0.0035052770501033965\n","\n","\tTesting: Initial condition loss: 0.00680512934923172\n","\tTesting: Boundary condition loss: 0.008837556466460228\n","\tTesting: PDE loss: 0.021207593381404877\n","\tTesting: Data loss: 0.02214120700955391\n","\n","Epoch 727\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00645621120929718\n","\tBefore adaption: Boundary condition loss: 0.008349007926881313\n","\tBefore adaption: PDE loss: 0.021170545369386673\n","\tBefore adaption: Data loss: 0.022019939497113228\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0607, 0.1856, 0.4938, 0.2598], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011984933869478127\n","\t\tAfter adaption: Boundary condition loss: 0.0005070781933819423\n","\t\tAfter adaption: PDE loss: 0.010453638646165254\n","\t\tAfter adaption: Data loss: 0.005721842145773143\n","\n","\tTesting: Initial condition loss: 0.00790566485375166\n","\tTesting: Boundary condition loss: 0.010182426311075687\n","\tTesting: PDE loss: 0.021071897819638252\n","\tTesting: Data loss: 0.024548405781388283\n","\n","Epoch 728\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0072786686941981316\n","\tBefore adaption: Boundary condition loss: 0.00966061931103468\n","\tBefore adaption: PDE loss: 0.02105259895324707\n","\tBefore adaption: Data loss: 0.02441779337823391\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0097, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0926, 0.1292, 0.4625, 0.3157], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009405844136398412\n","\t\tAfter adaption: Boundary condition loss: 0.0008948191467482388\n","\t\tAfter adaption: PDE loss: 0.009735975322988104\n","\t\tAfter adaption: Data loss: 0.007708453017330978\n","\n","\tTesting: Initial condition loss: 0.007489273324608803\n","\tTesting: Boundary condition loss: 0.01010197028517723\n","\tTesting: PDE loss: 0.020691990852355957\n","\tTesting: Data loss: 0.024814095348119736\n","\n","Epoch 729\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006962542422115803\n","\tBefore adaption: Boundary condition loss: 0.009605951607227325\n","\tBefore adaption: PDE loss: 0.02066536247730255\n","\tBefore adaption: Data loss: 0.0246812105178833\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0096, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1191, 0.1101, 0.4179, 0.3529], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007666211416290037\n","\t\tAfter adaption: Boundary condition loss: 0.0011440660325073549\n","\t\tAfter adaption: PDE loss: 0.008635188159719072\n","\t\tAfter adaption: Data loss: 0.008710876337564665\n","\n","\tTesting: Initial condition loss: 0.005798835773020983\n","\tTesting: Boundary condition loss: 0.00865321233868599\n","\tTesting: PDE loss: 0.02011215128004551\n","\tTesting: Data loss: 0.02292771078646183\n","\n","Epoch 730\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005674242042005062\n","\tBefore adaption: Boundary condition loss: 0.008231940679252148\n","\tBefore adaption: PDE loss: 0.020090142264962196\n","\tBefore adaption: Data loss: 0.0227995403110981\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0082, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1365, 0.1079, 0.3807, 0.3749], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006121043010938035\n","\t\tAfter adaption: Boundary condition loss: 0.0011237758782366976\n","\t\tAfter adaption: PDE loss: 0.00764919710221818\n","\t\tAfter adaption: Data loss: 0.008546811975917048\n","\n","\tTesting: Initial condition loss: 0.0037006824277341366\n","\tTesting: Boundary condition loss: 0.006383282132446766\n","\tTesting: PDE loss: 0.019434679299592972\n","\tTesting: Data loss: 0.019433772191405296\n","\n","Epoch 731\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004148644395172596\n","\tBefore adaption: Boundary condition loss: 0.00607548002153635\n","\tBefore adaption: PDE loss: 0.01939365081489086\n","\tBefore adaption: Data loss: 0.01931677758693695\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1451, 0.1083, 0.3593, 0.3872], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004494997290814577\n","\t\tAfter adaption: Boundary condition loss: 0.000881409451731117\n","\t\tAfter adaption: PDE loss: 0.006968757144540678\n","\t\tAfter adaption: Data loss: 0.007480283961790912\n","\n","\tTesting: Initial condition loss: 0.002323283115401864\n","\tTesting: Boundary condition loss: 0.004028702154755592\n","\tTesting: PDE loss: 0.01867697574198246\n","\tTesting: Data loss: 0.015218917280435562\n","\n","Epoch 732\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0033787712454795837\n","\tBefore adaption: Boundary condition loss: 0.003830075031146407\n","\tBefore adaption: PDE loss: 0.01863263174891472\n","\tBefore adaption: Data loss: 0.015117784030735493\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0038, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1455, 0.1059, 0.3553, 0.3932], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003579807876157902\n","\t\tAfter adaption: Boundary condition loss: 0.0005574385003168642\n","\t\tAfter adaption: PDE loss: 0.006620854469415609\n","\t\tAfter adaption: Data loss: 0.0059438722675333525\n","\n","\tTesting: Initial condition loss: 0.0026254451368004084\n","\tTesting: Boundary condition loss: 0.002101847669109702\n","\tTesting: PDE loss: 0.017900681123137474\n","\tTesting: Data loss: 0.011169143952429295\n","\n","Epoch 733\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0041689700447022915\n","\tBefore adaption: Boundary condition loss: 0.0019952799193561077\n","\tBefore adaption: PDE loss: 0.017839767038822174\n","\tBefore adaption: Data loss: 0.011087127961218357\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1380, 0.1013, 0.3683, 0.3924], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004221384190929554\n","\t\tAfter adaption: Boundary condition loss: 0.00027538254744459884\n","\t\tAfter adaption: PDE loss: 0.00657111517346475\n","\t\tAfter adaption: Data loss: 0.0043504194825100964\n","\n","\tTesting: Initial condition loss: 0.005160196218639612\n","\tTesting: Boundary condition loss: 0.0008101530256681144\n","\tTesting: PDE loss: 0.017114832997322083\n","\tTesting: Data loss: 0.007929970510303974\n","\n","Epoch 734\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006890146527439356\n","\tBefore adaption: Boundary condition loss: 0.000765850069001317\n","\tBefore adaption: PDE loss: 0.01704113371670246\n","\tBefore adaption: Data loss: 0.007867355830967426\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1220, 0.0998, 0.3965, 0.3816], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006879755989434083\n","\t\tAfter adaption: Boundary condition loss: 9.345787304510528e-05\n","\t\tAfter adaption: PDE loss: 0.006756652179155595\n","\t\tAfter adaption: Data loss: 0.0030024054575699195\n","\n","\tTesting: Initial condition loss: 0.009880241006612778\n","\tTesting: Boundary condition loss: 0.00017097365343943238\n","\tTesting: PDE loss: 0.016337426379323006\n","\tTesting: Data loss: 0.005798129364848137\n","\n","Epoch 735\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011469973251223564\n","\tBefore adaption: Boundary condition loss: 0.00016511010471731424\n","\tBefore adaption: PDE loss: 0.01625080779194832\n","\tBefore adaption: Data loss: 0.005754734855145216\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0975, 0.1132, 0.4339, 0.3554], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001298246477337398\n","\t\tAfter adaption: Boundary condition loss: 1.6097800983981854e-05\n","\t\tAfter adaption: PDE loss: 0.0070513691244502635\n","\t\tAfter adaption: Data loss: 0.0020452732128659495\n","\n","\tTesting: Initial condition loss: 0.016102446243166924\n","\tTesting: Boundary condition loss: 8.013295155251399e-05\n","\tTesting: PDE loss: 0.015542073175311089\n","\tTesting: Data loss: 0.004760307259857655\n","\n","Epoch 736\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01745934784412384\n","\tBefore adaption: Boundary condition loss: 8.906683069653809e-05\n","\tBefore adaption: PDE loss: 0.01546446979045868\n","\tBefore adaption: Data loss: 0.004734705667942762\n","tensor(8.9067e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.9067e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0671, 0.1572, 0.4664, 0.3093], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0027449099418942516\n","\t\tAfter adaption: Boundary condition loss: 5.977510951525185e-06\n","\t\tAfter adaption: PDE loss: 0.0072124391100123406\n","\t\tAfter adaption: Data loss: 0.0014643599040986993\n","\n","\tTesting: Initial condition loss: 0.02277548238635063\n","\tTesting: Boundary condition loss: 0.00030142825562506914\n","\tTesting: PDE loss: 0.014830546453595161\n","\tTesting: Data loss: 0.004557406529784203\n","\n","Epoch 737\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02380320057272911\n","\tBefore adaption: Boundary condition loss: 0.00031599056092090905\n","\tBefore adaption: PDE loss: 0.014742217026650906\n","\tBefore adaption: Data loss: 0.004547069314867258\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0380, 0.2410, 0.4735, 0.2475], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005735595713399066\n","\t\tAfter adaption: Boundary condition loss: 1.201619433945784e-05\n","\t\tAfter adaption: PDE loss: 0.006980742391639018\n","\t\tAfter adaption: Data loss: 0.0011253683437560402\n","\n","\tTesting: Initial condition loss: 0.028117960318922997\n","\tTesting: Boundary condition loss: 0.0005906884907744825\n","\tTesting: PDE loss: 0.014273354783654213\n","\tTesting: Data loss: 0.004756936337798834\n","\n","Epoch 738\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02900880016386509\n","\tBefore adaption: Boundary condition loss: 0.0006068349466659129\n","\tBefore adaption: PDE loss: 0.014189667999744415\n","\tBefore adaption: Data loss: 0.004757803864777088\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0183, 0.3497, 0.4458, 0.1862], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010144761740056912\n","\t\tAfter adaption: Boundary condition loss: 1.1078657154784882e-05\n","\t\tAfter adaption: PDE loss: 0.006325612825802976\n","\t\tAfter adaption: Data loss: 0.0008860932365053261\n","\n","\tTesting: Initial condition loss: 0.030195022001862526\n","\tTesting: Boundary condition loss: 0.0007217992097139359\n","\tTesting: PDE loss: 0.01404905691742897\n","\tTesting: Data loss: 0.004887237213551998\n","\n","Epoch 739\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03115888498723507\n","\tBefore adaption: Boundary condition loss: 0.0007385284989140928\n","\tBefore adaption: PDE loss: 0.013965013436973095\n","\tBefore adaption: Data loss: 0.0048934039659798145\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0099, 0.4525, 0.3965, 0.1411], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014099324316810179\n","\t\tAfter adaption: Boundary condition loss: 7.322127039453022e-06\n","\t\tAfter adaption: PDE loss: 0.005536478664106301\n","\t\tAfter adaption: Data loss: 0.0006906258294813347\n","\n","\tTesting: Initial condition loss: 0.02785515785217285\n","\tTesting: Boundary condition loss: 0.0005896605434827507\n","\tTesting: PDE loss: 0.014261658303439617\n","\tTesting: Data loss: 0.004698496777564287\n","\n","Epoch 740\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029120221734046936\n","\tBefore adaption: Boundary condition loss: 0.0006070822710171342\n","\tBefore adaption: PDE loss: 0.014180082827806473\n","\tBefore adaption: Data loss: 0.004702551290392876\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0089, 0.5274, 0.3484, 0.1153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01535932862749403\n","\t\tAfter adaption: Boundary condition loss: 5.429635059238827e-06\n","\t\tAfter adaption: PDE loss: 0.0049397083714441785\n","\t\tAfter adaption: Data loss: 0.0005419929887977959\n","\n","\tTesting: Initial condition loss: 0.021626366302371025\n","\tTesting: Boundary condition loss: 0.0002897113445214927\n","\tTesting: PDE loss: 0.01495148055255413\n","\tTesting: Data loss: 0.0043873353861272335\n","\n","Epoch 741\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023325446993112564\n","\tBefore adaption: Boundary condition loss: 0.0003063041949644685\n","\tBefore adaption: PDE loss: 0.014873377047479153\n","\tBefore adaption: Data loss: 0.004382256884127855\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0103, 0.5700, 0.3165, 0.1031], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013296523612733056\n","\t\tAfter adaption: Boundary condition loss: 3.151192463936522e-06\n","\t\tAfter adaption: PDE loss: 0.00470792280575206\n","\t\tAfter adaption: Data loss: 0.0004519630450936954\n","\n","\tTesting: Initial condition loss: 0.013682919554412365\n","\tTesting: Boundary condition loss: 9.00054510566406e-05\n","\tTesting: PDE loss: 0.016060231253504753\n","\tTesting: Data loss: 0.004554823972284794\n","\n","Epoch 742\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015778306871652603\n","\tBefore adaption: Boundary condition loss: 9.866384789347649e-05\n","\tBefore adaption: PDE loss: 0.015989303588867188\n","\tBefore adaption: Data loss: 0.004533920902758837\n","tensor(9.8664e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(9.8664e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0110, 0.5826, 0.3071, 0.0994], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00919202529779344\n","\t\tAfter adaption: Boundary condition loss: 1.0842480873435847e-06\n","\t\tAfter adaption: PDE loss: 0.0049097404075188365\n","\t\tAfter adaption: Data loss: 0.0004505484122377679\n","\n","\tTesting: Initial condition loss: 0.00688176741823554\n","\tTesting: Boundary condition loss: 0.00033866617013700306\n","\tTesting: PDE loss: 0.017430724576115608\n","\tTesting: Data loss: 0.005878988187760115\n","\n","Epoch 743\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009029124863445759\n","\tBefore adaption: Boundary condition loss: 0.00031693323398940265\n","\tBefore adaption: PDE loss: 0.017365209758281708\n","\tBefore adaption: Data loss: 0.005836872849613428\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0104, 0.5652, 0.3221, 0.1024], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005102963869472587\n","\t\tAfter adaption: Boundary condition loss: 3.287615116981293e-06\n","\t\tAfter adaption: PDE loss: 0.0055927409779331924\n","\t\tAfter adaption: Data loss: 0.0005976588467338657\n","\n","\tTesting: Initial condition loss: 0.0031455529388040304\n","\tTesting: Boundary condition loss: 0.0012511654058471322\n","\tTesting: PDE loss: 0.018870417028665543\n","\tTesting: Data loss: 0.008674896322190762\n","\n","Epoch 744\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004859193228185177\n","\tBefore adaption: Boundary condition loss: 0.001164721790701151\n","\tBefore adaption: PDE loss: 0.0187953170388937\n","\tBefore adaption: Data loss: 0.008607440628111362\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0098, 0.5133, 0.3616, 0.1153], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0024943200731804152\n","\t\tAfter adaption: Boundary condition loss: 1.1401601651408815e-05\n","\t\tAfter adaption: PDE loss: 0.006796469487878726\n","\t\tAfter adaption: Data loss: 0.0009923211866033088\n","\n","\tTesting: Initial condition loss: 0.002622724510729313\n","\tTesting: Boundary condition loss: 0.0028283412102609873\n","\tTesting: PDE loss: 0.02015640027821064\n","\tTesting: Data loss: 0.012664268724620342\n","\n","Epoch 745\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0035858391784131527\n","\tBefore adaption: Boundary condition loss: 0.002649248344823718\n","\tBefore adaption: PDE loss: 0.020082252100110054\n","\tBefore adaption: Data loss: 0.012571028433740139\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0129, 0.4234, 0.4189, 0.1448], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015183771115572953\n","\t\tAfter adaption: Boundary condition loss: 3.4080652083483245e-05\n","\t\tAfter adaption: PDE loss: 0.008413061459798803\n","\t\tAfter adaption: Data loss: 0.0018198858573769971\n","\n","\tTesting: Initial condition loss: 0.004183302167803049\n","\tTesting: Boundary condition loss: 0.004798291716724634\n","\tTesting: PDE loss: 0.02108735777437687\n","\tTesting: Data loss: 0.017069902271032333\n","\n","Epoch 746\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0043412065133452415\n","\tBefore adaption: Boundary condition loss: 0.00450530368834734\n","\tBefore adaption: PDE loss: 0.021049372851848602\n","\tBefore adaption: Data loss: 0.01695517636835575\n","tensor(0.0045, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0045, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0246, 0.3071, 0.4731, 0.1952], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013330807577137131\n","\t\tAfter adaption: Boundary condition loss: 0.00011098752003297896\n","\t\tAfter adaption: PDE loss: 0.00995925434514135\n","\t\tAfter adaption: Data loss: 0.0033088188307448248\n","\n","\tTesting: Initial condition loss: 0.006210534367710352\n","\tTesting: Boundary condition loss: 0.00666265981271863\n","\tTesting: PDE loss: 0.021606285125017166\n","\tTesting: Data loss: 0.020915914326906204\n","\n","Epoch 747\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005721730645745993\n","\tBefore adaption: Boundary condition loss: 0.006271820515394211\n","\tBefore adaption: PDE loss: 0.02158869244158268\n","\tBefore adaption: Data loss: 0.02078535594046116\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0464, 0.1997, 0.4960, 0.2579], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011426685507252507\n","\t\tAfter adaption: Boundary condition loss: 0.00029124521161072057\n","\t\tAfter adaption: PDE loss: 0.010707472219015279\n","\t\tAfter adaption: Data loss: 0.005360124902351222\n","\n","\tTesting: Initial condition loss: 0.007423472125083208\n","\tTesting: Boundary condition loss: 0.007760362699627876\n","\tTesting: PDE loss: 0.02174227125942707\n","\tTesting: Data loss: 0.023348011076450348\n","\n","Epoch 748\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006578043103218079\n","\tBefore adaption: Boundary condition loss: 0.00731999147683382\n","\tBefore adaption: PDE loss: 0.021723365411162376\n","\tBefore adaption: Data loss: 0.02320815809071064\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0723, 0.1335, 0.4799, 0.3143], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008784147537170396\n","\t\tAfter adaption: Boundary condition loss: 0.0005295263903503631\n","\t\tAfter adaption: PDE loss: 0.010424056802244543\n","\t\tAfter adaption: Data loss: 0.007293581567610007\n","\n","\tTesting: Initial condition loss: 0.007229216396808624\n","\tTesting: Boundary condition loss: 0.00769142946228385\n","\tTesting: PDE loss: 0.021555274724960327\n","\tTesting: Data loss: 0.02382846362888813\n","\n","Epoch 749\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006382439285516739\n","\tBefore adaption: Boundary condition loss: 0.007266542874276638\n","\tBefore adaption: PDE loss: 0.021542206406593323\n","\tBefore adaption: Data loss: 0.02368636056780815\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0943, 0.1079, 0.4443, 0.3535], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006887442095064597\n","\t\tAfter adaption: Boundary condition loss: 0.0006851810526030854\n","\t\tAfter adaption: PDE loss: 0.009570967724497836\n","\t\tAfter adaption: Data loss: 0.00837326389797013\n","\n","\tTesting: Initial condition loss: 0.0057245222851634026\n","\tTesting: Boundary condition loss: 0.006480453070253134\n","\tTesting: PDE loss: 0.02113872952759266\n","\tTesting: Data loss: 0.022286968305706978\n","\n","Epoch 750\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005203784443438053\n","\tBefore adaption: Boundary condition loss: 0.006125942338258028\n","\tBefore adaption: PDE loss: 0.021122252568602562\n","\tBefore adaption: Data loss: 0.022150222212076187\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1086, 0.1032, 0.4110, 0.3771], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005369607784355641\n","\t\tAfter adaption: Boundary condition loss: 0.0006655741801428226\n","\t\tAfter adaption: PDE loss: 0.008682280605915145\n","\t\tAfter adaption: Data loss: 0.00835319804257655\n","\n","\tTesting: Initial condition loss: 0.0036295726895332336\n","\tTesting: Boundary condition loss: 0.00457757106050849\n","\tTesting: PDE loss: 0.020532865077257156\n","\tTesting: Data loss: 0.01915871724486351\n","\n","Epoch 751\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003645810531452298\n","\tBefore adaption: Boundary condition loss: 0.004324478097259998\n","\tBefore adaption: PDE loss: 0.0205247700214386\n","\tBefore adaption: Data loss: 0.01903311163187027\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1151, 0.1032, 0.3912, 0.3905], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00037619840269857057\n","\t\tAfter adaption: Boundary condition loss: 0.0004978300579547866\n","\t\tAfter adaption: PDE loss: 0.008029685819648191\n","\t\tAfter adaption: Data loss: 0.007431952999809053\n","\n","\tTesting: Initial condition loss: 0.0019925402011722326\n","\tTesting: Boundary condition loss: 0.0026662335731089115\n","\tTesting: PDE loss: 0.019839560613036156\n","\tTesting: Data loss: 0.015225615352392197\n","\n","Epoch 752\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002606577705591917\n","\tBefore adaption: Boundary condition loss: 0.0025104538071900606\n","\tBefore adaption: PDE loss: 0.019785743206739426\n","\tBefore adaption: Data loss: 0.015116091817617416\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0025, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1142, 0.1004, 0.3883, 0.3971], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00026170416910692814\n","\t\tAfter adaption: Boundary condition loss: 0.0002866378291417904\n","\t\tAfter adaption: PDE loss: 0.007683715252441783\n","\t\tAfter adaption: Data loss: 0.006002216499596434\n","\n","\tTesting: Initial condition loss: 0.0018180236220359802\n","\tTesting: Boundary condition loss: 0.0012089031515643\n","\tTesting: PDE loss: 0.018984932452440262\n","\tTesting: Data loss: 0.011333148926496506\n","\n","Epoch 753\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0029744156636297703\n","\tBefore adaption: Boundary condition loss: 0.0011261822655797005\n","\tBefore adaption: PDE loss: 0.01893046870827675\n","\tBefore adaption: Data loss: 0.011243069544434547\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1060, 0.0940, 0.4029, 0.3972], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002794746664860725\n","\t\tAfter adaption: Boundary condition loss: 0.00011938525389629016\n","\t\tAfter adaption: PDE loss: 0.0076266851705467514\n","\t\tAfter adaption: Data loss: 0.004465214670569974\n","\n","\tTesting: Initial condition loss: 0.0036953918170183897\n","\tTesting: Boundary condition loss: 0.00035200186539441347\n","\tTesting: PDE loss: 0.018061628565192223\n","\tTesting: Data loss: 0.00813154224306345\n","\n","Epoch 754\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005226349923759699\n","\tBefore adaption: Boundary condition loss: 0.00032098236260935664\n","\tBefore adaption: PDE loss: 0.01802022196352482\n","\tBefore adaption: Data loss: 0.008062205277383327\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0907, 0.0885, 0.4331, 0.3877], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004622738571041463\n","\t\tAfter adaption: Boundary condition loss: 2.912890373117536e-05\n","\t\tAfter adaption: PDE loss: 0.0078043941489430255\n","\t\tAfter adaption: Data loss: 0.0031257898632382074\n","\n","\tTesting: Initial condition loss: 0.007697391789406538\n","\tTesting: Boundary condition loss: 5.930829865974374e-05\n","\tTesting: PDE loss: 0.017140358686447144\n","\tTesting: Data loss: 0.005947337951511145\n","\n","Epoch 755\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009376105852425098\n","\tBefore adaption: Boundary condition loss: 5.971083010081202e-05\n","\tBefore adaption: PDE loss: 0.01707574725151062\n","\tBefore adaption: Data loss: 0.005897945258766413\n","tensor(5.9711e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(5.9711e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0693, 0.0945, 0.4729, 0.3634], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008858525307084182\n","\t\tAfter adaption: Boundary condition loss: 4.134988317152579e-06\n","\t\tAfter adaption: PDE loss: 0.008075391350705612\n","\t\tAfter adaption: Data loss: 0.0021430414390390122\n","\n","\tTesting: Initial condition loss: 0.013429277576506138\n","\tTesting: Boundary condition loss: 0.00021354037744458765\n","\tTesting: PDE loss: 0.01619216799736023\n","\tTesting: Data loss: 0.00481066619977355\n","\n","Epoch 756\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015073167160153389\n","\tBefore adaption: Boundary condition loss: 0.0002269458054797724\n","\tBefore adaption: PDE loss: 0.016122907400131226\n","\tBefore adaption: Data loss: 0.004779164679348469\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0449, 0.1282, 0.5076, 0.3193], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019325957633911533\n","\t\tAfter adaption: Boundary condition loss: 1.0185633672051697e-05\n","\t\tAfter adaption: PDE loss: 0.008184396583331852\n","\t\tAfter adaption: Data loss: 0.0015258855629175082\n","\n","\tTesting: Initial condition loss: 0.020025867968797684\n","\tTesting: Boundary condition loss: 0.0006142851198092103\n","\tTesting: PDE loss: 0.01524270512163639\n","\tTesting: Data loss: 0.004522786941379309\n","\n","Epoch 757\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02161169983446598\n","\tBefore adaption: Boundary condition loss: 0.0006290867459028959\n","\tBefore adaption: PDE loss: 0.015176533721387386\n","\tBefore adaption: Data loss: 0.0045056892558932304\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0243, 0.2020, 0.5153, 0.2583], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0043661349341934195\n","\t\tAfter adaption: Boundary condition loss: 1.5297839121484326e-05\n","\t\tAfter adaption: PDE loss: 0.007820857793143166\n","\t\tAfter adaption: Data loss: 0.001163954866495329\n","\n","\tTesting: Initial condition loss: 0.025890253484249115\n","\tTesting: Boundary condition loss: 0.0010069292038679123\n","\tTesting: PDE loss: 0.014451269060373306\n","\tTesting: Data loss: 0.004714699927717447\n","\n","Epoch 758\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027485033497214317\n","\tBefore adaption: Boundary condition loss: 0.0010194792412221432\n","\tBefore adaption: PDE loss: 0.014381619170308113\n","\tBefore adaption: Data loss: 0.004708573687821627\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0134, 0.3076, 0.4836, 0.1954], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008454432590723577\n","\t\tAfter adaption: Boundary condition loss: 1.3652643844454768e-05\n","\t\tAfter adaption: PDE loss: 0.006954876554719107\n","\t\tAfter adaption: Data loss: 0.0009201108257715941\n","\n","\tTesting: Initial condition loss: 0.029187237843871117\n","\tTesting: Boundary condition loss: 0.0011716036824509501\n","\tTesting: PDE loss: 0.01393818948417902\n","\tTesting: Data loss: 0.004947498440742493\n","\n","Epoch 759\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03093993104994297\n","\tBefore adaption: Boundary condition loss: 0.0011824031826108694\n","\tBefore adaption: PDE loss: 0.013864369131624699\n","\tBefore adaption: Data loss: 0.00494707515463233\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0119, 0.4152, 0.4256, 0.1473], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012847263618973502\n","\t\tAfter adaption: Boundary condition loss: 1.405703265595003e-05\n","\t\tAfter adaption: PDE loss: 0.005900901396735845\n","\t\tAfter adaption: Data loss: 0.0007285184466971354\n","\n","\tTesting: Initial condition loss: 0.02852945774793625\n","\tTesting: Boundary condition loss: 0.0009912558598443866\n","\tTesting: PDE loss: 0.013801095075905323\n","\tTesting: Data loss: 0.0049145882949233055\n","\n","Epoch 760\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030551675707101822\n","\tBefore adaption: Boundary condition loss: 0.0010027606040239334\n","\tBefore adaption: PDE loss: 0.013736724853515625\n","\tBefore adaption: Data loss: 0.004913817159831524\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0149, 0.4999, 0.3664, 0.1188], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015273660675748733\n","\t\tAfter adaption: Boundary condition loss: 1.4950639434382037e-05\n","\t\tAfter adaption: PDE loss: 0.005033070764227678\n","\t\tAfter adaption: Data loss: 0.0005835958370259192\n","\n","\tTesting: Initial condition loss: 0.023759031668305397\n","\tTesting: Boundary condition loss: 0.0005447756848298013\n","\tTesting: PDE loss: 0.014115091413259506\n","\tTesting: Data loss: 0.0046868110075592995\n","\n","Epoch 761\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026122072711586952\n","\tBefore adaption: Boundary condition loss: 0.0005584058817476034\n","\tBefore adaption: PDE loss: 0.01405931543558836\n","\tBefore adaption: Data loss: 0.004679509438574314\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0179, 0.5541, 0.3229, 0.1051], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01447408932288997\n","\t\tAfter adaption: Boundary condition loss: 9.992487753787673e-06\n","\t\tAfter adaption: PDE loss: 0.004539749068785389\n","\t\tAfter adaption: Data loss: 0.0004918687355585515\n","\n","\tTesting: Initial condition loss: 0.01637749932706356\n","\tTesting: Boundary condition loss: 0.00012530916137620807\n","\tTesting: PDE loss: 0.014884615316987038\n","\tTesting: Data loss: 0.004769675899296999\n","\n","Epoch 762\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01899867132306099\n","\tBefore adaption: Boundary condition loss: 0.00013609009329229593\n","\tBefore adaption: PDE loss: 0.014834490604698658\n","\tBefore adaption: Data loss: 0.004750013817101717\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0186, 0.5793, 0.3015, 0.1006], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011005245746863639\n","\t\tAfter adaption: Boundary condition loss: 2.531172290544102e-06\n","\t\tAfter adaption: PDE loss: 0.004473307633399958\n","\t\tAfter adaption: Data loss: 0.00047779821299725144\n","\n","\tTesting: Initial condition loss: 0.008962789550423622\n","\tTesting: Boundary condition loss: 0.00014409197319764644\n","\tTesting: PDE loss: 0.016030391678214073\n","\tTesting: Data loss: 0.005870251450687647\n","\n","Epoch 763\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011558035388588905\n","\tBefore adaption: Boundary condition loss: 0.00013186274736654013\n","\tBefore adaption: PDE loss: 0.015978634357452393\n","\tBefore adaption: Data loss: 0.005831674672663212\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0167, 0.5760, 0.3043, 0.1030], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006657099301400807\n","\t\tAfter adaption: Boundary condition loss: 2.207349424790477e-06\n","\t\tAfter adaption: PDE loss: 0.004861602786594876\n","\t\tAfter adaption: Data loss: 0.0006008493590248751\n","\n","\tTesting: Initial condition loss: 0.00406428799033165\n","\tTesting: Boundary condition loss: 0.0008847617427818477\n","\tTesting: PDE loss: 0.017323065549135208\n","\tTesting: Data loss: 0.008483435958623886\n","\n","Epoch 764\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0061666034162044525\n","\tBefore adaption: Boundary condition loss: 0.0008191564702428877\n","\tBefore adaption: PDE loss: 0.01727043278515339\n","\tBefore adaption: Data loss: 0.008421487174928188\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0138, 0.5402, 0.3312, 0.1148], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0033311339748723356\n","\t\tAfter adaption: Boundary condition loss: 1.1274884024197597e-05\n","\t\tAfter adaption: PDE loss: 0.005720401679598635\n","\t\tAfter adaption: Data loss: 0.0009669650614272575\n","\n","\tTesting: Initial condition loss: 0.0023987696040421724\n","\tTesting: Boundary condition loss: 0.0024097012355923653\n","\tTesting: PDE loss: 0.018580621108412743\n","\tTesting: Data loss: 0.012529034167528152\n","\n","Epoch 765\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037131868302822113\n","\tBefore adaption: Boundary condition loss: 0.002259954810142517\n","\tBefore adaption: PDE loss: 0.018526531755924225\n","\tBefore adaption: Data loss: 0.012442346662282944\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0132, 0.4657, 0.3785, 0.1426], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017292791448354564\n","\t\tAfter adaption: Boundary condition loss: 2.984933765993922e-05\n","\t\tAfter adaption: PDE loss: 0.007011453505754262\n","\t\tAfter adaption: Data loss: 0.0017745791356414587\n","\n","\tTesting: Initial condition loss: 0.0033014731016010046\n","\tTesting: Boundary condition loss: 0.004529848229140043\n","\tTesting: PDE loss: 0.019550777971744537\n","\tTesting: Data loss: 0.01730026863515377\n","\n","Epoch 766\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037619962822645903\n","\tBefore adaption: Boundary condition loss: 0.004276525229215622\n","\tBefore adaption: PDE loss: 0.01951666921377182\n","\tBefore adaption: Data loss: 0.017191046848893166\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0209, 0.3553, 0.4309, 0.1929], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013366268953183295\n","\t\tAfter adaption: Boundary condition loss: 8.920377149294381e-05\n","\t\tAfter adaption: PDE loss: 0.008409624435121752\n","\t\tAfter adaption: Data loss: 0.0033169971279839025\n","\n","\tTesting: Initial condition loss: 0.005206097848713398\n","\tTesting: Boundary condition loss: 0.006707681808620691\n","\tTesting: PDE loss: 0.020160812884569168\n","\tTesting: Data loss: 0.021716060116887093\n","\n","Epoch 767\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004967185202986002\n","\tBefore adaption: Boundary condition loss: 0.006353188306093216\n","\tBefore adaption: PDE loss: 0.02012941986322403\n","\tBefore adaption: Data loss: 0.021589504554867744\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0409, 0.2367, 0.4617, 0.2607], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011758584675749578\n","\t\tAfter adaption: Boundary condition loss: 0.00025960743705258875\n","\t\tAfter adaption: PDE loss: 0.009293757121406178\n","\t\tAfter adaption: Data loss: 0.0056286359711183115\n","\n","\tTesting: Initial condition loss: 0.006659725680947304\n","\tTesting: Boundary condition loss: 0.008178169839084148\n","\tTesting: PDE loss: 0.020419234409928322\n","\tTesting: Data loss: 0.024743828922510147\n","\n","Epoch 768\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005996515974402428\n","\tBefore adaption: Boundary condition loss: 0.007767681032419205\n","\tBefore adaption: PDE loss: 0.020396973937749863\n","\tBefore adaption: Data loss: 0.024605823680758476\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0078, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0689, 0.1501, 0.4551, 0.3260], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008997873299662218\n","\t\tAfter adaption: Boundary condition loss: 0.0005351391005415136\n","\t\tAfter adaption: PDE loss: 0.009282613886807964\n","\t\tAfter adaption: Data loss: 0.008020451125815672\n","\n","\tTesting: Initial condition loss: 0.00682751415297389\n","\tTesting: Boundary condition loss: 0.008422181941568851\n","\tTesting: PDE loss: 0.02040140889585018\n","\tTesting: Data loss: 0.025674648582935333\n","\n","Epoch 769\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006103969179093838\n","\tBefore adaption: Boundary condition loss: 0.008012264966964722\n","\tBefore adaption: PDE loss: 0.02037401869893074\n","\tBefore adaption: Data loss: 0.025533564388751984\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0080, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0950, 0.1087, 0.4237, 0.3726], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006636855814975161\n","\t\tAfter adaption: Boundary condition loss: 0.0007607858593022414\n","\t\tAfter adaption: PDE loss: 0.008633351277003598\n","\t\tAfter adaption: Data loss: 0.009513136705634641\n","\n","\tTesting: Initial condition loss: 0.005624006036669016\n","\tTesting: Boundary condition loss: 0.007377880625426769\n","\tTesting: PDE loss: 0.020163197070360184\n","\tTesting: Data loss: 0.024330152198672295\n","\n","Epoch 770\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0051908595487475395\n","\tBefore adaption: Boundary condition loss: 0.0070206113159656525\n","\tBefore adaption: PDE loss: 0.020128805190324783\n","\tBefore adaption: Data loss: 0.024193119257688522\n","tensor(0.0070, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0070, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1131, 0.0968, 0.3902, 0.3999], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005023476343458773\n","\t\tAfter adaption: Boundary condition loss: 0.0007938875042527941\n","\t\tAfter adaption: PDE loss: 0.007854994413436771\n","\t\tAfter adaption: Data loss: 0.009675030195255186\n","\n","\tTesting: Initial condition loss: 0.003671780228614807\n","\tTesting: Boundary condition loss: 0.00547249848023057\n","\tTesting: PDE loss: 0.01977027766406536\n","\tTesting: Data loss: 0.02112448401749134\n","\n","Epoch 771\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003755588084459305\n","\tBefore adaption: Boundary condition loss: 0.005198873113840818\n","\tBefore adaption: PDE loss: 0.019726362079381943\n","\tBefore adaption: Data loss: 0.020997848361730576\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1224, 0.0953, 0.3681, 0.4143], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00035775226397454207\n","\t\tAfter adaption: Boundary condition loss: 0.0006363434322177943\n","\t\tAfter adaption: PDE loss: 0.0072609939314661484\n","\t\tAfter adaption: Data loss: 0.00869846562329722\n","\n","\tTesting: Initial condition loss: 0.002025944646447897\n","\tTesting: Boundary condition loss: 0.003428129479289055\n","\tTesting: PDE loss: 0.0192544125020504\n","\tTesting: Data loss: 0.01689860410988331\n","\n","Epoch 772\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0026932526379823685\n","\tBefore adaption: Boundary condition loss: 0.003248100634664297\n","\tBefore adaption: PDE loss: 0.019202275201678276\n","\tBefore adaption: Data loss: 0.016786033287644386\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0032, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1235, 0.0936, 0.3623, 0.4206], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002519647364420343\n","\t\tAfter adaption: Boundary condition loss: 0.0004012978439999639\n","\t\tAfter adaption: PDE loss: 0.00695724736876125\n","\t\tAfter adaption: Data loss: 0.00705993014432515\n","\n","\tTesting: Initial condition loss: 0.0017235889099538326\n","\tTesting: Boundary condition loss: 0.001751585048623383\n","\tTesting: PDE loss: 0.01867085136473179\n","\tTesting: Data loss: 0.012592806480824947\n","\n","Epoch 773\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002838299609720707\n","\tBefore adaption: Boundary condition loss: 0.001647929660975933\n","\tBefore adaption: PDE loss: 0.018605811521410942\n","\tBefore adaption: Data loss: 0.01249734964221716\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1171, 0.0889, 0.3739, 0.4201], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002524195738083098\n","\t\tAfter adaption: Boundary condition loss: 0.00019290589176095859\n","\t\tAfter adaption: PDE loss: 0.006957591653660549\n","\t\tAfter adaption: Data loss: 0.0052496324821849375\n","\n","\tTesting: Initial condition loss: 0.003412484424188733\n","\tTesting: Boundary condition loss: 0.0006467138882726431\n","\tTesting: PDE loss: 0.018022622913122177\n","\tTesting: Data loss: 0.008941962383687496\n","\n","Epoch 774\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004712248686701059\n","\tBefore adaption: Boundary condition loss: 0.0006015016697347164\n","\tBefore adaption: PDE loss: 0.017963998019695282\n","\tBefore adaption: Data loss: 0.008864471688866615\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1031, 0.0844, 0.4022, 0.4103], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003978827056248625\n","\t\tAfter adaption: Boundary condition loss: 6.200591302754848e-05\n","\t\tAfter adaption: PDE loss: 0.007225068379934527\n","\t\tAfter adaption: Data loss: 0.0036369299273912984\n","\n","\tTesting: Initial condition loss: 0.007179236505180597\n","\tTesting: Boundary condition loss: 0.00013197804219089448\n","\tTesting: PDE loss: 0.01734962873160839\n","\tTesting: Data loss: 0.006341877393424511\n","\n","Epoch 775\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008393838070333004\n","\tBefore adaption: Boundary condition loss: 0.00012603068898897618\n","\tBefore adaption: PDE loss: 0.017291175201535225\n","\tBefore adaption: Data loss: 0.006282241083681583\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0821, 0.0889, 0.4430, 0.3860], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007461781626571625\n","\t\tAfter adaption: Boundary condition loss: 1.034324461073604e-05\n","\t\tAfter adaption: PDE loss: 0.007660349902315484\n","\t\tAfter adaption: Data loss: 0.002425031698955926\n","\n","\tTesting: Initial condition loss: 0.01262949500232935\n","\tTesting: Boundary condition loss: 0.00012851509382016957\n","\tTesting: PDE loss: 0.016648277640342712\n","\tTesting: Data loss: 0.004869935568422079\n","\n","Epoch 776\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013602453283965588\n","\tBefore adaption: Boundary condition loss: 0.00014152124640531838\n","\tBefore adaption: PDE loss: 0.01658145897090435\n","\tBefore adaption: Data loss: 0.00482747470960021\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0565, 0.1170, 0.4848, 0.3417], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015912394209784267\n","\t\tAfter adaption: Boundary condition loss: 8.000569441133301e-06\n","\t\tAfter adaption: PDE loss: 0.008038279170534821\n","\t\tAfter adaption: Data loss: 0.0016495971524729065\n","\n","\tTesting: Initial condition loss: 0.0190189890563488\n","\tTesting: Boundary condition loss: 0.00044438272016122937\n","\tTesting: PDE loss: 0.0159179475158453\n","\tTesting: Data loss: 0.004359866492450237\n","\n","Epoch 777\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0197069700807333\n","\tBefore adaption: Boundary condition loss: 0.0004668181645683944\n","\tBefore adaption: PDE loss: 0.015854211524128914\n","\tBefore adaption: Data loss: 0.004333504009991884\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0326, 0.1823, 0.5068, 0.2784], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0035918376678357434\n","\t\tAfter adaption: Boundary condition loss: 1.5212478698757745e-05\n","\t\tAfter adaption: PDE loss: 0.00803473679103654\n","\t\tAfter adaption: Data loss: 0.0012062786475897545\n","\n","\tTesting: Initial condition loss: 0.02513750083744526\n","\tTesting: Boundary condition loss: 0.0008454601629637182\n","\tTesting: PDE loss: 0.01524488627910614\n","\tTesting: Data loss: 0.0044633918441832066\n","\n","Epoch 778\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025617558509111404\n","\tBefore adaption: Boundary condition loss: 0.0008725917432457209\n","\tBefore adaption: PDE loss: 0.015179228037595749\n","\tBefore adaption: Data loss: 0.004451550077646971\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0170, 0.2810, 0.4922, 0.2098], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007197470917494108\n","\t\tAfter adaption: Boundary condition loss: 1.4848535117301083e-05\n","\t\tAfter adaption: PDE loss: 0.0074709629170115355\n","\t\tAfter adaption: Data loss: 0.0009341190430193558\n","\n","\tTesting: Initial condition loss: 0.029271962121129036\n","\tTesting: Boundary condition loss: 0.001111106132157147\n","\tTesting: PDE loss: 0.01474874559789896\n","\tTesting: Data loss: 0.004724937025457621\n","\n","Epoch 779\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02977985516190529\n","\tBefore adaption: Boundary condition loss: 0.001140517182648182\n","\tBefore adaption: PDE loss: 0.014682658016681671\n","\tBefore adaption: Data loss: 0.004723713267594576\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0119, 0.3876, 0.4458, 0.1547], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01154390028705909\n","\t\tAfter adaption: Boundary condition loss: 1.3549838461722702e-05\n","\t\tAfter adaption: PDE loss: 0.006545595879233027\n","\t\tAfter adaption: Data loss: 0.0007306332095343448\n","\n","\tTesting: Initial condition loss: 0.02976738102734089\n","\tTesting: Boundary condition loss: 0.001086247037164867\n","\tTesting: PDE loss: 0.014596235007047653\n","\tTesting: Data loss: 0.004742009565234184\n","\n","Epoch 780\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03053530491888523\n","\tBefore adaption: Boundary condition loss: 0.0011147487675771117\n","\tBefore adaption: PDE loss: 0.014535456895828247\n","\tBefore adaption: Data loss: 0.00474532088264823\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0135, 0.4760, 0.3899, 0.1206], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014534549790515432\n","\t\tAfter adaption: Boundary condition loss: 1.500662145040049e-05\n","\t\tAfter adaption: PDE loss: 0.005668017920932245\n","\t\tAfter adaption: Data loss: 0.0005722950708819209\n","\n","\tTesting: Initial condition loss: 0.026073215529322624\n","\tTesting: Boundary condition loss: 0.0007655801018700004\n","\tTesting: PDE loss: 0.014890328049659729\n","\tTesting: Data loss: 0.004421852063387632\n","\n","Epoch 781\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027274155989289284\n","\tBefore adaption: Boundary condition loss: 0.0007914543966762722\n","\tBefore adaption: PDE loss: 0.014834686182439327\n","\tBefore adaption: Data loss: 0.004422568716108799\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0168, 0.5351, 0.3446, 0.1035], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014595366742904424\n","\t\tAfter adaption: Boundary condition loss: 1.3263257993554837e-05\n","\t\tAfter adaption: PDE loss: 0.005111882265734091\n","\t\tAfter adaption: Data loss: 0.00045780852985635815\n","\n","\tTesting: Initial condition loss: 0.019188445061445236\n","\tTesting: Boundary condition loss: 0.00033326554694212973\n","\tTesting: PDE loss: 0.015651319175958633\n","\tTesting: Data loss: 0.0041038878262043\n","\n","Epoch 782\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02094322256743908\n","\tBefore adaption: Boundary condition loss: 0.00035361608024686575\n","\tBefore adaption: PDE loss: 0.015587082132697105\n","\tBefore adaption: Data loss: 0.004095034208148718\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0187, 0.5656, 0.3193, 0.0964], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011845467545830459\n","\t\tAfter adaption: Boundary condition loss: 6.596437870556241e-06\n","\t\tAfter adaption: PDE loss: 0.004977078225511687\n","\t\tAfter adaption: Data loss: 0.00039491928458427735\n","\n","\tTesting: Initial condition loss: 0.011691627092659473\n","\tTesting: Boundary condition loss: 0.00010850092075997964\n","\tTesting: PDE loss: 0.016727058216929436\n","\tTesting: Data loss: 0.004425120539963245\n","\n","Epoch 783\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01375116128474474\n","\tBefore adaption: Boundary condition loss: 0.00011518617975525558\n","\tBefore adaption: PDE loss: 0.016671109944581985\n","\tBefore adaption: Data loss: 0.0044014472514390945\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0181, 0.5693, 0.3174, 0.0952], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007829115857223096\n","\t\tAfter adaption: Boundary condition loss: 2.087830557760754e-06\n","\t\tAfter adaption: PDE loss: 0.005290584616181834\n","\t\tAfter adaption: Data loss: 0.0004189361428278585\n","\n","\tTesting: Initial condition loss: 0.0058021326549351215\n","\tTesting: Boundary condition loss: 0.00041305815102532506\n","\tTesting: PDE loss: 0.018010025843977928\n","\tTesting: Data loss: 0.005951746366918087\n","\n","Epoch 784\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007834499701857567\n","\tBefore adaption: Boundary condition loss: 0.00038492257590405643\n","\tBefore adaption: PDE loss: 0.017954789102077484\n","\tBefore adaption: Data loss: 0.005906910635530949\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0157, 0.5448, 0.3399, 0.0997], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004268007577292497\n","\t\tAfter adaption: Boundary condition loss: 6.0269160228568456e-06\n","\t\tAfter adaption: PDE loss: 0.00610208335234476\n","\t\tAfter adaption: Data loss: 0.0005889965309330413\n","\n","\tTesting: Initial condition loss: 0.0028595475014299154\n","\tTesting: Boundary condition loss: 0.0013964030658826232\n","\tTesting: PDE loss: 0.01931229792535305\n","\tTesting: Data loss: 0.008852173574268818\n","\n","Epoch 785\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0044202422723174095\n","\tBefore adaption: Boundary condition loss: 0.0013041544007137418\n","\tBefore adaption: PDE loss: 0.01927027851343155\n","\tBefore adaption: Data loss: 0.008782759308815002\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0134, 0.4865, 0.3859, 0.1143], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002150263004632705\n","\t\tAfter adaption: Boundary condition loss: 1.745181574741766e-05\n","\t\tAfter adaption: PDE loss: 0.007435861123967791\n","\t\tAfter adaption: Data loss: 0.0010037627496373637\n","\n","\tTesting: Initial condition loss: 0.0028187341522425413\n","\tTesting: Boundary condition loss: 0.0030331204179674387\n","\tTesting: PDE loss: 0.02045121230185032\n","\tTesting: Data loss: 0.01277271006256342\n","\n","Epoch 786\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036154179833829403\n","\tBefore adaption: Boundary condition loss: 0.002845487091690302\n","\tBefore adaption: PDE loss: 0.02041977271437645\n","\tBefore adaption: Data loss: 0.012679757550358772\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0028, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0156, 0.3924, 0.4460, 0.1460], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001418631745003372\n","\t\tAfter adaption: Boundary condition loss: 4.438639420023475e-05\n","\t\tAfter adaption: PDE loss: 0.009107124214421758\n","\t\tAfter adaption: Data loss: 0.001851518522954195\n","\n","\tTesting: Initial condition loss: 0.0045151906087994576\n","\tTesting: Boundary condition loss: 0.0050374362617731094\n","\tTesting: PDE loss: 0.02125677652657032\n","\tTesting: Data loss: 0.016962628811597824\n","\n","Epoch 787\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004500642418861389\n","\tBefore adaption: Boundary condition loss: 0.004744423553347588\n","\tBefore adaption: PDE loss: 0.02122962847352028\n","\tBefore adaption: Data loss: 0.016849590465426445\n","tensor(0.0047, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0047, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0276, 0.2787, 0.4959, 0.1978], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001254272703267442\n","\t\tAfter adaption: Boundary condition loss: 0.00013092112842996161\n","\t\tAfter adaption: PDE loss: 0.010527830480072102\n","\t\tAfter adaption: Data loss: 0.0033330981081463444\n","\n","\tTesting: Initial condition loss: 0.0064735193736851215\n","\tTesting: Boundary condition loss: 0.006894825492054224\n","\tTesting: PDE loss: 0.02163882739841938\n","\tTesting: Data loss: 0.0205531008541584\n","\n","Epoch 788\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005816427059471607\n","\tBefore adaption: Boundary condition loss: 0.006519007496535778\n","\tBefore adaption: PDE loss: 0.021622631698846817\n","\tBefore adaption: Data loss: 0.020424814894795418\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0501, 0.1817, 0.5092, 0.2591], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010567866308491976\n","\t\tAfter adaption: Boundary condition loss: 0.00032631384853286236\n","\t\tAfter adaption: PDE loss: 0.011009477966493868\n","\t\tAfter adaption: Data loss: 0.005291853200651798\n","\n","\tTesting: Initial condition loss: 0.007574107963591814\n","\tTesting: Boundary condition loss: 0.00799243152141571\n","\tTesting: PDE loss: 0.021638173609972\n","\tTesting: Data loss: 0.02279653213918209\n","\n","Epoch 789\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006577245891094208\n","\tBefore adaption: Boundary condition loss: 0.0075806183740496635\n","\tBefore adaption: PDE loss: 0.021631214767694473\n","\tBefore adaption: Data loss: 0.022658850997686386\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0763, 0.1264, 0.4852, 0.3121], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008310983577503931\n","\t\tAfter adaption: Boundary condition loss: 0.0005781824000974393\n","\t\tAfter adaption: PDE loss: 0.010496027130873806\n","\t\tAfter adaption: Data loss: 0.007072802200195519\n","\n","\tTesting: Initial condition loss: 0.007318292744457722\n","\tTesting: Boundary condition loss: 0.007958661764860153\n","\tTesting: PDE loss: 0.021334365010261536\n","\tTesting: Data loss: 0.023222945630550385\n","\n","Epoch 790\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0063332789577543736\n","\tBefore adaption: Boundary condition loss: 0.0075644575990736485\n","\tBefore adaption: PDE loss: 0.021329354494810104\n","\tBefore adaption: Data loss: 0.023083116859197617\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0985, 0.1067, 0.4461, 0.3487], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006759455296874236\n","\t\tAfter adaption: Boundary condition loss: 0.0007448931212669331\n","\t\tAfter adaption: PDE loss: 0.0095157754907482\n","\t\tAfter adaption: Data loss: 0.0080482211636509\n","\n","\tTesting: Initial condition loss: 0.005847154650837183\n","\tTesting: Boundary condition loss: 0.00681772455573082\n","\tTesting: PDE loss: 0.02081170864403248\n","\tTesting: Data loss: 0.02178051881492138\n","\n","Epoch 791\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005202301777899265\n","\tBefore adaption: Boundary condition loss: 0.006484344135969877\n","\tBefore adaption: PDE loss: 0.020792866125702858\n","\tBefore adaption: Data loss: 0.02164558507502079\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1134, 0.1040, 0.4117, 0.3710], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005411009597470677\n","\t\tAfter adaption: Boundary condition loss: 0.0007351363821903818\n","\t\tAfter adaption: PDE loss: 0.008559706796897859\n","\t\tAfter adaption: Data loss: 0.008029461047298233\n","\n","\tTesting: Initial condition loss: 0.0038323006592690945\n","\tTesting: Boundary condition loss: 0.004988427273929119\n","\tTesting: PDE loss: 0.020110774785280228\n","\tTesting: Data loss: 0.01886719837784767\n","\n","Epoch 792\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037612426094710827\n","\tBefore adaption: Boundary condition loss: 0.004745570942759514\n","\tBefore adaption: PDE loss: 0.020080719143152237\n","\tBefore adaption: Data loss: 0.018743714317679405\n","tensor(0.0047, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0047, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1207, 0.1043, 0.3910, 0.3840], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00039224710943174446\n","\t\tAfter adaption: Boundary condition loss: 0.000572624342246123\n","\t\tAfter adaption: PDE loss: 0.00785204440765716\n","\t\tAfter adaption: Data loss: 0.007198039378408624\n","\n","\tTesting: Initial condition loss: 0.002267216332256794\n","\tTesting: Boundary condition loss: 0.0030700599309056997\n","\tTesting: PDE loss: 0.019267182797193527\n","\tTesting: Data loss: 0.015190991573035717\n","\n","Epoch 793\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002882670611143112\n","\tBefore adaption: Boundary condition loss: 0.0029217645060271025\n","\tBefore adaption: PDE loss: 0.019248757511377335\n","\tBefore adaption: Data loss: 0.015083584003150463\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1207, 0.1016, 0.3868, 0.3909], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00029281150935633036\n","\t\tAfter adaption: Boundary condition loss: 0.00035256410953963315\n","\t\tAfter adaption: PDE loss: 0.007445544212140728\n","\t\tAfter adaption: Data loss: 0.00589690673438832\n","\n","\tTesting: Initial condition loss: 0.0020940674003213644\n","\tTesting: Boundary condition loss: 0.0015268740244209766\n","\tTesting: PDE loss: 0.018337437883019447\n","\tTesting: Data loss: 0.011519080027937889\n","\n","Epoch 794\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003369539976119995\n","\tBefore adaption: Boundary condition loss: 0.0014522968558594584\n","\tBefore adaption: PDE loss: 0.01832703873515129\n","\tBefore adaption: Data loss: 0.011430689133703709\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1134, 0.0958, 0.3990, 0.3918], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003228804437097473\n","\t\tAfter adaption: Boundary condition loss: 0.00016468924376140994\n","\t\tAfter adaption: PDE loss: 0.007311991751146432\n","\t\tAfter adaption: Data loss: 0.004478594839936617\n","\n","\tTesting: Initial condition loss: 0.0038653446827083826\n","\tTesting: Boundary condition loss: 0.0005282018100842834\n","\tTesting: PDE loss: 0.017388561740517616\n","\tTesting: Data loss: 0.008445275947451591\n","\n","Epoch 795\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005652877036482096\n","\tBefore adaption: Boundary condition loss: 0.0004995904164388776\n","\tBefore adaption: PDE loss: 0.017359960824251175\n","\tBefore adaption: Data loss: 0.00837678648531437\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0988, 0.0919, 0.4255, 0.3838], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005194908737981536\n","\t\tAfter adaption: Boundary condition loss: 4.936254134648938e-05\n","\t\tAfter adaption: PDE loss: 0.007387166662934831\n","\t\tAfter adaption: Data loss: 0.0032147281861702372\n","\n","\tTesting: Initial condition loss: 0.007681776769459248\n","\tTesting: Boundary condition loss: 8.208528015529737e-05\n","\tTesting: PDE loss: 0.016406815499067307\n","\tTesting: Data loss: 0.006288381293416023\n","\n","Epoch 796\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009766815230250359\n","\tBefore adaption: Boundary condition loss: 7.900301716290414e-05\n","\tBefore adaption: PDE loss: 0.01638605259358883\n","\tBefore adaption: Data loss: 0.006238887552171946\n","tensor(7.9003e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(7.9003e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0774, 0.1003, 0.4605, 0.3618], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009796117026886469\n","\t\tAfter adaption: Boundary condition loss: 6.11459292015939e-06\n","\t\tAfter adaption: PDE loss: 0.0075460603597851\n","\t\tAfter adaption: Data loss: 0.0022571391276200886\n","\n","\tTesting: Initial condition loss: 0.013218861073255539\n","\tTesting: Boundary condition loss: 8.124697342282161e-05\n","\tTesting: PDE loss: 0.015427638776600361\n","\tTesting: Data loss: 0.005099359434098005\n","\n","Epoch 797\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015441740863025188\n","\tBefore adaption: Boundary condition loss: 8.566872566007078e-05\n","\tBefore adaption: PDE loss: 0.015399585478007793\n","\tBefore adaption: Data loss: 0.005066977348178625\n","tensor(8.5669e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.5669e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0520, 0.1364, 0.4904, 0.3211], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0021069361437936677\n","\t\tAfter adaption: Boundary condition loss: 4.457013574840746e-06\n","\t\tAfter adaption: PDE loss: 0.0075517231863548575\n","\t\tAfter adaption: Data loss: 0.0016272321122473988\n","\n","\tTesting: Initial condition loss: 0.01949690282344818\n","\tTesting: Boundary condition loss: 0.00034610394504852593\n","\tTesting: PDE loss: 0.014529120177030563\n","\tTesting: Data loss: 0.00471313763409853\n","\n","Epoch 798\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02177087403833866\n","\tBefore adaption: Boundary condition loss: 0.0003480797167867422\n","\tBefore adaption: PDE loss: 0.014488056302070618\n","\tBefore adaption: Data loss: 0.004694532603025436\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0288, 0.2120, 0.4954, 0.2638], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004615832755014654\n","\t\tAfter adaption: Boundary condition loss: 1.0017190404222126e-05\n","\t\tAfter adaption: PDE loss: 0.007177166922692341\n","\t\tAfter adaption: Data loss: 0.001238499768252095\n","\n","\tTesting: Initial condition loss: 0.02504488080739975\n","\tTesting: Boundary condition loss: 0.0006556393927894533\n","\tTesting: PDE loss: 0.013805322349071503\n","\tTesting: Data loss: 0.004804815165698528\n","\n","Epoch 799\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027365252375602722\n","\tBefore adaption: Boundary condition loss: 0.0006526035140268505\n","\tBefore adaption: PDE loss: 0.013763131573796272\n","\tBefore adaption: Data loss: 0.004796285647898912\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0140, 0.3178, 0.4651, 0.2031], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008697673145236945\n","\t\tAfter adaption: Boundary condition loss: 9.126153958827646e-06\n","\t\tAfter adaption: PDE loss: 0.006400571691816378\n","\t\tAfter adaption: Data loss: 0.0009742556428013497\n","\n","\tTesting: Initial condition loss: 0.028116784989833832\n","\tTesting: Boundary condition loss: 0.0008036348735913634\n","\tTesting: PDE loss: 0.013371436856687069\n","\tTesting: Data loss: 0.00497392937541008\n","\n","Epoch 800\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03055192157626152\n","\tBefore adaption: Boundary condition loss: 0.0007985355914570391\n","\tBefore adaption: PDE loss: 0.013328555040061474\n","\tBefore adaption: Data loss: 0.004970890004187822\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0088, 0.4251, 0.4111, 0.1549], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012987737880416444\n","\t\tAfter adaption: Boundary condition loss: 7.062298385525038e-06\n","\t\tAfter adaption: PDE loss: 0.005479568271842994\n","\t\tAfter adaption: Data loss: 0.0007701743982419874\n","\n","\tTesting: Initial condition loss: 0.02736032009124756\n","\tTesting: Boundary condition loss: 0.0006844024173915386\n","\tTesting: PDE loss: 0.013328883796930313\n","\tTesting: Data loss: 0.004942124243825674\n","\n","Epoch 801\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030010607093572617\n","\tBefore adaption: Boundary condition loss: 0.0006819505942985415\n","\tBefore adaption: PDE loss: 0.013285767287015915\n","\tBefore adaption: Data loss: 0.004938691388815641\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0095, 0.5094, 0.3560, 0.1250], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015286661069714536\n","\t\tAfter adaption: Boundary condition loss: 6.500143232523528e-06\n","\t\tAfter adaption: PDE loss: 0.004730382559010232\n","\t\tAfter adaption: Data loss: 0.0006175533105373472\n","\n","\tTesting: Initial condition loss: 0.02270464226603508\n","\tTesting: Boundary condition loss: 0.00035504900733940303\n","\tTesting: PDE loss: 0.013731257058680058\n","\tTesting: Data loss: 0.004778504371643066\n","\n","Epoch 802\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02560221217572689\n","\tBefore adaption: Boundary condition loss: 0.00035891495645046234\n","\tBefore adaption: PDE loss: 0.013691662810742855\n","\tBefore adaption: Data loss: 0.004768589977174997\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0115, 0.5628, 0.3158, 0.1100], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014407693368291858\n","\t\tAfter adaption: Boundary condition loss: 4.140504232333145e-06\n","\t\tAfter adaption: PDE loss: 0.0043232501496657935\n","\t\tAfter adaption: Data loss: 0.0005243248331050561\n","\n","\tTesting: Initial condition loss: 0.015621981583535671\n","\tTesting: Boundary condition loss: 6.54314790153876e-05\n","\tTesting: PDE loss: 0.014582294970750809\n","\tTesting: Data loss: 0.0049491398967802525\n","\n","Epoch 803\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018617194145917892\n","\tBefore adaption: Boundary condition loss: 7.107233977876604e-05\n","\tBefore adaption: PDE loss: 0.014551426284015179\n","\tBefore adaption: Data loss: 0.004927358590066433\n","tensor(7.1072e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(7.1072e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0123, 0.5862, 0.2968, 0.1047], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0109137152889739\n","\t\tAfter adaption: Boundary condition loss: 8.740570427994157e-07\n","\t\tAfter adaption: PDE loss: 0.00431933720841803\n","\t\tAfter adaption: Data loss: 0.0005156584570123369\n","\n","\tTesting: Initial condition loss: 0.008561143651604652\n","\tTesting: Boundary condition loss: 0.00016932524158619344\n","\tTesting: PDE loss: 0.015817759558558464\n","\tTesting: Data loss: 0.006102689076215029\n","\n","Epoch 804\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011305483058094978\n","\tBefore adaption: Boundary condition loss: 0.00015831616474315524\n","\tBefore adaption: PDE loss: 0.015787603333592415\n","\tBefore adaption: Data loss: 0.006062362343072891\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0113, 0.5804, 0.3012, 0.1071], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006561651459233957\n","\t\tAfter adaption: Boundary condition loss: 1.7814027045890768e-06\n","\t\tAfter adaption: PDE loss: 0.004755636845535688\n","\t\tAfter adaption: Data loss: 0.0006494371334610272\n","\n","\tTesting: Initial condition loss: 0.003908008802682161\n","\tTesting: Boundary condition loss: 0.0009445495088584721\n","\tTesting: PDE loss: 0.01719476282596588\n","\tTesting: Data loss: 0.008680772967636585\n","\n","Epoch 805\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006026904098689556\n","\tBefore adaption: Boundary condition loss: 0.0008856449276208878\n","\tBefore adaption: PDE loss: 0.017158059403300285\n","\tBefore adaption: Data loss: 0.008617683313786983\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0096, 0.5413, 0.3294, 0.1197], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0032624873030472016\n","\t\tAfter adaption: Boundary condition loss: 8.542371293370109e-06\n","\t\tAfter adaption: PDE loss: 0.005651187313316171\n","\t\tAfter adaption: Data loss: 0.0010313065017555224\n","\n","\tTesting: Initial condition loss: 0.002328370464965701\n","\tTesting: Boundary condition loss: 0.0024436735548079014\n","\tTesting: PDE loss: 0.018530402332544327\n","\tTesting: Data loss: 0.012579244561493397\n","\n","Epoch 806\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003586576785892248\n","\tBefore adaption: Boundary condition loss: 0.0022999478969722986\n","\tBefore adaption: PDE loss: 0.018488647416234016\n","\tBefore adaption: Data loss: 0.012492856942117214\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0109, 0.4635, 0.3771, 0.1484], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0016624748399740965\n","\t\tAfter adaption: Boundary condition loss: 2.5107257322592988e-05\n","\t\tAfter adaption: PDE loss: 0.006972414664909041\n","\t\tAfter adaption: Data loss: 0.0018544108960905606\n","\n","\tTesting: Initial condition loss: 0.0031663423869758844\n","\tTesting: Boundary condition loss: 0.004424831364303827\n","\tTesting: PDE loss: 0.019611883908510208\n","\tTesting: Data loss: 0.017120005562901497\n","\n","Epoch 807\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0035519800148904324\n","\tBefore adaption: Boundary condition loss: 0.004178974311798811\n","\tBefore adaption: PDE loss: 0.019572371616959572\n","\tBefore adaption: Data loss: 0.017012538388371468\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0042, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0204, 0.3511, 0.4297, 0.1988], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012470714913025494\n","\t\tAfter adaption: Boundary condition loss: 8.505001768056511e-05\n","\t\tAfter adaption: PDE loss: 0.008410711361876105\n","\t\tAfter adaption: Data loss: 0.0033826412848402087\n","\n","\tTesting: Initial condition loss: 0.004956022370606661\n","\tTesting: Boundary condition loss: 0.006388263776898384\n","\tTesting: PDE loss: 0.020321663469076157\n","\tTesting: Data loss: 0.021289221942424774\n","\n","Epoch 808\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004649476148188114\n","\tBefore adaption: Boundary condition loss: 0.006049616727977991\n","\tBefore adaption: PDE loss: 0.02028185874223709\n","\tBefore adaption: Data loss: 0.02116522565484047\n","tensor(0.0060, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0060, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0410, 0.2323, 0.4617, 0.2650], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010801281570704013\n","\t\tAfter adaption: Boundary condition loss: 0.0002478789056838911\n","\t\tAfter adaption: PDE loss: 0.009364135330941215\n","\t\tAfter adaption: Data loss: 0.005609071825103487\n","\n","\tTesting: Initial condition loss: 0.006327190902084112\n","\tTesting: Boundary condition loss: 0.007681684568524361\n","\tTesting: PDE loss: 0.020654378458857536\n","\tTesting: Data loss: 0.024136686697602272\n","\n","Epoch 809\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005605495534837246\n","\tBefore adaption: Boundary condition loss: 0.007292376831173897\n","\tBefore adaption: PDE loss: 0.020624492317438126\n","\tBefore adaption: Data loss: 0.02400217019021511\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0073, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0681, 0.1460, 0.4580, 0.3279], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008183448484379724\n","\t\tAfter adaption: Boundary condition loss: 0.0004965440554275408\n","\t\tAfter adaption: PDE loss: 0.009446451966684238\n","\t\tAfter adaption: Data loss: 0.007870266038680409\n","\n","\tTesting: Initial condition loss: 0.006499588489532471\n","\tTesting: Boundary condition loss: 0.00786509457975626\n","\tTesting: PDE loss: 0.020683934912085533\n","\tTesting: Data loss: 0.025026844814419746\n","\n","Epoch 810\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0057156565599143505\n","\tBefore adaption: Boundary condition loss: 0.007478735409677029\n","\tBefore adaption: PDE loss: 0.020661229267716408\n","\tBefore adaption: Data loss: 0.024889059364795685\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0075, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0926, 0.1047, 0.4300, 0.3727], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005984945114461686\n","\t\tAfter adaption: Boundary condition loss: 0.0006927203806421746\n","\t\tAfter adaption: PDE loss: 0.00888443949163708\n","\t\tAfter adaption: Data loss: 0.009275098446439648\n","\n","\tTesting: Initial condition loss: 0.005371357314288616\n","\tTesting: Boundary condition loss: 0.006895819213241339\n","\tTesting: PDE loss: 0.020499212667346\n","\tTesting: Data loss: 0.023806970566511154\n","\n","Epoch 811\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004864824470132589\n","\tBefore adaption: Boundary condition loss: 0.006561257876455784\n","\tBefore adaption: PDE loss: 0.02044801227748394\n","\tBefore adaption: Data loss: 0.02367299236357212\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0066, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1094, 0.0926, 0.3991, 0.3990], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00045025463249667903\n","\t\tAfter adaption: Boundary condition loss: 0.000717582729738112\n","\t\tAfter adaption: PDE loss: 0.008161065881510422\n","\t\tAfter adaption: Data loss: 0.009444745824081457\n","\n","\tTesting: Initial condition loss: 0.003510136855766177\n","\tTesting: Boundary condition loss: 0.005158769432455301\n","\tTesting: PDE loss: 0.020105602219700813\n","\tTesting: Data loss: 0.02084735594689846\n","\n","Epoch 812\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0035061538219451904\n","\tBefore adaption: Boundary condition loss: 0.0049061537720263\n","\tBefore adaption: PDE loss: 0.020061388611793518\n","\tBefore adaption: Data loss: 0.02072286419570446\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1176, 0.0909, 0.3786, 0.4129], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003186670306899299\n","\t\tAfter adaption: Boundary condition loss: 0.0005771408966019373\n","\t\tAfter adaption: PDE loss: 0.007595368792623165\n","\t\tAfter adaption: Data loss: 0.008555837304951458\n","\n","\tTesting: Initial condition loss: 0.0018878687405958772\n","\tTesting: Boundary condition loss: 0.0032677247654646635\n","\tTesting: PDE loss: 0.019589895382523537\n","\tTesting: Data loss: 0.016895968466997147\n","\n","Epoch 813\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0024554296396672726\n","\tBefore adaption: Boundary condition loss: 0.003103958908468485\n","\tBefore adaption: PDE loss: 0.019538715481758118\n","\tBefore adaption: Data loss: 0.016785169020295143\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1182, 0.0891, 0.3736, 0.4191], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002187891069953644\n","\t\tAfter adaption: Boundary condition loss: 0.0003668830334106833\n","\t\tAfter adaption: PDE loss: 0.007300335984075459\n","\t\tAfter adaption: Data loss: 0.007034040030631443\n","\n","\tTesting: Initial condition loss: 0.0014762294013053179\n","\tTesting: Boundary condition loss: 0.001668785116635263\n","\tTesting: PDE loss: 0.01897510141134262\n","\tTesting: Data loss: 0.012798074632883072\n","\n","Epoch 814\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002480747178196907\n","\tBefore adaption: Boundary condition loss: 0.0015854074154049158\n","\tBefore adaption: PDE loss: 0.018920069560408592\n","\tBefore adaption: Data loss: 0.012703106738626957\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0016, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1116, 0.0842, 0.3854, 0.4187], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002089811243179761\n","\t\tAfter adaption: Boundary condition loss: 0.00017694693063356835\n","\t\tAfter adaption: PDE loss: 0.007292159376636543\n","\t\tAfter adaption: Data loss: 0.005319166619172571\n","\n","\tTesting: Initial condition loss: 0.0029112196061760187\n","\tTesting: Boundary condition loss: 0.0006001172005198896\n","\tTesting: PDE loss: 0.018299028277397156\n","\tTesting: Data loss: 0.009242421016097069\n","\n","Epoch 815\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00410051504150033\n","\tBefore adaption: Boundary condition loss: 0.0005722522619180381\n","\tBefore adaption: PDE loss: 0.018240036442875862\n","\tBefore adaption: Data loss: 0.00916382111608982\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0980, 0.0789, 0.4133, 0.4097], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00032357824713790426\n","\t\tAfter adaption: Boundary condition loss: 5.6107219680596634e-05\n","\t\tAfter adaption: PDE loss: 0.0075385542466514304\n","\t\tAfter adaption: Data loss: 0.0037548277988613\n","\n","\tTesting: Initial condition loss: 0.006330879405140877\n","\tTesting: Boundary condition loss: 0.00011699978495016694\n","\tTesting: PDE loss: 0.01753499172627926\n","\tTesting: Data loss: 0.006625686306506395\n","\n","Epoch 816\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007489713374525309\n","\tBefore adaption: Boundary condition loss: 0.00011623097816482186\n","\tBefore adaption: PDE loss: 0.01749992184340954\n","\tBefore adaption: Data loss: 0.006563402246683836\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0780, 0.0812, 0.4535, 0.3873], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006081271020300138\n","\t\tAfter adaption: Boundary condition loss: 9.06927977326469e-06\n","\t\tAfter adaption: PDE loss: 0.007935354040523836\n","\t\tAfter adaption: Data loss: 0.0025421755851598236\n","\n","\tTesting: Initial condition loss: 0.011443437077105045\n","\tTesting: Boundary condition loss: 0.00011018667282769457\n","\tTesting: PDE loss: 0.016755588352680206\n","\tTesting: Data loss: 0.0050560543313622475\n","\n","Epoch 817\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01242848951369524\n","\tBefore adaption: Boundary condition loss: 0.00011635880946414545\n","\tBefore adaption: PDE loss: 0.016714224591851234\n","\tBefore adaption: Data loss: 0.005009996704757214\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0540, 0.1052, 0.4948, 0.3460], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013068967080652263\n","\t\tAfter adaption: Boundary condition loss: 6.280964723238404e-06\n","\t\tAfter adaption: PDE loss: 0.008270634294636085\n","\t\tAfter adaption: Data loss: 0.0017336646329151931\n","\n","\tTesting: Initial condition loss: 0.017613230273127556\n","\tTesting: Boundary condition loss: 0.0004086584667675197\n","\tTesting: PDE loss: 0.015957718715071678\n","\tTesting: Data loss: 0.0044183689169585705\n","\n","Epoch 818\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018374193459749222\n","\tBefore adaption: Boundary condition loss: 0.00041333012632094324\n","\tBefore adaption: PDE loss: 0.01590333878993988\n","\tBefore adaption: Data loss: 0.004387339577078819\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0313, 0.1649, 0.5178, 0.2860], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0030302692841855175\n","\t\tAfter adaption: Boundary condition loss: 1.2933180469141541e-05\n","\t\tAfter adaption: PDE loss: 0.008235048829674066\n","\t\tAfter adaption: Data loss: 0.0012546510195503026\n","\n","\tTesting: Initial condition loss: 0.023805640637874603\n","\tTesting: Boundary condition loss: 0.0007932538283057511\n","\tTesting: PDE loss: 0.015189889818429947\n","\tTesting: Data loss: 0.00442302692681551\n","\n","Epoch 819\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024382753297686577\n","\tBefore adaption: Boundary condition loss: 0.0007970340666361153\n","\tBefore adaption: PDE loss: 0.015137490816414356\n","\tBefore adaption: Data loss: 0.004405675455927849\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0162, 0.2598, 0.5051, 0.2189], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006333599168459915\n","\t\tAfter adaption: Boundary condition loss: 1.2932334767838114e-05\n","\t\tAfter adaption: PDE loss: 0.007646675466482489\n","\t\tAfter adaption: Data loss: 0.0009642642257749261\n","\n","\tTesting: Initial condition loss: 0.02839639224112034\n","\tTesting: Boundary condition loss: 0.0010647604940459132\n","\tTesting: PDE loss: 0.01459320355206728\n","\tTesting: Data loss: 0.004663900472223759\n","\n","Epoch 820\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02898491360247135\n","\tBefore adaption: Boundary condition loss: 0.0010673950891941786\n","\tBefore adaption: PDE loss: 0.01454298384487629\n","\tBefore adaption: Data loss: 0.0046576266176998615\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0111, 0.3674, 0.4592, 0.1624], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010647903647071697\n","\t\tAfter adaption: Boundary condition loss: 1.1829791001933168e-05\n","\t\tAfter adaption: PDE loss: 0.006678001357151275\n","\t\tAfter adaption: Data loss: 0.0007562405432347751\n","\n","\tTesting: Initial condition loss: 0.02975243330001831\n","\tTesting: Boundary condition loss: 0.0010738528799265623\n","\tTesting: PDE loss: 0.014319945126771927\n","\tTesting: Data loss: 0.004747757222503424\n","\n","Epoch 821\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03056258335709572\n","\tBefore adaption: Boundary condition loss: 0.0010766595369204879\n","\tBefore adaption: PDE loss: 0.01427651196718216\n","\tBefore adaption: Data loss: 0.004747296683490276\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0126, 0.4608, 0.4009, 0.1257], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014081794193711644\n","\t\tAfter adaption: Boundary condition loss: 1.3580195498157644e-05\n","\t\tAfter adaption: PDE loss: 0.005723791978906889\n","\t\tAfter adaption: Data loss: 0.0005967828390352389\n","\n","\tTesting: Initial condition loss: 0.027098720893263817\n","\tTesting: Boundary condition loss: 0.0007979431538842618\n","\tTesting: PDE loss: 0.014470363967120647\n","\tTesting: Data loss: 0.00451956270262599\n","\n","Epoch 822\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02829458750784397\n","\tBefore adaption: Boundary condition loss: 0.0008027705480344594\n","\tBefore adaption: PDE loss: 0.014430264942348003\n","\tBefore adaption: Data loss: 0.0045185633935034275\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0159, 0.5265, 0.3512, 0.1064], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014896758021693829\n","\t\tAfter adaption: Boundary condition loss: 1.2778766446864597e-05\n","\t\tAfter adaption: PDE loss: 0.005067423289183501\n","\t\tAfter adaption: Data loss: 0.00048089805392146\n","\n","\tTesting: Initial condition loss: 0.02100411430001259\n","\tTesting: Boundary condition loss: 0.00037869944935664535\n","\tTesting: PDE loss: 0.01507881935685873\n","\tTesting: Data loss: 0.004210838582366705\n","\n","Epoch 823\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022707976400852203\n","\tBefore adaption: Boundary condition loss: 0.0003870849614031613\n","\tBefore adaption: PDE loss: 0.015041043050587177\n","\tBefore adaption: Data loss: 0.004203475546091795\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0179, 0.5637, 0.3204, 0.0980], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012799667754929472\n","\t\tAfter adaption: Boundary condition loss: 6.941328569099535e-06\n","\t\tAfter adaption: PDE loss: 0.004819462448691007\n","\t\tAfter adaption: Data loss: 0.00041186812613873896\n","\n","\tTesting: Initial condition loss: 0.013497316278517246\n","\tTesting: Boundary condition loss: 0.000108877029560972\n","\tTesting: PDE loss: 0.016065089032053947\n","\tTesting: Data loss: 0.0043722642585635185\n","\n","Epoch 824\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01567876897752285\n","\tBefore adaption: Boundary condition loss: 0.00011486930452520028\n","\tBefore adaption: PDE loss: 0.01603691838681698\n","\tBefore adaption: Data loss: 0.004353693220764399\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0176, 0.5743, 0.3123, 0.0958], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009003811401621818\n","\t\tAfter adaption: Boundary condition loss: 2.0184895826347376e-06\n","\t\tAfter adaption: PDE loss: 0.00500854024791648\n","\t\tAfter adaption: Data loss: 0.00041728777221025073\n","\n","\tTesting: Initial condition loss: 0.007131488528102636\n","\tTesting: Boundary condition loss: 0.00030326706473715603\n","\tTesting: PDE loss: 0.017309073358774185\n","\tTesting: Data loss: 0.005594252143055201\n","\n","Epoch 825\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009324280545115471\n","\tBefore adaption: Boundary condition loss: 0.00028899364406242967\n","\tBefore adaption: PDE loss: 0.017276788130402565\n","\tBefore adaption: Data loss: 0.005556952673941851\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0152, 0.5574, 0.3281, 0.0992], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005197586108823757\n","\t\tAfter adaption: Boundary condition loss: 4.399907255259744e-06\n","\t\tAfter adaption: PDE loss: 0.005668624132603644\n","\t\tAfter adaption: Data loss: 0.0005514919460867299\n","\n","\tTesting: Initial condition loss: 0.003400952322408557\n","\tTesting: Boundary condition loss: 0.0011845056433230639\n","\tTesting: PDE loss: 0.018625788390636444\n","\tTesting: Data loss: 0.008154179900884628\n","\n","Epoch 826\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005228307563811541\n","\tBefore adaption: Boundary condition loss: 0.0011169839417561889\n","\tBefore adaption: PDE loss: 0.018595868721604347\n","\tBefore adaption: Data loss: 0.00809455756098032\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0011, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0127, 0.5082, 0.3675, 0.1115], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0026572470845086867\n","\t\tAfter adaption: Boundary condition loss: 1.4225249336381926e-05\n","\t\tAfter adaption: PDE loss: 0.006834325170749452\n","\t\tAfter adaption: Data loss: 0.0009025721386478454\n","\n","\tTesting: Initial condition loss: 0.0026759253814816475\n","\tTesting: Boundary condition loss: 0.002736418042331934\n","\tTesting: PDE loss: 0.01983214169740677\n","\tTesting: Data loss: 0.011834057047963142\n","\n","Epoch 827\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037564244121313095\n","\tBefore adaption: Boundary condition loss: 0.0025733085349202156\n","\tBefore adaption: PDE loss: 0.01980586163699627\n","\tBefore adaption: Data loss: 0.011751482263207436\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0141, 0.4229, 0.4238, 0.1392], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015884936105240491\n","\t\tAfter adaption: Boundary condition loss: 3.632504623609603e-05\n","\t\tAfter adaption: PDE loss: 0.008394228284561298\n","\t\tAfter adaption: Data loss: 0.0016356225515007036\n","\n","\tTesting: Initial condition loss: 0.0040041254833340645\n","\tTesting: Boundary condition loss: 0.004708630032837391\n","\tTesting: PDE loss: 0.020757921040058136\n","\tTesting: Data loss: 0.015979336574673653\n","\n","Epoch 828\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004251432605087757\n","\tBefore adaption: Boundary condition loss: 0.004433376248925924\n","\tBefore adaption: PDE loss: 0.02073671668767929\n","\tBefore adaption: Data loss: 0.01587546616792679\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0246, 0.3115, 0.4771, 0.1867], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013245168180318497\n","\t\tAfter adaption: Boundary condition loss: 0.00010923761929037806\n","\t\tAfter adaption: PDE loss: 0.009893116632285235\n","\t\tAfter adaption: Data loss: 0.002964454154395311\n","\n","\tTesting: Initial condition loss: 0.0059874714352190495\n","\tTesting: Boundary condition loss: 0.006684030871838331\n","\tTesting: PDE loss: 0.02130676805973053\n","\tTesting: Data loss: 0.01974639855325222\n","\n","Epoch 829\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0055348738096654415\n","\tBefore adaption: Boundary condition loss: 0.00631833728402853\n","\tBefore adaption: PDE loss: 0.021295592188835144\n","\tBefore adaption: Data loss: 0.019624952226877213\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0461, 0.2067, 0.5002, 0.2469], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011442458494280655\n","\t\tAfter adaption: Boundary condition loss: 0.00029149598384034596\n","\t\tAfter adaption: PDE loss: 0.010652883521948334\n","\t\tAfter adaption: Data loss: 0.004845244683785922\n","\n","\tTesting: Initial condition loss: 0.007412623148411512\n","\tTesting: Boundary condition loss: 0.008043903857469559\n","\tTesting: PDE loss: 0.021475156769156456\n","\tTesting: Data loss: 0.02235337160527706\n","\n","Epoch 830\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006528456695377827\n","\tBefore adaption: Boundary condition loss: 0.007630052510648966\n","\tBefore adaption: PDE loss: 0.021468717604875565\n","\tBefore adaption: Data loss: 0.022220304235816002\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0076, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0731, 0.1394, 0.4851, 0.3024], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009099959715450772\n","\t\tAfter adaption: Boundary condition loss: 0.000557974247920691\n","\t\tAfter adaption: PDE loss: 0.010414509592686704\n","\t\tAfter adaption: Data loss: 0.0067189867344030684\n","\n","\tTesting: Initial condition loss: 0.0075982180424034595\n","\tTesting: Boundary condition loss: 0.008336483500897884\n","\tTesting: PDE loss: 0.021323705092072487\n","\tTesting: Data loss: 0.023261703550815582\n","\n","Epoch 831\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006631738040596247\n","\tBefore adaption: Boundary condition loss: 0.007923507131636143\n","\tBefore adaption: PDE loss: 0.021312594413757324\n","\tBefore adaption: Data loss: 0.023124434053897858\n","tensor(0.0079, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0079, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0973, 0.1115, 0.4492, 0.3420], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007393154107218402\n","\t\tAfter adaption: Boundary condition loss: 0.0007709514158858031\n","\t\tAfter adaption: PDE loss: 0.00957401344237976\n","\t\tAfter adaption: Data loss: 0.007908568878696731\n","\n","\tTesting: Initial condition loss: 0.006486881989985704\n","\tTesting: Boundary condition loss: 0.007476717233657837\n","\tTesting: PDE loss: 0.02091946452856064\n","\tTesting: Data loss: 0.02231510728597641\n","\n","Epoch 832\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0057785119861364365\n","\tBefore adaption: Boundary condition loss: 0.007109775673598051\n","\tBefore adaption: PDE loss: 0.020902371034026146\n","\tBefore adaption: Data loss: 0.022181035950779915\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1142, 0.1056, 0.4138, 0.3664], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006102333190208756\n","\t\tAfter adaption: Boundary condition loss: 0.0008121554826741676\n","\t\tAfter adaption: PDE loss: 0.008649543085031523\n","\t\tAfter adaption: Data loss: 0.008126206812651388\n","\n","\tTesting: Initial condition loss: 0.004594252444803715\n","\tTesting: Boundary condition loss: 0.005771792959421873\n","\tTesting: PDE loss: 0.020322460681200027\n","\tTesting: Data loss: 0.019793443381786346\n","\n","Epoch 833\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004398842807859182\n","\tBefore adaption: Boundary condition loss: 0.005486268550157547\n","\tBefore adaption: PDE loss: 0.02029711939394474\n","\tBefore adaption: Data loss: 0.01966906152665615\n","tensor(0.0055, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0055, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1234, 0.1060, 0.3902, 0.3804], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00046641256334328736\n","\t\tAfter adaption: Boundary condition loss: 0.0006767483752874332\n","\t\tAfter adaption: PDE loss: 0.0079201319022674\n","\t\tAfter adaption: Data loss: 0.007482234839622629\n","\n","\tTesting: Initial condition loss: 0.0028180165681988\n","\tTesting: Boundary condition loss: 0.0038169720210134983\n","\tTesting: PDE loss: 0.019578399136662483\n","\tTesting: Data loss: 0.016318054869771004\n","\n","Epoch 834\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0032617829274386168\n","\tBefore adaption: Boundary condition loss: 0.0036272727884352207\n","\tBefore adaption: PDE loss: 0.01955372653901577\n","\tBefore adaption: Data loss: 0.016208356246352196\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1251, 0.1048, 0.3822, 0.3879], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003418978260404174\n","\t\tAfter adaption: Boundary condition loss: 0.0004539114214833653\n","\t\tAfter adaption: PDE loss: 0.007472714729905972\n","\t\tAfter adaption: Data loss: 0.006286878179378778\n","\n","\tTesting: Initial condition loss: 0.0020721761975437403\n","\tTesting: Boundary condition loss: 0.002118766075000167\n","\tTesting: PDE loss: 0.018738728016614914\n","\tTesting: Data loss: 0.012631004676222801\n","\n","Epoch 835\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003176974132657051\n","\tBefore adaption: Boundary condition loss: 0.002014112425968051\n","\tBefore adaption: PDE loss: 0.01870889775454998\n","\tBefore adaption: Data loss: 0.012539216317236423\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1198, 0.1003, 0.3902, 0.3898], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003185031981432409\n","\t\tAfter adaption: Boundary condition loss: 0.00024123181007559797\n","\t\tAfter adaption: PDE loss: 0.0073001974333511575\n","\t\tAfter adaption: Data loss: 0.004887487776681265\n","\n","\tTesting: Initial condition loss: 0.0030420587863773108\n","\tTesting: Boundary condition loss: 0.0008946459856815636\n","\tTesting: PDE loss: 0.017837604507803917\n","\tTesting: Data loss: 0.009364168159663677\n","\n","Epoch 836\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0046732136979699135\n","\tBefore adaption: Boundary condition loss: 0.0008529953774996102\n","\tBefore adaption: PDE loss: 0.017796389758586884\n","\tBefore adaption: Data loss: 0.00929192267358303\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1073, 0.0953, 0.4132, 0.3843], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00044541910853420524\n","\t\tAfter adaption: Boundary condition loss: 9.149069097675779e-05\n","\t\tAfter adaption: PDE loss: 0.007352859834454313\n","\t\tAfter adaption: Data loss: 0.003570538521091958\n","\n","\tTesting: Initial condition loss: 0.006029101088643074\n","\tTesting: Boundary condition loss: 0.00024106062483042479\n","\tTesting: PDE loss: 0.016878865659236908\n","\tTesting: Data loss: 0.006913268472999334\n","\n","Epoch 837\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007968200370669365\n","\tBefore adaption: Boundary condition loss: 0.00023162399884313345\n","\tBefore adaption: PDE loss: 0.016841471195220947\n","\tBefore adaption: Data loss: 0.006859698332846165\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0878, 0.0979, 0.4471, 0.3672], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007798387478238124\n","\t\tAfter adaption: Boundary condition loss: 2.032716399009944e-05\n","\t\tAfter adaption: PDE loss: 0.007530399669724126\n","\t\tAfter adaption: Data loss: 0.002519136897101181\n","\n","\tTesting: Initial condition loss: 0.010837642475962639\n","\tTesting: Boundary condition loss: 7.093238673405722e-05\n","\tTesting: PDE loss: 0.01590888202190399\n","\tTesting: Data loss: 0.00540566723793745\n","\n","Epoch 838\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012879660353064537\n","\tBefore adaption: Boundary condition loss: 7.389385427813977e-05\n","\tBefore adaption: PDE loss: 0.015864208340644836\n","\tBefore adaption: Data loss: 0.005369400605559349\n","tensor(7.3894e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(7.3894e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0631, 0.1214, 0.4818, 0.3337], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0015631826213660669\n","\t\tAfter adaption: Boundary condition loss: 4.664549190112091e-06\n","\t\tAfter adaption: PDE loss: 0.0076432895148605216\n","\t\tAfter adaption: Data loss: 0.0017918326662772965\n","\n","\tTesting: Initial condition loss: 0.016767317429184914\n","\tTesting: Boundary condition loss: 0.0002212591061834246\n","\tTesting: PDE loss: 0.01496698334813118\n","\tTesting: Data loss: 0.004748987033963203\n","\n","Epoch 839\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018828174099326134\n","\tBefore adaption: Boundary condition loss: 0.00022577894560527056\n","\tBefore adaption: PDE loss: 0.014921015128493309\n","\tBefore adaption: Data loss: 0.004727293271571398\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0382, 0.1798, 0.4993, 0.2827], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0033848415260585574\n","\t\tAfter adaption: Boundary condition loss: 8.635057521809416e-06\n","\t\tAfter adaption: PDE loss: 0.0074500645599005644\n","\t\tAfter adaption: Data loss: 0.0013363047851546888\n","\n","\tTesting: Initial condition loss: 0.022634441033005714\n","\tTesting: Boundary condition loss: 0.000498794368468225\n","\tTesting: PDE loss: 0.014165956526994705\n","\tTesting: Data loss: 0.004689089488238096\n","\n","Epoch 840\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024660935625433922\n","\tBefore adaption: Boundary condition loss: 0.0005005954881198704\n","\tBefore adaption: PDE loss: 0.014116148464381695\n","\tBefore adaption: Data loss: 0.004678552504628897\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0195, 0.2734, 0.4840, 0.2231], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00674306270124624\n","\t\tAfter adaption: Boundary condition loss: 9.78557474596436e-06\n","\t\tAfter adaption: PDE loss: 0.0068316447324006145\n","\t\tAfter adaption: Data loss: 0.0010436043182551374\n","\n","\tTesting: Initial condition loss: 0.02685675211250782\n","\tTesting: Boundary condition loss: 0.0007151940953917801\n","\tTesting: PDE loss: 0.013604487292468548\n","\tTesting: Data loss: 0.004864920862019062\n","\n","Epoch 841\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02890622988343239\n","\tBefore adaption: Boundary condition loss: 0.0007144161500036716\n","\tBefore adaption: PDE loss: 0.013555347919464111\n","\tBefore adaption: Data loss: 0.004862027708441019\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0104, 0.3806, 0.4385, 0.1705], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011001843946143492\n","\t\tAfter adaption: Boundary condition loss: 7.424252726532059e-06\n","\t\tAfter adaption: PDE loss: 0.005944376743358485\n","\t\tAfter adaption: Data loss: 0.0008288627269871765\n","\n","\tTesting: Initial condition loss: 0.027939587831497192\n","\tTesting: Boundary condition loss: 0.000732694286853075\n","\tTesting: PDE loss: 0.013382949866354465\n","\tTesting: Data loss: 0.004943585954606533\n","\n","Epoch 842\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030103448778390884\n","\tBefore adaption: Boundary condition loss: 0.00073158775921911\n","\tBefore adaption: PDE loss: 0.013335565105080605\n","\tBefore adaption: Data loss: 0.004943009931594133\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0089, 0.4740, 0.3826, 0.1346], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014268000169636901\n","\t\tAfter adaption: Boundary condition loss: 6.4911722287653835e-06\n","\t\tAfter adaption: PDE loss: 0.00510159956014363\n","\t\tAfter adaption: Data loss: 0.0006653561266605006\n","\n","\tTesting: Initial condition loss: 0.02522728405892849\n","\tTesting: Boundary condition loss: 0.0005254058050923049\n","\tTesting: PDE loss: 0.01358205545693636\n","\tTesting: Data loss: 0.004823558032512665\n","\n","Epoch 843\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027550186961889267\n","\tBefore adaption: Boundary condition loss: 0.0005273694987408817\n","\tBefore adaption: PDE loss: 0.013533290475606918\n","\tBefore adaption: Data loss: 0.004819349851459265\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0105, 0.5393, 0.3354, 0.1148], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014858353877968673\n","\t\tAfter adaption: Boundary condition loss: 5.534267758582576e-06\n","\t\tAfter adaption: PDE loss: 0.004538589276161186\n","\t\tAfter adaption: Data loss: 0.0005533641875106457\n","\n","\tTesting: Initial condition loss: 0.019319556653499603\n","\tTesting: Boundary condition loss: 0.0002234272687928751\n","\tTesting: PDE loss: 0.014220871031284332\n","\tTesting: Data loss: 0.004769702907651663\n","\n","Epoch 844\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021832983940839767\n","\tBefore adaption: Boundary condition loss: 0.0002289479598402977\n","\tBefore adaption: PDE loss: 0.014178043231368065\n","\tBefore adaption: Data loss: 0.004756048321723938\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0119, 0.5750, 0.3069, 0.1062], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012553737591354712\n","\t\tAfter adaption: Boundary condition loss: 2.731270084927313e-06\n","\t\tAfter adaption: PDE loss: 0.0043512658077928075\n","\t\tAfter adaption: Data loss: 0.0005049917817255105\n","\n","\tTesting: Initial condition loss: 0.012171045877039433\n","\tTesting: Boundary condition loss: 8.085379522526637e-05\n","\tTesting: PDE loss: 0.01528587844222784\n","\tTesting: Data loss: 0.00533554470166564\n","\n","Epoch 845\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014680047519505024\n","\tBefore adaption: Boundary condition loss: 8.416401396971196e-05\n","\tBefore adaption: PDE loss: 0.01523810438811779\n","\tBefore adaption: Data loss: 0.005306127481162548\n","tensor(8.4164e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.4164e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0118, 0.5823, 0.3006, 0.1052], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008548828786579822\n","\t\tAfter adaption: Boundary condition loss: 9.951675054202823e-07\n","\t\tAfter adaption: PDE loss: 0.0045803569111130225\n","\t\tAfter adaption: Data loss: 0.0005584513153183612\n","\n","\tTesting: Initial condition loss: 0.006119665689766407\n","\tTesting: Boundary condition loss: 0.00037817456177435815\n","\tTesting: PDE loss: 0.016611233353614807\n","\tTesting: Data loss: 0.00707169808447361\n","\n","Epoch 846\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00835137628018856\n","\tBefore adaption: Boundary condition loss: 0.0003638233174569905\n","\tBefore adaption: PDE loss: 0.01656428538262844\n","\tBefore adaption: Data loss: 0.0070208474062383175\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0104, 0.5598, 0.3176, 0.1123], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004675023367350482\n","\t\tAfter adaption: Boundary condition loss: 3.782672854502977e-06\n","\t\tAfter adaption: PDE loss: 0.00526011610878473\n","\t\tAfter adaption: Data loss: 0.0007881203964041913\n","\n","\tTesting: Initial condition loss: 0.0028541439678519964\n","\tTesting: Boundary condition loss: 0.0013052362482994795\n","\tTesting: PDE loss: 0.01795489341020584\n","\tTesting: Data loss: 0.010171862319111824\n","\n","Epoch 847\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0044883741065859795\n","\tBefore adaption: Boundary condition loss: 0.0012421878054738045\n","\tBefore adaption: PDE loss: 0.017908910289406776\n","\tBefore adaption: Data loss: 0.010096825659275055\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0012, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0095, 0.5022, 0.3569, 0.1315], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00225388298104304\n","\t\tAfter adaption: Boundary condition loss: 1.1779585167185422e-05\n","\t\tAfter adaption: PDE loss: 0.006390857472283131\n","\t\tAfter adaption: Data loss: 0.001327763679111352\n","\n","\tTesting: Initial condition loss: 0.0023736192379146814\n","\tTesting: Boundary condition loss: 0.002790910890325904\n","\tTesting: PDE loss: 0.019117360934615135\n","\tTesting: Data loss: 0.01426966767758131\n","\n","Epoch 848\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003221267368644476\n","\tBefore adaption: Boundary condition loss: 0.0026495354250073433\n","\tBefore adaption: PDE loss: 0.01909431256353855\n","\tBefore adaption: Data loss: 0.014170479029417038\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0026, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0130, 0.4073, 0.4102, 0.1695], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013119642995565273\n","\t\tAfter adaption: Boundary condition loss: 3.434251920690396e-05\n","\t\tAfter adaption: PDE loss: 0.007832848589767733\n","\t\tAfter adaption: Data loss: 0.00240242134492737\n","\n","\tTesting: Initial condition loss: 0.003585502738133073\n","\tTesting: Boundary condition loss: 0.004512897226959467\n","\tTesting: PDE loss: 0.019997473806142807\n","\tTesting: Data loss: 0.01856512576341629\n","\n","Epoch 849\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036930516362190247\n","\tBefore adaption: Boundary condition loss: 0.0042912825010716915\n","\tBefore adaption: PDE loss: 0.019987082108855247\n","\tBefore adaption: Data loss: 0.018446097150444984\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0043, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0252, 0.2896, 0.4574, 0.2279], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010693333311905012\n","\t\tAfter adaption: Boundary condition loss: 0.00010804636810875827\n","\t\tAfter adaption: PDE loss: 0.009141606903632749\n","\t\tAfter adaption: Data loss: 0.004203738006321961\n","\n","\tTesting: Initial condition loss: 0.005157582461833954\n","\tTesting: Boundary condition loss: 0.0060219853185117245\n","\tTesting: PDE loss: 0.020515888929367065\n","\tTesting: Data loss: 0.022124670445919037\n","\n","Epoch 850\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00470701651647687\n","\tBefore adaption: Boundary condition loss: 0.005736486986279488\n","\tBefore adaption: PDE loss: 0.02052147127687931\n","\tBefore adaption: Data loss: 0.021991297602653503\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0462, 0.1841, 0.4752, 0.2945], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008666286173617261\n","\t\tAfter adaption: Boundary condition loss: 0.00026492414482383634\n","\t\tAfter adaption: PDE loss: 0.009751109119862756\n","\t\tAfter adaption: Data loss: 0.006477251865764874\n","\n","\tTesting: Initial condition loss: 0.006026505958288908\n","\tTesting: Boundary condition loss: 0.006801449228078127\n","\tTesting: PDE loss: 0.02071494422852993\n","\tTesting: Data loss: 0.024172334000468254\n","\n","Epoch 851\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005303377751260996\n","\tBefore adaption: Boundary condition loss: 0.006493809632956982\n","\tBefore adaption: PDE loss: 0.02070918120443821\n","\tBefore adaption: Data loss: 0.024031639099121094\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0698, 0.1195, 0.4599, 0.3507], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006338223164494251\n","\t\tAfter adaption: Boundary condition loss: 0.0004534449566913087\n","\t\tAfter adaption: PDE loss: 0.009525183221493849\n","\t\tAfter adaption: Data loss: 0.008428130580647872\n","\n","\tTesting: Initial condition loss: 0.0057033030316233635\n","\tTesting: Boundary condition loss: 0.006563324946910143\n","\tTesting: PDE loss: 0.020629195496439934\n","\tTesting: Data loss: 0.024280352517962456\n","\n","Epoch 852\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005047815851867199\n","\tBefore adaption: Boundary condition loss: 0.006274847313761711\n","\tBefore adaption: PDE loss: 0.020622212439775467\n","\tBefore adaption: Data loss: 0.024139704182744026\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0892, 0.0936, 0.4293, 0.3879], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004722434239448743\n","\t\tAfter adaption: Boundary condition loss: 0.0005598383706336537\n","\t\tAfter adaption: PDE loss: 0.008853016534254294\n","\t\tAfter adaption: Data loss: 0.009364543010758\n","\n","\tTesting: Initial condition loss: 0.004352808929979801\n","\tTesting: Boundary condition loss: 0.005431594327092171\n","\tTesting: PDE loss: 0.020326996222138405\n","\tTesting: Data loss: 0.022488169372081757\n","\n","Epoch 853\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004051268100738525\n","\tBefore adaption: Boundary condition loss: 0.005200901534408331\n","\tBefore adaption: PDE loss: 0.02031390368938446\n","\tBefore adaption: Data loss: 0.022354478016495705\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1013, 0.0875, 0.4019, 0.4093], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00035437037611040146\n","\t\tAfter adaption: Boundary condition loss: 0.0005269398185339799\n","\t\tAfter adaption: PDE loss: 0.008163480395606139\n","\t\tAfter adaption: Data loss: 0.009150686366690391\n","\n","\tTesting: Initial condition loss: 0.002667199820280075\n","\tTesting: Boundary condition loss: 0.003843033919110894\n","\tTesting: PDE loss: 0.019858473911881447\n","\tTesting: Data loss: 0.01928255334496498\n","\n","Epoch 854\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0028835602570325136\n","\tBefore adaption: Boundary condition loss: 0.0036842389963567257\n","\tBefore adaption: PDE loss: 0.019842447713017464\n","\tBefore adaption: Data loss: 0.019161364063620567\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1061, 0.0864, 0.3870, 0.4205], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002491085413685514\n","\t\tAfter adaption: Boundary condition loss: 0.0003908131493171594\n","\t\tAfter adaption: PDE loss: 0.007679229769300916\n","\t\tAfter adaption: Data loss: 0.008057800870315527\n","\n","\tTesting: Initial condition loss: 0.0015560376923531294\n","\tTesting: Boundary condition loss: 0.0022660137619823217\n","\tTesting: PDE loss: 0.019260164350271225\n","\tTesting: Data loss: 0.015401986427605152\n","\n","Epoch 855\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002301948145031929\n","\tBefore adaption: Boundary condition loss: 0.0021796757355332375\n","\tBefore adaption: PDE loss: 0.01924668438732624\n","\tBefore adaption: Data loss: 0.015297221019864082\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1041, 0.0836, 0.3877, 0.4246], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0001924333739738756\n","\t\tAfter adaption: Boundary condition loss: 0.00022693408979774542\n","\t\tAfter adaption: PDE loss: 0.007462233080353545\n","\t\tAfter adaption: Data loss: 0.006494817439324193\n","\n","\tTesting: Initial condition loss: 0.001843782956711948\n","\tTesting: Boundary condition loss: 0.001040773349814117\n","\tTesting: PDE loss: 0.018596474081277847\n","\tTesting: Data loss: 0.011591778136789799\n","\n","Epoch 856\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0029316695872694254\n","\tBefore adaption: Boundary condition loss: 0.0010097979102283716\n","\tBefore adaption: PDE loss: 0.018577251583337784\n","\tBefore adaption: Data loss: 0.011505530215799809\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0957, 0.0786, 0.4043, 0.4214], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00023048753963060477\n","\t\tAfter adaption: Boundary condition loss: 9.659799680745721e-05\n","\t\tAfter adaption: PDE loss: 0.007510921468387486\n","\t\tAfter adaption: Data loss: 0.004848565327631655\n","\n","\tTesting: Initial condition loss: 0.00397014943882823\n","\tTesting: Boundary condition loss: 0.00033157155849039555\n","\tTesting: PDE loss: 0.01787392981350422\n","\tTesting: Data loss: 0.008420147933065891\n","\n","Epoch 857\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0051679788157343864\n","\tBefore adaption: Boundary condition loss: 0.0003292103938292712\n","\tBefore adaption: PDE loss: 0.01784958876669407\n","\tBefore adaption: Data loss: 0.008351554162800312\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0810, 0.0760, 0.4351, 0.4080], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003925951605501258\n","\t\tAfter adaption: Boundary condition loss: 2.6655103743064176e-05\n","\t\tAfter adaption: PDE loss: 0.007766390598833763\n","\t\tAfter adaption: Data loss: 0.003407135140056278\n","\n","\tTesting: Initial condition loss: 0.007966216653585434\n","\tTesting: Boundary condition loss: 0.00010097844642587006\n","\tTesting: PDE loss: 0.017078252509236336\n","\tTesting: Data loss: 0.006186159327626228\n","\n","Epoch 858\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009066482074558735\n","\tBefore adaption: Boundary condition loss: 0.00010730871872510761\n","\tBefore adaption: PDE loss: 0.017061352729797363\n","\tBefore adaption: Data loss: 0.006133893504738808\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0613, 0.0857, 0.4739, 0.3791], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007772074145374662\n","\t\tAfter adaption: Boundary condition loss: 6.581448312677253e-06\n","\t\tAfter adaption: PDE loss: 0.008085152146312948\n","\t\tAfter adaption: Data loss: 0.002325099933265521\n","\n","\tTesting: Initial condition loss: 0.013406332582235336\n","\tTesting: Boundary condition loss: 0.0002044958237092942\n","\tTesting: PDE loss: 0.016278276219964027\n","\tTesting: Data loss: 0.004931343253701925\n","\n","Epoch 859\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014328998513519764\n","\tBefore adaption: Boundary condition loss: 0.0002111972135026008\n","\tBefore adaption: PDE loss: 0.016243459656834602\n","\tBefore adaption: Data loss: 0.004894590470939875\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0400, 0.1224, 0.5068, 0.3308], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017532484581283111\n","\t\tAfter adaption: Boundary condition loss: 8.451064096675022e-06\n","\t\tAfter adaption: PDE loss: 0.008232272247736594\n","\t\tAfter adaption: Data loss: 0.001619241521138521\n","\n","\tTesting: Initial condition loss: 0.01964561641216278\n","\tTesting: Boundary condition loss: 0.00047744024777784944\n","\tTesting: PDE loss: 0.01545289158821106\n","\tTesting: Data loss: 0.004498509224504232\n","\n","Epoch 860\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02035125344991684\n","\tBefore adaption: Boundary condition loss: 0.0004827168595511466\n","\tBefore adaption: PDE loss: 0.015421447344124317\n","\tBefore adaption: Data loss: 0.004476403351873159\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0222, 0.1956, 0.5150, 0.2672], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003981047700861207\n","\t\tAfter adaption: Boundary condition loss: 1.0719510715718397e-05\n","\t\tAfter adaption: PDE loss: 0.007941657954396202\n","\t\tAfter adaption: Data loss: 0.001196101156623403\n","\n","\tTesting: Initial condition loss: 0.025350887328386307\n","\tTesting: Boundary condition loss: 0.0007631446933373809\n","\tTesting: PDE loss: 0.014719463884830475\n","\tTesting: Data loss: 0.004575815051794052\n","\n","Epoch 861\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026024412363767624\n","\tBefore adaption: Boundary condition loss: 0.0007661731797270477\n","\tBefore adaption: PDE loss: 0.014694501645863056\n","\tBefore adaption: Data loss: 0.004566332325339317\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0123, 0.2972, 0.4880, 0.2026], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007733715674349223\n","\t\tAfter adaption: Boundary condition loss: 9.396697462997497e-06\n","\t\tAfter adaption: PDE loss: 0.007170580095004244\n","\t\tAfter adaption: Data loss: 0.000925077710916454\n","\n","\tTesting: Initial condition loss: 0.028921978548169136\n","\tTesting: Boundary condition loss: 0.0009128192323260009\n","\tTesting: PDE loss: 0.01421850360929966\n","\tTesting: Data loss: 0.004766736179590225\n","\n","Epoch 862\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029751146212220192\n","\tBefore adaption: Boundary condition loss: 0.0009144062059931457\n","\tBefore adaption: PDE loss: 0.014203154481947422\n","\tBefore adaption: Data loss: 0.0047660525888204575\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0102, 0.4019, 0.4356, 0.1523], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011955858833663005\n","\t\tAfter adaption: Boundary condition loss: 9.296711837846431e-06\n","\t\tAfter adaption: PDE loss: 0.0061874970522560226\n","\t\tAfter adaption: Data loss: 0.000726004287223058\n","\n","\tTesting: Initial condition loss: 0.02901657670736313\n","\tTesting: Boundary condition loss: 0.000830865406896919\n","\tTesting: PDE loss: 0.01408088207244873\n","\tTesting: Data loss: 0.004750122781842947\n","\n","Epoch 863\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030169496312737465\n","\tBefore adaption: Boundary condition loss: 0.0008343719528056681\n","\tBefore adaption: PDE loss: 0.014063294045627117\n","\tBefore adaption: Data loss: 0.004752479027956724\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0121, 0.4869, 0.3795, 0.1214], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01468906936028183\n","\t\tAfter adaption: Boundary condition loss: 1.0125813054383772e-05\n","\t\tAfter adaption: PDE loss: 0.005337682365950753\n","\t\tAfter adaption: Data loss: 0.0005771030648413224\n","\n","\tTesting: Initial condition loss: 0.025280756875872612\n","\tTesting: Boundary condition loss: 0.0005466874572448432\n","\tTesting: PDE loss: 0.014371621422469616\n","\tTesting: Data loss: 0.004490677732974291\n","\n","Epoch 864\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026869144290685654\n","\tBefore adaption: Boundary condition loss: 0.0005544762243516743\n","\tBefore adaption: PDE loss: 0.014350436627864838\n","\tBefore adaption: Data loss: 0.004489947576075792\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0145, 0.5437, 0.3362, 0.1057], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014609335129171654\n","\t\tAfter adaption: Boundary condition loss: 8.015636081409358e-06\n","\t\tAfter adaption: PDE loss: 0.004824071339631802\n","\t\tAfter adaption: Data loss: 0.0004744074854953641\n","\n","\tTesting: Initial condition loss: 0.018696565181016922\n","\tTesting: Boundary condition loss: 0.00022984274255577475\n","\tTesting: PDE loss: 0.015091278590261936\n","\tTesting: Data loss: 0.004323647357523441\n","\n","Epoch 865\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02074892446398735\n","\tBefore adaption: Boundary condition loss: 0.0002399508812231943\n","\tBefore adaption: PDE loss: 0.015076096169650555\n","\tBefore adaption: Data loss: 0.004314124584197998\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0153, 0.5729, 0.3127, 0.0991], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011887286840110787\n","\t\tAfter adaption: Boundary condition loss: 3.6649034373122684e-06\n","\t\tAfter adaption: PDE loss: 0.0047143498429413275\n","\t\tAfter adaption: Data loss: 0.0004275798724351439\n","\n","\tTesting: Initial condition loss: 0.011371172033250332\n","\tTesting: Boundary condition loss: 0.000124314843560569\n","\tTesting: PDE loss: 0.016178667545318604\n","\tTesting: Data loss: 0.004819564986974001\n","\n","Epoch 866\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013771846890449524\n","\tBefore adaption: Boundary condition loss: 0.0001307447237195447\n","\tBefore adaption: PDE loss: 0.01615222729742527\n","\tBefore adaption: Data loss: 0.0047964658588171005\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0143, 0.5755, 0.3117, 0.0986], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007925197682734563\n","\t\tAfter adaption: Boundary condition loss: 1.86336865420061e-06\n","\t\tAfter adaption: PDE loss: 0.005034850406868727\n","\t\tAfter adaption: Data loss: 0.00047279574917156227\n","\n","\tTesting: Initial condition loss: 0.005770571529865265\n","\tTesting: Boundary condition loss: 0.0004843863716814667\n","\tTesting: PDE loss: 0.01740964502096176\n","\tTesting: Data loss: 0.006492322776466608\n","\n","Epoch 867\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.008003011345863342\n","\tBefore adaption: Boundary condition loss: 0.00047146889846771955\n","\tBefore adaption: PDE loss: 0.017427220940589905\n","\tBefore adaption: Data loss: 0.00645069032907486\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0121, 0.5491, 0.3342, 0.1046], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004394500440183067\n","\t\tAfter adaption: Boundary condition loss: 5.705134217790705e-06\n","\t\tAfter adaption: PDE loss: 0.005823625879751986\n","\t\tAfter adaption: Data loss: 0.0006749020898366446\n","\n","\tTesting: Initial condition loss: 0.0029622032307088375\n","\tTesting: Boundary condition loss: 0.0014935124199837446\n","\tTesting: PDE loss: 0.018703659996390343\n","\tTesting: Data loss: 0.009469772689044476\n","\n","Epoch 868\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004637372214347124\n","\tBefore adaption: Boundary condition loss: 0.001424569170922041\n","\tBefore adaption: PDE loss: 0.018708739429712296\n","\tBefore adaption: Data loss: 0.009407367557287216\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0014, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0110, 0.4888, 0.3784, 0.1218], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0022668334073352213\n","\t\tAfter adaption: Boundary condition loss: 1.5605746972676723e-05\n","\t\tAfter adaption: PDE loss: 0.0070800307214889694\n","\t\tAfter adaption: Data loss: 0.0011457432087615992\n","\n","\tTesting: Initial condition loss: 0.0028498610481619835\n","\tTesting: Boundary condition loss: 0.003075494198128581\n","\tTesting: PDE loss: 0.019834786653518677\n","\tTesting: Data loss: 0.013389735482633114\n","\n","Epoch 869\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037106331437826157\n","\tBefore adaption: Boundary condition loss: 0.0029181139543652534\n","\tBefore adaption: PDE loss: 0.019849460572004318\n","\tBefore adaption: Data loss: 0.013305469416081905\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0150, 0.3936, 0.4347, 0.1567], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001460522940361796\n","\t\tAfter adaption: Boundary condition loss: 4.3790778886367566e-05\n","\t\tAfter adaption: PDE loss: 0.008628392085442778\n","\t\tAfter adaption: Data loss: 0.002084925873761969\n","\n","\tTesting: Initial condition loss: 0.0043533556163311005\n","\tTesting: Boundary condition loss: 0.004939432255923748\n","\tTesting: PDE loss: 0.020681949332356453\n","\tTesting: Data loss: 0.017513738945126534\n","\n","Epoch 870\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004403485916554928\n","\tBefore adaption: Boundary condition loss: 0.004677029326558113\n","\tBefore adaption: PDE loss: 0.02069096267223358\n","\tBefore adaption: Data loss: 0.017410172149538994\n","tensor(0.0047, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0047, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0286, 0.2801, 0.4805, 0.2109], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012332632855060399\n","\t\tAfter adaption: Boundary condition loss: 0.00013359125119811574\n","\t\tAfter adaption: PDE loss: 0.00994228741220146\n","\t\tAfter adaption: Data loss: 0.003671068887754994\n","\n","\tTesting: Initial condition loss: 0.006143375765532255\n","\tTesting: Boundary condition loss: 0.006644864100962877\n","\tTesting: PDE loss: 0.021149227395653725\n","\tTesting: Data loss: 0.02099180966615677\n","\n","Epoch 871\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005564364138990641\n","\tBefore adaption: Boundary condition loss: 0.006298013962805271\n","\tBefore adaption: PDE loss: 0.021166089922189713\n","\tBefore adaption: Data loss: 0.02087349072098732\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0511, 0.1832, 0.4929, 0.2728], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001019365826729463\n","\t\tAfter adaption: Boundary condition loss: 0.000321754820425066\n","\t\tAfter adaption: PDE loss: 0.01043356039445666\n","\t\tAfter adaption: Data loss: 0.005693839627175312\n","\n","\tTesting: Initial condition loss: 0.007174913305789232\n","\tTesting: Boundary condition loss: 0.007623143028467894\n","\tTesting: PDE loss: 0.021261485293507576\n","\tTesting: Data loss: 0.023097023367881775\n","\n","Epoch 872\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006268492434173822\n","\tBefore adaption: Boundary condition loss: 0.007242992985993624\n","\tBefore adaption: PDE loss: 0.021291416138410568\n","\tBefore adaption: Data loss: 0.022970695048570633\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0761, 0.1268, 0.4718, 0.3253], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007950324651546252\n","\t\tAfter adaption: Boundary condition loss: 0.0005514004365171458\n","\t\tAfter adaption: PDE loss: 0.010044986015469605\n","\t\tAfter adaption: Data loss: 0.007471340336700663\n","\n","\tTesting: Initial condition loss: 0.0069508482702076435\n","\tTesting: Boundary condition loss: 0.00750272162258625\n","\tTesting: PDE loss: 0.02107619121670723\n","\tTesting: Data loss: 0.02339784987270832\n","\n","Epoch 873\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006059951148927212\n","\tBefore adaption: Boundary condition loss: 0.007140762638300657\n","\tBefore adaption: PDE loss: 0.021116023883223534\n","\tBefore adaption: Data loss: 0.023270489647984505\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0969, 0.1056, 0.4368, 0.3607], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006396484855055151\n","\t\tAfter adaption: Boundary condition loss: 0.0006919271451071098\n","\t\tAfter adaption: PDE loss: 0.009224096245869272\n","\t\tAfter adaption: Data loss: 0.008394106474151654\n","\n","\tTesting: Initial condition loss: 0.005583536345511675\n","\tTesting: Boundary condition loss: 0.0063375262543559074\n","\tTesting: PDE loss: 0.020687473937869072\n","\tTesting: Data loss: 0.02188125252723694\n","\n","Epoch 874\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005023307632654905\n","\tBefore adaption: Boundary condition loss: 0.0060395728796720505\n","\tBefore adaption: PDE loss: 0.02070685848593712\n","\tBefore adaption: Data loss: 0.02175900712609291\n","tensor(0.0060, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0060, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1104, 0.1015, 0.4063, 0.3819], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005097525018336583\n","\t\tAfter adaption: Boundary condition loss: 0.000666480002383541\n","\t\tAfter adaption: PDE loss: 0.00841291737978556\n","\t\tAfter adaption: Data loss: 0.008309409149994923\n","\n","\tTesting: Initial condition loss: 0.0037088878452777863\n","\tTesting: Boundary condition loss: 0.004576831124722958\n","\tTesting: PDE loss: 0.020091542974114418\n","\tTesting: Data loss: 0.018955683335661888\n","\n","Epoch 875\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036994018591940403\n","\tBefore adaption: Boundary condition loss: 0.004379143938422203\n","\tBefore adaption: PDE loss: 0.020129024982452393\n","\tBefore adaption: Data loss: 0.01884414441883564\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1163, 0.1012, 0.3888, 0.3938], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003743187265833551\n","\t\tAfter adaption: Boundary condition loss: 0.000509283224798047\n","\t\tAfter adaption: PDE loss: 0.007825465567503851\n","\t\tAfter adaption: Data loss: 0.007419948540437586\n","\n","\tTesting: Initial condition loss: 0.002245961455628276\n","\tTesting: Boundary condition loss: 0.0027753824833780527\n","\tTesting: PDE loss: 0.01938057504594326\n","\tTesting: Data loss: 0.015303109772503376\n","\n","Epoch 876\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002878027269616723\n","\tBefore adaption: Boundary condition loss: 0.002667350461706519\n","\tBefore adaption: PDE loss: 0.019414285197854042\n","\tBefore adaption: Data loss: 0.01520644873380661\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0027, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1153, 0.0986, 0.3869, 0.3992], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00028385612591449327\n","\t\tAfter adaption: Boundary condition loss: 0.00030741799738126676\n","\t\tAfter adaption: PDE loss: 0.007510965724730136\n","\t\tAfter adaption: Data loss: 0.006071031749607117\n","\n","\tTesting: Initial condition loss: 0.0020355822052806616\n","\tTesting: Boundary condition loss: 0.0013507731491699815\n","\tTesting: PDE loss: 0.018581196665763855\n","\tTesting: Data loss: 0.01164660882204771\n","\n","Epoch 877\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003248069901019335\n","\tBefore adaption: Boundary condition loss: 0.0013079771306365728\n","\tBefore adaption: PDE loss: 0.018610062077641487\n","\tBefore adaption: Data loss: 0.0115667674690485\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1073, 0.0934, 0.4008, 0.3985], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003034727718932563\n","\t\tAfter adaption: Boundary condition loss: 0.00014029150098135548\n","\t\tAfter adaption: PDE loss: 0.007459165679687709\n","\t\tAfter adaption: Data loss: 0.0046093119780652786\n","\n","\tTesting: Initial condition loss: 0.003659284906461835\n","\tTesting: Boundary condition loss: 0.0004859400214627385\n","\tTesting: PDE loss: 0.017704719677567482\n","\tTesting: Data loss: 0.008556360378861427\n","\n","Epoch 878\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005291955545544624\n","\tBefore adaption: Boundary condition loss: 0.0004748777428176254\n","\tBefore adaption: PDE loss: 0.017728660255670547\n","\tBefore adaption: Data loss: 0.008493851870298386\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0924, 0.0897, 0.4290, 0.3889], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00047474315406314236\n","\t\tAfter adaption: Boundary condition loss: 4.3876920868987975e-05\n","\t\tAfter adaption: PDE loss: 0.0076050047354383485\n","\t\tAfter adaption: Data loss: 0.0033034841078732583\n","\n","\tTesting: Initial condition loss: 0.007280340418219566\n","\tTesting: Boundary condition loss: 0.00012232484004925936\n","\tTesting: PDE loss: 0.016801590099930763\n","\tTesting: Data loss: 0.006346478592604399\n","\n","Epoch 879\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009060624986886978\n","\tBefore adaption: Boundary condition loss: 0.0001239724806509912\n","\tBefore adaption: PDE loss: 0.016804659739136696\n","\tBefore adaption: Data loss: 0.00630028685554862\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0717, 0.0971, 0.4656, 0.3657], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008795911284902127\n","\t\tAfter adaption: Boundary condition loss: 8.884748351419947e-06\n","\t\tAfter adaption: PDE loss: 0.007824180174539112\n","\t\tAfter adaption: Data loss: 0.0023037526256538834\n","\n","\tTesting: Initial condition loss: 0.012608354911208153\n","\tTesting: Boundary condition loss: 8.40582069940865e-05\n","\tTesting: PDE loss: 0.01585654728114605\n","\tTesting: Data loss: 0.005075029097497463\n","\n","Epoch 880\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.014282305724918842\n","\tBefore adaption: Boundary condition loss: 8.954857185017318e-05\n","\tBefore adaption: PDE loss: 0.015861626714468002\n","\tBefore adaption: Data loss: 0.005044179502874613\n","tensor(8.9549e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.9549e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0481, 0.1298, 0.4978, 0.3243], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0018543589593834468\n","\t\tAfter adaption: Boundary condition loss: 4.30516015165211e-06\n","\t\tAfter adaption: PDE loss: 0.00789513336129704\n","\t\tAfter adaption: Data loss: 0.0016360131512085103\n","\n","\tTesting: Initial condition loss: 0.01877620257437229\n","\tTesting: Boundary condition loss: 0.0002284837100887671\n","\tTesting: PDE loss: 0.014950125478208065\n","\tTesting: Data loss: 0.004601107444614172\n","\n","Epoch 881\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.020310522988438606\n","\tBefore adaption: Boundary condition loss: 0.00023405168030876666\n","\tBefore adaption: PDE loss: 0.014950049109756947\n","\tBefore adaption: Data loss: 0.004583852365612984\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0267, 0.1993, 0.5069, 0.2671], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004047411754786087\n","\t\tAfter adaption: Boundary condition loss: 6.25684406340124e-06\n","\t\tAfter adaption: PDE loss: 0.007577698848158036\n","\t\tAfter adaption: Data loss: 0.001224450354864106\n","\n","\tTesting: Initial condition loss: 0.024417119100689888\n","\tTesting: Boundary condition loss: 0.0004036461468786001\n","\tTesting: PDE loss: 0.014183609746396542\n","\tTesting: Data loss: 0.004634808283299208\n","\n","Epoch 882\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025891786441206932\n","\tBefore adaption: Boundary condition loss: 0.0004090888542123139\n","\tBefore adaption: PDE loss: 0.01418223138898611\n","\tBefore adaption: Data loss: 0.004628442693501711\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0128, 0.2994, 0.4815, 0.2063], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007751702187611532\n","\t\tAfter adaption: Boundary condition loss: 5.232675580514036e-06\n","\t\tAfter adaption: PDE loss: 0.006828440405280981\n","\t\tAfter adaption: Data loss: 0.0009550404351697711\n","\n","\tTesting: Initial condition loss: 0.028010709211230278\n","\tTesting: Boundary condition loss: 0.0004951648297719657\n","\tTesting: PDE loss: 0.013669981621205807\n","\tTesting: Data loss: 0.004810360725969076\n","\n","Epoch 883\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029546450823545456\n","\tBefore adaption: Boundary condition loss: 0.0005000376841053367\n","\tBefore adaption: PDE loss: 0.013661923818290234\n","\tBefore adaption: Data loss: 0.00481073185801506\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0072, 0.4052, 0.4304, 0.1572], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011971780398972256\n","\t\tAfter adaption: Boundary condition loss: 3.6036225500622522e-06\n","\t\tAfter adaption: PDE loss: 0.005880234152591616\n","\t\tAfter adaption: Data loss: 0.0007562353333542873\n","\n","\tTesting: Initial condition loss: 0.02823113091289997\n","\tTesting: Boundary condition loss: 0.00043893884867429733\n","\tTesting: PDE loss: 0.013498317450284958\n","\tTesting: Data loss: 0.004835453815758228\n","\n","Epoch 884\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029950862750411034\n","\tBefore adaption: Boundary condition loss: 0.00044431485002860427\n","\tBefore adaption: PDE loss: 0.01348789781332016\n","\tBefore adaption: Data loss: 0.004836978390812874\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0067, 0.4925, 0.3748, 0.1260], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014749471163645193\n","\t\tAfter adaption: Boundary condition loss: 2.9943515021683153e-06\n","\t\tAfter adaption: PDE loss: 0.005055454656983209\n","\t\tAfter adaption: Data loss: 0.0006094144462711017\n","\n","\tTesting: Initial condition loss: 0.02471431903541088\n","\tTesting: Boundary condition loss: 0.00026021766825579107\n","\tTesting: PDE loss: 0.013733492232859135\n","\tTesting: Data loss: 0.004696181509643793\n","\n","Epoch 885\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026682887226343155\n","\tBefore adaption: Boundary condition loss: 0.00026640231953933835\n","\tBefore adaption: PDE loss: 0.013724381104111671\n","\tBefore adaption: Data loss: 0.004692734684795141\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0077, 0.5513, 0.3313, 0.1098], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014709759506406855\n","\t\tAfter adaption: Boundary condition loss: 2.051604878964333e-06\n","\t\tAfter adaption: PDE loss: 0.004546306164791375\n","\t\tAfter adaption: Data loss: 0.00051507605718738\n","\n","\tTesting: Initial condition loss: 0.01832953281700611\n","\tTesting: Boundary condition loss: 8.34377424325794e-05\n","\tTesting: PDE loss: 0.014398345723748207\n","\tTesting: Data loss: 0.004742344841361046\n","\n","Epoch 886\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02058803103864193\n","\tBefore adaption: Boundary condition loss: 8.912666089599952e-05\n","\tBefore adaption: PDE loss: 0.014385024085640907\n","\tBefore adaption: Data loss: 0.0047285608015954494\n","tensor(8.9127e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.9127e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0081, 0.5813, 0.3072, 0.1034], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011967928396263147\n","\t\tAfter adaption: Boundary condition loss: 7.251347304785044e-07\n","\t\tAfter adaption: PDE loss: 0.004419063548146398\n","\t\tAfter adaption: Data loss: 0.0004887427845215382\n","\n","\tTesting: Initial condition loss: 0.011100705713033676\n","\tTesting: Boundary condition loss: 0.00011243781045777723\n","\tTesting: PDE loss: 0.015417763963341713\n","\tTesting: Data loss: 0.005549618508666754\n","\n","Epoch 887\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.013484904542565346\n","\tBefore adaption: Boundary condition loss: 0.00011349349369993433\n","\tBefore adaption: PDE loss: 0.015434623695909977\n","\tBefore adaption: Data loss: 0.00552024133503437\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0075, 0.5832, 0.3051, 0.1041], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007864780375023698\n","\t\tAfter adaption: Boundary condition loss: 8.523170321695853e-07\n","\t\tAfter adaption: PDE loss: 0.0047095075576008005\n","\t\tAfter adaption: Data loss: 0.0005748520011487558\n","\n","\tTesting: Initial condition loss: 0.005437265150249004\n","\tTesting: Boundary condition loss: 0.0005668941885232925\n","\tTesting: PDE loss: 0.016666708514094353\n","\tTesting: Data loss: 0.0076291230507195\n","\n","Epoch 888\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007589022163301706\n","\tBefore adaption: Boundary condition loss: 0.0005507426103577018\n","\tBefore adaption: PDE loss: 0.01668843813240528\n","\tBefore adaption: Data loss: 0.007579145021736622\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0006, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0065, 0.5544, 0.3258, 0.1133], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004206991585053238\n","\t\tAfter adaption: Boundary condition loss: 3.587547281946183e-06\n","\t\tAfter adaption: PDE loss: 0.005437158906037138\n","\t\tAfter adaption: Data loss: 0.0008589411038426945\n","\n","\tTesting: Initial condition loss: 0.002674468792974949\n","\tTesting: Boundary condition loss: 0.001566458959132433\n","\tTesting: PDE loss: 0.017930930480360985\n","\tTesting: Data loss: 0.011077485978603363\n","\n","Epoch 889\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004169129766523838\n","\tBefore adaption: Boundary condition loss: 0.001511374139226973\n","\tBefore adaption: PDE loss: 0.01795715093612671\n","\tBefore adaption: Data loss: 0.011004193685948849\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0015, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0073, 0.4894, 0.3671, 0.1362], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0020403462709024825\n","\t\tAfter adaption: Boundary condition loss: 1.101829127795532e-05\n","\t\tAfter adaption: PDE loss: 0.006591883658916054\n","\t\tAfter adaption: Data loss: 0.0014990582124392768\n","\n","\tTesting: Initial condition loss: 0.0026046328712254763\n","\tTesting: Boundary condition loss: 0.0032425157260149717\n","\tTesting: PDE loss: 0.019016489386558533\n","\tTesting: Data loss: 0.015431231819093227\n","\n","Epoch 890\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0032732668332755566\n","\tBefore adaption: Boundary condition loss: 0.003104950301349163\n","\tBefore adaption: PDE loss: 0.019053496420383453\n","\tBefore adaption: Data loss: 0.015335502102971077\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0136, 0.3882, 0.4187, 0.1795], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012705468023292681\n","\t\tAfter adaption: Boundary condition loss: 4.2087273466915933e-05\n","\t\tAfter adaption: PDE loss: 0.007978650049199397\n","\t\tAfter adaption: Data loss: 0.0027532790084692856\n","\n","\tTesting: Initial condition loss: 0.004023090470582247\n","\tTesting: Boundary condition loss: 0.005175009369850159\n","\tTesting: PDE loss: 0.01980825886130333\n","\tTesting: Data loss: 0.0198203232139349\n","\n","Epoch 891\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003935637418180704\n","\tBefore adaption: Boundary condition loss: 0.004943193402141333\n","\tBefore adaption: PDE loss: 0.019843831658363342\n","\tBefore adaption: Data loss: 0.019706368446350098\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0049, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0295, 0.2694, 0.4586, 0.2425], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010603241771388525\n","\t\tAfter adaption: Boundary condition loss: 0.00014573267087856942\n","\t\tAfter adaption: PDE loss: 0.009100273278343464\n","\t\tAfter adaption: Data loss: 0.004778943281033554\n","\n","\tTesting: Initial condition loss: 0.005579143296927214\n","\tTesting: Boundary condition loss: 0.006773739587515593\n","\tTesting: PDE loss: 0.02025873027741909\n","\tTesting: Data loss: 0.023285381495952606\n","\n","Epoch 892\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004960804246366024\n","\tBefore adaption: Boundary condition loss: 0.006469735875725746\n","\tBefore adaption: PDE loss: 0.020292749628424644\n","\tBefore adaption: Data loss: 0.02315906248986721\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0065, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0536, 0.1700, 0.4664, 0.3100], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008431944804548629\n","\t\tAfter adaption: Boundary condition loss: 0.0003466924688699292\n","\t\tAfter adaption: PDE loss: 0.009464658317962836\n","\t\tAfter adaption: Data loss: 0.007180136122382907\n","\n","\tTesting: Initial condition loss: 0.006282979156821966\n","\tTesting: Boundary condition loss: 0.007474537938833237\n","\tTesting: PDE loss: 0.020386792719364166\n","\tTesting: Data loss: 0.025059964507818222\n","\n","Epoch 893\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005432147067040205\n","\tBefore adaption: Boundary condition loss: 0.007146531715989113\n","\tBefore adaption: PDE loss: 0.020426081493496895\n","\tBefore adaption: Data loss: 0.02492809295654297\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0071, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0785, 0.1133, 0.4445, 0.3637], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006152759299385003\n","\t\tAfter adaption: Boundary condition loss: 0.0005611943694410364\n","\t\tAfter adaption: PDE loss: 0.009078585696456648\n","\t\tAfter adaption: Data loss: 0.009067513663196901\n","\n","\tTesting: Initial condition loss: 0.005743037443608046\n","\tTesting: Boundary condition loss: 0.007012231275439262\n","\tTesting: PDE loss: 0.020270518958568573\n","\tTesting: Data loss: 0.024770580232143402\n","\n","Epoch 894\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005002685356885195\n","\tBefore adaption: Boundary condition loss: 0.006713255774229765\n","\tBefore adaption: PDE loss: 0.020297270268201828\n","\tBefore adaption: Data loss: 0.024640001356601715\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0979, 0.0920, 0.4123, 0.3978], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00046003257032226026\n","\t\tAfter adaption: Boundary condition loss: 0.0006573909560280048\n","\t\tAfter adaption: PDE loss: 0.008368009552869139\n","\t\tAfter adaption: Data loss: 0.009802918396259016\n","\n","\tTesting: Initial condition loss: 0.004222598858177662\n","\tTesting: Boundary condition loss: 0.005595037247985601\n","\tTesting: PDE loss: 0.019956298172473907\n","\tTesting: Data loss: 0.02255157008767128\n","\n","Epoch 895\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0038935584016144276\n","\tBefore adaption: Boundary condition loss: 0.005370555445551872\n","\tBefore adaption: PDE loss: 0.019973888993263245\n","\tBefore adaption: Data loss: 0.02242857590317726\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1097, 0.0874, 0.3862, 0.4167], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00034017392972381734\n","\t\tAfter adaption: Boundary condition loss: 0.0005891541088923382\n","\t\tAfter adaption: PDE loss: 0.007714104247833671\n","\t\tAfter adaption: Data loss: 0.009346463301141496\n","\n","\tTesting: Initial condition loss: 0.0024969952646642923\n","\tTesting: Boundary condition loss: 0.0037719998508691788\n","\tTesting: PDE loss: 0.01947002485394478\n","\tTesting: Data loss: 0.018983792513608932\n","\n","Epoch 896\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002750106854364276\n","\tBefore adaption: Boundary condition loss: 0.003635719418525696\n","\tBefore adaption: PDE loss: 0.0195118747651577\n","\tBefore adaption: Data loss: 0.018873561173677444\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0036, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1137, 0.0861, 0.3740, 0.4262], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00023691254462966316\n","\t\tAfter adaption: Boundary condition loss: 0.00041327775026785623\n","\t\tAfter adaption: PDE loss: 0.007297476654815208\n","\t\tAfter adaption: Data loss: 0.008043530662026437\n","\n","\tTesting: Initial condition loss: 0.0015450612409040332\n","\tTesting: Boundary condition loss: 0.0021101527381688356\n","\tTesting: PDE loss: 0.018915334716439247\n","\tTesting: Data loss: 0.014873132109642029\n","\n","Epoch 897\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002344925422221422\n","\tBefore adaption: Boundary condition loss: 0.002048441208899021\n","\tBefore adaption: PDE loss: 0.018936902284622192\n","\tBefore adaption: Data loss: 0.014778297394514084\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1103, 0.0829, 0.3779, 0.4289], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0001943444680306341\n","\t\tAfter adaption: Boundary condition loss: 0.00022598576879039246\n","\t\tAfter adaption: PDE loss: 0.007156527673171802\n","\t\tAfter adaption: Data loss: 0.00633820255481318\n","\n","\tTesting: Initial condition loss: 0.0021725876722484827\n","\tTesting: Boundary condition loss: 0.0009965613717213273\n","\tTesting: PDE loss: 0.018259422853589058\n","\tTesting: Data loss: 0.01099356822669506\n","\n","Epoch 898\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003324999939650297\n","\tBefore adaption: Boundary condition loss: 0.0009682966629043221\n","\tBefore adaption: PDE loss: 0.018279235810041428\n","\tBefore adaption: Data loss: 0.010916045866906643\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1000, 0.0780, 0.3980, 0.4241], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00025922391030377224\n","\t\tAfter adaption: Boundary condition loss: 9.683279577205789e-05\n","\t\tAfter adaption: PDE loss: 0.0072742246628004536\n","\t\tAfter adaption: Data loss: 0.004629324063099488\n","\n","\tTesting: Initial condition loss: 0.00478333281353116\n","\tTesting: Boundary condition loss: 0.000341585255227983\n","\tTesting: PDE loss: 0.017524799332022667\n","\tTesting: Data loss: 0.007884930819272995\n","\n","Epoch 899\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006005381233990192\n","\tBefore adaption: Boundary condition loss: 0.00033520424040034413\n","\tBefore adaption: PDE loss: 0.017553241923451424\n","\tBefore adaption: Data loss: 0.00782373733818531\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0834, 0.0771, 0.4317, 0.4078], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00046282084881397187\n","\t\tAfter adaption: Boundary condition loss: 2.7951511865228325e-05\n","\t\tAfter adaption: PDE loss: 0.007578221995513874\n","\t\tAfter adaption: Data loss: 0.003190659416567996\n","\n","\tTesting: Initial condition loss: 0.009302373975515366\n","\tTesting: Boundary condition loss: 8.114689262583852e-05\n","\tTesting: PDE loss: 0.01674664206802845\n","\tTesting: Data loss: 0.005787820089608431\n","\n","Epoch 900\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010321365669369698\n","\tBefore adaption: Boundary condition loss: 8.469314343528822e-05\n","\tBefore adaption: PDE loss: 0.016777802258729935\n","\tBefore adaption: Data loss: 0.005742591340094805\n","tensor(8.4693e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.4693e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0619, 0.0917, 0.4719, 0.3745], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009465825783675329\n","\t\tAfter adaption: Boundary condition loss: 5.239721951442346e-06\n","\t\tAfter adaption: PDE loss: 0.00791764660359313\n","\t\tAfter adaption: Data loss: 0.0021506556560655704\n","\n","\tTesting: Initial condition loss: 0.015137648209929466\n","\tTesting: Boundary condition loss: 0.00010196700895903632\n","\tTesting: PDE loss: 0.01595931500196457\n","\tTesting: Data loss: 0.004690835252404213\n","\n","Epoch 901\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.015889042988419533\n","\tBefore adaption: Boundary condition loss: 0.00010868268873309717\n","\tBefore adaption: PDE loss: 0.015978174284100533\n","\tBefore adaption: Data loss: 0.004660680890083313\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0391, 0.1367, 0.5031, 0.3211], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002172422050987325\n","\t\tAfter adaption: Boundary condition loss: 4.246297375538565e-06\n","\t\tAfter adaption: PDE loss: 0.00803885243926475\n","\t\tAfter adaption: Data loss: 0.0014964980790705062\n","\n","\tTesting: Initial condition loss: 0.021512942388653755\n","\tTesting: Boundary condition loss: 0.00026515714125707746\n","\tTesting: PDE loss: 0.015153203159570694\n","\tTesting: Data loss: 0.004384499974548817\n","\n","Epoch 902\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.021976163610816002\n","\tBefore adaption: Boundary condition loss: 0.00027350016171112657\n","\tBefore adaption: PDE loss: 0.015186349861323833\n","\tBefore adaption: Data loss: 0.004368653520941734\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0205, 0.2192, 0.5063, 0.2540], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.004816755763618791\n","\t\tAfter adaption: Boundary condition loss: 5.608862082206585e-06\n","\t\tAfter adaption: PDE loss: 0.0076891695826166945\n","\t\tAfter adaption: Data loss: 0.0011095941591741031\n","\n","\tTesting: Initial condition loss: 0.026855384930968285\n","\tTesting: Boundary condition loss: 0.0004299133724998683\n","\tTesting: PDE loss: 0.014495513401925564\n","\tTesting: Data loss: 0.0045103514567017555\n","\n","Epoch 903\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02730456367135048\n","\tBefore adaption: Boundary condition loss: 0.00043979196925647557\n","\tBefore adaption: PDE loss: 0.014527108520269394\n","\tBefore adaption: Data loss: 0.004507302772253752\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0100, 0.3258, 0.4744, 0.1897], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.008896146541854475\n","\t\tAfter adaption: Boundary condition loss: 4.409279688578433e-06\n","\t\tAfter adaption: PDE loss: 0.006892140483656901\n","\t\tAfter adaption: Data loss: 0.0008551665986768581\n","\n","\tTesting: Initial condition loss: 0.02960619144141674\n","\tTesting: Boundary condition loss: 0.00047892547445371747\n","\tTesting: PDE loss: 0.01411466021090746\n","\tTesting: Data loss: 0.004657627549022436\n","\n","Epoch 904\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030256640166044235\n","\tBefore adaption: Boundary condition loss: 0.0004912765580229461\n","\tBefore adaption: PDE loss: 0.014142644591629505\n","\tBefore adaption: Data loss: 0.0046635642647743225\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0065, 0.4294, 0.4214, 0.1427], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012990810375222601\n","\t\tAfter adaption: Boundary condition loss: 3.2129587229447653e-06\n","\t\tAfter adaption: PDE loss: 0.005959789673508952\n","\t\tAfter adaption: Data loss: 0.0006654910101568822\n","\n","\tTesting: Initial condition loss: 0.02867196686565876\n","\tTesting: Boundary condition loss: 0.00036536212428472936\n","\tTesting: PDE loss: 0.01411740854382515\n","\tTesting: Data loss: 0.0045507741160690784\n","\n","Epoch 905\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029665669426321983\n","\tBefore adaption: Boundary condition loss: 0.0003762931446544826\n","\tBefore adaption: PDE loss: 0.0141426557675004\n","\tBefore adaption: Data loss: 0.0045598288998007774\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0067, 0.5093, 0.3688, 0.1152], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.01510823236214099\n","\t\tAfter adaption: Boundary condition loss: 2.5321214536857834e-06\n","\t\tAfter adaption: PDE loss: 0.005215158077638644\n","\t\tAfter adaption: Data loss: 0.0005254448590249469\n","\n","\tTesting: Initial condition loss: 0.024004055187106133\n","\tTesting: Boundary condition loss: 0.00017483800183981657\n","\tTesting: PDE loss: 0.014544453471899033\n","\tTesting: Data loss: 0.004249259829521179\n","\n","Epoch 906\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02547529712319374\n","\tBefore adaption: Boundary condition loss: 0.00018210789130534977\n","\tBefore adaption: PDE loss: 0.01456565409898758\n","\tBefore adaption: Data loss: 0.004253279883414507\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0076, 0.5598, 0.3308, 0.1018], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014261362602904847\n","\t\tAfter adaption: Boundary condition loss: 1.3761396731443743e-06\n","\t\tAfter adaption: PDE loss: 0.004818932725882705\n","\t\tAfter adaption: Data loss: 0.00043293896643233895\n","\n","\tTesting: Initial condition loss: 0.01693074405193329\n","\tTesting: Boundary condition loss: 9.251049777958542e-05\n","\tTesting: PDE loss: 0.01533361617475748\n","\tTesting: Data loss: 0.004224781412631273\n","\n","Epoch 907\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.018952107056975365\n","\tBefore adaption: Boundary condition loss: 9.613307338440791e-05\n","\tBefore adaption: PDE loss: 0.01535375602543354\n","\tBefore adaption: Data loss: 0.004216094501316547\n","tensor(9.6133e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(9.6133e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0076, 0.5823, 0.3135, 0.0966], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011035356279770692\n","\t\tAfter adaption: Boundary condition loss: 7.323222751488603e-07\n","\t\tAfter adaption: PDE loss: 0.004813745992480429\n","\t\tAfter adaption: Data loss: 0.0004072058300359458\n","\n","\tTesting: Initial condition loss: 0.009795884601771832\n","\tTesting: Boundary condition loss: 0.00040405013714917004\n","\tTesting: PDE loss: 0.01636197790503502\n","\tTesting: Data loss: 0.005196227692067623\n","\n","Epoch 908\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012070631608366966\n","\tBefore adaption: Boundary condition loss: 0.00039807232678867877\n","\tBefore adaption: PDE loss: 0.016393862664699554\n","\tBefore adaption: Data loss: 0.005167114082723856\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0069, 0.5771, 0.3187, 0.0973], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006966102688911425\n","\t\tAfter adaption: Boundary condition loss: 2.7656505879532797e-06\n","\t\tAfter adaption: PDE loss: 0.005224169670451278\n","\t\tAfter adaption: Data loss: 0.0005026273584085818\n","\n","\tTesting: Initial condition loss: 0.004650393966585398\n","\tTesting: Boundary condition loss: 0.0013244395377114415\n","\tTesting: PDE loss: 0.017563099041581154\n","\tTesting: Data loss: 0.0076599083840847015\n","\n","Epoch 909\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006623700261116028\n","\tBefore adaption: Boundary condition loss: 0.0012934899423271418\n","\tBefore adaption: PDE loss: 0.017603935673832893\n","\tBefore adaption: Data loss: 0.0076043629087507725\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0013, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0072, 0.5405, 0.3463, 0.1061], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003579891693489068\n","\t\tAfter adaption: Boundary condition loss: 9.269430213471381e-06\n","\t\tAfter adaption: PDE loss: 0.006095481955457808\n","\t\tAfter adaption: Data loss: 0.0008068969303942462\n","\n","\tTesting: Initial condition loss: 0.002475583925843239\n","\tTesting: Boundary condition loss: 0.002935589523985982\n","\tTesting: PDE loss: 0.01878894492983818\n","\tTesting: Data loss: 0.01170724630355835\n","\n","Epoch 910\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037834267131984234\n","\tBefore adaption: Boundary condition loss: 0.002857424085959792\n","\tBefore adaption: PDE loss: 0.018837807700037956\n","\tBefore adaption: Data loss: 0.011623010039329529\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0029, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0118, 0.4662, 0.3923, 0.1297], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0017639161862039532\n","\t\tAfter adaption: Boundary condition loss: 3.369139644198066e-05\n","\t\tAfter adaption: PDE loss: 0.007390451838299282\n","\t\tAfter adaption: Data loss: 0.0015071197837266505\n","\n","\tTesting: Initial condition loss: 0.0030352426692843437\n","\tTesting: Boundary condition loss: 0.005153399892151356\n","\tTesting: PDE loss: 0.019862379878759384\n","\tTesting: Data loss: 0.016673799604177475\n","\n","Epoch 911\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003551554400473833\n","\tBefore adaption: Boundary condition loss: 0.004976712632924318\n","\tBefore adaption: PDE loss: 0.019914744421839714\n","\tBefore adaption: Data loss: 0.016562974080443382\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0258, 0.3570, 0.4418, 0.1754], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012678122926799392\n","\t\tAfter adaption: Boundary condition loss: 0.000128248485882508\n","\t\tAfter adaption: PDE loss: 0.008798669572027913\n","\t\tAfter adaption: Data loss: 0.0029057957342371486\n","\n","\tTesting: Initial condition loss: 0.004859935957938433\n","\tTesting: Boundary condition loss: 0.007308033294975758\n","\tTesting: PDE loss: 0.020588448271155357\n","\tTesting: Data loss: 0.021162940189242363\n","\n","Epoch 912\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0046664876863360405\n","\tBefore adaption: Boundary condition loss: 0.0070145768113434315\n","\tBefore adaption: PDE loss: 0.020628271624445915\n","\tBefore adaption: Data loss: 0.021032294258475304\n","tensor(0.0070, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0070, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0512, 0.2393, 0.4690, 0.2405], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011165772326420483\n","\t\tAfter adaption: Boundary condition loss: 0.00035927619933071237\n","\t\tAfter adaption: PDE loss: 0.00967530241497858\n","\t\tAfter adaption: Data loss: 0.0050577266870399295\n","\n","\tTesting: Initial condition loss: 0.006297096610069275\n","\tTesting: Boundary condition loss: 0.008629629388451576\n","\tTesting: PDE loss: 0.02088869921863079\n","\tTesting: Data loss: 0.024003854021430016\n","\n","Epoch 913\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005678131245076656\n","\tBefore adaption: Boundary condition loss: 0.00826122984290123\n","\tBefore adaption: PDE loss: 0.020952580496668816\n","\tBefore adaption: Data loss: 0.023863229900598526\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0816, 0.1514, 0.4609, 0.3060], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008597091962839302\n","\t\tAfter adaption: Boundary condition loss: 0.0006744697499867576\n","\t\tAfter adaption: PDE loss: 0.009657869009176185\n","\t\tAfter adaption: Data loss: 0.007302400121768869\n","\n","\tTesting: Initial condition loss: 0.00644545117393136\n","\tTesting: Boundary condition loss: 0.008689630776643753\n","\tTesting: PDE loss: 0.020876087248325348\n","\tTesting: Data loss: 0.02464240789413452\n","\n","Epoch 914\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005769196432083845\n","\tBefore adaption: Boundary condition loss: 0.008305436000227928\n","\tBefore adaption: PDE loss: 0.020942451432347298\n","\tBefore adaption: Data loss: 0.024501986801624298\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0083, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1073, 0.1068, 0.4308, 0.3550], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006164164306952216\n","\t\tAfter adaption: Boundary condition loss: 0.0008915601479571694\n","\t\tAfter adaption: PDE loss: 0.009022310108168863\n","\t\tAfter adaption: Data loss: 0.008698024679358613\n","\n","\tTesting: Initial condition loss: 0.005356888752430677\n","\tTesting: Boundary condition loss: 0.007522098254412413\n","\tTesting: PDE loss: 0.020637018606066704\n","\tTesting: Data loss: 0.023095814511179924\n","\n","Epoch 915\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004946012049913406\n","\tBefore adaption: Boundary condition loss: 0.0071821995079517365\n","\tBefore adaption: PDE loss: 0.020693007856607437\n","\tBefore adaption: Data loss: 0.022963499650359154\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0072, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1238, 0.0924, 0.3991, 0.3847], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00045692537532210386\n","\t\tAfter adaption: Boundary condition loss: 0.0008892354680345676\n","\t\tAfter adaption: PDE loss: 0.008258852157768417\n","\t\tAfter adaption: Data loss: 0.008833897942521233\n","\n","\tTesting: Initial condition loss: 0.003714830381795764\n","\tTesting: Boundary condition loss: 0.005629005376249552\n","\tTesting: PDE loss: 0.02025703340768814\n","\tTesting: Data loss: 0.019897282123565674\n","\n","Epoch 916\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003768759546801448\n","\tBefore adaption: Boundary condition loss: 0.005374750588089228\n","\tBefore adaption: PDE loss: 0.020298289135098457\n","\tBefore adaption: Data loss: 0.0197792686522007\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0054, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1312, 0.0903, 0.3785, 0.3999], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00034043192172450036\n","\t\tAfter adaption: Boundary condition loss: 0.0007051403136913738\n","\t\tAfter adaption: PDE loss: 0.007683421523182717\n","\t\tAfter adaption: Data loss: 0.007910704537807497\n","\n","\tTesting: Initial condition loss: 0.002308980794623494\n","\tTesting: Boundary condition loss: 0.00364484079182148\n","\tTesting: PDE loss: 0.01972097158432007\n","\tTesting: Data loss: 0.0159109178930521\n","\n","Epoch 917\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002937768818810582\n","\tBefore adaption: Boundary condition loss: 0.003476792946457863\n","\tBefore adaption: PDE loss: 0.01978505589067936\n","\tBefore adaption: Data loss: 0.01581425964832306\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1306, 0.0897, 0.3742, 0.4055], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002636639709094154\n","\t\tAfter adaption: Boundary condition loss: 0.0004541970338560538\n","\t\tAfter adaption: PDE loss: 0.007402608206899667\n","\t\tAfter adaption: Data loss: 0.006412078372506586\n","\n","\tTesting: Initial condition loss: 0.0018863868899643421\n","\tTesting: Boundary condition loss: 0.0019966133404523134\n","\tTesting: PDE loss: 0.019125189632177353\n","\tTesting: Data loss: 0.012073202058672905\n","\n","Epoch 918\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0029874308966100216\n","\tBefore adaption: Boundary condition loss: 0.0018957203719764948\n","\tBefore adaption: PDE loss: 0.01917445659637451\n","\tBefore adaption: Data loss: 0.0119963763281703\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0019, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1229, 0.0871, 0.3870, 0.4031], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002601172483284026\n","\t\tAfter adaption: Boundary condition loss: 0.00023294950970841258\n","\t\tAfter adaption: PDE loss: 0.007420116295204578\n","\t\tAfter adaption: Data loss: 0.0048353584379114516\n","\n","\tTesting: Initial condition loss: 0.0030163051560521126\n","\tTesting: Boundary condition loss: 0.0008711366099305451\n","\tTesting: PDE loss: 0.018359271809458733\n","\tTesting: Data loss: 0.00896294042468071\n","\n","Epoch 919\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004435751587152481\n","\tBefore adaption: Boundary condition loss: 0.000823714944999665\n","\tBefore adaption: PDE loss: 0.018425868824124336\n","\tBefore adaption: Data loss: 0.008903604932129383\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1081, 0.0841, 0.4159, 0.3918], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003731753884159434\n","\t\tAfter adaption: Boundary condition loss: 8.907782761099067e-05\n","\t\tAfter adaption: PDE loss: 0.007663364474685501\n","\t\tAfter adaption: Data loss: 0.00348867047201217\n","\n","\tTesting: Initial condition loss: 0.005860723555088043\n","\tTesting: Boundary condition loss: 0.00028452606056816876\n","\tTesting: PDE loss: 0.01750723458826542\n","\tTesting: Data loss: 0.006673137191683054\n","\n","Epoch 920\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007430701516568661\n","\tBefore adaption: Boundary condition loss: 0.0002690941037144512\n","\tBefore adaption: PDE loss: 0.017563531175255775\n","\tBefore adaption: Data loss: 0.006625637877732515\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0870, 0.0885, 0.4562, 0.3684], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006572645167824973\n","\t\tAfter adaption: Boundary condition loss: 2.3398653047799135e-05\n","\t\tAfter adaption: PDE loss: 0.008012544573277164\n","\t\tAfter adaption: Data loss: 0.002440820617875923\n","\n","\tTesting: Initial condition loss: 0.010260555893182755\n","\tTesting: Boundary condition loss: 0.00010507438128115609\n","\tTesting: PDE loss: 0.016619769856333733\n","\tTesting: Data loss: 0.00522261718288064\n","\n","Epoch 921\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.011796567589044571\n","\tBefore adaption: Boundary condition loss: 0.00010946982365567237\n","\tBefore adaption: PDE loss: 0.01667208969593048\n","\tBefore adaption: Data loss: 0.005185325164347887\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0617, 0.1124, 0.4967, 0.3291], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013263844329504553\n","\t\tAfter adaption: Boundary condition loss: 6.758723416987201e-06\n","\t\tAfter adaption: PDE loss: 0.00828173244284979\n","\t\tAfter adaption: Data loss: 0.0017063802751820349\n","\n","\tTesting: Initial condition loss: 0.015639007091522217\n","\tTesting: Boundary condition loss: 0.00017512861813884228\n","\tTesting: PDE loss: 0.01574968546628952\n","\tTesting: Data loss: 0.004535363055765629\n","\n","Epoch 922\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.017083829268813133\n","\tBefore adaption: Boundary condition loss: 0.00018981436733156443\n","\tBefore adaption: PDE loss: 0.01578686013817787\n","\tBefore adaption: Data loss: 0.0045079817064106464\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0373, 0.1678, 0.5197, 0.2752], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00286731123931614\n","\t\tAfter adaption: Boundary condition loss: 7.078255798278038e-06\n","\t\tAfter adaption: PDE loss: 0.008204654966993574\n","\t\tAfter adaption: Data loss: 0.0012404045035675404\n","\n","\tTesting: Initial condition loss: 0.021121006458997726\n","\tTesting: Boundary condition loss: 0.00035297920112498105\n","\tTesting: PDE loss: 0.014921076595783234\n","\tTesting: Data loss: 0.00440397160127759\n","\n","Epoch 923\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022514626383781433\n","\tBefore adaption: Boundary condition loss: 0.0003719227097462863\n","\tBefore adaption: PDE loss: 0.014959979802370071\n","\tBefore adaption: Data loss: 0.004386354703456163\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0191, 0.2545, 0.5099, 0.2165], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0057302359382707556\n","\t\tAfter adaption: Boundary condition loss: 7.11470157309907e-06\n","\t\tAfter adaption: PDE loss: 0.007627388548123972\n","\t\tAfter adaption: Data loss: 0.0009496704623625824\n","\n","\tTesting: Initial condition loss: 0.025323862209916115\n","\tTesting: Boundary condition loss: 0.0005015261704102159\n","\tTesting: PDE loss: 0.014275630936026573\n","\tTesting: Data loss: 0.004533815197646618\n","\n","Epoch 924\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.026785731315612793\n","\tBefore adaption: Boundary condition loss: 0.0005216689314693213\n","\tBefore adaption: PDE loss: 0.014313673600554466\n","\tBefore adaption: Data loss: 0.0045242528431117535\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0099, 0.3554, 0.4684, 0.1663], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009519586991250146\n","\t\tAfter adaption: Boundary condition loss: 5.168211996491674e-06\n","\t\tAfter adaption: PDE loss: 0.006705048741317714\n","\t\tAfter adaption: Data loss: 0.0007521948029855452\n","\n","\tTesting: Initial condition loss: 0.02697441726922989\n","\tTesting: Boundary condition loss: 0.0005275126895867288\n","\tTesting: PDE loss: 0.013925070874392986\n","\tTesting: Data loss: 0.004634309560060501\n","\n","Epoch 925\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02857528254389763\n","\tBefore adaption: Boundary condition loss: 0.0005465992726385593\n","\tBefore adaption: PDE loss: 0.01396303903311491\n","\tBefore adaption: Data loss: 0.004629631992429495\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0005, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0076, 0.4469, 0.4138, 0.1316], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012771632923047982\n","\t\tAfter adaption: Boundary condition loss: 4.170165396564879e-06\n","\t\tAfter adaption: PDE loss: 0.0057776742855152365\n","\t\tAfter adaption: Data loss: 0.0006094454302976137\n","\n","\tTesting: Initial condition loss: 0.025296024978160858\n","\tTesting: Boundary condition loss: 0.000403362704673782\n","\tTesting: PDE loss: 0.013945826329290867\n","\tTesting: Data loss: 0.004576553590595722\n","\n","Epoch 926\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.027114763855934143\n","\tBefore adaption: Boundary condition loss: 0.0004195451328996569\n","\tBefore adaption: PDE loss: 0.013984265737235546\n","\tBefore adaption: Data loss: 0.004572661593556404\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0084, 0.5148, 0.3648, 0.1120], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013959102864579812\n","\t\tAfter adaption: Boundary condition loss: 3.5176060244277587e-06\n","\t\tAfter adaption: PDE loss: 0.005101807558971343\n","\t\tAfter adaption: Data loss: 0.0005120237964893192\n","\n","\tTesting: Initial condition loss: 0.02050534076988697\n","\tTesting: Boundary condition loss: 0.00019819795852527022\n","\tTesting: PDE loss: 0.014374998398125172\n","\tTesting: Data loss: 0.004520702175796032\n","\n","Epoch 927\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022610623389482498\n","\tBefore adaption: Boundary condition loss: 0.00021135401038918644\n","\tBefore adaption: PDE loss: 0.01441238448023796\n","\tBefore adaption: Data loss: 0.00451277568936348\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0093, 0.5557, 0.3321, 0.1029], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.012563820020452553\n","\t\tAfter adaption: Boundary condition loss: 1.970720008132621e-06\n","\t\tAfter adaption: PDE loss: 0.004786485187876335\n","\t\tAfter adaption: Data loss: 0.0004643929855695201\n","\n","\tTesting: Initial condition loss: 0.014148607850074768\n","\tTesting: Boundary condition loss: 8.48869894980453e-05\n","\tTesting: PDE loss: 0.015157398767769337\n","\tTesting: Data loss: 0.004897342529147863\n","\n","Epoch 928\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01641213521361351\n","\tBefore adaption: Boundary condition loss: 9.312143811257556e-05\n","\tBefore adaption: PDE loss: 0.01519692875444889\n","\tBefore adaption: Data loss: 0.004881253931671381\n","tensor(9.3121e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(9.3121e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0092, 0.5700, 0.3198, 0.1010], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009354241634460374\n","\t\tAfter adaption: Boundary condition loss: 8.610493801302267e-07\n","\t\tAfter adaption: PDE loss: 0.0048597036616948655\n","\t\tAfter adaption: Data loss: 0.0004930674186997878\n","\n","\tTesting: Initial condition loss: 0.008158791810274124\n","\tTesting: Boundary condition loss: 0.00026403903029859066\n","\tTesting: PDE loss: 0.016203435137867928\n","\tTesting: Data loss: 0.006200544070452452\n","\n","Epoch 929\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010336224921047688\n","\tBefore adaption: Boundary condition loss: 0.00025675405049696565\n","\tBefore adaption: PDE loss: 0.016237232834100723\n","\tBefore adaption: Data loss: 0.006171505898237228\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0082, 0.5567, 0.3292, 0.1059], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005754180933633831\n","\t\tAfter adaption: Boundary condition loss: 2.1078574011534253e-06\n","\t\tAfter adaption: PDE loss: 0.005345043445158946\n","\t\tAfter adaption: Data loss: 0.0006535952814131081\n","\n","\tTesting: Initial condition loss: 0.004052566364407539\n","\tTesting: Boundary condition loss: 0.0009422072907909751\n","\tTesting: PDE loss: 0.017360402271151543\n","\tTesting: Data loss: 0.00870553683489561\n","\n","Epoch 930\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005877984222024679\n","\tBefore adaption: Boundary condition loss: 0.0008962194551713765\n","\tBefore adaption: PDE loss: 0.01738615892827511\n","\tBefore adaption: Data loss: 0.008659270592033863\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0009, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0074, 0.5121, 0.3597, 0.1207], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0030101279650170598\n","\t\tAfter adaption: Boundary condition loss: 6.672761688762135e-06\n","\t\tAfter adaption: PDE loss: 0.006254075114813829\n","\t\tAfter adaption: Data loss: 0.0010454897884183958\n","\n","\tTesting: Initial condition loss: 0.002435334725305438\n","\tTesting: Boundary condition loss: 0.002154374960809946\n","\tTesting: PDE loss: 0.018460674211382866\n","\tTesting: Data loss: 0.012272677384316921\n","\n","Epoch 931\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0036244161892682314\n","\tBefore adaption: Boundary condition loss: 0.002044330583885312\n","\tBefore adaption: PDE loss: 0.01849670149385929\n","\tBefore adaption: Data loss: 0.012206966057419777\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0099, 0.4328, 0.4059, 0.1514], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001568645753328112\n","\t\tAfter adaption: Boundary condition loss: 2.0171996436891766e-05\n","\t\tAfter adaption: PDE loss: 0.0075086185129376965\n","\t\tAfter adaption: Data loss: 0.0018480032478009711\n","\n","\tTesting: Initial condition loss: 0.00281264609657228\n","\tTesting: Boundary condition loss: 0.0037076668813824654\n","\tTesting: PDE loss: 0.019372910261154175\n","\tTesting: Data loss: 0.01634424552321434\n","\n","Epoch 932\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0032715690322220325\n","\tBefore adaption: Boundary condition loss: 0.003521566977724433\n","\tBefore adaption: PDE loss: 0.019412212073802948\n","\tBefore adaption: Data loss: 0.016260651871562004\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0035, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0194, 0.3259, 0.4528, 0.2018], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010662915236506216\n","\t\tAfter adaption: Boundary condition loss: 6.831999303382376e-05\n","\t\tAfter adaption: PDE loss: 0.008790417507579846\n","\t\tAfter adaption: Data loss: 0.003282104773620266\n","\n","\tTesting: Initial condition loss: 0.004106621723622084\n","\tTesting: Boundary condition loss: 0.005262349266558886\n","\tTesting: PDE loss: 0.019978085532784462\n","\tTesting: Data loss: 0.02011599950492382\n","\n","Epoch 933\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003944342024624348\n","\tBefore adaption: Boundary condition loss: 0.00500196497887373\n","\tBefore adaption: PDE loss: 0.020024290308356285\n","\tBefore adaption: Data loss: 0.020017940551042557\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0050, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0376, 0.2179, 0.4786, 0.2659], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008596218816105207\n","\t\tAfter adaption: Boundary condition loss: 0.00018801200657353833\n","\t\tAfter adaption: PDE loss: 0.00958373146363602\n","\t\tAfter adaption: Data loss: 0.0053221463928364325\n","\n","\tTesting: Initial condition loss: 0.005239367485046387\n","\tTesting: Boundary condition loss: 0.006350636016577482\n","\tTesting: PDE loss: 0.020246731117367744\n","\tTesting: Data loss: 0.02280016615986824\n","\n","Epoch 934\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004666916094720364\n","\tBefore adaption: Boundary condition loss: 0.006056228652596474\n","\tBefore adaption: PDE loss: 0.020297857001423836\n","\tBefore adaption: Data loss: 0.022692371159791946\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0605, 0.1396, 0.4728, 0.3270], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006516289865622952\n","\t\tAfter adaption: Boundary condition loss: 0.0003665612793877563\n","\t\tAfter adaption: PDE loss: 0.009597491384494172\n","\t\tAfter adaption: Data loss: 0.007420708361685792\n","\n","\tTesting: Initial condition loss: 0.005513590294867754\n","\tTesting: Boundary condition loss: 0.0066363755613565445\n","\tTesting: PDE loss: 0.02022886462509632\n","\tTesting: Data loss: 0.02383391000330448\n","\n","Epoch 935\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0048073153011500835\n","\tBefore adaption: Boundary condition loss: 0.006346748676151037\n","\tBefore adaption: PDE loss: 0.02027435041964054\n","\tBefore adaption: Data loss: 0.02372184954583645\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0817, 0.0997, 0.4460, 0.3725], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00047936085096489265\n","\t\tAfter adaption: Boundary condition loss: 0.0005187153321074084\n","\t\tAfter adaption: PDE loss: 0.009043363377796354\n","\t\tAfter adaption: Data loss: 0.008836533982047447\n","\n","\tTesting: Initial condition loss: 0.004776304122060537\n","\tTesting: Boundary condition loss: 0.006033339537680149\n","\tTesting: PDE loss: 0.01996704190969467\n","\tTesting: Data loss: 0.023034727200865746\n","\n","Epoch 936\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004232623614370823\n","\tBefore adaption: Boundary condition loss: 0.0057836310006678104\n","\tBefore adaption: PDE loss: 0.02000899612903595\n","\tBefore adaption: Data loss: 0.022923748940229416\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0058, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0970, 0.0858, 0.4161, 0.4010], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003631561520084375\n","\t\tAfter adaption: Boundary condition loss: 0.0005612626458695317\n","\t\tAfter adaption: PDE loss: 0.008326494375566446\n","\t\tAfter adaption: Data loss: 0.009192873728809774\n","\n","\tTesting: Initial condition loss: 0.0033935406245291233\n","\tTesting: Boundary condition loss: 0.004770725034177303\n","\tTesting: PDE loss: 0.019498420879244804\n","\tTesting: Data loss: 0.02064596116542816\n","\n","Epoch 937\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003275758121162653\n","\tBefore adaption: Boundary condition loss: 0.004587321542203426\n","\tBefore adaption: PDE loss: 0.019550250843167305\n","\tBefore adaption: Data loss: 0.02054123766720295\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0046, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1055, 0.0826, 0.3949, 0.4171], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00027056466611322257\n","\t\tAfter adaption: Boundary condition loss: 0.00048375775317667486\n","\t\tAfter adaption: PDE loss: 0.007719518350897583\n","\t\tAfter adaption: Data loss: 0.008567609856939634\n","\n","\tTesting: Initial condition loss: 0.002135189948603511\n","\tTesting: Boundary condition loss: 0.003248583059757948\n","\tTesting: PDE loss: 0.01889996975660324\n","\tTesting: Data loss: 0.01724352315068245\n","\n","Epoch 938\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0025632507167756557\n","\tBefore adaption: Boundary condition loss: 0.0031406604684889317\n","\tBefore adaption: PDE loss: 0.018950369209051132\n","\tBefore adaption: Data loss: 0.017149971798062325\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0031, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1073, 0.0809, 0.3870, 0.4248], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00020728412975872025\n","\t\tAfter adaption: Boundary condition loss: 0.00033711542007565327\n","\t\tAfter adaption: PDE loss: 0.00733406251743026\n","\t\tAfter adaption: Data loss: 0.007284945826141102\n","\n","\tTesting: Initial condition loss: 0.0018470842624083161\n","\tTesting: Boundary condition loss: 0.001858995296061039\n","\tTesting: PDE loss: 0.018219122663140297\n","\tTesting: Data loss: 0.013525363057851791\n","\n","Epoch 939\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002788790035992861\n","\tBefore adaption: Boundary condition loss: 0.0018085719784721732\n","\tBefore adaption: PDE loss: 0.018247457221150398\n","\tBefore adaption: Data loss: 0.013447081670165062\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0018, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1030, 0.0777, 0.3938, 0.4255], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002166653665648452\n","\t\tAfter adaption: Boundary condition loss: 0.00018629805369186454\n","\t\tAfter adaption: PDE loss: 0.007186159083191483\n","\t\tAfter adaption: Data loss: 0.005721503133120434\n","\n","\tTesting: Initial condition loss: 0.003134372876957059\n","\tTesting: Boundary condition loss: 0.0008475783979520202\n","\tTesting: PDE loss: 0.01744775101542473\n","\tTesting: Data loss: 0.01012218277901411\n","\n","Epoch 940\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004439135082066059\n","\tBefore adaption: Boundary condition loss: 0.0008331651915796101\n","\tBefore adaption: PDE loss: 0.017479438334703445\n","\tBefore adaption: Data loss: 0.010061107575893402\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0925, 0.0755, 0.4144, 0.4176], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003349482406312403\n","\t\tAfter adaption: Boundary condition loss: 7.709573129150293e-05\n","\t\tAfter adaption: PDE loss: 0.007243361530947233\n","\t\tAfter adaption: Data loss: 0.004201714529261216\n","\n","\tTesting: Initial condition loss: 0.00624670647084713\n","\tTesting: Boundary condition loss: 0.0003004456521011889\n","\tTesting: PDE loss: 0.016621200367808342\n","\tTesting: Data loss: 0.0074624125845730305\n","\n","Epoch 941\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.007725902833044529\n","\tBefore adaption: Boundary condition loss: 0.000300474843243137\n","\tBefore adaption: PDE loss: 0.016658691689372063\n","\tBefore adaption: Data loss: 0.0074185654520988464\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0763, 0.0817, 0.4449, 0.3971], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006310140652183346\n","\t\tAfter adaption: Boundary condition loss: 2.2915018727556357e-05\n","\t\tAfter adaption: PDE loss: 0.007411961741261556\n","\t\tAfter adaption: Data loss: 0.0029461449225245003\n","\n","\tTesting: Initial condition loss: 0.010979419574141502\n","\tTesting: Boundary condition loss: 0.000100153629318811\n","\tTesting: PDE loss: 0.015767917037010193\n","\tTesting: Data loss: 0.0057218316942453384\n","\n","Epoch 942\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012536248192191124\n","\tBefore adaption: Boundary condition loss: 0.00010538976493990049\n","\tBefore adaption: PDE loss: 0.015792539343237877\n","\tBefore adaption: Data loss: 0.005694201681762934\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0559, 0.1089, 0.4760, 0.3593], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0013650432443122037\n","\t\tAfter adaption: Boundary condition loss: 5.888666087261878e-06\n","\t\tAfter adaption: PDE loss: 0.007516805002006671\n","\t\tAfter adaption: Data loss: 0.002045727431329257\n","\n","\tTesting: Initial condition loss: 0.016818994656205177\n","\tTesting: Boundary condition loss: 0.00013167905854061246\n","\tTesting: PDE loss: 0.014917867258191109\n","\tTesting: Data loss: 0.004850773140788078\n","\n","Epoch 943\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01831628754734993\n","\tBefore adaption: Boundary condition loss: 0.00013712525833398104\n","\tBefore adaption: PDE loss: 0.014954055659472942\n","\tBefore adaption: Data loss: 0.004838109482079744\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0349, 0.1697, 0.4919, 0.3035], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0031078729245333854\n","\t\tAfter adaption: Boundary condition loss: 4.790399493243274e-06\n","\t\tAfter adaption: PDE loss: 0.007355938793183674\n","\t\tAfter adaption: Data loss: 0.0014682914301712543\n","\n","\tTesting: Initial condition loss: 0.022694021463394165\n","\tTesting: Boundary condition loss: 0.00027830133331008255\n","\tTesting: PDE loss: 0.014166736043989658\n","\tTesting: Data loss: 0.00462990440428257\n","\n","Epoch 944\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02413950115442276\n","\tBefore adaption: Boundary condition loss: 0.00028286679298616946\n","\tBefore adaption: PDE loss: 0.014208766631782055\n","\tBefore adaption: Data loss: 0.0046301973052322865\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0183, 0.2639, 0.4789, 0.2388], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.006371355854304124\n","\t\tAfter adaption: Boundary condition loss: 5.189663539903089e-06\n","\t\tAfter adaption: PDE loss: 0.0068050479030157445\n","\t\tAfter adaption: Data loss: 0.0011056031085388798\n","\n","\tTesting: Initial condition loss: 0.02708231844007969\n","\tTesting: Boundary condition loss: 0.0004149973392486572\n","\tTesting: PDE loss: 0.013638418167829514\n","\tTesting: Data loss: 0.004717821255326271\n","\n","Epoch 945\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028603315353393555\n","\tBefore adaption: Boundary condition loss: 0.00041892315493896604\n","\tBefore adaption: PDE loss: 0.013671423308551311\n","\tBefore adaption: Data loss: 0.004727465100586414\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0092, 0.3720, 0.4380, 0.1807], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010641718594129011\n","\t\tAfter adaption: Boundary condition loss: 3.849039343080333e-06\n","\t\tAfter adaption: PDE loss: 0.005988511655178221\n","\t\tAfter adaption: Data loss: 0.0008544208991321063\n","\n","\tTesting: Initial condition loss: 0.02852773852646351\n","\tTesting: Boundary condition loss: 0.00044103653635829687\n","\tTesting: PDE loss: 0.013425219804048538\n","\tTesting: Data loss: 0.0047715106047689915\n","\n","Epoch 946\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030258888378739357\n","\tBefore adaption: Boundary condition loss: 0.00044575182255357504\n","\tBefore adaption: PDE loss: 0.013455579988658428\n","\tBefore adaption: Data loss: 0.0047851307317614555\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0064, 0.4681, 0.3857, 0.1399], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014163069936325724\n","\t\tAfter adaption: Boundary condition loss: 2.8426521409029133e-06\n","\t\tAfter adaption: PDE loss: 0.005189539279612135\n","\t\tAfter adaption: Data loss: 0.0006693443865632871\n","\n","\tTesting: Initial condition loss: 0.026298046112060547\n","\tTesting: Boundary condition loss: 0.00032967058359645307\n","\tTesting: PDE loss: 0.013617366552352905\n","\tTesting: Data loss: 0.00463778106495738\n","\n","Epoch 947\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028309738263487816\n","\tBefore adaption: Boundary condition loss: 0.00033675075974315405\n","\tBefore adaption: PDE loss: 0.013639220967888832\n","\tBefore adaption: Data loss: 0.004649080336093903\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0066, 0.5372, 0.3399, 0.1163], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015207966021104127\n","\t\tAfter adaption: Boundary condition loss: 2.207464548626327e-06\n","\t\tAfter adaption: PDE loss: 0.004635937921480426\n","\t\tAfter adaption: Data loss: 0.0005409107934668309\n","\n","\tTesting: Initial condition loss: 0.020859835669398308\n","\tTesting: Boundary condition loss: 0.00016139345825649798\n","\tTesting: PDE loss: 0.014223506674170494\n","\tTesting: Data loss: 0.004496543202549219\n","\n","Epoch 948\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02313527837395668\n","\tBefore adaption: Boundary condition loss: 0.0001703380112303421\n","\tBefore adaption: PDE loss: 0.01425717119127512\n","\tBefore adaption: Data loss: 0.004499194677919149\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0072, 0.5768, 0.3109, 0.1051], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013343855025789183\n","\t\tAfter adaption: Boundary condition loss: 1.228188703586091e-06\n","\t\tAfter adaption: PDE loss: 0.00443312961786744\n","\t\tAfter adaption: Data loss: 0.0004727480570336193\n","\n","\tTesting: Initial condition loss: 0.013818121515214443\n","\tTesting: Boundary condition loss: 0.00010248139733448625\n","\tTesting: PDE loss: 0.0152462562546134\n","\tTesting: Data loss: 0.004821901675313711\n","\n","Epoch 949\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.016237536445260048\n","\tBefore adaption: Boundary condition loss: 0.00010955757170449942\n","\tBefore adaption: PDE loss: 0.015277230180799961\n","\tBefore adaption: Data loss: 0.004811252001672983\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0072, 0.5882, 0.3027, 0.1018], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009551047616205984\n","\t\tAfter adaption: Boundary condition loss: 7.926843344442216e-07\n","\t\tAfter adaption: PDE loss: 0.004624597215103718\n","\t\tAfter adaption: Data loss: 0.0004900008804046142\n","\n","\tTesting: Initial condition loss: 0.007447555661201477\n","\tTesting: Boundary condition loss: 0.0003497666912153363\n","\tTesting: PDE loss: 0.016556303948163986\n","\tTesting: Data loss: 0.006154381670057774\n","\n","Epoch 950\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.009708932600915432\n","\tBefore adaption: Boundary condition loss: 0.0003421037399675697\n","\tBefore adaption: PDE loss: 0.016586175188422203\n","\tBefore adaption: Data loss: 0.006127004977315664\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0067, 0.5706, 0.3169, 0.1058], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0055401633444919435\n","\t\tAfter adaption: Boundary condition loss: 2.2844141534599233e-06\n","\t\tAfter adaption: PDE loss: 0.0052559599970550186\n","\t\tAfter adaption: Data loss: 0.0006482912936201903\n","\n","\tTesting: Initial condition loss: 0.00347981508821249\n","\tTesting: Boundary condition loss: 0.0011004500556737185\n","\tTesting: PDE loss: 0.017959918826818466\n","\tTesting: Data loss: 0.008785249665379524\n","\n","Epoch 951\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005233333446085453\n","\tBefore adaption: Boundary condition loss: 0.0010459494078531861\n","\tBefore adaption: PDE loss: 0.017998121678829193\n","\tBefore adaption: Data loss: 0.008738931268453598\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0068, 0.5197, 0.3535, 0.1201], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0027197345534694566\n","\t\tAfter adaption: Boundary condition loss: 7.091913570783611e-06\n","\t\tAfter adaption: PDE loss: 0.0063615109023053285\n","\t\tAfter adaption: Data loss: 0.001049290061350336\n","\n","\tTesting: Initial condition loss: 0.0023751871194690466\n","\tTesting: Boundary condition loss: 0.00239734910428524\n","\tTesting: PDE loss: 0.019277378916740417\n","\tTesting: Data loss: 0.01251919660717249\n","\n","Epoch 952\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0033537119161337614\n","\tBefore adaption: Boundary condition loss: 0.002253889571875334\n","\tBefore adaption: PDE loss: 0.019321082159876823\n","\tBefore adaption: Data loss: 0.012453470379114151\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0023, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0105, 0.4320, 0.4067, 0.1508], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001448859562501856\n","\t\tAfter adaption: Boundary condition loss: 2.3632939728083618e-05\n","\t\tAfter adaption: PDE loss: 0.007858431937756215\n","\t\tAfter adaption: Data loss: 0.0018776007604718113\n","\n","\tTesting: Initial condition loss: 0.003356891218572855\n","\tTesting: Boundary condition loss: 0.003998737316578627\n","\tTesting: PDE loss: 0.020332342013716698\n","\tTesting: Data loss: 0.0167058277875185\n","\n","Epoch 953\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0034922733902931213\n","\tBefore adaption: Boundary condition loss: 0.0037495093420147896\n","\tBefore adaption: PDE loss: 0.020387399941682816\n","\tBefore adaption: Data loss: 0.016623789444565773\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0216, 0.3173, 0.4594, 0.2017], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001108122392671496\n","\t\tAfter adaption: Boundary condition loss: 8.095966979890282e-05\n","\t\tAfter adaption: PDE loss: 0.009366554725391807\n","\t\tAfter adaption: Data loss: 0.003352555579122157\n","\n","\tTesting: Initial condition loss: 0.005121343303471804\n","\tTesting: Boundary condition loss: 0.005584078375250101\n","\tTesting: PDE loss: 0.021019689738750458\n","\tTesting: Data loss: 0.020488031208515167\n","\n","Epoch 954\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004545045085251331\n","\tBefore adaption: Boundary condition loss: 0.005228010937571526\n","\tBefore adaption: PDE loss: 0.021084213629364967\n","\tBefore adaption: Data loss: 0.02039445750415325\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0408, 0.2067, 0.4873, 0.2652], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0009394459402638968\n","\t\tAfter adaption: Boundary condition loss: 0.0002133156629766134\n","\t\tAfter adaption: PDE loss: 0.010273893835939933\n","\t\tAfter adaption: Data loss: 0.005409050306743715\n","\n","\tTesting: Initial condition loss: 0.006445388775318861\n","\tTesting: Boundary condition loss: 0.00664869649335742\n","\tTesting: PDE loss: 0.02132660523056984\n","\tTesting: Data loss: 0.023079901933670044\n","\n","Epoch 955\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005435716360807419\n","\tBefore adaption: Boundary condition loss: 0.006227770354598761\n","\tBefore adaption: PDE loss: 0.021395370364189148\n","\tBefore adaption: Data loss: 0.022979818284511566\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0062, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0635, 0.1325, 0.4801, 0.3239], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007200434850989179\n","\t\tAfter adaption: Boundary condition loss: 0.0003955861135147807\n","\t\tAfter adaption: PDE loss: 0.010272444717877032\n","\t\tAfter adaption: Data loss: 0.0074429368837143715\n","\n","\tTesting: Initial condition loss: 0.006630650255829096\n","\tTesting: Boundary condition loss: 0.006836199667304754\n","\tTesting: PDE loss: 0.02128101885318756\n","\tTesting: Data loss: 0.023958537727594376\n","\n","Epoch 956\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005545358173549175\n","\tBefore adaption: Boundary condition loss: 0.00640932796522975\n","\tBefore adaption: PDE loss: 0.021357735618948936\n","\tBefore adaption: Data loss: 0.023856978863477707\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0834, 0.0993, 0.4514, 0.3659], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000550919670438817\n","\t\tAfter adaption: Boundary condition loss: 0.0005343692314248093\n","\t\tAfter adaption: PDE loss: 0.00964088043694772\n","\t\tAfter adaption: Data loss: 0.008728750127799112\n","\n","\tTesting: Initial condition loss: 0.005608880892395973\n","\tTesting: Boundary condition loss: 0.006093382369726896\n","\tTesting: PDE loss: 0.020965836942195892\n","\tTesting: Data loss: 0.022990576922893524\n","\n","Epoch 957\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0047879768535494804\n","\tBefore adaption: Boundary condition loss: 0.0057202051393687725\n","\tBefore adaption: PDE loss: 0.02104245126247406\n","\tBefore adaption: Data loss: 0.02289201132953167\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0970, 0.0909, 0.4207, 0.3914], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00043513908028799714\n","\t\tAfter adaption: Boundary condition loss: 0.0005547505788675844\n","\t\tAfter adaption: PDE loss: 0.008852907635002\n","\t\tAfter adaption: Data loss: 0.008960407879660562\n","\n","\tTesting: Initial condition loss: 0.0038653374649584293\n","\tTesting: Boundary condition loss: 0.004716547206044197\n","\tTesting: PDE loss: 0.020443467423319817\n","\tTesting: Data loss: 0.0204639695584774\n","\n","Epoch 958\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0035605765879154205\n","\tBefore adaption: Boundary condition loss: 0.0044386982917785645\n","\tBefore adaption: PDE loss: 0.020505046471953392\n","\tBefore adaption: Data loss: 0.020371977239847183\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1039, 0.0905, 0.4000, 0.4057], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00032206085530874916\n","\t\tAfter adaption: Boundary condition loss: 0.0004610292081601746\n","\t\tAfter adaption: PDE loss: 0.00820129565530392\n","\t\tAfter adaption: Data loss: 0.00826526411910375\n","\n","\tTesting: Initial condition loss: 0.002239876426756382\n","\tTesting: Boundary condition loss: 0.0031818437855690718\n","\tTesting: PDE loss: 0.01975659281015396\n","\tTesting: Data loss: 0.016981344670057297\n","\n","Epoch 959\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0025767036713659763\n","\tBefore adaption: Boundary condition loss: 0.0029997513629496098\n","\tBefore adaption: PDE loss: 0.019816428422927856\n","\tBefore adaption: Data loss: 0.01689920946955681\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1046, 0.0892, 0.3935, 0.4127], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00022971894863685726\n","\t\tAfter adaption: Boundary condition loss: 0.00031391941823753354\n","\t\tAfter adaption: PDE loss: 0.0077977891983192485\n","\t\tAfter adaption: Data loss: 0.006974267155143346\n","\n","\tTesting: Initial condition loss: 0.001626706449314952\n","\tTesting: Boundary condition loss: 0.0018203099025413394\n","\tTesting: PDE loss: 0.018966583535075188\n","\tTesting: Data loss: 0.013249085284769535\n","\n","Epoch 960\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.002548558171838522\n","\tBefore adaption: Boundary condition loss: 0.001720190979540348\n","\tBefore adaption: PDE loss: 0.019015202298760414\n","\tBefore adaption: Data loss: 0.013179076835513115\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0997, 0.0846, 0.4022, 0.4135], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0002157018983853739\n","\t\tAfter adaption: Boundary condition loss: 0.00017144225185154678\n","\t\tAfter adaption: PDE loss: 0.007648770713821391\n","\t\tAfter adaption: Data loss: 0.005448932477379557\n","\n","\tTesting: Initial condition loss: 0.002632065676152706\n","\tTesting: Boundary condition loss: 0.000826203846372664\n","\tTesting: PDE loss: 0.018090683966875076\n","\tTesting: Data loss: 0.009878227487206459\n","\n","Epoch 961\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003979765810072422\n","\tBefore adaption: Boundary condition loss: 0.0007884994265623391\n","\tBefore adaption: PDE loss: 0.018137523904442787\n","\tBefore adaption: Data loss: 0.009821618907153606\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0008, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0890, 0.0795, 0.4252, 0.4063], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003163747846464199\n","\t\tAfter adaption: Boundary condition loss: 7.016093045637871e-05\n","\t\tAfter adaption: PDE loss: 0.007712832616584158\n","\t\tAfter adaption: Data loss: 0.003990345802664763\n","\n","\tTesting: Initial condition loss: 0.00552567932754755\n","\tTesting: Boundary condition loss: 0.0002820393710862845\n","\tTesting: PDE loss: 0.017178090289235115\n","\tTesting: Data loss: 0.007262279745191336\n","\n","Epoch 962\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0071004643104970455\n","\tBefore adaption: Boundary condition loss: 0.00027510806103236973\n","\tBefore adaption: PDE loss: 0.01720116287469864\n","\tBefore adaption: Data loss: 0.007219085469841957\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0729, 0.0813, 0.4587, 0.3871], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000576944418392514\n","\t\tAfter adaption: Boundary condition loss: 2.006601664829218e-05\n","\t\tAfter adaption: PDE loss: 0.007889630819354048\n","\t\tAfter adaption: Data loss: 0.0027947835774071697\n","\n","\tTesting: Initial condition loss: 0.010179487057030201\n","\tTesting: Boundary condition loss: 8.284848445327953e-05\n","\tTesting: PDE loss: 0.016200486570596695\n","\tTesting: Data loss: 0.0055566467344760895\n","\n","Epoch 963\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01178645621985197\n","\tBefore adaption: Boundary condition loss: 8.865921699907631e-05\n","\tBefore adaption: PDE loss: 0.016238383948802948\n","\tBefore adaption: Data loss: 0.005526128690689802\n","tensor(8.8659e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.8659e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0532, 0.1029, 0.4928, 0.3512], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012124628074247521\n","\t\tAfter adaption: Boundary condition loss: 4.716571751553288e-06\n","\t\tAfter adaption: PDE loss: 0.008001495267360974\n","\t\tAfter adaption: Data loss: 0.0019406644971366044\n","\n","\tTesting: Initial condition loss: 0.016034377738833427\n","\tTesting: Boundary condition loss: 0.00010951106378342956\n","\tTesting: PDE loss: 0.01525295339524746\n","\tTesting: Data loss: 0.004710529465228319\n","\n","Epoch 964\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01760595105588436\n","\tBefore adaption: Boundary condition loss: 0.00011915644427062944\n","\tBefore adaption: PDE loss: 0.015276472084224224\n","\tBefore adaption: Data loss: 0.004691972862929106\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0332, 0.1582, 0.5111, 0.2975], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.002785901154714515\n","\t\tAfter adaption: Boundary condition loss: 3.955100363105732e-06\n","\t\tAfter adaption: PDE loss: 0.007807267780898346\n","\t\tAfter adaption: Data loss: 0.0013958902717877502\n","\n","\tTesting: Initial condition loss: 0.02206539176404476\n","\tTesting: Boundary condition loss: 0.00024321340606547892\n","\tTesting: PDE loss: 0.014388998039066792\n","\tTesting: Data loss: 0.0045131840743124485\n","\n","Epoch 965\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.023627756163477898\n","\tBefore adaption: Boundary condition loss: 0.0002541666617617011\n","\tBefore adaption: PDE loss: 0.014410068280994892\n","\tBefore adaption: Data loss: 0.00450538843870163\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0174, 0.2497, 0.4983, 0.2346], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0058999293987468\n","\t\tAfter adaption: Boundary condition loss: 4.41253662994923e-06\n","\t\tAfter adaption: PDE loss: 0.0071809133365142086\n","\t\tAfter adaption: Data loss: 0.0010570067707362687\n","\n","\tTesting: Initial condition loss: 0.02683812566101551\n","\tTesting: Boundary condition loss: 0.0003667587006930262\n","\tTesting: PDE loss: 0.013732509687542915\n","\tTesting: Data loss: 0.004639707505702972\n","\n","Epoch 966\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.028461236506700516\n","\tBefore adaption: Boundary condition loss: 0.00037785936729051173\n","\tBefore adaption: PDE loss: 0.013750230893492699\n","\tBefore adaption: Data loss: 0.004640317056328058\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0085, 0.3589, 0.4548, 0.1777], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010214303003377301\n","\t\tAfter adaption: Boundary condition loss: 3.226492238943424e-06\n","\t\tAfter adaption: PDE loss: 0.006254020157674752\n","\t\tAfter adaption: Data loss: 0.0008247974874745364\n","\n","\tTesting: Initial condition loss: 0.028872184455394745\n","\tTesting: Boundary condition loss: 0.0003927755751647055\n","\tTesting: PDE loss: 0.013387017883360386\n","\tTesting: Data loss: 0.004752710461616516\n","\n","Epoch 967\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.03066333569586277\n","\tBefore adaption: Boundary condition loss: 0.0004038719926029444\n","\tBefore adaption: PDE loss: 0.013404667377471924\n","\tBefore adaption: Data loss: 0.004757806193083525\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0058, 0.4587, 0.3979, 0.1376], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014066216179382083\n","\t\tAfter adaption: Boundary condition loss: 2.330919662777534e-06\n","\t\tAfter adaption: PDE loss: 0.0053339706665579915\n","\t\tAfter adaption: Data loss: 0.0006545723512572888\n","\n","\tTesting: Initial condition loss: 0.027308953925967216\n","\tTesting: Boundary condition loss: 0.0002953322837129235\n","\tTesting: PDE loss: 0.013429380021989346\n","\tTesting: Data loss: 0.004676974378526211\n","\n","Epoch 968\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.029315629974007607\n","\tBefore adaption: Boundary condition loss: 0.0003068657824769616\n","\tBefore adaption: PDE loss: 0.013449297286570072\n","\tBefore adaption: Data loss: 0.004681622143834829\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0059, 0.5327, 0.3469, 0.1145], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015615949451742009\n","\t\tAfter adaption: Boundary condition loss: 1.8118714496767705e-06\n","\t\tAfter adaption: PDE loss: 0.004665695091333924\n","\t\tAfter adaption: Data loss: 0.0005360549417189975\n","\n","\tTesting: Initial condition loss: 0.02234046719968319\n","\tTesting: Boundary condition loss: 0.00014062956324778497\n","\tTesting: PDE loss: 0.013893130235373974\n","\tTesting: Data loss: 0.004553597420454025\n","\n","Epoch 969\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.024577725678682327\n","\tBefore adaption: Boundary condition loss: 0.00015176487795542926\n","\tBefore adaption: PDE loss: 0.013922247104346752\n","\tBefore adaption: Data loss: 0.004552880302071571\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0065, 0.5773, 0.3127, 0.1036], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014187604498734819\n","\t\tAfter adaption: Boundary condition loss: 9.870818596606402e-07\n","\t\tAfter adaption: PDE loss: 0.004353326757815047\n","\t\tAfter adaption: Data loss: 0.00047146291990446566\n","\n","\tTesting: Initial condition loss: 0.015365580096840858\n","\tTesting: Boundary condition loss: 7.930188439786434e-05\n","\tTesting: PDE loss: 0.014780531637370586\n","\tTesting: Data loss: 0.00482970243319869\n","\n","Epoch 970\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01776144653558731\n","\tBefore adaption: Boundary condition loss: 8.747404353925958e-05\n","\tBefore adaption: PDE loss: 0.014806661754846573\n","\tBefore adaption: Data loss: 0.004819259513169527\n","tensor(8.7474e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(8.7474e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0065, 0.5937, 0.2993, 0.1005], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.010545070676345318\n","\t\tAfter adaption: Boundary condition loss: 5.677051223666743e-07\n","\t\tAfter adaption: PDE loss: 0.004432060587497074\n","\t\tAfter adaption: Data loss: 0.00048421681762564524\n","\n","\tTesting: Initial condition loss: 0.008588332682847977\n","\tTesting: Boundary condition loss: 0.0003114399441983551\n","\tTesting: PDE loss: 0.015986481681466103\n","\tTesting: Data loss: 0.006071694195270538\n","\n","Epoch 971\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010966700501739979\n","\tBefore adaption: Boundary condition loss: 0.000305415247566998\n","\tBefore adaption: PDE loss: 0.016006484627723694\n","\tBefore adaption: Data loss: 0.006047428119927645\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0059, 0.5816, 0.3082, 0.1043], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00637844447148439\n","\t\tAfter adaption: Boundary condition loss: 1.802918072179796e-06\n","\t\tAfter adaption: PDE loss: 0.004933456310015941\n","\t\tAfter adaption: Data loss: 0.0006305122525569038\n","\n","\tTesting: Initial condition loss: 0.0040998575277626514\n","\tTesting: Boundary condition loss: 0.0010202573612332344\n","\tTesting: PDE loss: 0.017288491129875183\n","\tTesting: Data loss: 0.008632992394268513\n","\n","Epoch 972\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006029809359461069\n","\tBefore adaption: Boundary condition loss: 0.0009731253376230597\n","\tBefore adaption: PDE loss: 0.017320528626441956\n","\tBefore adaption: Data loss: 0.008591970428824425\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0059, 0.5369, 0.3393, 0.1178], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0032376511099455195\n","\t\tAfter adaption: Boundary condition loss: 5.789965955152718e-06\n","\t\tAfter adaption: PDE loss: 0.005876680274001907\n","\t\tAfter adaption: Data loss: 0.001012298487377464\n","\n","\tTesting: Initial condition loss: 0.002448496175929904\n","\tTesting: Boundary condition loss: 0.0022880660835653543\n","\tTesting: PDE loss: 0.01854555681347847\n","\tTesting: Data loss: 0.012401559390127659\n","\n","Epoch 973\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.00365779479034245\n","\tBefore adaption: Boundary condition loss: 0.0021609091199934483\n","\tBefore adaption: PDE loss: 0.018595309928059578\n","\tBefore adaption: Data loss: 0.012342624366283417\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0022, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0094, 0.4553, 0.3879, 0.1474], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.001665415133618041\n","\t\tAfter adaption: Boundary condition loss: 2.025604361201479e-05\n","\t\tAfter adaption: PDE loss: 0.007213351929962276\n","\t\tAfter adaption: Data loss: 0.0018193975038883741\n","\n","\tTesting: Initial condition loss: 0.00310327485203743\n","\tTesting: Boundary condition loss: 0.0039214640855789185\n","\tTesting: PDE loss: 0.01960422284901142\n","\tTesting: Data loss: 0.01677657850086689\n","\n","Epoch 974\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003474897937849164\n","\tBefore adaption: Boundary condition loss: 0.003696420695632696\n","\tBefore adaption: PDE loss: 0.019649293273687363\n","\tBefore adaption: Data loss: 0.016701119020581245\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0037, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0200, 0.3428, 0.4392, 0.1980], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0011912411587717527\n","\t\tAfter adaption: Boundary condition loss: 7.40438001359454e-05\n","\t\tAfter adaption: PDE loss: 0.008629900303166994\n","\t\tAfter adaption: Data loss: 0.003306132800445545\n","\n","\tTesting: Initial condition loss: 0.004804308991879225\n","\tTesting: Boundary condition loss: 0.0055831922218203545\n","\tTesting: PDE loss: 0.020338760688900948\n","\tTesting: Data loss: 0.020873835310339928\n","\n","Epoch 975\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004421402234584093\n","\tBefore adaption: Boundary condition loss: 0.005250975955277681\n","\tBefore adaption: PDE loss: 0.02037372812628746\n","\tBefore adaption: Data loss: 0.02078566886484623\n","tensor(0.0053, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0053, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0393, 0.2275, 0.4696, 0.2636], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010060038402887408\n","\t\tAfter adaption: Boundary condition loss: 0.00020616627894302954\n","\t\tAfter adaption: PDE loss: 0.009566623802611833\n","\t\tAfter adaption: Data loss: 0.005480139608703848\n","\n","\tTesting: Initial condition loss: 0.006267231423407793\n","\tTesting: Boundary condition loss: 0.006782937794923782\n","\tTesting: PDE loss: 0.02070343680679798\n","\tTesting: Data loss: 0.023823749274015427\n","\n","Epoch 976\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005386763717979193\n","\tBefore adaption: Boundary condition loss: 0.006382671184837818\n","\tBefore adaption: PDE loss: 0.020744875073432922\n","\tBefore adaption: Data loss: 0.02372719533741474\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0064, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0628, 0.1446, 0.4659, 0.3267], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0007787910498551996\n","\t\tAfter adaption: Boundary condition loss: 0.00040061386661539844\n","\t\tAfter adaption: PDE loss: 0.009665869188635587\n","\t\tAfter adaption: Data loss: 0.007752121754025575\n","\n","\tTesting: Initial condition loss: 0.006666256580501795\n","\tTesting: Boundary condition loss: 0.007104282267391682\n","\tTesting: PDE loss: 0.020746367052197456\n","\tTesting: Data loss: 0.02501031756401062\n","\n","Epoch 977\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005645740311592817\n","\tBefore adaption: Boundary condition loss: 0.006696522701531649\n","\tBefore adaption: PDE loss: 0.020789068192243576\n","\tBefore adaption: Data loss: 0.024910414591431618\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0067, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0838, 0.1042, 0.4389, 0.3730], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0005884600142579383\n","\t\tAfter adaption: Boundary condition loss: 0.0005613139401354847\n","\t\tAfter adaption: PDE loss: 0.009125022741287563\n","\t\tAfter adaption: Data loss: 0.0092919225867568\n","\n","\tTesting: Initial condition loss: 0.005806678906083107\n","\tTesting: Boundary condition loss: 0.006455836817622185\n","\tTesting: PDE loss: 0.02052876353263855\n","\tTesting: Data loss: 0.024225682020187378\n","\n","Epoch 978\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005015568342059851\n","\tBefore adaption: Boundary condition loss: 0.006098106969147921\n","\tBefore adaption: PDE loss: 0.02056925557553768\n","\tBefore adaption: Data loss: 0.024127211421728134\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0986, 0.0920, 0.4081, 0.4013], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0004614884899484881\n","\t\tAfter adaption: Boundary condition loss: 0.0006010186719432535\n","\t\tAfter adaption: PDE loss: 0.008394098787138315\n","\t\tAfter adaption: Data loss: 0.009683233792416325\n","\n","\tTesting: Initial condition loss: 0.0041198465041816235\n","\tTesting: Boundary condition loss: 0.005112679675221443\n","\tTesting: PDE loss: 0.02010158821940422\n","\tTesting: Data loss: 0.02172449231147766\n","\n","Epoch 979\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003828149987384677\n","\tBefore adaption: Boundary condition loss: 0.004846806172281504\n","\tBefore adaption: PDE loss: 0.020141946151852608\n","\tBefore adaption: Data loss: 0.021631823852658272\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0048, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1063, 0.0905, 0.3861, 0.4170], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00034655717620046773\n","\t\tAfter adaption: Boundary condition loss: 0.0005154296657593213\n","\t\tAfter adaption: PDE loss: 0.007777428007558314\n","\t\tAfter adaption: Data loss: 0.009020385791700726\n","\n","\tTesting: Initial condition loss: 0.0024389028549194336\n","\tTesting: Boundary condition loss: 0.003544123377650976\n","\tTesting: PDE loss: 0.019514625892043114\n","\tTesting: Data loss: 0.018122946843504906\n","\n","Epoch 980\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0027610466349869967\n","\tBefore adaption: Boundary condition loss: 0.003372481558471918\n","\tBefore adaption: PDE loss: 0.019566310569643974\n","\tBefore adaption: Data loss: 0.01803961582481861\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0034, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1079, 0.0895, 0.3781, 0.4245], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00024719018303557714\n","\t\tAfter adaption: Boundary condition loss: 0.0003637927549300382\n","\t\tAfter adaption: PDE loss: 0.0073978418130021565\n","\t\tAfter adaption: Data loss: 0.007658004099704956\n","\n","\tTesting: Initial condition loss: 0.0016776911215856671\n","\tTesting: Boundary condition loss: 0.0021107422653585672\n","\tTesting: PDE loss: 0.018830720335245132\n","\tTesting: Data loss: 0.014169948175549507\n","\n","Epoch 981\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0025603193789720535\n","\tBefore adaption: Boundary condition loss: 0.0020175250247120857\n","\tBefore adaption: PDE loss: 0.018880410119891167\n","\tBefore adaption: Data loss: 0.014098727144300938\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0020, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.1037, 0.0857, 0.3852, 0.4255], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00021929728500242885\n","\t\tAfter adaption: Boundary condition loss: 0.0002091386153263355\n","\t\tAfter adaption: PDE loss: 0.007272772336619066\n","\t\tAfter adaption: Data loss: 0.005998789670445854\n","\n","\tTesting: Initial condition loss: 0.0025057673919945955\n","\tTesting: Boundary condition loss: 0.0010345951886847615\n","\tTesting: PDE loss: 0.018077710643410683\n","\tTesting: Data loss: 0.010534255765378475\n","\n","Epoch 982\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0037511195987462997\n","\tBefore adaption: Boundary condition loss: 0.0010010979603976011\n","\tBefore adaption: PDE loss: 0.018116720020771027\n","\tBefore adaption: Data loss: 0.010476603172719479\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0010, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0938, 0.0807, 0.4069, 0.4186], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003025743914642362\n","\t\tAfter adaption: Boundary condition loss: 9.387888913533721e-05\n","\t\tAfter adaption: PDE loss: 0.007372591971898467\n","\t\tAfter adaption: Data loss: 0.004385630208040268\n","\n","\tTesting: Initial condition loss: 0.005210479721426964\n","\tTesting: Boundary condition loss: 0.000403302168706432\n","\tTesting: PDE loss: 0.01727631315588951\n","\tTesting: Data loss: 0.007658448535948992\n","\n","Epoch 983\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.006582598201930523\n","\tBefore adaption: Boundary condition loss: 0.00039699868648312986\n","\tBefore adaption: PDE loss: 0.017302589491009712\n","\tBefore adaption: Data loss: 0.007615176495164633\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0785, 0.0811, 0.4404, 0.4000], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.000533884377259152\n","\t\tAfter adaption: Boundary condition loss: 3.115588285370274e-05\n","\t\tAfter adaption: PDE loss: 0.00761975322124376\n","\t\tAfter adaption: Data loss: 0.00304632613205751\n","\n","\tTesting: Initial condition loss: 0.009625985287129879\n","\tTesting: Boundary condition loss: 0.00012288117432035506\n","\tTesting: PDE loss: 0.016426479443907738\n","\tTesting: Data loss: 0.005729469936341047\n","\n","Epoch 984\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.010989543050527573\n","\tBefore adaption: Boundary condition loss: 0.00012886588228866458\n","\tBefore adaption: PDE loss: 0.016445567831397057\n","\tBefore adaption: Data loss: 0.005700622219592333\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0001, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0591, 0.0989, 0.4773, 0.3647], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010869645894622919\n","\t\tAfter adaption: Boundary condition loss: 7.611467046840319e-06\n","\t\tAfter adaption: PDE loss: 0.007849116998771541\n","\t\tAfter adaption: Data loss: 0.002079285791376028\n","\n","\tTesting: Initial condition loss: 0.01527450978755951\n","\tTesting: Boundary condition loss: 8.47664923639968e-05\n","\tTesting: PDE loss: 0.015570593066513538\n","\tTesting: Data loss: 0.004716039169579744\n","\n","Epoch 985\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.01656750962138176\n","\tBefore adaption: Boundary condition loss: 9.588658576831222e-05\n","\tBefore adaption: PDE loss: 0.01558301504701376\n","\tBefore adaption: Data loss: 0.004700548946857452\n","tensor(9.5887e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(9.5887e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0385, 0.1482, 0.5023, 0.3110], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0024553257315161384\n","\t\tAfter adaption: Boundary condition loss: 3.688793758471184e-06\n","\t\tAfter adaption: PDE loss: 0.007827836135633202\n","\t\tAfter adaption: Data loss: 0.0014618556186672168\n","\n","\tTesting: Initial condition loss: 0.021332377567887306\n","\tTesting: Boundary condition loss: 0.00018187890236731619\n","\tTesting: PDE loss: 0.014753841795027256\n","\tTesting: Data loss: 0.004418244585394859\n","\n","Epoch 986\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.022532282397150993\n","\tBefore adaption: Boundary condition loss: 0.00019514758605509996\n","\tBefore adaption: PDE loss: 0.01477059070020914\n","\tBefore adaption: Data loss: 0.00441490113735199\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0210, 0.2338, 0.4990, 0.2461], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.005269066596489781\n","\t\tAfter adaption: Boundary condition loss: 4.106148713204769e-06\n","\t\tAfter adaption: PDE loss: 0.007370521224710969\n","\t\tAfter adaption: Data loss: 0.0010865666814926672\n","\n","\tTesting: Initial condition loss: 0.02642694301903248\n","\tTesting: Boundary condition loss: 0.0003047989448532462\n","\tTesting: PDE loss: 0.014101353473961353\n","\tTesting: Data loss: 0.004514343570917845\n","\n","Epoch 987\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02764977514743805\n","\tBefore adaption: Boundary condition loss: 0.0003186298126820475\n","\tBefore adaption: PDE loss: 0.014114695601165295\n","\tBefore adaption: Data loss: 0.0045209298841655254\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0102, 0.3407, 0.4635, 0.1855], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.009421510832069067\n","\t\tAfter adaption: Boundary condition loss: 3.265756568298699e-06\n","\t\tAfter adaption: PDE loss: 0.006542536029124137\n","\t\tAfter adaption: Data loss: 0.000838538586643542\n","\n","\tTesting: Initial condition loss: 0.029047710821032524\n","\tTesting: Boundary condition loss: 0.0003597473260015249\n","\tTesting: PDE loss: 0.013735122978687286\n","\tTesting: Data loss: 0.00464567169547081\n","\n","Epoch 988\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.030416840687394142\n","\tBefore adaption: Boundary condition loss: 0.00037395392428152263\n","\tBefore adaption: PDE loss: 0.013747612945735455\n","\tBefore adaption: Data loss: 0.004658047575503588\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0004, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0060, 0.4425, 0.4102, 0.1413], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.013458308202146876\n","\t\tAfter adaption: Boundary condition loss: 2.227283392544646e-06\n","\t\tAfter adaption: PDE loss: 0.0056398309140622575\n","\t\tAfter adaption: Data loss: 0.0006583710736959589\n","\n","\tTesting: Initial condition loss: 0.028168050572276115\n","\tTesting: Boundary condition loss: 0.0003018399002030492\n","\tTesting: PDE loss: 0.01373901404440403\n","\tTesting: Data loss: 0.004581098910421133\n","\n","Epoch 989\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.02978486195206642\n","\tBefore adaption: Boundary condition loss: 0.0003168662660755217\n","\tBefore adaption: PDE loss: 0.013755482621490955\n","\tBefore adaption: Data loss: 0.004593816585838795\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0003, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0053, 0.5203, 0.3590, 0.1154], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.015497620361274587\n","\t\tAfter adaption: Boundary condition loss: 1.6949768101633946e-06\n","\t\tAfter adaption: PDE loss: 0.004937819516268224\n","\t\tAfter adaption: Data loss: 0.0005299466805251797\n","\n","\tTesting: Initial condition loss: 0.02379191480576992\n","\tTesting: Boundary condition loss: 0.00016877568850759417\n","\tTesting: PDE loss: 0.014168299734592438\n","\tTesting: Data loss: 0.004378656856715679\n","\n","Epoch 990\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.025685852393507957\n","\tBefore adaption: Boundary condition loss: 0.00018414558144286275\n","\tBefore adaption: PDE loss: 0.014186847023665905\n","\tBefore adaption: Data loss: 0.004385980311781168\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0058, 0.5692, 0.3225, 0.1025], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.014619474656016004\n","\t\tAfter adaption: Boundary condition loss: 1.0730457441765056e-06\n","\t\tAfter adaption: PDE loss: 0.004574666892908109\n","\t\tAfter adaption: Data loss: 0.0004497814909133498\n","\n","\tTesting: Initial condition loss: 0.017083195969462395\n","\tTesting: Boundary condition loss: 8.335898019140586e-05\n","\tTesting: PDE loss: 0.015019522048532963\n","\tTesting: Data loss: 0.004414228722453117\n","\n","Epoch 991\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.019230911508202553\n","\tBefore adaption: Boundary condition loss: 9.561234764987603e-05\n","\tBefore adaption: PDE loss: 0.01503384206444025\n","\tBefore adaption: Data loss: 0.004411582835018635\n","tensor(9.5612e-05, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(9.5612e-05, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0060, 0.5902, 0.3059, 0.0979], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.011350100822086786\n","\t\tAfter adaption: Boundary condition loss: 5.756155529534259e-07\n","\t\tAfter adaption: PDE loss: 0.004599180238173523\n","\t\tAfter adaption: Data loss: 0.00043170332253795947\n","\n","\tTesting: Initial condition loss: 0.01019431184977293\n","\tTesting: Boundary condition loss: 0.00021627733076456934\n","\tTesting: PDE loss: 0.016161605715751648\n","\tTesting: Data loss: 0.005231034941971302\n","\n","Epoch 992\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.012399302795529366\n","\tBefore adaption: Boundary condition loss: 0.00021658898913301528\n","\tBefore adaption: PDE loss: 0.016189465299248695\n","\tBefore adaption: Data loss: 0.005214884411543608\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0002, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0057, 0.5838, 0.3113, 0.0992], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.007238617488805287\n","\t\tAfter adaption: Boundary condition loss: 1.227291849904398e-06\n","\t\tAfter adaption: PDE loss: 0.005040376554750677\n","\t\tAfter adaption: Data loss: 0.0005173384931094569\n","\n","\tTesting: Initial condition loss: 0.005058533977717161\n","\tTesting: Boundary condition loss: 0.0007395284483209252\n","\tTesting: PDE loss: 0.01746833510696888\n","\tTesting: Data loss: 0.007248331792652607\n","\n","Epoch 993\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0070118652656674385\n","\tBefore adaption: Boundary condition loss: 0.0007070463616400957\n","\tBefore adaption: PDE loss: 0.01750791259109974\n","\tBefore adaption: Data loss: 0.007215562276542187\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0007, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0055, 0.5469, 0.3393, 0.1083], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.003834978024244236\n","\t\tAfter adaption: Boundary condition loss: 3.90599297637386e-06\n","\t\tAfter adaption: PDE loss: 0.005940243534016899\n","\t\tAfter adaption: Data loss: 0.0007811522026080678\n","\n","\tTesting: Initial condition loss: 0.0026264532934874296\n","\tTesting: Boundary condition loss: 0.0017776025924831629\n","\tTesting: PDE loss: 0.018785638734698296\n","\tTesting: Data loss: 0.010498934425413609\n","\n","Epoch 994\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004009671043604612\n","\tBefore adaption: Boundary condition loss: 0.0016729587223380804\n","\tBefore adaption: PDE loss: 0.018836185336112976\n","\tBefore adaption: Data loss: 0.0104481540620327\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0017, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0077, 0.4750, 0.3870, 0.1303], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0019043956463574623\n","\t\tAfter adaption: Boundary condition loss: 1.2837927463677716e-05\n","\t\tAfter adaption: PDE loss: 0.007290266251394433\n","\t\tAfter adaption: Data loss: 0.0013618144251936245\n","\n","\tTesting: Initial condition loss: 0.002690973225980997\n","\tTesting: Boundary condition loss: 0.003206737572327256\n","\tTesting: PDE loss: 0.019941136240959167\n","\tTesting: Data loss: 0.014551469124853611\n","\n","Epoch 995\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.003300896380096674\n","\tBefore adaption: Boundary condition loss: 0.0029998915269970894\n","\tBefore adaption: PDE loss: 0.01997741498053074\n","\tBefore adaption: Data loss: 0.01448384951800108\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0030, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0156, 0.3700, 0.4429, 0.1716], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0012212237203031858\n","\t\tAfter adaption: Boundary condition loss: 4.6739268341281474e-05\n","\t\tAfter adaption: PDE loss: 0.008847437832359207\n","\t\tAfter adaption: Data loss: 0.002485140417204681\n","\n","\tTesting: Initial condition loss: 0.004198207054287195\n","\tTesting: Boundary condition loss: 0.004760028328746557\n","\tTesting: PDE loss: 0.02077283337712288\n","\tTesting: Data loss: 0.01865004561841488\n","\n","Epoch 996\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004027429968118668\n","\tBefore adaption: Boundary condition loss: 0.00444194208830595\n","\tBefore adaption: PDE loss: 0.020811494439840317\n","\tBefore adaption: Data loss: 0.018568703904747963\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0044, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0315, 0.2538, 0.4839, 0.2309], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0010221056888572307\n","\t\tAfter adaption: Boundary condition loss: 0.00013973556278460087\n","\t\tAfter adaption: PDE loss: 0.010070225251094926\n","\t\tAfter adaption: Data loss: 0.004287093680686869\n","\n","\tTesting: Initial condition loss: 0.005855434108525515\n","\tTesting: Boundary condition loss: 0.006068766117095947\n","\tTesting: PDE loss: 0.02123546041548252\n","\tTesting: Data loss: 0.021975083276629448\n","\n","Epoch 997\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.0050841704942286015\n","\tBefore adaption: Boundary condition loss: 0.005659028422087431\n","\tBefore adaption: PDE loss: 0.02127019502222538\n","\tBefore adaption: Data loss: 0.02188386768102646\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0057, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0528, 0.1617, 0.4911, 0.2944], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0008221066219529337\n","\t\tAfter adaption: Boundary condition loss: 0.00029893159237594436\n","\t\tAfter adaption: PDE loss: 0.01044634941074341\n","\t\tAfter adaption: Data loss: 0.0064415266841708636\n","\n","\tTesting: Initial condition loss: 0.0067104678601026535\n","\tTesting: Boundary condition loss: 0.006741456221789122\n","\tTesting: PDE loss: 0.021331829950213432\n","\tTesting: Data loss: 0.023858502507209778\n","\n","Epoch 998\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005647269077599049\n","\tBefore adaption: Boundary condition loss: 0.0062911007553339005\n","\tBefore adaption: PDE loss: 0.021373119205236435\n","\tBefore adaption: Data loss: 0.023762203752994537\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0063, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0737, 0.1116, 0.4688, 0.3459], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0006300823776251352\n","\t\tAfter adaption: Boundary condition loss: 0.00046393296133448295\n","\t\tAfter adaption: PDE loss: 0.010019320971070536\n","\t\tAfter adaption: Data loss: 0.008219372305375387\n","\n","\tTesting: Initial condition loss: 0.006358320824801922\n","\tTesting: Boundary condition loss: 0.006541548762470484\n","\tTesting: PDE loss: 0.021126801148056984\n","\tTesting: Data loss: 0.023945843800902367\n","\n","Epoch 999\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.005353132262825966\n","\tBefore adaption: Boundary condition loss: 0.0061147334054112434\n","\tBefore adaption: PDE loss: 0.021168138831853867\n","\tBefore adaption: Data loss: 0.023849358782172203\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0061, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0898, 0.0941, 0.4360, 0.3801], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.00050350275853315\n","\t\tAfter adaption: Boundary condition loss: 0.0005491253237912253\n","\t\tAfter adaption: PDE loss: 0.009229158567756636\n","\t\tAfter adaption: Data loss: 0.009066229587150988\n","\n","\tTesting: Initial condition loss: 0.004975632298737764\n","\tTesting: Boundary condition loss: 0.005575543735176325\n","\tTesting: PDE loss: 0.020684633404016495\n","\tTesting: Data loss: 0.022286737337708473\n","\n","Epoch 1000\n","-------------------------------\n","\tBefore adaption: Initial condition loss: 0.004345928318798542\n","\tBefore adaption: Boundary condition loss: 0.00522476015612483\n","\tBefore adaption: PDE loss: 0.020724331960082054\n","\tBefore adaption: Data loss: 0.022194482386112213\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","==> Interpreting finite difference order as 4 sinceno explicit order was specified.\n","tensor(0.0052, grad_fn=<MseLossBackward0>)\n","\t\tAdapt weights (bound,init,pde,data): tensor([0.0996, 0.0914, 0.4084, 0.4005], dtype=torch.float64)\n","\t\tAfter adaption: Initial condition loss: 0.0003972761663419367\n","\t\tAfter adaption: Boundary condition loss: 0.0005203896939985243\n","\t\tAfter adaption: PDE loss: 0.008464580317873113\n","\t\tAfter adaption: Data loss: 0.008889974981911576\n","\n","\tTesting: Initial condition loss: 0.0032055287156254053\n","\tTesting: Boundary condition loss: 0.004196276422590017\n","\tTesting: PDE loss: 0.020053990185260773\n","\tTesting: Data loss: 0.01931370422244072\n","\n","Training complete!\n","\n"]}],"source":["#PINN Model setup\n","model = NeuralNetwork()\n","model.to(device)\n","model.apply(init_weights)\n","loss_fn = combined_physics_data_loss\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","#Place reshaped input tensors with correct data-type and with calculation of derivatives enabled on available device\n","x_interior_train=torch.from_numpy(x_interior_train.reshape(x_interior_train.shape[0],1)).float().requires_grad_().to(device)\n","t_interior_train=torch.from_numpy(t_interior_train.reshape(t_interior_train.shape[0],1)).float().requires_grad_().to(device)\n","x_init_train=torch.from_numpy(x_init_train.reshape(x_init_train.shape[0],1)).float().requires_grad_().to(device)\n","t_init_train=torch.from_numpy(t_init_train.reshape(t_init_train.shape[0],1)).float().requires_grad_().to(device)\n","x_bound_train=torch.from_numpy(x_bound_train.reshape(x_bound_train.shape[0],1)).float().requires_grad_().to(device)\n","t_bound_train=torch.from_numpy(t_bound_train.reshape(t_bound_train.shape[0],1)).float().requires_grad_().to(device)\n","labels_bound_train=torch.from_numpy(labels_bound_train.reshape(labels_bound_train.shape[0],1)).float().requires_grad_().to(device)\n","labels_init_train=torch.from_numpy(labels_init_train.reshape(labels_init_train.shape[0],1)).float().requires_grad_().to(device)\n","labels_interior_train=torch.from_numpy(labels_interior_train.reshape(labels_interior_train.shape[0],1)).float().requires_grad_().to(device)\n","\n","x_interior_test=torch.from_numpy(x_interior_test.reshape(x_interior_test.shape[0],1)).float().requires_grad_().to(device)\n","t_interior_test=torch.from_numpy(t_interior_test.reshape(t_interior_test.shape[0],1)).float().requires_grad_().to(device)\n","x_init_test=torch.from_numpy(x_init_test.reshape(x_init_test.shape[0],1)).float().requires_grad_().to(device)\n","t_init_test=torch.from_numpy(t_init_test.reshape(t_init_test.shape[0],1)).float().requires_grad_().to(device)\n","x_bound_test=torch.from_numpy(x_bound_test.reshape(x_bound_test.shape[0],1)).float().requires_grad_().to(device)\n","t_bound_test=torch.from_numpy(t_bound_test.reshape(t_bound_test.shape[0],1)).float().requires_grad_().to(device)\n","labels_bound_test=torch.from_numpy(labels_bound_test.reshape(labels_bound_test.shape[0],1)).float().requires_grad_().to(device)\n","labels_init_test=torch.from_numpy(labels_init_test.reshape(labels_init_test.shape[0],1)).float().requires_grad_().to(device)\n","labels_interior_test=torch.from_numpy(labels_interior_test.reshape(labels_interior_test.shape[0],1)).float().requires_grad_().to(device)\n","\n","#Setup Tensorboard for QCs\n","tensorboard_dir_name = \"weighting\"\n","writer = SummaryWriter(\"softadapt-man/\" + tensorboard_dir_name)\n","\n","epochs = 1000\n","boundary_losses = []\n","pde_losses = []\n","init_losses = []\n","data_losses = []\n","adapt_weights = torch.tensor([1,1,1,1])\n","\n","for epoch in range(epochs):\n","    print(f\"\\nEpoch {epoch+1}\\n-------------------------------\")\n","\n","    train_loop_softadapt(\n","        x_bound_train, x_init_train, x_interior_train,\n","        t_bound_train, t_init_train, t_interior_train,\n","        labels_bound_train, labels_init_train, labels_interior_train,\n","        boundary_losses, pde_losses, init_losses, data_losses, adapt_weights,\n","        model, loss_fn, optimizer, writer)\n","    \n","    test_loop(\n","        x_bound_test, x_init_test, x_interior_test,\\\n","        t_bound_test, t_init_test, t_interior_test,\\\n","        labels_bound_test, labels_init_test, labels_interior_test,\\\n","        model, loss_fn, writer)\n","\n","print(\"\\nTraining complete!\\n\")\n"]},{"cell_type":"code","execution_count":774,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"elapsed":663,"status":"ok","timestamp":1682006984448,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"SoddI-AsY3Us","outputId":"c069e1ea-838c-4f8e-b358-6a792ec0d6d0"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAqkAAAETCAYAAAAVn59JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAADeCElEQVR4nOx9e7wd09n/d83e+5yTRBK5kAiJhLqkTWiaFImSeBF3SlWJIiTKS7UhKNVKKFJRkda1rRDqlpfihwYJrbhFEYm6tLSooIlUkHvO2Xvm+f0xs9Y8a82a2TPn7JOT5Mz385lz9p5ZM7Nm9jPPfNdzW4KICDly5MiRI0eOHDlybERw2roDOXLkyJEjR44cOXKYyElqjhw5cuTIkSNHjo0OOUnNkSNHjhw5cuTIsdEhJ6k5cuTIkSNHjhw5NjrkJDVHjhw5cuTIkSPHRoecpObIkSNHjhw5cuTY6JCT1Bw5cuTIkSNHjhwbHXKSmiNHjhw5cuTIkWOjQ05Sc+TIkSNHjhw5cmx02GRI6l//+lccffTR6NevH+rr69GrVy8MHz4cEydO1NqNGjUKo0aNapM+PvPMMxBC4Jlnnsm879tvv43Jkyfj3//+d837NXnyZAghqrYbO3YshBBq6dSpE/r3748jjzwSt99+OxobG5vdh9mzZ2Py5MnN3r8tMXPmTO2+FItFbLfddjj11FPxySefbJA+9O/fH2PHjlXfmytrL774IiZPnowvv/yypv0DfPnp379/1XajRo1S99JxHHTu3Blf+cpX8N3vfhcPPPAAPM9rdh/uueceTJ8+vdn7txVsMrbNNtvg+OOPxz//+c9WO29a3QBEZbCt+wMAp512Gg4++GBt3cKFCzFy5Eh07doVQghMnz69Rbq5pRBCaLpvxowZ2HbbbbFmzZoN3peNAW0h65u6nLdnbBIk9U9/+hNGjBiBlStXYurUqZgzZw5+/etfY++998asWbO0tjfddBNuuummNupp8/H222/jsssuaxWSmgUdOnTA/PnzMX/+fDz22GO4/PLL0alTJ5x++ukYOnQoPv7442Ydd/bs2bjssstq3NsNi9tvvx3z58/H3Llzcfrpp+Pee+/FPvvs0yYvm2984xuYP38+vvGNb2Ta78UXX8Rll13WKiQ1C3bYYQfMnz8fL774Ih5++GFcdNFFWLduHb773e9i1KhRWLFiRbOOu6mSVAkpY0899RR++MMf4pFHHsG3vvUtfPHFF61yvvHjx2P+/PmtcuzWxsKFC3HHHXfgiiuu0NafdtppWLJkCe677z7Mnz8fxx9/fLOfl9bAKaecgk6dOmHq1Klt3ZU2xYaU9U1Zzts7im3dgTSYOnUqBgwYgCeffBLFYtjl448/PvKgf/WrX93Q3dus4DgO9tprL23dySefjFNPPRWHH344jj32WLz00ktt1Lu2xaBBgzBs2DAAwH777QfXdfGLX/wCDz/8ME488UTrPmvXrkXHjh1r3pcuXbpEfqdNCR06dIj0f/z48bj99ttx2mmn4Qc/+EFkANoewGVs1KhRcF0XkyZNwsMPP4xTTz215ufbbrvtsN1229X8uBsCv/zlL7HHHnuo+yXx5ptv4vTTT8chhxyird9YnpdisYgzzjgDv/jFL/CTn/ykVfTDpoANKeubspy3d2wSltTly5ejZ8+eGkGVcBz9Ekx3/7///W8IIXDNNdfg6quvRv/+/dGhQweMGjUK7777LsrlMi666CL06dMHXbt2xdFHH41ly5ZpxzTdNRJp3AKvvvoqjj/+eHXe/v3744QTTsCHH36o2sycORPf/e53AfjkR7pBZs6cqdo89dRT2H///dGlSxd07NgRe++9N55++unI+f70pz/h61//Ourr6zFgwAD86le/SuxfWowePRqnn346/vrXv+LZZ59V62fNmoXRo0djm222QYcOHTBw4EBcdNFFmnVx7NixuPHGGwFAc/NIq/GNN96IfffdF1tvvTU6deqEwYMHY+rUqSiXyzXpe2tBvvTkbzl27FhsscUWeOONNzB69Gh07twZ+++/PwCgqakJV1xxBXbddVfU19djq622wqmnnor//ve/2jHL5TIuvPBC9O7dGx07dsS3vvUtvPzyy5Fzx7kv//rXv+KII45Ajx490NDQgB133BETJkwA4LuYLrjgAgDAgAED1O/AjzFr1iwMHz4cnTp1whZbbIGDDjoICxcujJx/5syZ2GWXXVBfX4+BAwfizjvvbNY9NHHqqafi0EMPxf333689I2lkZNSoUfjTn/6EDz/8UJMzicsuuwx77rknunfvji5duuAb3/gGZsyYASKqSd9bA/Il/umnn2rrX331VRx55JHo3r07GhoaMGTIEPzf//2f1mbt2rU4//zzMWDAADQ0NKB79+4YNmwY7r33XtXG5nZMK4NxLkvpzuVeoTR6Igs+/fRTPPTQQzjppJMi561UKrj55pu13998Xj777DP07dsXI0aM0GTo7bffRqdOnbTjrly5Ut3Huro6bLvttpgwYUKk7ytXrsTpp5+OHj16YIsttsDBBx+Md99919r/E088EStXrsR9993XrOvfHGGT9fYu5zk2EUvq8OHDceutt+JHP/oRTjzxRHzjG99AqVTKdIwbb7wRu+22G2688UZ8+eWXmDhxIo444gjsueeeKJVKuO222/Dhhx/i/PPPx/jx4/HII4/UpO///ve/scsuu+D4449H9+7dsWTJEtx888345je/ibfffhs9e/bEYYcdhquuugo//elPceONNyqX1I477ggAuOuuu3DyySfjqKOOwh133IFSqYTf/va3OOigg/Dkk08qIvT000/jqKOOwvDhw3HffffBdV1MnTo18oJrLo488kjcdNNNePbZZ7HvvvsCAP75z3/i0EMPxYQJE9CpUyf84x//wNVXX42XX34Zf/7znwEAP//5z7FmzRo88MADmstlm222AQC89957GDNmjHoJvP7667jyyivxj3/8A7fddltN+t4a+Ne//gUA2GqrrdS6pqYmHHnkkTjjjDNw0UUXoVKpwPM8HHXUUXjuuedw4YUXYsSIEfjwww8xadIkjBo1Cq+++io6dOgAADj99NNx55134vzzz8eBBx6IN998E8cccwxWrVpVtT9PPvkkjjjiCAwcOBDTpk1Dv3798O9//xtz5swB4FsqP//8c1x//fV48MEH1f2X3oerrroKP/vZz3DqqafiZz/7GZqamnDNNddgn332wcsvv6zazZw5E6eeeiqOOuooXHvttVixYgUmT56MxsbGyKCxOTjyyCMxe/ZsPPfcc9h+++0BpJORm266CT/4wQ/w3nvv4aGHHooc99///jfOOOMM9OvXDwDw0ksv4ZxzzsEnn3yCSy+9tMX9bg188MEHAICdd95ZrfvLX/6Cgw8+GHvuuSduueUWdO3aFffddx++973vYe3atWrgfN555+EPf/gDrrjiCgwZMgRr1qzBm2++ieXLlyeesyUyGIc0eiIL5syZg3K5jP3220+tO+ywwzB//nwMHz4cxx57bCRfgaNnz5647777MGrUKPzkJz/BtGnTsHbtWnz3u99Fv379cMsttwDwCdDIkSPx8ccf46c//Sl22203vPXWW7j00kvxxhtv4KmnnoIQAkSEb3/723jxxRdx6aWX4pvf/CZeeOGFiDVXonfv3th1113xpz/9Caeddlrm698cYcp6Luc5AAC0CeCzzz6jb33rWwSAAFCpVKIRI0bQlClTaNWqVVrbkSNH0siRI9X3Dz74gADQ7rvvTq7rqvXTp08nAHTkkUdq+0+YMIEA0IoVK9Q6ADRp0qRIv7bffns65ZRT1Pe//OUvBID+8pe/xF5LpVKh1atXU6dOnejXv/61Wn///fdb912zZg11796djjjiCG2967q0++670x577KHW7bnnntSnTx9at26dWrdy5Urq3r07pfmpTznlFOrUqVPs9r///e8EgP73f//Xut3zPCqXyzRv3jwCQK+//rradvbZZ6fqg+u6VC6X6c4776RCoUCff/551X1aG7fffjsBoJdeeonK5TKtWrWKHnvsMdpqq62oc+fOtHTpUiLy7x8Auu2227T97733XgJAf/zjH7X1r7zyCgGgm266iYjC+3vuuedq7e6++24CUFXWdtxxR9pxxx2139/ENddcQwDogw8+0NYvXryYisUinXPOOdr6VatWUe/evem4444jIv/36dOnD33jG98gz/NUu3//+99UKpVo++23jz23xMiRI+lrX/ta7PbHH3+cANDVV19t3Z4kI4cddliqPshjXH755dSjRw/tWtoCNhl74oknqHfv3rTvvvtSuVxWbXfddVcaMmSIto6I6PDDD6dtttlG6blBgwbRt7/97cTzTpo0SXsus8igua95LaaMSSTpibhjmvjf//1f6tChg/V3A0Bnn322ti5ON1999dUEgB566CE65ZRTqEOHDvS3v/1NbZ8yZQo5jkOvvPKKtt8DDzxAAGj27NlEFMos1+lERFdeeWXs++PEE0+kXr16Vb3WzQ1pZT2X8xxERJuEu79Hjx547rnn8Morr+CXv/wljjrqKLz77ru4+OKLMXjwYHz22WdVj3HooYdqVp6BAwcC8EffHHL94sWLa9L31atX4yc/+Qm+8pWvoFgsolgsYosttsCaNWvw97//ver+L774Ij7//HOccsopqFQqavE8DwcffDBeeeUVrFmzBmvWrMErr7yCY445Bg0NDWr/zp0744gjjqjJtZDFLfr+++9jzJgx6N27NwqFAkqlEkaOHAkAqa4P8BMgjjzySPTo0UMd4+STT4brurHusrbAXnvthVKphM6dO+Pwww9H79698fjjj6NXr15au+985zva98ceewxbbrkljjjiCO03/PrXv47evXsrF+Rf/vIXAIjEtx533HHWUBeOd999F++99x7GjRun/f5p8eSTT6JSqeDkk0/W+tjQ0ICRI0eqPr7zzjv4z3/+gzFjxmgusO233x4jRozIfF4bbHJWCxn585//jAMOOABdu3ZVx7j00kuxfPnySIhPW4HL2MEHH4xu3brh//2//6d+/3/961/4xz/+oWSE/1aHHnoolixZgnfeeQcAsMcee+Dxxx/HRRddhGeeeQbr1q2rev6WyGASaqEnOP7zn/9gq622anGG9AUXXIDDDjsMJ5xwAu644w5cf/31GDx4sNr+2GOPYdCgQfj617+u3euDDjpICx+Iu29jxoyJPffWW2+NZcuWoVKptOgaNlUkyXou5zkkNgl3v8SwYcNU3Eq5XMZPfvITXHfddZg6dWrVTMnu3btr3+vq6hLXr1+/viZ9HjNmDJ5++mn8/Oc/xze/+U106dIFQggceuihqR4m6ao/9thjY9t8/vnnEELA8zz07t07st22rjmQMYJ9+vQB4BPwffbZBw0NDbjiiiuw8847o2PHjvjoo49wzDHHpLq+xYsXY5999sEuu+yCX//61+jfvz8aGhrw8ssv4+yzz051jA2FO++8EwMHDkSxWESvXr2Uu5yjY8eO6NKli7bu008/xZdffqlky4QcZEn3lPl7FYtF9OjRI7FvMra1uckBUs6++c1vWrfLAV5cH+W6WlSnMOWsFjLy8ssvY/To0Rg1ahR+//vfY7vttkNdXR0efvhhXHnllRuNnEkZW7VqFWbNmoXf/va3OOGEE/D4448DCH+n888/H+eff771GFKefvOb32C77bbDrFmzcPXVV6OhoQEHHXQQrrnmGuy0007WfVsig3GohZ4wsW7dumYNxkwIITB27Fj86U9/Qu/evbVYVMC/3//6179iw8v4s2u7R0m6t6GhAUSE9evXY4sttmjhlWx6SJL1XM5zSGxSJJWjVCph0qRJuO666/Dmm2+26rnq6+utNUKrxbysWLECjz32GCZNmoSLLrpIrW9sbMTnn3+e6tw9e/YEAFx//fWx2am9evVCuVyGEAJLly6NbLetaw5knK5MTPvzn/+M//znP3jmmWfUaBFApvJGDz/8MNasWYMHH3xQxR8CwKJFi2rR5Zpi4MCBkUxiEzbLTs+ePdGjRw888cQT1n06d+4MAEo5Ll26FNtuu63aXqlUqsqajIttbokwKWcPPPCA9juY4H00UUs5E0KouOdayMh9992HUqmExx57TCM3Dz/8cE36XCtwGZMVJG699VY88MADOPbYY9XvdPHFF+OYY46xHmOXXXYBAHTq1AmXXXYZLrvsMnz66afK2nTEEUfgH//4h3XfLDIo72NjYyPq6+vVetOzVQs9YaJnz5547bXXmr2/xJIlS3D22Wfj61//Ot566y2cf/75+M1vfqOdp0OHDrGx8fL36NGjh7pHnOQkPROff/456uvr2yVBBZJlXVqz27uc59hEsvuXLFliXS/N59Li0lro378//va3v2nr/vznP2P16tWJ+8mAei7YAHDrrbfCdV1tnWxjjrb23ntvbLnllnj77beVJdlc6urq0KlTJ+yxxx548MEHNSvwqlWr8Oijj2a+ZhNz587FrbfeihEjRuBb3/qWuj7ed4nf/va3kf3jrs92DCLC73//+xb3eWPB4YcfjuXLl8N1XevvJ5WtJP933323tv///d//VXUJ7rzzzthxxx1x2223JU66EPc7HHTQQSgWi3jvvfdi5QzwXwzbbLMN7r33Xs0t/+GHH+LFF19Md0MScPvtt+Pxxx/HCSecoBKcsshIfX291WIhi4YXCgW1bt26dfjDH/7Q4j63JqZOnYpu3brh0ksvhed52GWXXbDTTjvh9ddfj/2d5KCHo1evXhg7dixOOOEEvPPOO1i7dq31fFlkUE7cYOpGU99k0RNpseuuu2L58uXNrqcLAK7r4oQTToAQAo8//jimTJmikgolDj/8cLz33nvo0aOH9V7LeyATuMz7ds8998Se//33389LJjJwWd9pp51yOc8BYBOxpB500EHYbrvtcMQRR2DXXXeF53lYtGgRrr32WmyxxRb48Y9/3KrnP+mkk/Dzn/8cl156KUaOHIm3334bN9xwA7p27Zq4X5cuXbDvvvvimmuuQc+ePdG/f3/MmzcPM2bMwJZbbqm1HTRoEADgd7/7HTp37oyGhgYMGDAAPXr0wPXXX49TTjkFn3/+OY499lhsvfXW+O9//4vXX38d//3vf3HzzTcDAH7xi1/g4IMPxoEHHoiJEyfCdV1cffXV6NSpU2rLred5qg5qY2MjFi9ejMcffxz/93//h4EDB2rlP0aMGIFu3brhzDPPxKRJk1AqlXD33Xfj9ddfjxxXjoyvvvpqHHLIISgUCthtt91w4IEHoq6uDieccAIuvPBCrF+/HjfffHOrFS9vCxx//PG4++67ceihh+LHP/4x9thjD5RKJXz88cf4y1/+gqOOOgpHH300Bg4ciO9///uYPn06SqUSDjjgALz55pv41a9+FQkhsOHGG2/EEUccgb322gvnnnsu+vXrh8WLF+PJJ59Uylj+Dr/+9a9xyimnoFQqYZdddkH//v1x+eWX45JLLsH777+vYsQ+/fRTvPzyy8pa4TgOfvGLX2D8+PE4+uijcfrpp+PLL7/E5MmTM4WVrFu3TsnZunXr8P777+Phhx/GY489hpEjR6rsagCZZGTw4MF48MEHcfPNN2Po0KFwHAfDhg3DYYcdhmnTpmHMmDH4wQ9+gOXLl+NXv/pV5IWysaFbt264+OKLceGFF+Kee+7B97//ffz2t7/FIYccgoMOOghjx47Ftttui88//xx///vf8dprr+H+++8HAOy55544/PDDsdtuu6Fbt274+9//jj/84Q8YPnx4bG3OLDJ46KGHonv37hg3bhwuv/xyFItFzJw5Ex999JHWLoueSItRo0aBiPDXv/4Vo0ePbtYxJk2ahOeeew5z5sxB7969MXHiRMybNw/jxo3DkCFDMGDAAEyYMAF//OMfse++++Lcc8/FbrvtBs/zsHjxYsyZMwcTJ07EnnvuidGjR2PffffFhRdeiDVr1mDYsGF44YUXYgdBnufh5Zdfxrhx45p9DzY3mLKey3kOAJtGetmsWbNozJgxtNNOO9EWW2xBpVKJ+vXrRyeddBK9/fbbWtu47P5rrrlGayezPe+//35tvczY49mcjY2NdOGFF1Lfvn2pQ4cONHLkSFq0aFGq7P6PP/6YvvOd71C3bt2oc+fOdPDBB9Obb74Z2ZfIrzgwYMAAKhQKBIBuv/12tW3evHl02GGHUffu3alUKtG2225Lhx12WKT/jzzyCO22225UV1dH/fr1o1/+8pepMwlldrpcOnToQP369aMjjjiCbrvtNmpsbIzs8+KLL9Lw4cOpY8eOtNVWW9H48ePptddei/S/sbGRxo8fT1tttRUJIbSsyEcffZR23313amhooG233ZYuuOAClS2bVClhQ8EmEzYkVUcol8v0q1/9Sl3nFltsQbvuuiudccYZ9M9//lO1a2xspIkTJ9LWW29NDQ0NtNdee9H8+fNTV5KYP38+HXLIIdS1a1eqr6+nHXfcMZLBevHFF1OfPn3IcZzIMR5++GHab7/9qEuXLlRfX0/bb789HXvssfTUU09px7j11ltpp512orq6Otp5553ptttuo1NOOSV1dj+Xs06dOtEOO+xAxx57LN1///1aFQ6JtDLy+eef07HHHktbbrmlkjOJ2267jXbZZReqr6+nHXbYgaZMmUIzZsxIzNDdUEiSsXXr1lG/fv1op512okqlQkREr7/+Oh133HG09dZbU6lUot69e9P//M//0C233KL2u+iii2jYsGHUrVs3dc3nnnsuffbZZ6qNTTeklUEiopdffplGjBhBnTp1om233ZYmTZpEt956a+SeptUTaXWV67rUv39/OuussyLbkCK7f86cOeQ4TiTrfvny5dSvXz/65je/qfTd6tWr6Wc/+xntsssuVFdXR127dqXBgwfTueeeqyp7EBF9+eWXdNppp9GWW25JHTt2pAMPPJD+8Y9/WLP7n376aQJACxYsqHqtmxuyyHp7l/McRIJoI65knSNHjhw5clhw7bXX4sorr8Qnn3yi6gxvKjjppJPw/vvv44UXXmjrruTIsVFjk4hJzZEjR44cOTjOPvtsdO3aVc1mt6ngvffeU5noOXLkSEZOUnPkyJEjxyaHhoYG/OEPf9jo44pNLF68GDfccINKQM2RI0c8cnd/jhw5cuTIkSNHjo0Om40l9aabbsKAAQPQ0NCAoUOH4rnnnmvrLuXIkSNHjhw5cuRoJjYLkjpr1ixMmDABl1xyCRYuXIh99tkHhxxySM2mNs3R9nj22WdxxBFHoE+fPhBCpCrCPm/ePAwdOhQNDQ3YYYcdtLJGOXIkIZe3HBsauczlyBHFZkFSp02bhnHjxmH8+PEYOHAgpk+fjr59+6r6oTk2faxZswa77747brjhhlTtP/jgAxx66KHYZ599sHDhQvz0pz/Fj370I/zxj39s5Z7m2ByQy1uODY1c5nLkiGKTj0ltampCx44dcf/99+Poo49W63/84x9j0aJFmDdvXmSfxsZGbVYez/Pw+eefo0ePHtZpLXPYQURYtWoV+vTpo+Z23xAQQuChhx7Ct7/97dg2P/nJT/DII4+oWckA4Mwzz8Trr7+O+fPnb4BehsjlrXZoC5nb1OQNyGWuVsh1XDrk8lYbtJW8bczYJGacSsJnn30G13XRq1cvbX2vXr1i502eMmUKLrvssg3RvXaBjz76CNttt536vn79ejQ1NSXuQ0QR5VVfX1+zTN358+dHZqI56KCDMGPGDJTLZZRKpZqcJw1yeas9uMylkTegdWVuY5I3IJe5WiPXccnI5a22aI68AUBdXR0aGhpas2sbHJs8SZUwlYFNQUhcfPHFOO+889T3FStWoF+/fti3w3dQ6twN6NoZXsd6uJ1KKHcuotLgoNLRQbkT4NYJlDsBXgPBqwPcjh6ozoNTX0FdhzLqSy461DVhy4b16FhsQpfienQtrcMWhUZ0K67FFoV16CCa0NVZiwango6iCR1FBfXCQ0kADUKgAIGicOAE0RgFIeAGBm8PHirkwQVhPRHKBDSSg7VUxFqqw3qviBVeR6yjOqxwO2JlpQNWu/VYUe6AlZUGrK3U4cv1DVjXVIfGcgGN6+pAjQWIJgeFNQ6cJsBpFCitAQpNhNIaoLjWQ3G9h9KqCgprynDWNgIrVqG86gs8u+6P2hzK69evx4Dtt8DSZW7i77XFFltg9erV2rpJkyZh8uTJqX/zJCxdutQ6cKlUKvjss8+wzTbb1OQ8aRArbwN/BKdjJ5S71MGtLwQyJuDWA5UOApUGwCsBbkeCV+eB6giiwYVTclEsuejY0IT6YgUdS2V0qfPlrXOhCZ2L61DvVNCluA4dnCY0iCZ0dhrRIMooigoaRAUFEIrCRUl4AIAC4h0qLvznqEwOPAh45GA9FdFEBTRSCWupHmu9Oqzz6rHCbcA6tw6rKh2wyq3DereElY0NWFOuQ5NbxNrGEipNBVQqBdC6AkTFgWgSKK4T/v/1QGk1obAeqFvlobTGRXGti+LK9RDrmuA2rsEzH9+qZC6tvAGtK3Mbk7wB8TL3LRyKIlqZvAgBCAfC8f/DERAFx1/vOKFedgTgFKL7EwHkAR6BXNf/7nkg119PXrB9AzgBKyjjeczOdVwVxMlb/4mXQnSuBxUAcgjkAOQAcAhUICBYRJHgFD04BRf1DRWUCi7qCi7qixXUOS6KBQ8NhTKKjoc6p4IGp4x6x0WnQiM6FJpQEi46OoF+c8ro6qxDgygH+q+MEjzUCxcdHQ8lhO9UF0ATAWuoiEYqYJVXj0YqYY1XjxVeRzR5Jaz1SljtNqBMBVQ8BxUqoEIO1rklrHUDvVYpobFSRNktYF25hHLFgVsuoNJUBJUdoCzglB3AA4QHeEUABQIVg3vgEOAJ0MomfHLJlc2SNwDo3bs3Pvjgg82KqG7yJLVnz54oFAoRq+myZcsiD7BE3Gi2KEooOnVAoR7k1EEU6kDFElByQHUOvBKAOgGqA9w6AuoAavBJqqh34XQoQpQqcOodiHpAFB04dYBTIjgFARQ9FAoERzgoFDzUOY0oCqDeAUrw0BAQ1Toh4IBQgAdHCCAgEB4RXBCKEGgiACTkE48mrw51VELZq4fjNqBAdSi49UC5AxyvDk65AaKpAaJSB8dpAAp1EIUiHCqBRAHCceBUHBQEUCCBQhkoEKFQB5SaPBSKHoqFMoqOgCgAcBpB5L9g+GCgqakJS5e5+GDB9ujS2e6uWLnKw4ChH+Kjjz7S5kmudb1D28DFtr61EStvhXo4xQZQsQ6iVABKDrw6AZQAqhOgekDUAagnoJ5AdR7Q4MKp8+CUKnAaHDilCop1DgolQqHooFgCikUP9Y7wlbxD6OB4qHc81DuEBkG+jMGFI4A6CDiCUAApMmqDRwIuBMpU8NtREQUqQlAJrlcCeUVUvBJKlXqUvToUK3UolBtQcIsoFutRLNfBrRThOIHcVXwJF2UHjhBwPAFHCBQ8oFAiFF2gWPJQKrgoFCooFgiiICCcMoDwN0wjb8CGkbmNRd6ABJlDCUWxASxsBPjMBBAQgCgE9yEgqwAAB4KET1Y5PAKRA3ge4AX30XMAeP56coPjtP5lyLFbruOSESdvTn0DREO9Tk7l52JAVB0CigRRciEKBNSXQQUPVHRBxQpcxyevVCzDBcEtVOAWynAdF26xiLJTDwgXZacJcCpoFC6aCkU4ooyi04iCKEMIF0VRhuuUAfjvUQAow0EjFdDk1aNMBZS9DmiiEpq8erhuA8peCWWvDmW3Hh4JeFSA6xXgkgPXLYEqJbhuEVQpgdwCvEoBKJSAcgEoFCBEASIYpAlHQHgAPAFR8q+dSgQUPV+WCfDK/u+WVd6AUOaamppykroxoa6uDkOHDsXcuXO1mNS5c+fiqKOOat5BjRG6CGYZFxR+BgkIEOCF3z1P+C9zz4FL/oir7BVQ8QooOwWUvSLKTgEFFFGmIsrkogDCenKVkPq2UkIJgCf8vvjq2YdLhDIAl4D15KAMB+upEBwvXBq9kn8+Cs7vFVCh4OHyHBAJf/GEf6LgOfGJr3GttvvjJVsxOmxB6LCFvU05uL9dunTRFHgt0bt3b+vApVgsokePHq1yzszwkjer30CCfZa/H+ATSPO/B6FIp8fyI11yUBIuXAi11iMR+8KXxwRCi6oLX75dCP8/Cbhw4ClLq4BLIlDqfl8IvsjIPstnxrze2O/yXsXIXZK8Aa0vc5uEvG1oeL7lh0j46k04APdwEYGEHGjz/bzQeip1DXmhVXUjQa7jUoK9P4l/9uCnbnvCH5h4Av7YxIHnECqug4LjKLXngFBwPHhSr5EDR3ioeAUUHRdlKqDkuSgJX+4aRBlNVECd8Nc1OE1YT00oBZ4kF77eWu/53qD1nm9BXU8lNHolrHIb0OgVfS+RW/Lfo+Sg4hXgQaDJLWC9W0TZK6DRLaASLJ7nv1fJQ8APBOMJwbWb9yi0RcUirY7b3LDJk1QAOO+883DSSSdh2LBhGD58OH73u99h8eLFOPPMM7MfjL0EQ0IKCCI7gSMBkBRKn6i6nvDdAp6DCjkok4PGgKA2eiUUHA9lKmA9+RaNElWCE/rHrIMHF74LlqtvDz459QA0aQTVP9Z6Kvmjwcji90P2yQ36SZ4IiYL12uR1Q21L+5Lw4MVysPgttcPw4cPx6KOPauvmzJmDYcOGbfD4wEywDgqYYiOh/QSkyKBPEN3g93TJJ40moSwJFx45KAjP3x5YUT2KYakIyakXHAfwia8bkAsPjrK0+ucVjLA6iqxKgiqvQ33hgyFzcORRSFYTZC9J3uT21sQmK28bAhS47QVBkPDJqiMA14UoFADXcGOa5HQDuvezINdxGSGNOx75j7cDCE/41lT1DiX/Heo6EIJQdh2mm4ookAfX8++tR8InqcKD4xVRcQpwhKdIaqNTRpmKKImKT1KphLJThAMPhSDMySUHawNiut4r+Z+9EhqpiLVuHRq9Ihq9ItZUfEuqfI965KApMP6UFUEN9GDwXxmAtPcn03smBBK9A22t49oKmwVJ/d73vofly5fj8ssvx5IlSzBo0CDMnj0b22+/fbYDeexHNhWihcCZo0Np3fI831rpSqLqFVARHiONRaynEhzy4MBTZBUAIPyHryQ8eEEfNEsqBMoBWeAEtYkKaAo++9bUgrKi+kvYJy9YiI3wbNcVWpApYuWqBpdIxdHatmXF6tWr8a9//Ut9/+CDD7Bo0SJ0794d/fr1w8UXX4xPPvkEd955JwA/y/WGG27Aeeedh9NPPx3z58/HjBkzcO+992Y+d1vA/D38dYLJGjTyx60Lcr0iqsL/DyGtqi7cQKqcYL+4mNTQehpaUT1GTpU1NRhOmVZd+VkRVNOCKl9cNqt9BjFJkje5PQvam7y1OogAcn05CMgqEPMTb+TkVCLXcekROAUhPIAcAUHkywIFVhcBPybTE/ACguq6TrBf+F6ueA5cx4MQ4cC66HgoCg8VcuCA4AQvq0aniHKhgFJgSV1PZaz3Sr4lVZDv7QksqdJ6utarw3qvhIrnYJ1Xh0bXJ6nr3aKyoPokVfgW1ErRf8e7gQHIdZTBSpJUIY1B5gCc2M0RFPEsmai1jttUsFmQVAA466yzcNZZZ9X8uEJaExGOgBR5C8z5Qgolc/mHoy7fklkkR7NuNlERpcDdX6bQklAAwQtcEb4lNRQ86cLl8YEhKfWXJkZQpRVVuigqgWvWC8gOBVZgId39NsLKIR+CFA9DBR7KCduy4tVXX8V+++2nvssg/VNOOQUzZ87EkiVLtMkbBgwYgNmzZ+Pcc8/FjTfeiD59+uA3v/kNvvOd72Q+94aGdUAQ+S2Etkq51gPXuySNUl4ATlB9F6u0Jsh2cYgSVW41leQ0/MwJq8eOSxGyGr1GHlqj7kUL5U1uz4L2JG8bFBpZdSAQ6D7hBP5fbPTkVCLXcSkgSBlyRMBJ1XfPj/QIB98UvkddX4cIaYgM9IYTkEshCBS8N4ueB0d4KDoFOCJ8Z3YoNPkhAMJFyXFR8urQ0fGTrBzpSYJAo+dbUctUwDrXJ6u+BdU38DR5Bayt1LGBfxjWV/EclBlBdd3AAOQaVlTp9pdohiW11jpuU8FmQ1JrCk7GAje/zdIYtaQijEs1iGpFeL5AOwWs90qod8ooUwEFeGgiPcO1AEIJLrxAkh02auTJK5KgSguqfNDkf2XFlQTVCx8wzwutchFyoFnv5Pf0BBUAvIBsx23LilGjRiGppO/MmTMj60aOHInXXnst87k2CrDRtpDfmcVeNSMRsV7yWFBpQVVufyFUbrcLB4XgbWFaUk3SKkMHPAqOwwipIsSqjTw3s/SyfmrWVPVsRd1ggv3eoorcJcmb3J4F7U7eNjQ4WQVYkCI2enIqkeu4DJDvE8GefyKZeBHGpgZjFU/4JM91HV9UHAIqgBCEgkNoEqQ8SBXh+eTUC9+XAFAhB41OBSXhoej41lRpWXVAQXiUo8ip/79OkdMKOWhyi2jyCmh0i9r7kwC4kqC6hZCguo4/vuJW1GrGH35fElBrHbepICepcbC4+22xqUroWIynH5fK3P2BNbMcJFI5DikyCQdwmDujAIIrPLgkVGwNlz2foPpkgRPUSByqF41HlaM/zwvjaGE+RB6/ToSjwIyotSusvSAxrEIp99Aq6ZFuRVXEFNCJZJAcpVzzIkyn8oms/UcOraO6NTV09YeW/ZCYhhZ7TlTVWIcTcDY40q2nlnvjUawmb6+usE0eavBbvbzOxoZcx2WENgAFG3QH3kgBlUAVhib5FR3CqgUE14Ny93skUHB83SXJqfzf5BVQ5xRRX6jAcSlMrhKuMvx45Bt9Gr0imrwiGgNSKklqxXNQ9gpYXylqYUv+u1Sg7Bb88D5JUC2xqBEjF1iOgZBWCFRR/u1Xx+UkNQny5emZMZqh+V66/P2nLYy/cz3/BU4UJFEJP7u+TAU4RIEVleAQoWQo6BIqAQlwUAB3ycpkGGEQVOnm1139FQrjUSmw7rpeaNnyR7HyOoR6mLIQhziUQSjH7BC3vj0ivL+SgOmB9prFnu3nE74wrk9Z2rkVU4WHOIpUluAr/wJk4pRuRZWklENLnJLHIocdN7SwcqIs42M1SEVPUHGJtvsRXiRSyV2SvMntOXLUErmOS49IyCV/tomZEaWxJ2jrwa8IwUkqADiiANcRQBEqWVSdK/hfcRxUHBdNXgFFx4PjkqoEUAiO45LQyGmTVwwNOuT4SVGeg6ZKUeVUSwOBS0K59z3XCbP6XScw/uhhdMorFny1xqAmENX2quNykmpCxkJxwxJZ/psEQpr4lSs9iFkhWfzX862bjk9S/Sx/gkN+QhWHTyZcFCBQhrGNHJThl5Iyk6T8EWFJs6aG5+dJUzKGFv5DZFyP9plfNxBYWil0zcXAJX+J25YjRKqkNFOpy9XKhR4SQyB073uBix8I4kZFEJdK0poapOUZ5NR097twEIlJ5eeAJMWhFVXCCyy+PCZVv57oEnHvV7ESJMmb3J4jRy2R67iUCMbecqAt40zlNuEFKo0nUMn9CPAcAQeeCisSglBxCI6KU7WfsuQUUC748aiOIJVcVQzCAwCokLz1bklZTaVRp+IF5fU8B02VcCivrKmeJKmsWo70TLLSlMqamnSPBKFKi3ar43KSmgDB64Eyy1ZYEgfspSrrjkIRVNcjLY5FxqcW4Pl1U6kAhzw0Ufgz+IlTnrKiciuXSlYJyIEkqGayVMVz/BGhVnYqjEmVlix4wrdmyQfKk9fN/svTe1Q1LpBDGZhjtuWIQYx8+d+lqx+Qpai0mFRLjVJFIoMsf1eR1tBKLzP9bQiToFhGvzqmUOQ1TKBifQF385sElSUixtwK34ORTuaS5A1VtuXI0RzkOi4DAqKqfacgyx/yM5ThRDaRnzw4ShcIQagIwHE862EB/7XtFsI8kILjE9MKOQFhdYN2YSkpPwmqoDyg0qXvBdn7Zi4AEXwLKgmQy0lqmJCseWH5fYhTawk8tb3quJykpoBWgolZGkVQAF944cMlY1Kk9UjVSxVBnKjjwJExo6IAeEH5H2bIKqGCApyArAY14bTkFKERVD8bsaTHogYPnnS5+i4MqPptZNRvk1Uw7KWosg/RKiRQtrkzgm05ksGtq2FiEVPbjKDKBIIwcSqskeoxq6eESw4KwremFkBwjHhU3lYeT+7nW0zlsfVjqrqpjLDKfkmlrrm5uFjFEXMw+UuQwyR5k9tz5Kglch2XEcF7RkY1qSz/YJsiqALyjypTRUQQgboRQgBuMCuZeQqlawQ8z/OJalCyqiAIFc9B0fFQEIUw8coL3fpu8J7kLn3Pc/xpnE3njpwUhyVKwWpNha7TTDWmWYXi0V51XE5SYyCtqFohcTMAWj5U6r8voDJ73pPuApm8JC2pQk+cKpNPVuU73yWBumBWIKCgTVnpkYMmKsCDowiqtKCqrH4qhOdT2dhCufo9EpCTEOj9Dxf9umVSlW9NVcWYEyBdwnHbckShDRIQjQMWJJW2mXlvJk6FpZ9cRhhdEiq73/8NHH8QRNEpJs3YVEVOmTzxwv1hPxy9P9yCCugElV2vZm1QbfnnZKKaJG9ye44ctUSu45oPRVbl4Dt4Bwkhw9D89y0cP4tftZe7CBmrqt9nWcKKCPAKPgF1hD9TVcHxy1cVBGnufpcEmioF9b4GwIhusLiO/s6Tg25JSmXJqcD4I+R/9lkdwCYa0gaRIDbtVcflJNWCCAkzSIOZ0KLiTrzwwZOjMBnbUhBBpqDjwGGxqQUekxoQ1QI8eHBQCmoI8tpoZTm1KRw9/tTI7HeJzXrFEqckySGV1R8mTFmvzbgHaZEr8OrQLNSJBC20OqhtcrQfrIpMiaqR1tDyKeNS9YQ8gcjUlHwbTCuqjE11Qnd/YK2Vbn5OUmW/rDVSjc/WkJoqU/DKfrZHBZ6j7ZDruGZAPu/B7fHjVIUyAsGTXkVG7JxARYhwJxL+gNthOlSSU5/z+tOTOg7BcQiu48BxPLieQMEhlYAlk5zLcjpTQ0/5saYOPFdECDE4SeUE1RWQ9dPBySpF7As6qohMe9VxOUmtBsPiE7E2Upj9T4EllTxoyVOu58B1wpqlvtshiE1F4PYP4JDHElCMguusDqULJ0JMVV1UCs/lUhiPKkeGxIK6RVwRf/O6M0JOImDflv14mzXMwYBB2kz3NxAqZK5UwzjU8DvApkhlcamOLEMVyFii8uPufpbVH1pOw8x+l0KCLCHrCoYvEWlN5RbW6L3IEmaSJG/+9tSHypEjFXId1wLw+yNCPReWo6LQ7S+tqjImLRgsC4e08at6/1JgaCoIeI5vNRUOwXEcUNFFxSMty16VkJJhcOx4BJ+IehXL76w8kaGLX+Z4qAlyzPcpqhHVeMFprzouJ6lxIIpYEv3YVIvLP7CiahYukvVSRWjVDNzvDotNleWoJHyS6gQRqX4NN72YPy9DZbGiksOy+h2WoSj0kaJWx01fQmsWMStycD9SFvXnRd6j23IoxFhTNUsi324QVlkrNaybyoijTHISzPIZKHsvME8UgpRbczDEocWesgGUtKL6yXzhuQE/XIDHh0Wz+sMi/pGQLHaNaYlqkrz523PkqC1yHZcCArGJQsrDLb1EHnxrqUd+3KlAQFZFaGXk49ogXtX/DI00kkMgzyen5PjxrJ4gyJmvHMfTXfqyxqmhb9W70mVhVlJRKQ8qI6aku/pN76Q8buRepCjx0l51XE5STRgvReu89QTtxaoGeEpgg+QpllHvMte7Iy2pwq+TWvYKYeKUh2BGDKHIgRPUtATkNJdRK6pWF9XI6g+L+DuRQsNa//l1aETBfo+S+EMlYdRX2UxHfC1CAkGNlggToQIFQnJqZNnzDH9uKZXufZkw5Sl/WggP9pjU8LujyLCcuUXtqyoBhAmEfj/DPiddq/X6Ewr5A8ny5m+P3ZQjR7OQ67gWQiOEIsgDge/+D15MOllFxPuiVUKU7zYgCJ0LyKpDfqSA44fxOYL8CifS4xS48+HpuglAmGDMSarK+goH3oITVWlB9XSDlirBxa9bhFEM8nsc2quOy0mqDdq0qP7HiNtVEjxPqHZ+GSp/tOaRgBPs7noOCoKCBKoCHI9UbKoDUln+YeKUg5JTgZrmjFlaXQiUvaKysiqC6snPcparQuiC9RxII6jH4nZ4QLfworNihNcdXEgG9yvP9o5uS32YdgFVWoXkZxFV4DDjpKW73/9qS5ziGf4qoUkEtVSFh4JMnAKAWIsQi0llpaf4NL1KzlQIQHRa1NgaqbD8R6LXy97PBHnzt2c7Xo4c1ZDruBSII12BmhPwdZiypqrBeDADFSer7Jgk4JsOld9et2KSg9DD6QThA44IDK0k864g40r9Avy2fgbWWc/QyUF/BCOxIjifSVC5cUGA9ISxDGivOi4nqXHQ3LCkhC0qeEFMqsdiZ1hRf9+aKuA6YSKTgwKzpDooGolTDvwRpWeWBgoEtEwFn6R6upufx6IqS6py9YfTocr+KXLKZ8QwLVoxVtRq8AzLm75tM32aWgAbKbNb8P2BkP+dEUDWTCVOQbekKje98C2nLggOkmNSVXUAhMeQJajC2awYQTUSpxT/ZC8hM8Ofy10EKYv/Jcmbvz2XuRy1Ra7jWgiDqKq6qbJet/D/KLLKICDCUIDgWCKwhgoCUPDXkUAYRuD4ZauUZVWel2fmwziXfE9WmM6SIQzyu+IAUPqNv1M5d5BJYuF37aISLantVcflJJUhwr+IYK+RSrCWo2ILBSO4kKiSSqSqCFKxqQ4IFeFp7n5HEDz4mYtmrKB0rco5h6UVVVpSVdkpmdGvzTLlsKSp6CK064NmRRbcbJcCTVRAyZhJK9yW+jCbNyKF94wFxmBBxmCRJH1silsYpajM4vrSCipkXKof91xQsale7Cg9UsCfQld/aGEVmpVVz+bnVlT2UuGDIPO/to6tjMn0T5I3f3vsphw5moVcx6VAYA/RPNoUqgFF+iRp84QfnxmsI+UO19kbIYxb5d7AMFlJ+JX1pEoTzLoq/DAA/0Ay3hRhwhY7l5Ak1dVJqhaeGpDUiHsfpu4OjqwMWvp9qob2quNykpoS0g0bydbjn4OHRNZq8xiJcL2gFJXjQHikYlN9S6qjufsd+IlSkqxKmG5V5eYPYlV4LKpKmvKYyxVQgeAiWGzXwUd+1sSVFGRVWtTituUIQIay0rbBTt4ApuX9TVzWeJa/qgYhS0gFLn+QdPeHLwQgGosKsOx+w4oqS0/pLv7Q5Q9AJ6waQeUvgphrNO9TApLkTW7PkaOWyHVc86Fyj+T3YPztq6LQta4Ia/QIIQGW7yyXud8LgV5V1lGwUlZsPeATW2mFZWGnqoMkIFz23bB4Kve+rJKj9oP2LpX7y90lsbXeGAvaq47LSaoNmuUGatRjzdaT3wFNMMPkqfAl7bIXtoxNdVAILamyTip58IRQZFWCx/y58F37jV4R/oxSBS0W1Q1c/Yq48LmFY0d7Fjc/BdcvDbopalb6ty0+E3FzdUu0CMpqL9TgQDBSBxijclAw6NAtqjpBDMml/C5LUEFId79ezN9mTQ3jUvUC/sqSKokrO7d/Pj0UgdcxlNdlVauxpD1JgSdnvuYyl6PWyHVcdShLaOIAFNpAWU8sEpGken+fkO2FJDWMCwV80qgsppyYOtBJqCSpksGavFFuD9ordclMwsLT36Oqv8yKGvESSaIu37vx6gtA+9VxOUmNAydmEpy4kSGE0nwffOfB4J4nfHIQZNtXBKEQxKY6gvyMPWlJ9aAIaoE8VOBYSlD5JKHRKwYzSgkWj8qIrMzu91iRY/Oh8cLvtuQw/Z6kv31y2lb7ts1zxNca4AOjaBH8aI1UkgQSOmmV06NKogpC6O4XAVENYManhtn6jJDCLD2ln5eT5tgpUZUcivBam4kkefO35zKXo7bIdVxKmO5xCWk5le5+YRmHEkLrJtvmx6TqRhafTLJ2DnxiKtj34D85BsF0pbtfnkAySJYQJfsgSTVCXea78aNeITOPRV0rK1kl9biIvHB1tFcdl5NUE6alUAY5e9AsXKZVVQVCy2z/wHLpz+/radZUx3PgOT5xqHgOKqKgW1KDeFRZ35JbVMOSPyIkqMqKGmbzcyuqP7+wUX4qcE/wazPd/Po2475UsajKou5x23IgkJPwXsO2qLbmvtKKCq2sk3T5mO730GUfWDuFE7r7CYHvKTiGYU2Vo3fTisrjoznkNl9sRHCpFnIawFZ2KiuS5E1uz5Gjlsh1XAoYt0G559UKzYga9azwjR5b5+lNQICoQFWp8ZReCxv568P3M8Bc9W7ohie1Q9g/jYAKtgTnlsTT1GuaAQiGnjOWalF07VXH5SQ1LSzCpYiFFE4vyE7ULKoimJ4tKOzvORDwX/iVYAq4CnmGJZXgCA+F4ClwKIxNdYkTDxHWRaWCIiOyPqrrhedXMYFa34X9epKsqSkTqJILXbfAZNbeYBI4ipoblMsfnJyGGf68DBWE6/8u5MENJo2A0Oukmr+bVH6mFVWPkbaXnwonGgBgKNFIWEkSKa+C6oWuc5nLUVvkOi4FgldMostfkklju5ZgBW0czSOUlB5x5HSkBDgIqqDwGFNpVPWEsqoqK6nMzufkk4cguEwPs2Qsfg2qf6zT1uRQ+ZkQVGuR+1Qx/LRTHZeTVBsCIqaShihcLwxiB0RdskJZUUMC4XnS/e7PG+yXovIPUBGOYUklOCTgBU+FI8Ji/nxudlvh/rDsVOjql+5+aUm1zYihrlMjrOH1xyZRxSB3haWDLGAdftddRADC3wTc7a+7ijwys/v1bHt9SlP/YA4oyO73tIAoc0Quk6lMK2pS6SluXdUmKTMWfp1ZZYyjvbrCcrQdch2XEgaZs/23ldsz12sVGRmxlQYX4cJwuQutUD45BAcBweXHlft5vrlVhSAw3ujw7H7yO6YRaNmHmOuwEXAVPuD5hLpauFN71XE5Sa2C0EzPElmC77IeGrGXrfyuTPgygUpISxe0UlTwgIpTiLGkBiSVhNWSqggqFfzjsdJTMkRW1kZVM2ewfsLoNwySELr9sxMHD/Huhwyhre0HHkWVMPsvyNBzykIZutP1+NQwWUqtC+JSHQiA/Il3XQQmCTZ1S2S2KZaAJbP6uSXVbxMmBpoF/PXMfuN/cC3aS6MZPDVJ3uT2HDlqiVzHVUfEiso/m5ZF47O0pKp3sHyHcWsn2LsriEdV+kO+U+U+XnByVklHvvvMxCk5IRU/lpnQFcnw54YFFgoQG8pECL2wTH/Hob3quJykJkHNBMSky7BAhiQv6uqXAuiRgKCgoL4guAJwHQ+O58Ap+FZVbkl1UlhS/Yx+J5gKNYgPZFZUT06DKq1awYgtLOYf9J9/Nq1bmuIgdT/SwAvKFcVty4EwrteQr4gVwbSoUuDKCogrV276FKnMogrTkurBQWDNl0o8gJnhz11M0pLqf2YJU9oSkmWdqIbXYVaUMK9dg0hW3kCyvMntOXLUErmOSwE2PrW5/Fl+kkXvhZZJ5ZaXxJWTQC/8r8WFymNyYitEkKAVnjiScGXEnIYVA5jessSlattM0h0hqEHYlgrD4zfCjvaq43KSGgfNRwn9hRohDdDIqW9NJWVJlZZML5h5SnghyRSClNtfElVHkL9YLKncnSoJqnTzy8x+1wusWrLslGFJNeNRI4QhiTikJKplKoQzaUW2NcNUtrmCTYnK7zNXzuHvRZbfQ06PGi2ir2SG/XfJgRNk83sgeCliUnnSHs/qlzFSZq1UuU+YuMfIdECyAebu4v+biSR587fnMpejtsh1XAqw+E4eIhoBJ6Om21y+k4JapeaYlVtSNZIqS01xUimnUmWDZpXdT4wj2qy1gEaqhdEmdpBtgQrr8oJdUuzbXnVcTlJtiGT4w2pBtWVka4RVEUSARGhRkvGiTsHV3P4AfEsq+e5+R1lSSbNOyZhARVClmx9Qx+a1M0mWmeJE1TLzlDZqNQl50v2xIHle681zxFcryIkjrFZVQA2GVL1URk4jVlQILS7VE778FIQbuP6jMalmtj4QuvptWf1qCtZI+SlDfMwBHqLPUKzMVUH1ea1zmctRW+Q6LiUEBf7z5CYAQoJq6j6uGwxiqKrQcJIqov+FUCVU9eOzxCnp5k8iqSoMgFmJ9WuIGkQ1izHre+jyr+4taq86LiepSYibDSiG2AmCmnZUeMHUax5UdrNMYhIFgusJOMIBHA8FEqjAUUTVt6IKRVbN8lO8DqokqGGyVBD7GpxLxbrIh8ywqJrE1E4klCmM3YPkCJjkzNfN82HKDMOKak7Ba7r7lYyx3bmhn5NCPusUz7x3yXfxc2uqGZNq+324m58f3zYdqrX8lLYgnrAi+jkNqme+5jKXo7bIdVx1aK75GOKmWJ9BUDVdyHIoyNhfxaJyd78LLa5UEk9l/eS6hhNcRlCFjVAiCHMViCRgaddmXBq/ZhXaoN7BMnwrmai2Vx2Xk1QTFvLF61jarKjceioAI3nKt2CSoMDl7/gjuiA2FQBcQf6cwVriFCmyKsGJgT9rVZDBTzybn8WjBhUGVCyq7KMsTGwkT0WuD5aHMKVLoUKF2EzEymbqlmgWrNPOhh8jYRfa4v+mcbNOhfGinu6aV+WoPJVExV8gZp1UAJGEKXU8rXaqHpLiX57QyLR2ffIazOtsBpLkzd+ey1yO2iLXcSkQPNgmWQt1gFD/IwN00j+bLne+PmJJBTRrqAj+KJLKCaYHOEGGP0+a4mqQv/896MRbxdxKgwEjwUnhDUmGIRvaq47LSWocWNJUOHKTwzgZW6eXpArJqR+A45eiIrVOs6gGdVOFYAV6g0QqX8p9C6rDnuzQvRpkW0uCqiyrATHxhEZciBCW2GCEVXvIiV+ff/0qYSwoOJ8FpuXN3JaDQd5r3/wIKV+xyotpQWml5AlK2sxThvtfWVKD/T0luPEzTgHh7xkpNcW+++2i2f2cTMtrEcaiD5KyK9skeZPbc+SoJXIdlwLSmpnC5Q8gnqAykirbAcF6lxFV6U4Ksu81Y6gAnDBKKiS7MYlTWvypqoEKPRbVjEsNviqjKBkbtGuVep4gcwuS0F51XJte1ZQpU/DNb34TnTt3xtZbb41vf/vbeOedd7Q2RITJkyejT58+6NChA0aNGoW33npLa9PY2IhzzjkHPXv2RKdOnXDkkUfi448/bnkHPfbfloFtWB85+eNTniEgh7ywvpqByguz8mUylSQTPH5VxpnKWMAKI6ha4X7SzwMLMVUPvBn/Y1EO2nWrB7U6iSgHo764JUc8TOu1bk0V7HPwkRFE+T2SNGUW25dWUcjsf6GWaLa+XsDfWnoKOjmV/eGDJW2mKZtVpQWoJm+5zOWoNXJ5S4nq4Zax+R0aQeVWU8N66n8mCNe3ivqffbNn+D9cHJftby7s2DDPYSy6kcfos6nXyLheft0AY7Z2tFcd16Ykdd68eTj77LPx0ksvYe7cuahUKhg9ejTWrFmj2kydOhXTpk3DDTfcgFdeeQW9e/fGgQceiFWrVqk2EyZMwEMPPYT77rsPzz//PFavXo3DDz8crus2r2MaMZMWVWiWHlvilHqYeFISoKxIfkH9sMC+n4EfklBehF9OcxpZYtp7kujK4v2eE7pZZT9kvyxuft26FV6/kETVliyVkEDlAhrx0Zfm4aabbsKAAQPQ0NCAoUOH4rnnnktsf/fdd2P33XdHx44dsc022+DUU0/F8uXLm3n2VoAs5M9+o7gYYdPyqE0qgVBkNVc/WFwqy8ZXRJMR1AghNRbTihq6+g2XP7Oy+qJjkOoYoq09T/yCJKqUoUqWt1zmctQeuY6rDmIWRzVGTRiUmklSmlU1higKSUq98P0rPzuKuBKERyHhjBBTYm3Cdo5BWm3nUO9U872a6UZVb9JaOm5jR5uS1CeeeAJjx47F1772Ney+++64/fbbsXjxYixYsACAb0WdPn06LrnkEhxzzDEYNGgQ7rjjDqxduxb33HMPAGDFihWYMWMGrr32WhxwwAEYMmQI7rrrLrzxxht46qmnatNR6fq3kE/rwxRs862YCC2pnnxxB9YuT77coRFPjYgaMafWWaUIivASsfN4zJIqLace659BfCIjWUtulEiR2Q/Aao3jS1bMmjULEyZMwCWXXIKFCxdin332wSGHHILFixdb2z///PM4+eSTMW7cOLz11lu4//778corr2D8+PGZz73BELGg6olUWjtJ9hgZlP+5693/byQ2EbOkWoip3Ecjrnzhs0xZSDFkf+RiXB/3OlgtqlkVvKW/uczlaG3k8pYCFne4Atnj0fXBKiOJcn2EqFIMcdW/hxZWczvpFlZJaqUFVpFS0s5l9s0WphC9ZnZrEgbtNrSGjtsUsFFd1YoVKwAA3bt3BwB88MEHWLp0KUaPHq3a1NfXY+TIkXjxxRcBAAsWLEC5XNba9OnTB4MGDVJtTDQ2NmLlypXaYkJ4xkxL3KIKWImqRlqV4OrxhRRYOWXcqKfIqk5UJVk166DKbZygKnJKUG7+yAxTZMmctFjr1PXLz15IlLLEClYSXBKVZrglpk2bhnHjxmH8+PEYOHAgpk+fjr59++Lmm2+2tn/ppZfQv39//OhHP8KAAQPwrW99C2eccQZeffXVzOduKdLImwZDWWlZsMY2Pd45LPtkT6BylBVUWVJVOakEUmqLRZXEN7KelZ9SyleoRT4P1phU6NeWBUnylstcCpnLkRm5jgsRK29MBYQvEssBzHcSLMYTg6yaFs14K6tuCdUtpmRtoxFg1yCn8t1uSzxmhiyry99y3WnRGjouq+V+3rx5GDp0KBoaGrDDDjvglltuyXzOrNhoSCoR4bzzzsO3vvUtDBo0CACwdOlSAECvXr20tr169VLbli5dirq6OnTr1i22jYkpU6aga9euaunbt6+/wWIl1ATNeHisMSiKSAjmAggtqSBpRQ3IKXP7y/nXpTXMDaxQ/L9Zh1J38zthLCoxS6rZl6B/keuIuV65PgtMkmMuACJKrbGx0XqspqYmLFiwQBuIAMDo0aNjByIjRozAxx9/jNmzZ4OI8Omnn+KBBx7AYYcdlu1CaoBYeQsSpsIFMRZTREfn7LMKJWHxoFqmP8L/ygpKQiOgsaSUx69GrKihhRZgM0wBrB/hovrN/5vXiZTK3UA1ectlru8G78PmjlzeQiTJGyVZU00wHaCRPYOc6tZNaLGjjnT921z1EcIasy0hDlV4pLv7jZhUk2wnQXH3FO3T6ri0yGq5/+CDD3DooYdin332wcKFC/HTn/4UP/rRj/DHP/4x03mzYqMhqT/84Q/xt7/9Dffee29kmzDi0Ygoss5EUpuLL74YK1asUMtHH31UtX9a9rvlpapGeuyBilorA1d88FlZPSkkqiqRyotJnFLfhSKoKnRA1UWFmmnKJDnaA++Z/YPRnuxkIYVFNWpZ0xcA6Nu3r6bYpkyZYj3WZ599Btd1EwcrJkaMGIG7774b3/ve91BXV4fevXtjyy23xPXXX1+177VGVnmLGzwAFqVG4cDHNvMUz/DnLn9ONhNJqRa/Gu4bHssx/vMEKqgBk70+ajTb12rNT4Fq8pbLXHUdlyMbcnkLESdvBBjKq/qxzIQp07Vuut5hEEiTqEZIK/sv93UsllQzaUoPNSDtvWq+S7mhJ+uAOw5pdVxaZLXc33LLLejXrx+mT5+OgQMHYvz48TjttNPwq1/9qhaXF4uNogTVOeecg0ceeQTPPvsstttuO7W+d+/eAHxr6TbbbKPWL1u2TD3MvXv3RlNTE7744gvNmrps2TKMGDHCer76+nrU19fbO+Mx00/EDCSJmz0rXsimUmhV1V8KrJkEOH7tUs/xi/V7QRkqx/EDo+E5IEFBrTZbKSBoxDbM5IcKHyBuPTVJAn/YIqSBkyP2ZNnuRZXY1DIV4MROGegHu3700Ufo0qWLWh/7mwTIMlh5++238aMf/QiXXnopDjroICxZsgQXXHABzjzzTMyYMSPxPLVGorwB/r30EFhWLdttVkjlQg93sM48xZOnpCtfEBwiQDjBfw8wRuGe8TbRrKjyWEYpKtOKGyWq/rFsyRHWQaB2D5ovb/72XOZy1Ba5jgtRVd7S8CdzUM7frZobnaIxoZKgyrbqIIFuAfklqFzhqzpTFwXkloLSU+QI9frW61ix7yL4IgDImaXl/kBUh/HDZOOTANLruDSQlvuLLrpIW59kuZ8/f37E0n/QQQdhxowZKJfLKJVKqc+fBW1KUokI55xzDh566CE888wzGDBggLZ9wIAB6N27N+bOnYshQ4YA8G/uvHnzcPXVVwMAhg4dilKphLlz5+K4444DACxZsgRvvvkmpk6dWsPOQhc60h+kSCwq/Jez7xrwi/nLKVKF+uzAgwch/Cr+kqgK8uujknzIBEUJgPzM3fyeE1rWeNkpT0CVnIJu5TU/W92wzYAHB16MoV6u79Kli6bA49CzZ08UCoWIRYEPVkxMmTIFe++9Ny644AIAwG677YZOnTphn332wRVXXKENejY6WAY/pkVe/TBq0AK99FNwKD0m1dNc/4Akow7T7D5M15FugWX1eVVlAD02VcqnnhQQklVNR8cRUyAySIxDkrzJ7UAuczlqh1zHpYAIH3YK+Jz8r8F87wT/dasqsc+wkFT9PSxPogb+8uVHQvmQ5XGFy97bDgKdI6zWXyLDICX7yi9DhH3RCCn7nJWoptVxZvy5bQDRHMv90qVLre0rlQo+++yzVpO3zO7+uBFapVLBxRdfnOlYZ599Nu666y7cc8896Ny5M5YuXYqlS5di3bp1APxR5YQJE3DVVVfhoYcewptvvomxY8eiY8eOGDNmDACga9euGDduHCZOnIinn34aCxcuxPe//30MHjwYBxxwQNbLsyOOuMlRnbEuJIesPUFZMeVMUP5oSyY8hfGkBJ8USBe/x1z9NoKqkmcA/7gyacp0QXh6//j16IX8o9eZhihwqASvmCUL6urqMHToUMydO1dbP3fu3Fhr+dq1a+E4ungXCv4olDammTnMvphdi/muWVwVcUUoG9piuvxDqygALT6V10Hli2ZFRQpyCuhWVNVXPZPVtBzrcV3pf6dq8pbLXI5aI5e3FOCJU+x7XPJUHEG1Ddh1ckq6RVVz4Rvfg3JTjpEQZYs9jdtmuv1t3iHtuqrdphTyklbHpQ0xAbJZ7uPa29bXEpktqRMnTsTs2bPx+9//XmXh/+Mf/8CYMWOwYsWKxBtiQsY+jBo1Slt/++23Y+zYsQCACy+8EOvWrcNZZ52FL774AnvuuSfmzJmDzp07q/bXXXcdisUijjvuOKxbtw77778/Zs6cqR7YZoNZcTiJk65JbbYpNroyHyrfoxq4GYIRHgXueM8B4Ak4DsHzv0AIASEIQlBE2fFZpCRB9YKZpkglTYUJU3KWKavVlz9MxK8rNKxF3P4p4XoFVDz7/Xe99G4JifPOOw8nnXQShg0bhuHDh+N3v/sdFi9ejDPPPBOAHxP1ySef4M477wQAHHHEETj99NNx8803K1fYhAkTsMcee6BPnz6Zz98aEEq2AO7qN+NRYVmvRvEk45B5TKrf3iSVyuUvyCeogs0FbbiKzHmguRVVFfCPXUI59Y8dWlRVcqG8rhhZjEWMDCbJm789l7kctUWu41JCue/SERnT6MNd+Zychp5LirRRrn7IY5Fv3XQDK6pgx6eQkCpzqCNYv43+yeuQYQMegYRQu/peVMTrMWmdjYzQETkXR1odlybEpDmW+969e1vbF4tF9OjRI77jLURmkrpw4UKcdNJJGDx4MGbOnIl3330XF1xwAY499ljceOONmY6VZrQnhMDkyZMxefLk2DYNDQ24/vrraxswbsSh+v/lw0HaS5eTBo2owrdq+rEupFtUPRm8Err9JVEVQUyqfBh0d79JVEM3f1gXFRECAC9w9XtsXRxB4OSJXb/qQAoFzGtu2rZlxfe+9z0sX74cl19+OZYsWYJBgwZh9uzZ2H777QH4IR48K3Hs2LFYtWoVbrjhBkycOBFbbrkl/ud//keFiWysCOMyhbJwyxhoLUOeL/KjkovoNKnc5e+SgAN/QKSC7UWUlJrfeVZ/pHA/W6D6wsSJ9dW0NkTCGcD+p0SSvMntWdFeZC5H85DruBRIIl7S9R4HiuoGLTbVdPnz7WYcadAXIXx9qqKZGEFVJFUy22BqVTNpXrnxg/aKlCLkuNq5ky8xNdLquDQhJtxyf/TRR6v1c+fOxVFHHWXdZ/jw4Xj00Ue1dXPmzMGwYcNaLR4VaAZJHTBgAJ599lmce+65OPjgg1EoFHDnnXfi+OOPb43+tQ04CZMfLVYtkyyEVlOoxCnd6oWAnAYE3QtEugCAEVUp1UQmQdUJgJpZCsEDo84lLal63yIPd8w12K4XGQ0DspxW3Lbm4KyzzsJZZ51l3TZz5szIunPOOQfnnHNO8062oRBY60UwIo9ut/xXAwsBIgrDPRiRjZSfMkmmnx2Q8Bvp66VlNWpBDV3+cj8pn35/w9hoq5xZYFqU0yBJ3uT25mCzlLkcNUGu4zIgIH8kAoOqaZ003j08VyK0dsJCSklfJ7PuY0mqDBYVoTGG7wv4VlTW5+i1+PsHqSQgxzcmENh+kg8g/J8ESqHoaq3jslruzzzzTNxwww0477zzcPrpp2P+/PmYMWOGtSJTLdGsxKnHHnsM9957L0aMGIF33nkHv//977HvvvtuXC6GWsD81YNg6shLlD9QYN9l0jTBd7sTQCBlSVVHFwAcUkRVBA+ykGEBRheUlUoRVKEWZUmFT2LCpKnwwY70kyzXoq6X3YcMT0ElIROxOUWH2w3Ub0HQ3OLyv+0nYG51uwU1JKi+FTWIXxJI7e4H/BlPAGiEVGb1Wy2qkqwGJFqFx7BribPoZw0zSZI3uT1Hjloi13EpIHwCJpphWdZ1ITQdoVz0irySRlil9VNZVoO+KILMPaUyVMBlJ5aZT45QIXpqq2XALfOsAGZpZYdS+8rPAolGZBtqreOyWu4HDBiA2bNn49xzz8WNN96IPn364De/+Q2+853vZLuQjMhMUs844wzccccduOKKKzBx4kR8+umnOO200zB48GDcfPPNKsN+swKbfUqRB01ISSWIhJbTYKQmHxqBsCyVHMWp45BPMJ3AFUFsxAnTmgol3ZKghu5h/hkxdVDDfvL+m65W7XrZ/7RISh7ImlSw2aLKPTUHDmqRuzI5M7P7+cxTYb1Uj8WkZnP3A1BW2PCzzVoLjaxqpNoymLO9iCKDI3mvEgZJ1ZJVcpnLUWvkOq46fIKK0IqqbQME2GAcMZ4808BChgVV/nfB3mfsmFJvCDCXvr7dr4fK2Kx094Oi7YXfUaG8orJvgTVVNjXVldUqm6JNgNbQcVkt9yNHjsRrr72W+TwtQWaS+sILL+Cvf/0rdt99dwB+MO3s2bNx44034rTTTtt8SCojZ0p0KXx/atYuRiDI8pk0wipABVKufgqGd8LxiarnhF4GeWbNmioJAEKCGlpRodz8QnP3iwjZsbtU9LnirR6IlGQ1aS7hzXWO4WaDufy1ihBaG+OzlCljO5/xSRFUbvmk0JoK8N9It6TafiOX7W8W8OfnlTxTfo+8cMzrsd4Tdm9SoNrc1bnM5ag1ch2XAoItbB0nrCZ5NUOcktz+krCGSVVRo4pMAiYREFnpuZTbA4IaVuEjAH7cqpCGJSLFewX571rhcGNBcH5QdHBuuSfE7klabtledVxmkrpgwQJrttjZZ59du5JPbQgiCh8YnkDE3uGaNQjcemr/rPb3BMih0H2gyGtQP9UJPgeHt5WlIADcjarPLGVYeANXfyQkwfaZnUB9l9O/mYSBqGrSmwsHlZiHxuZKbreIsQ5afx9GTs14Yp8chhbViMs/sHZWyC/g7wWBUqpof5Vi/n5XHdhKT/nbws96Vj/7L8EGSJHECKPKQVokyZvcniNHLZHruJRQLm45QhXhenPwzZqqdRHjCkX0h5yBSr13RXgMbkkNLUCGJZXHpAYd88MGhPKEyuOpyQAs+kt7Zcu+pLk3qn/xrdurjst8VfX19Xjvvffws5/9DCeccAKWLVsGAHjiiSdQqVRq3sE2QVw8HJsKzd+mE9aoK1OEBJW54IXmmg+JpqqfGuxLjLASpFUqSlBVLKo6p2CufhESTRLhaDGOtAL6NdruQwrUcvq2doGYQYOmBGHRYdrgJCEe1bB8ykL8LvusT4saXXQrKrPUcmuqtkSvTdPixjVrVnxu2E2RtFdN3nKZy1Fr5PKWAmq8an9/RG6TofuURdR4T2lWVC3jnxDGpwZ1UF22yBqnchsjqGEbPo0qafpJi4XVQpSg9TPpfpAkoyZBrYL2quMyk9R58+Zh8ODB+Otf/4oHH3wQq1evBgD87W9/w6RJk2rewY0CPAM7gDVpir9weS038DaMQDJyqRPVkKzypCj/e7hOEVRixzNIsXoW+INtIz4mUVDrKTNBBYBKUNMtbsmB8L7aSJjlt4jKm1BteXY/d7XLQ2ixo4E1VJsqNUJInegirajMmgp2npCsMpFRcijCQZtBViMDJOM+aPcqBtXkLZe5HLVGLm8ZEVgxiX2OhWXQbuo/zbLK6qQKl/13QyIZFugn9Q5WSVesHSTBJWKhAKT3J2ZwrS6VqyvJs43rJU5YIztF0V51XGaSetFFF+GKK67A3LlzUVdXp9bvt99+mD9/fk07tzEiHEGR8QBRRIDNJeLeBDRyyV33ZBJQSVi51UyR0tCdKmNR1bmsyVP6A673m/TYVBMpM/xNy5y55AhgkC+bHNmtp/I3NmM+w1ql8qeK1kqN+8yX6Chds6LC+M8s//5JpRyHn62DIUOZW5+RFKgmb7nM5ag1cnnLgAy3w6bv7O8rPRZVBASTE9XQ2sqsqrZ1nmFZdYlZXPk5SD+f5f2uTdJiuw+SnFruT9J8B+1Vx2WOSX3jjTdwzz33RNZvtdVWWL58eU06tVHAk0SUCVzwYCS5LHnilC/Mfi1LIUmoIEAEcS4gv8SFrJkaJE+FpTLCrP7wfEJ78XM3v+nilwX8ZT90l4XdgqVfJycT4b1Id/vi3Q+bq1uiJRAUVpDQEDfg0baFMqHX0rW45UX4H8RjUvXTJsek2l39fKYpXoYq7lpM67BNqZv3JS4Wupq7K5e5HLVGruNSQgWJQqtaE6yquqtp1IkS1OC/tIaqfSlcDwCOr5+ES9qJtf3DtcE7G34FgmAHckwDgn9tkdjTpFclj41lbn8hkndrrzouM0ndcsstsWTJEgwYMEBbv3DhQmy77bY169hGBcuLMRJDZxBV7UXMA68JrACwT2AlQVX//RxBX/j5O16dzyCoynoq1EOrE2WLhdfS71jrabPc/Q6EZzfUV2LWt1fwChKm4gvbxPxGmkz4X6wzTsGPVdbilwQrW2LoN1s5E1vdVY+5+rXzyr4ZgyD79RvtKIa0J8hhkrzJ7Tly1BK5jksB5WqE/h/su6DoBjL0AqROgPHeMl3xNqIarHABIUkhLyml3P3B8VVtcwIc3wAg5NSnvPY5GSrJ6K9ax67VakFNyS3bq47LfFVjxozBT37yEyxduhRCCHiehxdeeAHnn38+Tj755Nbo4waH1VrD3OBaoLZB9CIv5riFl4oCdMKpSkkJLSZVzSTlGe2BsOSUESIQWVi/tH7z9Yrkmk9hwv0x0B4DvFsMg5RGZCpuHduXAGX0VlZO8Hqpdjd/+phUfX9e6kpNMkFA7ExTiF4Pv35rGEAKtNekghxth1zeUiKJoAagBLJmhgDZdKPmilfxpASYrnzXaKPiTcP/cp/Qmwq1T7gvrO/5xPh681ozikh71XGZLalXXnklxo4di2233RZEhK9+9atwXRdjxozBz372s9boY9uBKCCE5vr4B8fcRsY2IqGEnVQNNvgCyyypfgPogqyEXyeoIfHl7nzdvc/7labfGuQ9yGBR9btjf2gy8o/2ARVACgtxMwQhsJoqF5P6DYOBDbNmavGoIrCmGqWjfNhmmBKR79KCyicOkK7+eLLq/7fJoS32Vsvo5S+QBCTJm9yeI0ctkeu4ZkDGZFIMRzPedzZvEph+MJOBhXxnA0pH6vo0mFmKqzs3tMZK3SOtpnJnCqZK5XVQeX+E9B6xvsddu7woqR5Dt3+u42zITFJLpRLuvvtuXH755Vi4cCE8z8OQIUOw0047tUb/2g4RVyPClyaDkALKXrSmu59I+PsFxYEJARmVZEPWTxXsPEKE3239YN8Fj0uV5JURVz2rOuyXTk6NE5nltmz3hUz2HqLiOUDuCkuGYalWAfcy45QApbXjBhPSzR+EjoQZ/pJEQnP7OyrhKZhxKiYmFYgqRM2KiugIXpJiLSwFgIjIX4xrz7jOLEiSN7U9R44aItdxKaCNrQkQQotLTWVN5PpAG+BSqDu80GWvTi0JpMuLnPuz5ahq6DyEQLYTgllmw3epPHLo8qdQl/F3f5pLYtdPLC41iai2Vx2XmaRK7Ljjjthxxx1r2ZdNBqHw6kIsp0eVDxEB4ISQE1lZ0F8mUymiqqQ1OECcJVUem7n5ZdmrJOuoblllRDR4oPlosiXIkwoywFCs6pv2W4UL/3lEQPpIk0VJWPXkJkFm4pQ/Vap/oGi3rJZUSzZ/pDaq6eZX18PfWLbtpuWE1IumGtprUkGOtkOu45oJIwaVRAJXpYTP6h0W6gmN40l3PmmrAPDZpRAQXC/UNQ5phiZ4PokUCGPtpXHKRkwjSVTaRrTY3Z+0fXNEKpJ63nnnpT7gtGnTmt2ZNofFMhg+BKQEU66PzAjFSYTxGdLND7ZOTq0WuP1DogogwcKlCCerixqxlCIkMHHWU/PY3KIqP/NFg5dcYT1X4NmgBi5m0hQnbvw3U78taeuiBfWZFZUR1ornoOh4mZReXGkqW1Z/OOuU3m/Txc8HS9ySXMXzZe1re1TgOdoOuY5rBgJrqnT5I4agRg0rpOkOHhKkx6jy9eQTTPau8l39Ipxgjx1bthNukCQlqwAE71B/EnO/47zqjs14oK4BCF/lpvVYGEsVtFcdl4qkLly4UPu+YMECuK6LXXbZBQDw7rvvolAoYOjQobXv4YYGF2iPTB7nw7BkaeEk5gtYxnPKh1K1E4Hl1f8chgOIcHYOm8ypBzIkqHodSr4+6BubWMDmNo6Ew1gIrLwfaeGSAxE3ZeBmOsdwTWH7TfjnyCAoXKSuDpOnpEFABKEpwg8zzqj0VDY/I776Z9ZVNjizDZIA06ovr434CVNZUYFkeZPbc+SoJXId1wwwwpaKUiU8/uqdplzzxHQLqZqpMLz95JF+bpkgFdRFJeFbVqkgp0T138/CCaruQOjv05T9ldftd4R9N0lrDNqrjktFUv/yl7+oz9OmTUPnzp1xxx13oFu3bgCAL774Aqeeeir22Wef1unlhkYcGYspjG+SBi1xCmx7QFZlshSxdQRGVFUJquC8RmyqSVAlEY0QT+NBMktTgfUtssjrBaJEIQVZza0MzYCyFviKEIi6++W6aEIAj0v2FzN5SgC+NRXCr3hGfoypI+wWVc9QeomlpyCtqXof/L7ZCWr0+nm7bGS1vVoZcrQdch2XEhZiJqRFVa4XCcRVe1+RXZdwcgqEBNXwAhL51lBi7zDhkZ88FQb0h658DxBB/gh5BBREZJCteU4R9kOjwgYZlWoy3N6yd6rcvjkic0zqtddeizlz5iiCCgDdunXDFVdcgdGjR2PixIk17WCbQZmFlElK28wJn3L9B5/VrFDSna9ZlSjchsC9L9sh3C4Ee2I1MsK+S7ewmhFDGEQ6xooliZDWf0ZsoT/skfuR6vYxl69lWw4DWkJa1N0VsZ7C/p0nTkUWQaGiE/5gx4Mfm2qDLXFKn70qalGVmtf0GsTJIV8XkvAYWUuQvSR5k9tz5Kglch3XTCS4uc3bFutNMrZr9VEZQdUWAHAF4BCEE+g8Fs6nPru+NVW9q+W7PeiDptsQvkPJTrEjHQ6tqVzpBcQ9Ae1Vx2UmqStXrsSnn36Kr33ta9r6ZcuWYdWqVTXr2EYJFZ9peV4YYdAsqfJzEHdKTC6l1UkQBSM2hLNSBce0J07J/cDiUcMHSbO+ecZ3kxSQcVwwxdCCBCo3ofCwu5lmIbYU/u8Z/uhRayn7ToF53Rz8qPipkKzyxCmBcMQtM/3jdGtS4pR//DCUICw7ZUmesl0n4tz9epvU7v4qha5zmctRa+Q6LgVM3WKzmlbhVnoyJSC9kokufmVcQvgfvlVUf8eyNi5TPsyIIz9Ltz8KsoykjOHTPUaxGkvEfNZWx+u79qrjMpPUo48+GqeeeiquvfZa7LXXXgCAl156CRdccAGOOeaYmnewTcEsOuZLNMkaRMb62O9AOBsVEBJV6Q+wSTwxAuPpD62tP9W+W6+L/deD0dOTVkmO4rblYIhYDKErXkn42HYRDEhk3V3dmiqzTkXIXZk1VcWkimzuI2411TL8OUGV/QfCgVNAWgVbZ78PFguyvAdVkCRvcnuOHLVEruOaB/W+E9BLUUWsqGR8Nw/E2vlB9hGCKvh/IHD3A+Qa52FhAaTerYFe9WSHEXig5OtZLz+ZdL0q8sm0IkurkuX6I8dppzouM0m95ZZbcP755+P73/8+yuWyf5BiEePGjcM111xT8w62OdiDojhjMHrSylAAVuJKxPYNXtahS5+tC5wFytIq5Boddjew7o7Q1jHyYnO1yuOEsZDhNeuulvQEVXUjZpdsR9rMYVHE6rfQYjpDWYvEQRGYsiTY3P5e0EZOjeqg+YlTOjmNlp9S4S4AC4OBJo9mCIMmq/7Js93G6K2MbM+Ro5bIdVwLoFx+1ZhZ0DyWoEL9EBpBBSOfvBKN3KYdi1hlFQJEIbC48pd0aD3V3vVprlOehhFTRVxTkFN+ye1Rx2UmqR07dsRNN92Ea665Bu+99x6ICF/5ylfQqVOn1ujfxgMm+FoMCrN0hS9bS4F/hNZPORwj+JZTeAhmtCBlWQUsz7CVcAb1UeEfx8/kFxE3PycEZjkPLv38+vh1Z4VLDuJiHTfXLMQWw2Y5YL+5ObiIbANC7ScVqsXaKcknz/S3d6daTKpcF7YlWx9TLNosU2pfiibvxZDXJHlT23PkqCFyHdcMKMthoC+CdQlRRzpMXeHJ95bcLvWE8Z2vdwwdwmNSPfIJKgvrk+SXpNk3YkBIdeV28PhU/t2C9qrjml3Mv1OnTthtt91q2ZeNC3z0pQl8KJx86GJaviLWVBFdp1laOVENjiHDDjk0yyifWYrspFS1TSAHmsufn8984OV9SZhpSjULrHZx23IY0EhaKEtabH0MQTUt+dyiyS2qnhw8AWHd1OAN4VjG4bYp+Hg8qj2rX/4XiJNLLTZauwfhx6xW/CR5k9tz5Kglch2XEubjK0mpaUWMu2VVHv+IQYXHq6qY1IDMyphUTlR5G9IXm8tfkVde2sp4n0c7KRtJYk6MoAb/qohMe9VxmUnqmjVr8Mtf/hJPP/00li1bBs8o6v7+++/XrHNtBvIAFELBLbBtQewLILQMfx4TKEgnDopcsHqpiqiyUymiGgzfrCInSYD6HMh/ZA5jREpOWckBI0DqofMIEfOaRwlPYBSeJ3wSHbMthx2y/JScGlVqNTM82SZ34eILGSeTYY3UgKAKlukPWF8Q1sQpZkWNmzggYk01oZFR0tqGs0zx+1EdSfImt+fIUUvkOi47SAQF8YHQespd/5G4VPtx+KQzmqteS6gKLKT83SVjUtnvIwxiGiG3jlDt5FuZW1mJG6/UdYpo8X6w78rtH1xHCnFprzouM0kdP3485s2bh5NOOgnbbLONXyqpPUC+TNV39p8RPf6Cli9b7aVtEAl5DBn6otVNlU+BOmf4gHCCGj1u9Hw2S6rVgmpeYzPd/Xl5lmaAyRFfFw3XCGVKxjH721h93cCaqeJSAWVNlS5+geTRty1xyiS+mrVWXoMKf2HWVH4tqp1+TTy+jN+PsEPxFvz2Wp4lR9sh13EZwUmbhZRK0pr21tmMLRq4B9SwtmqnYJZWzeUPrmv9/spKPGk7ajZR9iUtJjXsfBKdaq86LjNJffzxx/GnP/0Je++9d2v0Z6OEIDbzlOkeR9RaGb6sob2I5XpOOgjSghoSVYA9ROSPyCIPJH/xszqp2sseBjlFdL1mWdW2sQenGUQ1d4VlgJyVDNB+J6urP3bAA4Tx0RTqZRIgTkwpTJySmf5A1HAORJWeWR9VExPl4rdoZXPgxK7POKH6mFXm2qsrLEfbIddxzQSzJMrvqWNSTXAlZFhR/e3G92DCHP0YRhsJOV25jO8PvkfOnwZcNVrIqb8++WDtVcdlJqndunVD9+7dW6MvGwdMQbXFZSIkcjLGTxFRRS5IWbL4em5ZFUFsTOjqZ0Q1GGiqc6n+BOvkOY2ZpkzrVCQEgLlTzcxILT5VIm7WqSokwgsSuOK25YgiOoECtP9q0gjVnsub8ZNIYohwBC5JqUlYgajutc9AZZ8SVXPzy/4qa2qcHIbXoHkjPL6NvTxaIG9ye44ctUSu41KAD0wB5eIWNkoaM8aNDXvju1oIpklYhUdq8hxN4bFYVNVGxaOyF3Fw3lCP+dtiuSWzmlqvkZP1FNlX7VXHZU4H+8UvfoFLL70Ua9eubY3+bDywvBj1DGT9szVpyfJdrVd1TUVknYqptu0H9pBYZpcy66XG9UPrrzyXum5GtKvck/jbFxevmOyyaO8IY61C+dISpmBYv4M2EcsqoJFH6fY340m9DIs8ZegZY8cP+kG8rwYBjeuvRlh5mwyoJm+5zOWoNXJ5awFUTGbwqMe4xWHZFjaSujJoZrOiykNwdz5/h7F4VWEmTsn2HkX3i/QFdp0Vdx3NEI/2quMyk9Rrr70WTz75JHr16oXBgwfjG9/4hrY0F1OmTIEQAhMmTFDriAiTJ09Gnz590KFDB4waNQpvvfWWtl9jYyPOOecc9OzZE506dcKRRx6Jjz/+uNn9sEJzQ/L1lnXBeptVUz1MXnRblLyGZFUbbMW1M7fBOK+NrJrXFPcMNsPdb+HJsZwlLW666SYMGDAADQ0NGDp0KJ577rnE9o2Njbjkkkuw/fbbo76+HjvuuCNuu+22Zp59A8Aop5JMRAE16xgnp0YbnzwyRQZJVn3LqEthtr9JSM3F5uondV42LSrvR9B3wforzPUwZFC+UDLUSq0mb7nM5ag1cnlrJrir37Y+A9eKeJ8s64WNZHqk72OGB8QkCmvTr5LFkMOvhUG3nlIYj2ppG4fW0nEbOzK7+7/97W/XvBOvvPIKfve730VKWk2dOhXTpk3DzJkzsfPOO+OKK67AgQceiHfeeQedO3cGAEyYMAGPPvoo7rvvPvTo0QMTJ07E4YcfjgULFqBQKNhOVx0xwklBpr+qgyrXqwxs350aumEJ0uXPSSIJ9tkDIASClBf/XGACR+YKG+kU2uxTZhvNMqoRA2LbQ4KkPeC2hzAFaSVPaBmU5rasmDVrFiZMmICbbroJe++9N37729/ikEMOwdtvv41+/fpZ9znuuOPw6aefYsaMGfjKV76CZcuWoVKpZD73hoCKezZiU5Pii5Wcadv8GNSQtPoBzURhbCqvaSpd/44x0rK5+5NH8UBUa4YhB/aBG6ltXA71belUb5K8ye1ZsbnLXI6WIddxzYB6AQaqyZJAZUNqIyGRPWHK9p2tFzZSGhxLsOnMVQs2fXXqPhtE1bSsCiDR7d8aOm5TQGaSOmnSpJp2YPXq1TjxxBPx+9//HldccYVaT0SYPn06LrnkEjXd6h133IFevXrhnnvuwRlnnIEVK1ZgxowZ+MMf/oADDjgAAHDXXXehb9++eOqpp3DQQQe1vINJsZgRshgSB9t2FYsabJMEQxbz14gqfwZ4FyIv/WjhfkGAWZLKbtkyLFjaeRKuOw2S3A/NcEtMmzYN48aNw/jx4wEA06dPx5NPPombb74ZU6ZMibR/4oknMG/ePLz//vsqhrp///6Zz9uqiLMUar+JJG1hfLPWLoEc+qQUikTK/+GMU/5gK5hPQu+C5TfSC/gzsqv6wkJXmNVUC12xXKPVcpzmPmkdruLuymUuR62R67jmwYxLjb2FIqoUbG1tA9oYcurHnAJaGr1hRVVxqTZ4CDL/9QF4WqimwT1IE4sa7lx7HbcpoM2nKDj77LNx2GGHKZIp8cEHH2Dp0qUYPXq0WldfX4+RI0fixRdfBAAsWLAA5XJZa9OnTx8MGjRItbGhsbERK1eu1BYrPF34TZeknvxBUaJoIbDJMaqm+za+LSeose1izq+vN67DI/UkhddL+v1IATPnxZYDY/4GjY2N1mM1NTVhwYIF2u8MAKNHj479nR955BEMGzYMU6dOxbbbboudd94Z559/PtatW5f6GmqFavKm1fzj1kUO4u2jv63NxS7/+4fV40erJUFZY1IjVlg58ArXRTL8Y2TRJK2RwZKXUX9Xkbdc5mJ0XI5mI5e3ELHyxmPVItZD/QFXLnDD5S/ViZWDme8qGCEAMTGqkR/K3AfQk6+M/ZN0U9x1mNfjH6jKwfh+KXXc5oZUJLV79+747LPPAITZ/XFLFtx333147bXXrKPEpUuXAgB69eqlre/Vq5fatnTpUtTV1aFbt26xbWyYMmUKunbtqpa+fftW72wMeVAkUX43XJhasXLj5RshkZKoevFkVbn3GUE1raK2fW1F08NrgzZ7hnadhuRTaverk7gAQN++fbXfwSYHAPDZZ5/Bdd1EWTDx/vvv4/nnn8ebb76Jhx56CNOnT8cDDzyAs88+O1X/a4lU8qYpQFL/q4Vw8DjP6O8exomGikzA8xxFXGUSVRwh1YlrQHYRkl5ei9V072vkmcFqDQYi7bKgmrzlMpdCx+XIhFzeQqSSN1viUFo3f1ojYfwcz+q/5tqX33kb8zOM96V23JT9kmN32wIZ9pCMtDpuc0Mqd/91112nYkCnT59ekxN/9NFH+PGPf4w5c+agoaEhtp05WQARVZ1AoFqbiy++GOedd576vnLlyshDRSSnJ40Kj4pJJVJPkTBfthTGsJjkgce3iOAUMuxUyirJ0hZcePm5EJ6jmtXUSl75/qrPRjygfkNstzIWSSM7uf6jjz5Cly5d1Pr6+vrEY2aRBc/zIITA3Xffja5duwLw3WnHHnssbrzxRnTo0CHllbQcaeQNQOJIPYxzjlpSif+uJIKbL//L7ZyoGnVTQXCMt4DNaB61ukpyCn1B+Dnsqz7wMmWTDwK1LF0+C1oCqlkScpmLkbkczUau40JUlTczHpOEto5/jaAaQbX9BrYfxqyRaiOl1d5z7J3fLGj3IfiYNnEqpY7b3JCKpJ5yyinWzy3BggULsGzZMgwdOlStc10Xzz77LG644Qa88847AHxr6TbbbKPaLFu2TI02e/fujaamJnzxxReaNXXZsmUYMWJE7Lnr6+urKgsNvI4aUeSZiCZM2chDdFH5UJJEAmo2CyW3lFDM3zxelfPppIH/J/3YMIlCM6SfExbbNgBdunTRFHgcevbsiUKhELEocFkwsc0222DbbbdVyhsABg4cCCLCxx9/jJ122inNVdQESfImPFmLL/jOFZH5u8L4HyGFAipZT/n5fbJK6j9Cgil4MX/9x7LFPulWVATnkUQ1xsXPris6KJLbooMjXd5TyF+SvAG5zOWoPXIdp5BK3myW1JTtSai3pR02Bmd7h0kvlcwDiUuYIlYnNS37M0h3xFqsbVfKL9y9mjU1pY7b3NBm9uH9998fb7zxBhYtWqSWYcOG4cQTT8SiRYuwww47oHfv3pg7d67ap6mpCfPmzVMEdOjQoSiVSlqbJUuW4M0330wkqS2GVkCfNKJgWiurxYXyNnFE0xZ3GtkH9uPHkQOT+GiF/GtQFJhIqGzEyJJxJFpXV4ehQ4dqvzMAzJ07N/Z33nvvvfGf//wHq1evVuveffddOI6D7bbbLvsFtTZsilJ9jvkvPxMf1PCFJUxBftetoNZ4VM+JrHM9x5gGlZecAhuQCeN/dBEWeZTQ5TK91k2Ut1zmcrQCch2XAYqgcWWFiFEy4t4X+rpUt7WaeVsezixBVc0Yk0YdVbserS2FluUU11VrHbepoM1IaufOnTFo0CBt6dSpE3r06IFBgwapmqlXXXUVHnroIbz55psYO3YsOnbsiDFjxgAAunbtinHjxmHixIl4+umnsXDhQnz/+9/H4MGDI4lYmWCLUZHfVS1LQ+BthI/C73GWT1tCiYghppKw2kitLSZRGOe3EeuoW5nCexBHnFJYVmtddPi8887Drbfeittuuw1///vfce6552Lx4sU488wzAfjuppNPPlm1HzNmDHr06IFTTz0Vb7/9Np599llccMEFOO200zaoGywT2AgeYL81LKQuYUBiEtWQsOqxqZK8mkQ1rpA/gf+u8rs8R/gGkZn9JlHVrgHJZFVZPBLixPRblyxvuczlqDVyeUsJnjglv/P/ql3CeyXr7eTvKCMGtarPnCy1Vc13XvrxcwiuJmPuQdJlttdi/plLUG1IXHjhhVi3bh3OOussfPHFF9hzzz0xZ84cFR8L+PGyxWIRxx13HNatW4f9998fM2fObH6NVAPCI1ABunWRCIAIhF+EU5qSLruSNJhu/4hLN/BkmA4Nq8hpZFj/nmiNJV0HaORGEmIbOfcQPrRZYJIO2zVkwPe+9z0sX74cl19+OZYsWYJBgwZh9uzZ2H777QH4FvTFixer9ltssQXmzp2Lc845B8OGDUOPHj1w3HHHaWXONhpY456jn/l//bcP40/DkBMZMw2o2qlCrpf6N3D3C9Lqotp+HrO2aphyG5VvTeYAOxll/VfXJWVNvRiq3zqt00lylctcjloj13HZIFUMIXjoA50ioFeEMsMCRLheAImuf3NQG/veSjn4bTa4ijQtwEoxss9p0Ao6blPARkVSn3nmGe27EAKTJ0/G5MmTY/dpaGjA9ddfj+uvv771OmYTYpMoBO0kCYiSRgJ3jZpJVRRDVG3nBfRzx7n3pdXUamHj12WS2ySkJauRJ9PY1gycddZZOOuss6zbZs6cGVm36667RtxnGy14EX/+2SB3avIIhOujMdB68hSp31a6/fXYVAAaK46LR5X/OVHVsvqtMgaN0JrW1AhRNbenRZK8ye3NwGYtczlahlzHpYdJ0mTiRdqkIWV5rPqGTDhIwn4xM0z52wAENi/5LqcEEyhxxp1kLc4qIq2k4zZ2tIikfvTRRxBCbHzxLy2BFzAEGxkLZp8wLaaSPPCC63FWVNleEVL+WRLV4Bm2PTImkawWz1rNPWzL5FdtkixZXhUzVxLh3UxHfC0Gv6VavBT0z+z3I3affXnyk6dCS70cGAXE1WJNNbWlnaSG28IEKt4fX4EKYoJrG/wkEFX1P+K1SIFqA6xc5nLUGrmOSwfTWhhVOTH7QbnGBYx9msvHZIZ/XEq95wGeAzgJpDUGVTmk/MDic9Nm9qsDtEMdlzkmtVKp4Oc//zm6du2K/v37Y/vtt0fXrl3xs5/9DOVyuTX62HbQso11CeBxppEYT5M4GuvN+FGt3qk6t04qtThVhMcUHrT4VdO1aju/SRS4tdV6nZb7AcCfJjb23onkJYePIM6Z10bl8ZiRmqkB4uJQqw1U7LGpjHxq22C0C7dZE6QQ/o96GewyFyGsTKYyTY1aTd5ymctRa+TyVh2coKoXmaVN1eP4/7R4zrSwxaGm1S3NTCKW/Yz0l9+L4L9IS1bbqY7LbEn94Q9/iIceeghTp07F8OHDAQDz58/H5MmT8dlnn+GWW26peSfbFAZpCEtSWARCIxGhS0AQgjJS/gcK2orgPyEgmgJq2CCtqjboMXywE19GnoXRL1t/bdeskYSso0rPX+K25YiClzezEVL5mYeKkPG765ZNMsgpYLOm+ghPWM3dr1UNMIkq+y5DrszBUpxllctbbPHsGCTJm9yeI0ctkeu4DLAQURKsBmzAsSKah5E86/aWIMsgOA62DlnXcbLO/quleh/aq47LTFLvvfde3HfffTjkkEPUut122w39+vXD8ccfv0mT1ETLoIlgDl8Z+yczsUm6/WG4YzmBBHsu5HeE34FQjjlfsLpJLSRF+262k8eRlixFdANiUCtBb4V4rc0O1ZSjxRoJ87cN1vPwkvD3D+OjSYtN1mNTs7n7JVENj2VaVIXx3ZRDwEZUKVzPT5ra3d8+47VytCFyHZcOAtHEqLjbU+vbyfWH5wFOywoa+T+50ZkYMQjjaI11xvWndvm3Ux2XmaQ2NDSgf//+kfX9+/dHXV1dLfq0cSLGAqniU9nLlxNTbu2KtOP/EX7npxB8I1+H8Pi2/yYZSHL320INWjrKVGEIMdtyBOA+dSBw/cMgof7AJ/obcXnzLadqABQhh0KRWNOaGkpg2KVoN0NzBsnvhqtfsHW2WGmbbNonkoARk1udrCbJm9yeI0ctkeu4FOBWQulSZNvIILBqnwCR7cqzLazkjoTI7IWJHiTF4DjOgpqWJwZtZQH/NLu1Vx2XeVhx9tln4xe/+AUaGxvVusbGRlx55ZX44Q9/WNPOtRlifThMeFkcqi0eL+JuN9ZVI5j2JKfkl7++jSzbKXIM/fpgkHELUa3mc1Dt2l/sTIsRiZuKKh7TAglTLgCdPLLFTHTS41H97Z4XV4MPqq1OeI3zsX5Z+2tsj20j70fWahK5zOXYUMjlLT3MeJ8q7u3I7UtDADNlIdlO2kJyy2F0hVtQtdmmAhJfdbYpeZB2KHOZLakLFy7E008/je222w677747AOD1119HU1MT9t9/fxxzzDGq7YMPPli7nm5okOe7ByyjKq0MkEcQTmDFki9xQCMQpstfwB9RkmwHZiy1yGpEftkL3WYh5UTYJLQ6OaCQzNoSVrRzUvWMfrOPcc9dDXXB5gYZMmKu04lfaFlVLZmscdd/SCLJIJcUWlOZJTVWT8uYVNnGVIwWwqzc/jDWsT7D/B50Io3O1vtnHMu2PUeOWiLXcdUhLaFVvNSEKMe0xaDGJiLVClmIapw11fhuJ9z+eQS/xmpKr53quMwkdcstt8R3vvMdbV3fvn1r1qGNFsodG64SlgSqkGQIbZ1m0QoYqUDwXbYLvrN/VuixpYiQA7ktdtAaQwKsU6M2d3TpIT6+dTN1SzQbMQMhEV2tWxwjgyCh76CILKltkZhVyAESqX2i3TP8b+bAC4AqPaUGYtG+ys/coq/io73wuk2kmkgiSd5QZVuOHM1BruPSwXjZCEncFFnTQwD0xiFZJSEgmFVHi/lsqRU1DZJOYfbHbM+vWa4S8r/tJW1BO9VxmUnq7bff3hr92DTAXqBaTCmzUsltmjULiFg2tZc2+8otq/H90I9pkuDY85hkVi0xlquWuD/ypIJ0sIZXmG24hVzoFkljwMJJq82Kb7OmgkSYqGcjqUZ34wv4i/C/1m/WR9tBWVttm2fcnyS006SCHG2IXMdVh7IYhs9xpBC+dT9oL8FMt1NYmGA1pNUzmunTJ85V1U5S6AKzqFbtQjvVcc1KdatUKnjqqafw29/+FqtWrQIA/Oc//8Hq1atr2rmNBRFLjvyuFR2HXsdUEQWKIYqBcFpIRjXSGXWp8v8Us5100gpE6q6q6zGuN/OUqIhachMtu+0VcWEVABs8RBOprL+92l8u8SQyEpsKQCvSbyx63JN5vHCdLY7aHEjFxdRq/Y+7NwDi4qGryVsuczlqjVzeqkNz9XNipllB2WKADFIYl0mvTtay5P14OPpJq/JBaygA6ftZRu9JsantVcdltqR++OGHOPjgg7F48WI0NjbiwAMPROfOnTF16lSsX79+ky5BZQXLugZ8skdqfWjVkvLh11IVmiWVv6wjli2E/wU7XRpLauSFL/8bL38bAeZuVf044XX67gXS1qeGQaxs/c8RQCYIVXPXGLIWZy1VYSTqt2Y1UiNklSAgwmD+GO0b5tAZZBX+8XkfI0QZ0P6bAyr/GARTxrIV82fniNueI0ctkeu46hBBUpDNBV4FtphUtc0JrI/CD3qNtHVENvd3KlOmuQ/vq4gS6CQCHqyTkQrCDHuwoZ3quMzjjh//+McYNmwYvvjiC3To0EGtP/roo/H000/XtHMbHVTcXPA9pmwQH9FErKIwrKl8BGS2TbMg+tK3HS+uT4IQIaK1GJHJcCPr0vLDbz4wrdTKekqR38kqJ9DXibhtqk3UmsoTocIsfn2BtT0si//rRowENhk0+weoa49UliCKJJRxJMpbLnM5WgG5jksJIYlY+F1TaIzERRLVeSxn1pta6zjVwFIbqZOaen9EFKMqQSVQNcO/veq4zJbU559/Hi+88EKkJur222+PTz75pGYd2yhQzR0LaVk1LEmynXph+59J247A6hVYXhGMHPXDW2EjnLaMfrld8D7HvOiFcV2x116LGMHNNHYmM5oRRhESVgKYJT+03AcWAZJW1vC7317KSUhWZX5/ktDxOqngn+V+PFaWE2YkkGuDWLdocNRO47VytCFyHVcdxm0QwlAzRtypiNnG28TBr51qsapKVCvkbyOfDuymPCe+IxrRNkk3YCGocaP3mAMnbd8MkZmkep4H13Uj6z/++GN07ty5Jp3aKGBJaFGElFkcSf5XpZyE74rgVidAexnLfeRnRSjDj9nc/ewlb3Pt8/Or7Z4ktmQhE+H1Ru4FkI5c5Zmv2RBYEAkIXf+eP7gRjFhy974mY8bAJDikHg4gBczI9A8c/takqbB/4THjiKaSLbY+SkQtkxVwyOvmSVNpBkbtNPM1Rxsi13FVIRDMS6/FXfp/zKIhArKd9IPD/iIU7E0Z8DaRQBoV+UyjR2KspLHWU+mvTwGeRBValSm9u7+d6rjM7v4DDzwQ06dPV9+FEFi9ejUmTZqEQw89tJZ9aztwEhYTk2laHnV3P3sg4yxHAHu5k/VlbyMDtjbmi9/cFpIEk3waVi6j79p1Z7T6Jbolsh1qs4eWmJZF0VhkRJcdof4L9llt94T6rk91aluYSUCTr+i6OEupds02WbfJWErLfTV5y2UuR62Ry1tKiIR8fsO1H9cmNt7TBgeKBVISec0IX9WFZto0bn8yCDqAsN88BCIF2quOy0xSr7vuOsybNw9f/epXsX79eowZMwb9+/fHJ598gquvvro1+rhBkRT3FjSIfua7aC/okCDa4kVtZNIkoqZlNGo9JSsZ0EJ+TOIQ22fLtcXehmr3qcqSw0dSnKXl948MVGAoJ4t8CfO+M7Kqx5eK2EWLTQXfhx9fKCuqTXHa+xG9fquyrTaRRDV5y2UuR62Ry1t1CP2jUB+q3CCbm9w4HgfJzP7mlJ9qBmz90mJnTRJtrgssqH43iS1JJ02xtBK++OILnHTSSejatSu6du2Kk046CV9++WXiPg8++CAOOugg9OzZE0IILFq0qFnnzuzu79OnDxYtWoT77rsPCxYsgOd5GDduHE488UQtkWqzhIoDJN/q4wioEADmmtWy+4FEgZIvdf/IRnwr9DZhP4L1GglOOI9JXDm5ZVULgOB7FjdrDPJ5rTOCxftyq3e4HdpvzcNIwn1MIsnakm/1JC7DQUyrL3Ui+ec2408hrah6v8K+cF9eAmGGMYDj1v4M8tde57XO0XbIdVx1SMOjjLvUQooEQJKYBezVVlfUr0VKCZZWHihXpTNOYL7kIQDm/iF71C/CgjSlqJKIdqrpUGXbNtRxY8aMwccff4wnnngCAPCDH/wAJ510Eh599NHYfdasWYO9994b3/3ud3H66ac3+9yZSeqzzz6LESNG4NRTT8Wpp56q1lcqFTz77LPYd999m92ZjQ1EAWWs8sI0k6eEB1ABIUlA+B+ATmCD50M+JnJGDXU8/vxwcgroL332PWK9gt4uOh98eDzLTVDXXtV6qu1nezrZthzWwYCKSwWUpVF4loELI308TpQPRMysfLVEZCpInUoRkxqf1a8v1kGT0f80LirBB01JaKdJBTnaELmOSwVOxHxrYUwBfD6ulTzS0i6pTqq/HyOhkpjGTQwiS0+ZJatMoio/W35y2/doshRb1PdgQK4sqFUUYhvpuL///e944okn8NJLL2HPPfcEAPz+97/H8OHD8c4772CXXXax7nfSSScBAP7973+36PyZ3f377bcfPv/888j6FStWYL/99mtRZzYJ8OBlCj9r1kzw/8QIBUUtSTYrE2RbMl78ZCWokfMqAkBsu0FETZLAH9BqAdppUI3I5IiHJZktYi0HjN+arxNq4COTrcLse6G1CZd05DO66MeP/Z1NeQXbLuWTy6r0VnAkxUWn6WuOHLVELm/pYRuRSuuoQd54VrxcJyHjQH3rqrC2UWhOPGq1CgASNutqnNXU0g1eeio1Uuq4lStXaktjY2OGk0Qxf/58dO3aVRFUANhrr73QtWtXvPjiiy06dhpkJqlE/kjIxPLly9GpU6eadGqjQmzJJt7GaMsJqbZdbouSjjh3aFgzkyLHMNtb41bBjxUSV0UMeP8i10XRzykTqKRrIm7JYUASM8Oq6m+Dtk4L2WDbrVZzc50mF3LIjxQLbxskYkGXQ2YcUNuS4rDNa0uFuOexirzlMpej1sjlLQUYGVNZ/kH8pQnbkx2pl5p4LqHiUklz1Vs+Z7oGYz8L+a2W1BWq0FAhqksToTU1qXtpdVzfvn1V7GjXrl0xZcqUrFesYenSpdh6660j67feemssXbq0RcdOg9Tu/mOOOQYAIITA2LFjUV9fr7a5rou//e1vGDFiRO172FZIkWnsx58SEMT2+W0Quv/Nl3JADNUDFLzYKeLyV5sjsL7woX/mJDlCXMHIDT8JJ8K1ACcnlm05AsSFklhjUpl0sN+d2Hc+YIm6+0XwOwexqcrtH3xI6+5n57FZYTVZBGJlQRFojw2gbNcet87oX2LoQC5zOWqNXMelg+bu5+vZAn295u63WSc5HADRqphRYinf6daY1OA4HkISGiGniGb0m/2zhQLEWFP9U2QQlJQ67qOPPkKXLl3Uas7VOCZPnozLLrss8ZSvvPJK0E8LMY8xWNYaqUlq165dAfgd69y5s5YkVVdXh7322qtFwbEbNbSkFv8zMcIgSWkkWUqRAOO/fJkj2pbvYv35Y0hphBxU+a8nunDSalpuY0hUNeQ1BLPDLHdGCGYz8wXEZnk3l5C0BrFWGjk1iCvYfz7QssEgnRo55duD9XGhCaHFXz5P5rHNe0Atr8uLKtty5GgOch1XFaG10H+G1cQ1fCPA6qRadoaF7EWIa0gs/bqpSPcbmNOh2mJRLUiMqY0l16RtN2N1+X8rUuq4Ll26aCQ1Dj/84Q9x/PHHJ7bp378//va3v+HTTz+NbPvvf/+LXr16VT1PS5GapN5+++0A/E6ff/75m6drPyuC6VAJzHoK+C9iD4Bgxf/lVBtCEl0RWk1Jf2ilnNrENSLD6qWPCAEIyUxIsIWnH1gjCyld+WkSqJKSYrIMHtsdYpLY+EAolDmogvyRZCno7cJtzJqqrKcJAqf6xd8Y0OTOtO6bFn5tMKSRagrP6VH0/Fmy+xPkTW7PkaOWyHVcOui5R4yoqZXhf57dz2NTrZxRQHO9kzDuu7SEcktpBstfGP/K1B/7TDxYUuj7hOtJr1hgbo4JfbCh1jquZ8+e6NmzZ9V2w4cPx4oVK/Dyyy9jjz32AAD89a9/xYoVKzaI9zxzTOqFF16omXg//PBDTJ8+HXPmzKlpx9oSioSlTdzw2HbDlW663CPWMNZOe4EjZl/o7eKsazo5iLFYyevxjPW2601r0cqRGpzsC8u9jczOZP39KVZupGU+Xl7Y20AR2JgF4bltBfwFovJplU0LIuEnuRUqR47NAvrc9EkNw4+RMlRcTRnqyF9vrOBk1JY8JQTICReNzBodpZjPvK+psvtToGqd1DbCwIEDcfDBB+P000/HSy+9hJdeegmnn346Dj/8cC2zf9ddd8VDDz2kvn/++edYtGgR3n77bQDAO++8g0WLFmWOY81MUo866ijceeedAIAvv/wSe+yxB6699locddRRuPnmm7MebuOHtDRyV2ywcCul1R3K1zMyYbd2WohqlUXbL0CkgoAlqz/S16B/Quurcd0ZkScVtAC2+2PIkzkIibSJLNwFrxNMf58q2jFG9qxVAuL2Zf0OF9KvIfEexAtOnjiVY0Mjl7fs4ElCUgmQzboafA/H0frG2DJQNlJpIZ/VUHWmKpuas7n4zW08moC5+NP0rC113N13343Bgwdj9OjRGD16NHbbbTf84Q9/0Nq88847WLFihfr+yCOPYMiQITjssMMAAMcffzyGDBmCW265JdO5M9dJfe2113DdddcBAB544AH07t0bCxcuxB//+Edceuml+N///d+sh9z0YYkZ9C2PwncJBJYmgi+X6oHi69n/YFMIoa+wWWBNS5VGYORnLySxumW2ChFtrgW1mbu1K3geG0iQT84KgKqXahA8/z+FRbHZNiVfxiBJRppwgklsu38AJP9e6jxCO47c1TpwssmkOUjSjm1sYAPCVDV6c3nLsaGRy1wyMriz/faA5vaX7n62TVlWTRObIwCXGCGlKDENrKjyM4hAjggJnrSsAqEJj63z+yX3Dz4nWE2txDWmLT90LNpI3rp374677rorsY2po8eOHYuxY8e2+NyZLalr165F586dAQBz5szBMcccA8dxsNdee+HDDz9scYc2SkQSWkivlQrLCxbheqvFS1qRLIRTtjUtZLb4P31/iiE1xrnkNTFLltrGix63JNufqiw5YhHO/sXWsXq8VpmJkR+dNEatqSJiCbUvQpadiqwP/5sE1RbiohAjC82uMJHiGnLkqClyeUsNLfaShQBw4hkp4wRELJAmkqyXkt0QJ55hh/T/0Q5rx+B9inw211m3xfADFZWQchDeDmUuM0n9yle+gocffhgfffQRnnzySYwePRoAsGzZslQZZSY++eQTfP/730ePHj3QsWNHfP3rX8eCBQvUdiLC5MmT0adPH3To0AGjRo3CW2+9pR2jsbER55xzDnr27IlOnTrhyCOPxMcff5y5L6lgqR2qkUkZl2oKDkGt11/oej1V84UeF48aJSTRY8MgwVo/GKwW1TiykOBy1Y7ZCm6Jm266CQMGDEBDQwOGDh2K5557LtV+L7zwAorFIr7+9a8378QbAub9ZtPVRmKRYciJQRrD9iLm9w9JKyeqkojaFv08Qj9+RM6Nz1I+wWQVUZmWSCSqcYPBVnKFbdYyl6NFyOUtHeyJUzHPeBwpZUTWbp1klk5Ad/WzNhph5RUBzNjUBMSFIKh+8usw11kgV1cjqu01pCkzSb300ktx/vnno3///thjjz0wfPhwAL5VdciQIZmO9cUXX2DvvfdGqVTC448/jrfffhvXXnstttxyS9Vm6tSpmDZtGm644Qa88sor6N27Nw488ECsWrVKtZkwYQIeeugh3HfffXj++eexevVqHH744XBdW/G0lDDJWIKlFADAXOmRbSmsSiZRrUpCTLLCjmU9H+8PGFnwotus1+1lewKisYcWwp0Bs2bNwoQJE3DJJZdg4cKF2GeffXDIIYdg8eLFifutWLECJ598Mvbff//sJ20DmOXAws+8DTSZ4SEcqm3swEbo+6vP6SyqcbIF49j2a4t+1hQrtxxntKhWk7dc5nLUGrm8VUfIAy03RBBsVlQyiZ4w1oNtZ4gQUxsJjXas6jWQnCQAUIlYkcz/uMNUP3zQDdL+W9u0go7bFJCZpB577LFYvHgxXn31VTz55JNq/f77769iVdPi6quvRt++fXH77bdjjz32QP/+/bH//vtjxx13BOBbUadPn45LLrkExxxzDAYNGoQ77rgDa9euxT333APAf0BnzJiBa6+9FgcccACGDBmCu+66C2+88QaeeuqprJengzydnBmENM4trhFD2dYCbk2NkAokCCFV2d/okyo9BUTb8bayPqpnrOf3Iy2qkZ2MmDZtGsaNG4fx48dj4MCBmD59Ovr27Vs1We+MM87AmDFj1GBqo4KqrmDIkUlOeQkx4/5Ff0u+H0JSifBznLUz3SK0/QXrQ4SExpJZvQ+JyjUtWU3T94zYLGUuR+2Qy1sqmATMNqOov4FCNcHIn1kCSiO1fHYpoPpUqOYMVGydJLJxVtWQBNsPzR1M0fMmdysVWkHHbQrITFIBoHfv3hgyZAhmzZqFNWvWAAD22GMP7LrrrpmO88gjj2DYsGH47ne/i6233hpDhgzB73//e7X9gw8+wNKlS1VIAeDPnjBy5Eg1Z+yCBQtQLpe1Nn369MGgQYNi55VtbGyMzG+biLiyTGYb88VrfTmT9uK2Ec04K6rNmqoRVL4N9vNHtsWRALP8VEakcUuknWO4qakJCxYs0H5jABg9enTi3MG333473nvvPUyaNClz/2uJRHlLGMBErPIGYa0qH4iRJW19Wguq/2aIhBIYcmzKonUdh+pP8MEmd2nq8qZ0heUyl6NWyOUtRKy8VTPvcUUlEP2s2gFRiysnp4BmcXVYG05C1fHsRDV1EX+bO59t1+q9xhxLVjpIFY+K9Dpuc0OzSKrEGWecYZ2JIC3ef/993Hzzzdhpp53w5JNP4swzz8SPfvQjVeJK1tMyZzXo1auX2rZ06VLU1dWhW7dusW1MTJkyRZvbtm/fvtk7z1+qpowpyxjUf80laxBL3sYkGtozHHnxk7G/3MYz+PU2Wv/A1pvWvJaiGulB+jmGP/vsM7iumygHJv75z3/ioosuwt13341iMXMRi5oilbxVS7zTCCvsAxPrICQkkwKWddp3EbtEZQ/GbxpDWrVrDPuvZNN2D2z3wqxBHLl/KRbkMpejhsjlTSFJ3mLrf9pIqWE1tVlTKQWZDE5sXyeEb3GVS1qXvy22NMl6arbV1jfjPZtSx21uaJFkpyoLkwDP8zBs2DBcddVVAIAhQ4bgrbfews0334yTTz5ZtTPnh00zZ2xSm4svvhjnnXee+r5y5crqStxwnxOEKhfkrwNCa6qcG10E7nMBKsjjAP6sU6Fgq88ECJD/QATt1LHB9odOPiOWM9YOgB5yoAgswYyhtcanprG02pD00ATr084xLJFWDlzXxZgxY3DZZZdh5513Tu7nBkCz5A2ALG3m32uh5riP/CSMGKryUyJKJImt92evIn/GKsjvSX0J/ytCHKxKjIsyFajtHDYZy6pbqinpXOZyolpr5DpOIU7eomGgxg0zrJBCrmOLWm+0l/v4bQSEnBI1cg6LBZXDEerdZy/uH3MsEzYSy/uZgFTToqbUcZsb2nT4tc022+CrX/2qtm7gwIH44x//CMAPKwB8a+k222yj2ixbtkyNOHv37o2mpiZ88cUXmjV12bJlsVN21dfXxysLj/w41ILFyMzjUAMIipcNjVAY5CEkpSEfDUkrBbtEJdu0PkXi/eQ6fs7gc5z8R8gqYL1WhRRJVEnuB7k+7RzDPXv2RKFQiFgUuBxwrFq1Cq+++ioWLlyIH/7wh0GXPRARisUi5syZg//5n/+pet5aIVHeAN2CyBcgUupM+42JyR/p28x1ct+gNKAvb3wfGG0jfdTPa7XEgq/TLabRMJRAKRsl0Job/F/N3ZXLXI5aI9dxIZLkTbq1KYmpGQSPDG5oI67xpacE4AVvVpuv2LSeSh2UhoDCJ8S8RqsWdmBx/dcKaXXc5oYWufsff/xxbLvtts3ef++998Y777yjrXv33Xex/fbbAwAGDBiA3r17Y+7cuWp7U1MT5s2bpwjo0KFDUSqVtDZLlizBm2++WZt5ZROy3gV/0cqEI/7yVm1Da6bpkjdf6jrZoMgij2fbzwwlUAlTrC/aOXhNVH4dtntQ42zrLKirq8PQoUO13xgA5s6da/2Nu3TpgjfeeAOLFi1Sy5lnnolddtkFixYtwp577pmtA20M0zpu/d1h3+bvJ6zypddNZeewLeD7C70t2L78c2TgYwyIDGIarmc7ppxIopq85TKXo9bI5a06UhXyNy2QjKhqsZ1GmSnZViOsBpk0OhMSVHPhBf5jaqrGTX8aez2x3/V7knayg1rruE0FzbKkVioVPPPMM3jvvfew++67o76+Hv/5z3/QpUsXbLHFFqmPc+6552LEiBG46qqrcNxxx+Hll1/G7373O/zud78DAAghMGHCBFx11VXYaaedsNNOO+Gqq65Cx44dMWbMGABA165dMW7cOEycOBE9evRA9+7dcf7552Pw4ME44IADmnN5UVhj50T0s20/Ctyqgr3YlcuVIBC4KCi0qMpmceAvee0FbyRlhe1Js15VvcZaxKXaSArflhHnnXceTjrpJAwbNgzDhw/H7373OyxevBhnnnkmAN/d9Mknn+DOO++E4zgYNGiQtv/WW2+NhoaGyPo2BfmWj9gBN/vNlHwQgjAbobUTgawp66ghI2oXgm5NZceW50nucxCfqp07ek79GqLbbGEpJjJNyZskb1XOE4fNUuZy1A65jksFXsg/Yk2NIaZCUEgWhb5drjOtqeo9Grj+1Y8g3fnGe41kOB4v3M9mnqIgfEDfx+g3uw6tfUoraqbZuFpBx20KyExSP/zwQxx88MFYvHgxGhsbceCBB6Jz586YOnUq1q9fn2le1m9+85t46KGHcPHFF+Pyyy/HgAEDMH36dJx44omqzYUXXoh169bhrLPOwhdffIE999wTc+bMUbNeAcB1112HYrGI4447DuvWrcP++++PmTNnolAo2E6bDmaiRhJx88I3v3xhkwegoBOJiLufb2NEVcUTQm8Xsc5We9HbhNpjVllJXmPIgLDdg4yWrbhtWfG9730Py5cvx+WXX44lS5Zg0KBBmD17trK6L1mypGo9wY0aaTLYKRQczd3PiSAjgUoWWTvl5lfnDdob35P7Gp476tqPrg/7b5wzbV3UNOElCfKmnTsDNnuZy9Ei5DquOhI96ILU+w7Gf9Pdb7WWyv+OAHm+UUtTcA4Ctz/rjMz0V9ZRoeuemKQs0qyt5oXEX2MSbAQ16VCtoeM2BQjKmP307W9/G507d8aMGTPQo0cPvP7669hhhx0wb948jB8/Hv/85z9bq6+thpUrV6Jr164Y5RyDUrEBoq4EUSgApSJEqQQUCkCxABQKoIIDlIogxwEKAlQqgBwBKjiggvDXOcGiPsN/8Bw/gUrFtKjRoDDcGkHHbBJrsURxK6oWWuBKohms8wjCJf+/R4AbfHc9f13Z9dd5HlCuQLge4LpAxQVcF1QuA+UKyHVBTWWUK+vxjPcgVqxYoeKu5L386v9ehUJ9g/V+u43r8fbNP9X2a0+Q92j/HqeiWOoQyJgDKhWBuhKo6IBKBXh1RVBBwKsrwCsJUFHArXNABcArCHil4H8R8EqBfMnPBcAr+P/Jkf99lkoFKNnz5dBQAQnBVErGXISlTypBUhdf5wJOxf/slAmiAjguUGiiYBv5nysEp+yhUPYgyh6cJheiqQJRdiEafXlDpQKquIDnolJZh6e//IOSnTTyBuQyp3QcjkJRlNq6O5sMKlTGM/h/uY7LCHmPdrrrIpS2qFOEzPMclMsFeK4DzxXwygXAFUBZwGlyfD1RFoGOEHCaAl1SBgqNgd5oBAqNhEKZUFjv6w+n7P+XhhVR8fz3WsWDaKqExpWC47+7eaAjr3tecSHd/15DHajk+Pq3rgAqCnjF4L1eALyigFsngv/wP5cAtyHQv0XAbSD/cx2B6ghUIKDeRbHeRaHooq6ugqLjqfvTuKqCv58wNbO8AZuvzGW2pD7//PN44YUXUFdXp63ffvvt8cknn9SsYxs1DOuiP1uPb+UiDyG59ALTlemaRdA22MLd/WZilQ3x7n452qLovtwKSggeTIQxgjV296dJKsgRQLr0PfJd+bzKAhmyQ34Cgs2CSaydLZEJso1h3TQDDhJH5NxCSkC1WaYi7aHLrxXNkI/2mlSQo+2Q67jqkElTsa8zFTvELZ7+v9D1H6wzjDhmbCqc0GtkdCCwqpJuJVVufgJcYx0Qm7FDDizxrpY+NtPCGof2quMyk1TP86zTjX788ceaC35zQWLMYOKOCIW02ktZlasKmySeUyOmpK2LtDMJRHP4Z5A1mhmbqfthQ0MEA6HY26mIYEhgiRHDMBzAHwGp+FYWmxo5XsK5lKHf4n6KJG5FBkusHd+nFgo2l7ccGxq5zNUGjJBK3eQrBumWh/Zfc/kLAdIUimD/2XrprndYG8jjCqOagND3iYmBtSZPVfHZJ4VAVC3s3w7lLXN2/4EHHojp06er70IIrF69GpMmTcKhhx5ay75tPPC8MEbVltHPoWX9R1/kKtuezBc6hS57IP4FbyGopjVVuvfVOY1+RLL4VWUCXkFAXl/CU5EwTWp7zEJsEdLE+hryErFOkkUWGCKxoiaRNNdZFgH7PrZj26z8/j5hx8w461iLfpUpeavJWy5zOWqNXN6yweeT6W5MJEHKWOf/F4FVU25n8aSO0NexGFS5b+wsU+bUqnFWU7O/ceRT9a9lQtFedVxmS+p1112H/fbbD1/96lexfv16jBkzBv/85z/Rs2dP3Hvvva3Rx40PHun0XpI8h5RAaxn9QGjp4tshYuqkBrtYfCTVLFe8TJXN7R8p1G8jR1myqmOQu8JSIu5ee8E2R/8NhQdtYghuZVWW+AjxY+tkaEogW9KaCmO/qt4DksdCdGGwzorG+h4ez9gxo1y2V1dYjrZDruOqQ7r6HUHwZNJnQraZn5nvf40kS9nyNiSc8GUZTgpgvEATTZjwXf4GQdXKXrGEq1hwi6sZjtBCtFcdl5mk9unTB4sWLcK9996L1157DZ7nYdy4cTjxxBPRoUOH1ujjJgVBgdHHgf98BHGpAmF5IJNoKMIAgJRpLGEGIG5BtREMVgBeWVz59K1ezKirlkJuISzathxRYhbAH8AY8AjCEYqERi2QxmcKSaty+wv2OeSpKiE20e3PQ1eMkXtEliyk1RZHre5BkjykDTNJkjdU2ZYjR3OQ67hmQzBXvpXAMTIqNHIauvYjZDCIS4WLwH3vG5OUK59Ic/Urg1GwTbWLs7BGL8JqVU3ex746LNOaIDjtVMc1q05qhw4dcNppp+G0006rdX/aFqZLMdHVTYAnIJxgaklZo5K/zC0CqaZUJUBOgcoTpZRF1SyLYbysbYkoYT1Uw0ql9Vv/HLqOKbyuOGSwsCa5HzZXt0Sz4XmA44SDCc1Kb7QNfltb7KkZRqJKTwG6giMmT+GYyH4+sx/q+CJCOCOuJ4M4c5lMsvInlqOKQTV3Vy5zOWqNXMdVhzbdp6VqiIxB1Vca/wNUnR4VYJZYssxaJVh7m0uf7MTUQVA3NdzXFodaNT5VXRdZN1dDe9VxzSKpn3zyCV544QUsW7YMnlHD8Ec/+lFNOrZRgvzSTZRUflW9fIP6a8HLnJQpy28mPICcgKhKtz8jqgATeFsMHyeokgCQYfJXBFQKOCOiVYhApEaqeY3V4CHeMruZuiVqCfl7UvDZHwQZIx9OQhH+xnIQpBZhb6vCSbhXrMpPG4l1NYixeZy48BTrcYHmy0aSvLXkuDlyxCHXcakgk4G4yz8Crta4EdMkf4bl1I859cmlVvNUtRG+NdVjhfvjLKS8mL/cN4F0Jk57aiOs2qHDBKrUBf3bqY7LTFJvv/12nHnmmairq0OPHj2CmR18CCE2D5JKFGb1e/LtTtp2QBKCcF0k5tT2MFBoQZXfNXc/Iw7x7n4E54CVXFhLUPFtWjvSSx6x61OfWexq2iz/3MrQOtBKUEkYBDSOBCqXPiEgsqTvx9rGogop5Z/NBMK4fsVb/S3yGDfxRDu1MuRoO+Q6roVIcPNbt5vkNOKKCRZZxN8Rmr6IiyfVya2ItFWWU9vrPNiWlDiVSGYNJBHW9qrjMpPUSy+9FJdeeikuvvhiOE7m4gCbD+SoLHD7Q0tmMVysQTyhtIypdtKaKgkthXKeJG9Ra2pABljlAC1uUMaj2sgtvx7+v6WIISW83zkYmuniJknyWBKTLQzAtJoqskqxujXoV/x6HpMaTeBj+2sElqIEV4IT0Kz3I0neUGVbjhzNQa7jqkIgg6VQdxKFpNNcZJvgu7KmqvUiDKVTdVIp2dIYF+9kI7ZJcagxxDrNdKlV71M71XGZSeratWtx/PHHt2+CGgePwqlQPSjiGpJWUkKvsvu5218ViWPuWANWgkohQbVlTGuyzx/UGmTxx0HNahWzLUcC2IBBEPmh0px8BjLDwYkpse/aoAVsnTTbc/dYSgXISaYZk2paVGMTpiTUAKoFBBXJ8ia358hRS+Q6Lj2E8D1A9o3md7Ks9JFktZQZ+L7Rx9LEUh81egxuQY3pX1y/I30xCW+0nQyFkATVrH6l7d5OdVxmpjlu3Djcf//9rdGXTQM8njP4bK07CgSxhMF6jxFGmyxxgmlYqLRkFG07JRwLxnljkqN4/82Y1RZYVW19j1xHDsTW/0xz74ns8sQJpHm/bev5MShmCaCSpmBpr7XRLa2Rc8dUmIi4/jWZbH5d3lzmctQaubxlg9VSGEfklJU0/B+XrBTJ8Bfmdj0OtWoZKSDKjGQYQGS90Vd+DapNbYShveq4zJbUKVOm4PDDD8cTTzyBwYMHo1TS54GeNm1azTq30YFZQjWrKUPoumejweCjZh0lhElT0jIWrPM3xz9IETLLragmWWDt1DXwY5io1Wgsjoyb/WnPMAcNCQOD0KIq1G+tKkoAmqU1NiYVhjUVTCZTvD/884hIjKnmvjdJq2rTyj96kryhyrYcOZqDXMdVhSNII6f652bcJpMQ6icDXObmr8GPEJl61bY+rn1NemAcrB3quMwk9aqrrsKTTz6JXXbZBQAiiVObLaq9ZD1AOIaceFAPFXf5C4QlLEy3f0ho7YlXiQRVtQn7qxFVwxAlLOsiCJLIsiIvdF0jqCoLSYOW4INhvVTuf22QwrYHLn8/1CRhJG7TyJaRe2R/Lnta34KHQVWeIOvxsqC9FrrO0XbIdVx6BPwxGTZLpOD1S/XmysrqxNzvGD4Sm9QM6BZUPmuVeV7oajFa0sokuNGLN138JqGPtG+nOi4zSZ02bRpuu+02jB07thW6s5EhcC+qTH8bPAS2dmZhZbVPw1JCIrS+ykQXIHzwCFaiau9XsKsXflbrGUGV8X7c1a+sXmaSisf2i7sXVaam5EhyP2yubomaQllV2SBQWTCD+C5GQtUgCIEStswGJcNQOXkUgWwKLkgxZoKIZZ5ZVM0kKn3mM35dWa8/Haq5u3KZy1Fr5DquFVEt3jNuvRxsy3JSjlGaisMsOaWdP53BLVIeK3KcuPXNMPy0Ux2XmaTW19dj7733bo2+bJwglgEFhC9P20uUhwPI74aEhuSVkQqWNKUR1QRwgqoX8Q/PE70WS39tbVoYj+ofB/HXsJk+TC1CtcShaveMW01ZW+6K59PuchmURNWEXYag/7a2z0wWrfKoBk6W66oie7FW/SR5Q5VtOXI0B7mOq4rUmf0BYgv2m9ZL/r0lDtwEokq2mqrq/LbMLHsf9f1aIBjtVMdlTpz68Y9/jOuvv741+rLxIymzjlkqtUQq5o4XgQWzWsJINTcS32YbIfLzKAKrpkqlsC8w+mqiJfGpRCob0VxqVuaqHcA6eiYmA0QRAqjaWPaztTPPFTmnQT5l28ix486X1CcgmKY3Xi5ShZskyFsuczlaBbmOSwVrxnozMn2S6o0m1UBNjbi2cTGwRpu4/1nqpCaineq4zJbUl19+GX/+85/x2GOP4Wtf+1okcerBBx+sWefaBBlc2oB0rcIq4FqiVOQ8hpNVxqFK6RYJMSacYMrv8plPENQosWDEOKuAV7lPuSusmUgMuZDbfRmxuvj5epNccuupPJSUJfM8CeAufpPUmu5/KxmWXgCPsstdQp/aoyssR9sh13Hpoc+wxDek2TnryTK2TwlFeM3+x50v43ohCE6C8m2vOi4zSd1yyy1xzDHHtEZfNm7I+dUBf2pUB5Z51sl/Aj3Sho98qkoBgFhlAE40tIQpLnCWREUrQVV91QumR4hAnIVUlqvi241pbyPf42CzrPFtOZIhp8AL5EsbwACaRZP/vKELP2wfiVsV+jEinxPWRVz0pnXVcsxIPHTkPDUQiCR5Q5VtOXI0B7mOaxVwl7+13mkcgilQZYZW3L6ZrKsxvua4kljaf7BwBIGAZcacJg3DbKc6rlnTorYLeB5QCCSUk1FeLkglSyF4A4twvTRlMVagT5sKENgxlEksfKmTuQ0G4YyQAt31Gynsz0tU8evgvNMsiySvPyOEC4iYB1y4mQ+3WSOSmOeRFgYd3cH4H3zWLKhgBJaTUuOzRlyzjtJjSC4vhRYXkxo5l3RXEbGKBumRJG9ye44ctUSu46rDjElV3p7YJCOupOLa6KvkDFMtgTW5ytKNuEx/W+WBJDe/H+6a67g0yExS2zVspYBMslowrKPBeuHoU5/61i6fqKqSVIb1tFp2v27BIp0QcCuWrfSU7K92bbbrtSCFNTV3haVEynhLQEDVRtW2mW31/5oVVYSyEU2c0hH7G1ksp9xqzy37UZe/7t6PtaxySFnzqEpMePt0heVoO+Q6LhtiZ5yqBWKIa83qM5vWUb4uyf3PrafBtsQyU0nb2qmOS0VSv/GNb+Dpp59Gt27dMGTIkMR6qK+99lrNOtdm8DygEJiyiCIPgIItIzsgrar+KTGh5hw3EhJgjLyYZTWyjiEimFppKaMd8TABi8U0MR4y46gvnzKwNuAJeGwULZPfpIxxt79pUYX8zEmjxaJqP7/9uz35z9LWJKqWts3IoYieu51OGZij7ZDruDZAa99WrTqPuS3ms2xuktO4fWPgCEKSMbS96rhUJPWoo45CfX09AODb3/52a/Zn40Kc21W6JZXr3ogXtLX3RGBllbZTgDyCcIRy+5vxqf6+tuMFTTQLFbRYVMHJTRWCaQ0LsCHLQ5BkJds8n6WawxqHqmQmbh/DOmpYPrUyVAi3Jcob9G3cQmomStlKS0WTqojtzxrKONzmoJpVNpe5HLVGruOaDWI6xLo9TSyqxcWurJUt6l26cxIrQ2U1Egd90SyvCXGpVdFOdVwqkjpp0iScdtpp+PWvf41Jkya1dp82TijSR/ZkKTBSIV3ssnA/325aoXmBfzYJQDWB4wRVHSfSRiefwoj3i5BTs1+29SmRu8KaCfbbpLlNvgXVN4fyBD3/WEa7QK6sVSdiLKa280Vjodl/g8BaY1KBZAt+gkzHob26wnK0HXIdlx7S1Z/V5V/1PjZ3+lPH+Bw3OE4xk5U+8xSs8ahkCEucWz9390eRuk7qHXfcgXXr1rVmXzY9mFYg/h8hCZQxo/4+UIklkRc4a5+k/Gztw/OEx5dtrMey9LeWddaS6rltrm6JVgOXH22d8d3cDlNe9M9ye4RkGseSxzBd9LHu/DjCS4hOQsHqvWrnjK1AYX+bVJO3XOZy1Bq5vGVDFoIaSbRsBrh3p9awTiJg+U4qGSxYJSIcNzXaq45LnTjVnPnbNzvwJCnbevZfJbj4Ri4fcvIqtk4Qc/sLhC/rwKoa2w+E+0cmCJCfveg6nTBXsZaq7c3wwVrITqR/OXSkfcZsCXxAhGRqllW+S/CZJ1PxM6eOTzXbMzIbJbHVr41P35sZSfKGKtty5GgOch3XLEQe8ZT3KpKIWWPETp+aBtWIp43UZkU71XGZsvuTEqY2a5CRtUL+qIUKInTXB9DiCJkrX2bwS5e/ascSqRRRDc4RS4jVuRBJlAqttxYrrsf3NSSa10itwYAkd4WlQBz5j7n/cdn9cUlMxMkp6WRUCythA6ZoX+L6XsWdb/RF/SfW57QvnRQWgvbqCsvRdsh1XHpYH+FqltUaWFMzQxqbYqBc+XGxqCwuNrIO0IQmK51qrzou07SoO++8M7p37564tFfEjcBscZ9mrVMlXGoqU9beXMCE1Qu/6/GHUQtpqv7VEi4lL83ATTfdhAEDBqChoQFDhw7Fc889F9v2wQcfxIEHHoitttoKXbp0wfDhw/Hkk08292raDil/H04EI4mlcZYLwwKqbU8YtccdT4WZMCKqDZZsqGbNT4tq8pbLXI5aI5e3lkML6PT/6boowaPYyqj2bjRLUUXiUNm2yLGbY+9rJR23sSMTSb3ssstw3XXXJS5ZUKlU8LOf/QwDBgxAhw4dsMMOO+Dyyy+Hx+LOiAiTJ09Gnz590KFDB4waNQpvvfWWdpzGxkacc8456NmzJzp16oQjjzwSH3/8caa+xMIcAsaVneL/g4x6/WFj2wDN6gnoRFV+Ny1VGgHhBFUdg6KufvMctjjANOWoMsa7qERG25LpSD5mzZqFCRMm4JJLLsHChQuxzz774JBDDsHixYut7Z999lkceOCBmD17NhYsWID99tsPRxxxBBYuXNiMs7cumuWhIESmzTWJJh+8mFn4VgKaQEwj5zCJbNJ+RhvTA6ANqpKqSyT1CwnylstcjlZAruPSg0jAS7Kcxg2kDVgJq4A/AyRrk9n4kokJRUFxllWAWVGNfSxdTJKb1tBxmwIyufuPP/54bL311jU7+dVXX41bbrkFd9xxB772ta/h1VdfxamnnoquXbvixz/+MQBg6tSpmDZtGmbOnImdd94ZV1xxBQ488EC888476Ny5MwBgwoQJePTRR3HfffehR48emDhxIg4//HAsWLAAhULS1D3pEZkVKL6hPkzygu8sBlDFpgKa2z/cTpEaqhpMgmo+lB4i2xPJduLlNHN0lkQ2mnHMadOmYdy4cRg/fjwAYPr06XjyySdx8803Y8qUKZH206dP175fddVV+H//7//h0UcfxZAhQzKfv60RcdUnNa6i8K2xqFleCnEnZ8Q4LrFKH5jFJPU1B9XIbS5zOWqNXMc1C5ExuTa4rk5kW+ry1kLyqrj3zf4JAiJlpWB8FsZiO2Rz9F4r6LhNAanHD60Rjzp//nwcddRROOyww9C/f38ce+yxGD16NF599VUAPkGaPn06LrnkEhxzzDEYNGgQ7rjjDqxduxb33HMPAGDFihWYMWMGrr32WhxwwAEYMmQI7rrrLrzxxht46qmnmt852w8uLbxcWOJc61WUl2b1BKIPoJxhx7bAIKDsGDZXv3ZuMznFdh3K6muJmUzrfvaSlyxoamrCggULMHr0aG396NGj8eKLL6Y6hud5WLVq1aYVkhITHsKhudhh/DcHL0nyZiA2/slCgM1wE9uxVF+NdQpxMlEjectlLketkctbOiQ54RIf7wwD5Kr3O+lESdxGvRdt+wWbqiVF2YhsM1BrHbepIDVJbY3s/m9961t4+umn8e677wIAXn/9dTz//PM49NBDAQAffPABli5dqj249fX1GDlypHpwFyxYgHK5rLXp06cPBg0aFPtwNzY2YuXKldpSE5hCEkdItTacWCJon5I88Je/RkB0YhLr+lBlqGr/28pM7bgFQOQ3aGxstB7rs88+g+u66NWrl7a+V69eWLp0aar+XHvttVizZg2OO+64ll1YM5BF3lQZEesgibXL8pOZJDYiP/pxY+NTDfm0xr5q1lRjql51PDkIktfVcvmrJm+5zNVIx+VQyOUtRE3kzWJ44Tqlms6zbue6JcXENqmQ4RChxZUN0Jt52rQ6bnNDapLqeV5NXf0A8JOf/AQnnHACdt11V5RKJQwZMgQTJkzACSecAADq4Ux6cJcuXYq6ujp069Ytto2JKVOmoGvXrmrp27evtZ0i5nFJR/IB0DLs9bZmXCqPCzVdn34bfV9zCY9l7Cc/c1d/kuXKck0i7jqCz5kGKl6VBUDfvn2138Hm0tL6ZxZRJkpl4b/33nsxefJkzJo1q+YynAZp5S0zLFZNwD6Qkesjn+MGRhbraDIxTWEusVpGkmUuNarJWy5zG7wPmz1yeVOoJm+2GqnqESeRifhFdJNND9aKkJrHNWGxkpoVAGqGlDpuc0OmmNRaY9asWbjrrrtwzz334Gtf+xoWLVqECRMmoE+fPjjllFNUu+Y8uEltLr74Ypx33nnq+8qVK9MrcVPwZQyq+YL1BOAE2zyCcBCdbQowYlKDGankoWzdJ31fuS4xe59b58yHtwoRby7SzGv90UcfoUuXLmq9nHrXRM+ePVEoFCKDjmXLlkUGMCZmzZqFcePG4f7778cBBxyQ5RJqhtTyFjcNr62dY5dtHm8ViWPlpahk+SkE//l3to8VhmXVtj4uJrVqeEAziWraea1zmctRK+Q6LkSt5C0xsROwGmo02H6PtHrEAeBWOZa1U0hHSFsYgJ9Wx21uaFOSesEFF+Ciiy7C8ccfDwAYPHgwPvzwQ0yZMgWnnHIKevfuDcC3lm6zzTZqP/7g9u7dG01NTfjiiy80a+qyZcswYsQI63nr6+tjlUUs+HSonjRt6pIZmWsdCEksEDxUQc1USCKLcBsnqqq9HTbLq1ZVICkEIGhrJbac1MprbQ5SxOV26dJFU+BxqKurw9ChQzF37lwcffTRav3cuXNx1FFHxe5377334rTTTsO9996Lww47LFv/a4hq8kZEEJ4HOI5ckf7gzMoet5ddLgEtWS/G4qq1T+hDEqqVn4pk4zZnwJQkb+yYuczlqBlyHadQTd6EUjQG0sxCZQx4o97JBOWXBTGWyKScgGjjyM7BlKgt6Zg8dzodt7mhhYUXWoa1a9fCcfQuFAoFVYJqwIAB6N27N+bOnau2NzU1Yd68eYqADh06FKVSSWuzZMkSvPnmm7EktdmwWVHN9crdHq4zS+5o8KKEMym+RNvG2sfPPcwyqJOIqXkdtu9qdfWHIbFURjOepfPOOw+33norbrvtNvz973/Hueeei8WLF+PMM88E4I/kTz75ZNX+3nvvxcknn4xrr70We+21F5YuXYqlS5dixYoV2U/eljDKhfHEOPO3jJSHgqnQ7feex43GxqNCXx9rKTXaaCEGNhmtkV6tJm+5zOWoNXJ5yw7r3PQR3RGtnRr33SSs/jpSRppmGy/ZAHpjQWvouE0BbWpJPeKII3DllVeiX79++NrXvoaFCxdi2rRpOO200wD4bv4JEybgqquuwk477YSddtoJV111FTp27IgxY8YAALp27Ypx48Zh4sSJ6NGjB7p3747zzz8fgwcPbrbrQys3RaxeVBK4pVVaT41dQ4sWs6YKEW4zXP2xcX6a1Uu3QHEravz+nFSnlOyMU6MKl+wKKdiWFd/73vewfPlyXH755ViyZAkGDRqE2bNnY/vttwfgD0x4PcHf/va3qFQqOPvss3H22Wer9aeccgpmzpyZ+fxtCuneJ0Kzh+R81+CzoPCQVd1oKX6yWGXJZFEO2Kyy2YKYqiR5k9uzol3LXI6qyHVcjZFEQPl2U8+Y+iVy3AQjjtyeEbUihIm1Y81ztoKO2xTQpiT1+uuvx89//nOcddZZWLZsGfr06YMzzjgDl156qWpz4YUXYt26dTjrrLPwxRdfYM8998ScOXNUjVQAuO6661AsFnHcccdh3bp12H///TFz5sya1UjVwN2ygOHODymodbsNKn7V4upPG5OaECQePsim1Y30dZFwgBZGYadwhWXFWWedhbPOOsu6zVTKzzzzTLPOsSlAizX1oBWytiYUMEup1Ilx3rfEhAR2fv45db3TuJdQLdxUreQKy2UuRyxyHZcJjiCdlDVzMKzaySVALEG1wZjpXGvPCK/Ss9L4YwubChpFZpyqdeJUO3X3tylJ7dy5M6ZPnx4pSswhhMDkyZMxefLk2DYNDQ24/vrrcf3119e+k3EwyGmEiHLCSoHl1COgIK2lwTq5W/DQSOKpWVUN2Ar3++uhW1GNckax9VtbGg9o62OKpIIcNUScldVcHUdizUSqGOjWi6R2ZA8VsLUDUsldUphJe00qyNF2yHVcC0DMGGOBljRvWE0jg10PEb0WiXMH92Tyttl+J39ALuQrPKEh+1+jTP/2quPalKRuspCEIGmUVrB8hmEthRytURge4NjbyXWR8wT9qWrJ8mI+c8QRhuYIfytYGdoFqg0YuFXU3Jx0WzlZtX2OIaiZ3FoW60akbyokJeYYrZGoJ7fnyFFL5DouNYQgaxmqTMfQrKYUkle5eGTXK1reh8WgFLSxflaDbWoF06jRhWrHb6c6rk0TpzYZpBm9qGDtGEullkjFBJ+3AbR6Z7GFenlNNPMY5giyWp+klbXWozBi/TSXzfNZqi0iSWzpd40NordZUflnRoATA/HNfataS+V/85pqKAhJ8pbLXI7WQK7jaoMkPRMZNJNOTKvd52qeQ+PYcUaCSGmsJANBXJxyDAeVr16nmkXg/7d39jFWVPf/f89d9kGeLk91H+ICq1IeLGpZCi6R1qQFpDXSlipIfigRTW3SKJTaItAubZOKpKHUCJJQSmxKikrdxha7LanAl7psBYRKXEOxrEXjrhSKu1oCe+/M5/fH3Jl7zsyZuTN35z4s9/NKbu69M2fOOXfuZ86853PO+ZwCtnEXL17E0qVL7Ti4S5cuxUcffeSZPpFI4Pvf/z6mTp2KIUOGoK6uDvfffz8++OCD0GWzSA0KGYFmtafTu8Whcpa/6AX16MaXcD7lWfkqvJ/ugecZnsRcyQlhJ0xZmF0ThseLW3AlGcYVewnPTBPs3GNI3Z8zemFVjbKX6PUoW4khPCj1Q7T62xvbHBM93MZlxiOcswuN5N5FFx5tTdqJI46PT7UpinuthOF4d+TpcvqQNbTAv53OFYVs45YsWYITJ06gtbUVra2tOHHiBJYuXeqZ/tKlS3jjjTfwgx/8AG+88QZeeukl/POf/8Tdd98dumzu7vfDMIAyDx1vjS8FXF0IckB1ssel2mnEsanOiSzWBWB1/6tQPeEB6YtXsXKUcnUrRX6+3a1hJlNxV1hwrLi7FpnOj2K3OMjftd0Zf9fKQ3On9SsjzAx/Z35W+CnLC5LRqxrWRkq0K4wpINzGBSKm+dxWgmwXH6QJgiANUQmxp7JMaA/FkJFEypB/ZCC1II85FlUq368eHjuytowCtXFvv/02Wltb0d7ejpkzZwIAtm/fjqamJpw6dQoTJ050HROPx6WwoIA5UX7GjBk4e/Ysxo4dG7h8FqleGAagig7g1yiJwlXKC6bPmtKTpeSQU6aAlWZce42dUXZBpBWKFIpDvDCddbfq6zUG0nO8bUChasB7sPhVunxbLjAfcjwIIVbt9IpJVK6Z/lG3dWFvUNngZ2/WfoaJEm7jQuMXQkm1PKpXL1B6nKjic6rrW0t9Vj4Qa5r3vA9RsKbukeYcAGdDGeQHw9NGQo/RDdjG9fb2Spv7u7DH4cOHEY/HbYEKALfddhvi8Tja2tqUIlVFT08PNE3DiBEjQpXP3f3ZIA7C9vIAGR77BVSr7LiCEztf9rGO8pz5edXZq7sik0AN2ZXg3y3BLXi2pMOOZanwrIZc/A7vbv9Iu7AC5qXstsow7CSTvbHNMVHD9hYOp0DNKNK8enacPTRB2yjl/ZZkYWrtM+RhBFLEAFsYO+pkt6G5mWAVtI2rr6+3x47G43E8+eST/Sq3u7sb1157rWv7tdde61rG14vLly9j9erVWLJkSaAV2ETYk+qADIImOlCDrqcuZSJ7Qc0uA83ORyOzHHvAjuXhsp/wUpsVtq5aYUO6WKyxqIIozTTWL5uxLJTpGO4KC4a4CIQPyvAprjRpx7zveFErrdcMfyGN+C7GWFWi2p7J9izPR3/h7n4m33AbF5iYBnjGmncFGHUnESdLqbr7XeNRpfxkRw4ZGhBTpLEcOIrJ0Olhe+4hTVJx0mdFo+qBQVpmmRGwjXvvvfckIejlRV2/fj1+9KMf+RZ55MgRAICm6NUlIuV2J4lEAosXL4ZhGNi6dWvG9E5YpEaAZhCoTLEikHOxKnG8qXWs2O0vCFVzn0+hDoHqu9ypUJ9+r5EeFG7Ao8NpVwJ+4lXq+ldl4SNkVbbnvClYx3mm9fubwwjTIJP3WKQy+YbbuIxoGmUXfkrVvjg+i6LVVa4gLs30Ge6PBmSBK/VgpsoyUk/24j2XhHu1+FAf8O8PZSUB27jhw4cH8lZ++9vfxuLFi33TjB8/Hm+++SY+/PBD177//Oc/qK6u9j0+kUjg3nvvRWdnJ1599dXQXlSARWowyDCN0TlZSrWyVCpNWnxSevwL0sfawf1jmlqoAhnHpLoEqtOLKu5zCVaP7dKFa12k4V1dmk7QPC7Bq3X5tkjI2AhpbmHq+zADpCfnmcdlWnkq57NUc3AD97M3az/DRAm3cblFOZHTSwBaMVINn/YrNUFVA0xvKmD2Yjlvb9KY1LSHViPH/V4hUP0gSisGCuFltYi6jRszZgzGjBmTMV1TUxN6enrw+uuvY8aMGQCAv//97+jp6cGsWbM8j7ME6unTp7F//36MHj06VP0seExqSEgl4tyJ1N9V40FTYlEMcyEd5zEmVSVQXWWqJkypvtvpSfjaz0ZWVXfV7yhlgoZIyQUef0EYgar0rPrk7T5e8fuz9fRnsje2OSZq2N5yT0oAiitIOUNOgRThFg3Hf+H4Li4p7gpbJaSxV2405HpIQ6Hs7e7vnqLaA99YqQVq4yZPnow777wTDz/8MNrb29He3o6HH34Yd911lzRpatKkSWhpaQEAJJNJfOMb38DRo0exa9cu6LqO7u5udHd3o6+vL1T57EnNBufMf4/u2EzjCJ1eLJdH1QunQBXy8yPQsqhAuFBTXjjDKjn3MdHic0p9Z/wjbYeReFAz5eH136tMLlNPgjNfvx/ANsdEDbdxGYllahAyDANwz+iHw5Ejjg/1EGuiQBXmAEglO8SeZhDIMACK2b2T6fzTY1PlCVPI3P5R5t/sSQHbuF27duHRRx/F3LlzAQB33303nnnmGSnNqVOn0NPTAwB4//338fLLLwMAbr31Vind/v37cccddwQum0VqRGgGgWwDEuKiWuNSre9A+iKywk6Jk6gswtibGLhf7KoQy/Lo0shZAGAyvMVulgsElBTWhD2VdzXmP3nJGislJvHq1vd4vrLzkg/w2B6EXN+z/ezN2s8wUcJtXCBiGkEPI8xsAai5tqnCLlr7RewJmc7hbta90Z5DIuRnCPdE0atqGNCozLyFE6AZaYGaabysJGAhF0ek2a9ADWQB27hRo0bhN7/5jW8asfd1/Pjx/e+NTcEiNVtE0enEGS81lTY9s1CRhzA+FYArfpuIvESq40JTpfMYYqAkqi4Dv+4H7grzxZyI59houO0tk4fUtdMSpAph6hK9qoyL+W/L1N3FNsdEDbdx/SPDKZI8lQ4xKAlC635miMdYXfWQBao1T8TP2+oUtIaYH9n10RzvVp2VHlYA1mz/rE2jRNs4Fqn9wTIaL0Hptc+AGQJDmMVPGmyham4LYHD2eFZHmQFWqlLui9LIDfEqVe1jRIh8Bob4ujszZSwfqgpgrTxmoOFnb/Z+hokQbuMy4hu83w+Hl1SanGSLw/T9T+zqF4e1Sdut3k5rgrNUXjqNKFLF5VFhWF5Ua4JyOoSkPdPf9bCf6i21dnh4TQNFPyjRNo5Fqgp72VKnITtjSlnbhSc0IP1ZnNVvXTRweEntdIJQBfwXPRaMURXU39wuPxW6vKrOJ0YVzu4De+hAEAGtA9B99jE2XnaVQ1Td/zkn2zZUCzC/08/e7P0MEyHcxgXGFKtmg6O83QTY5oqPqvoselZFsWnI90N3WR6eVFH4GpZoTZdnz/p3iGiNzF/rHbtaAxFJ3f2G/dmDEm3jWKRmwPRwibFPxStDSggIIaYk95W1LKrqGClmqiAcVGLVIQ7dXbReT/U+6VTHWN0a0qaQCoO9DLnD6/Rl63EVDxuof02JehmYAsJtXCA0xROxlxizxJ1n97koEO1VHcVZ/iSPR3UIVM0gkMe92DUWtRyAbgCDYqlezlRZhli2I8C/LVQFp5XrPh3q9KUp0TaORWpQnONMg+DR3S+NTRW9r1B4uDwMz+VBtb2cPkMFsunOz9bwDauliDDPqxHyeoLJHB0ieBkBtw/kv8XP3uz9DBMh3MZFinJcvCBKpTQOb6b9N1iTn1TjUVPvmjlpXy7bOSaVCJpugGKxVDc/pSZOWfs1V9gpr2EJ5uf0eFRVix7IXEq0jWORGgTV0qjOMFSqY2KOWf7WUmz2ZCnIk6hS+6wLMfCyqHaZjn2pC1UKPeUZAsjar7gIsjH+TF0rTCgyTpLKhJeTNUvna9FRopMKmALCbVxGshqTSpkFqxTDlCB4VGH/L+n97v9Jc94rrXdhRr+YD1nvhjgGVoNTRCsndomf7SKtmf2AQVqwgPUl2saxSO0PllHHYIpLsStBtfSpcJw0NtXT4xqiHkJZGY1V7AYRj4/SyA1rWqTXPiYQ+Wp4Cti+RbIClZ+92fsZJkK4jesfAWOkygHyLdEpbxOD/Zt5OzyjgM9cE5KPEQSq6OyBNBxA9KSaT/oqL6/9XSou/GpTZv1Ls41jkeqB72xr9QHes/z9sLyp1vGO7n/Pspyf/cad2mUptoUUCIHHpnIDnpGw43ytJ/p+uz7DZmFVs5g9riXagDMFhNu46LE9psJkJIX40wxhn9Wtb4tIYZstMtUeVTNfQcSm0lCqu1+LGSDdSE+cSsUkl8p3eHmddSXrOwCv2f2BKNE2jkVqrrAuFsvLao9DTYtZlYfVFfAfkMWrswzAtluXR0rs6g/hLY0kCC9PKig6As/oH4h/T4lOKmAKCLdxobEmTCnPjmqjLfZIKQBFz6q4MpTU1e9ccQqQpwGIYad03bz/6TowaJDbo2oLUkuwam7R6qi7LUwFgZrKwnVefCnRNo5FahjIfGwj0qCF8Zo6vazS+NOUeAVkj6qrXFVd4BaoQbr7gcwrTZHRr65mIgPksQKG13bGA++5VeGJwBGbNV7hhDWt31XyszdrP8NECbdxwRFFmFKQCZ5Gdxc/XJ5Kpzi1vzs8qNKEKMOQ54OkK2TvtwWqs9tfp9RKf5YI1hQz/Emuv/17HAH8HeKUhM/+57A02zgWqf1F7H4lYeag52pU8BYcYtc/PPIQrd3PJv32qbyqUY99NAx4LtN2lV5MkVCIwe+icB2oD+N+9gawzTHRw21cRvxkF6k8j9a7JPTcY1Pd4pRsL6rb++kQnKqKWPsF7ysZhtnlr6ePJWuilkFSvew6GXL9pQmvGRyhGSnRNo5FalCcAdctwy4rkyZPyceknuxSg7W9A/l7rAIUULB4LX/qmtWvukjFLhDrQpX2Z2n4hhVMTsFVejENKFQeVT9zK5bxqJ4Pfz72BrDNMdHDbVx02B5S4btDlDo/w7A8p5Bjo4qTnAQBSkTQDAOIxRzOnvR+GHrqWEPOw/LMEtKeVMGLasdPlepodfMDGmkgsYElDcjkXXZSom0ci9Rc4RxfKt5crXBUzpWprFBVgH/3rmCLypWkgkyiyjWux2TnPianOJ/iC01/Ra4Wg2/3gJ+92fsZJkK4jcseS6QJp9C15r2wLe01dY5PTXtPXe+OiVD2QjziBKPU/0S6kRamqXGpWpkOGGVmGl0QtzqZ/iqHJ9UpplWLEEji1a6CFiyUT4m2cSxSM5EpHqoTsftfgeQ1dYhXaZ94P/a4P7smSgnfM4b1CWvQIWcOkq6DNPUybURX5/JtTDjMsajRNKx+9gawzTHRw21cdihvPSTeBxXhm1yeVEqnk7ymkL2fBpkCFADInE8CImiauSwpgLTnlCiVJiVkrS5/QfySTpJgtmdAOaMROASrVyvn9KD6tYal2sZFNR3jqsY1291r0lEqnRR/lBSfPY4DPMRlJoHql6+ifFd8VFd58vasZvsb5P/Kgq1bt6KhoQFVVVVobGzEoUOHfNMfPHgQjY2NqKqqwvXXX49t27ZlVe5AJptY2gOSTPbGNsdEDdtbaCRRZnkVHULU+uz0RNqz9w0xvdqrKnf1G2Y3PqX/GxI+2wLVErRGWrCanlU5sD9sj64jRis5vbyCu8r+rZpV1WBd/CI5auOKHRapfgTxHgpPbK7tdj7yPmkZN8V4UjuEhgLXPufxhkLoGor04j4/AS2lDeFNtS5y5Sv8xfT8889jxYoVWLt2LY4fP47Zs2dj/vz5OHv2rDJ9Z2cnvvzlL2P27Nk4fvw41qxZg0cffRS/+93vQpfNRAtpWvQtj6+9sc0xOYDbuFDIM/whuQ3llRStnkZZCKonTSHtQbW8qOJkJ3FClEEpsWqkZvAL/5Wumy/D3Ee6nh4C4BS+dtlW+enxqK7ufsi/031OzPNipF4ZTmDkbdxAgEVqGIR4ahRU2DmRxKtjmyO/dLgLUgtXhUBVlhOibiTm2Y8nM7IvdPUrLJs2bcLy5cvx0EMPYfLkydi8eTPq6+vx7LPPKtNv27YNY8eOxebNmzF58mQ89NBDePDBB/Gzn/0s69+UF7JZEKKYyFT9WG5+XyZ7Y5tjoobtLUscYkyzRakZis4We3Z6OASq5QG19gv3R/GlCwLVEqaKyVDWduuenvayGmYeum72Pqby04gAq9vfS5xKL036PfYtNuxpy0EbNxBgkRo1fl3oqm59lVDNJDCd3fhCPi4vq9cqUzl+6iKDfF9h6Ovrw7FjxzB37lxp+9y5c9HW1qY85vDhw6708+bNw9GjR5FIJML9mFInrK4sgM7OZG9sc0zUsL31A0u8id8FXCGnIHyWPKwkj0PVZc+nFfeU9NRYU1GsGg6Bahj2WFTR22rvS5WlpQSqLZQV4tQ1CUzwDqt+b6BTFnEbN1DgiVNRQpSesQ/HKlFeK0upjrc+q45zpveqh/O7SpjmUKgm6Qq8QmIkYTagvb290vbKykpUVla60p8/fx66rqO6ulraXl1dje7ubmUZ3d3dyvTJZBLnz59HbW1t4N/CqCFNCK+qFUSb2vjZG8A2x0QPt3HhcY3FFIScW9g5Ramwn5AONZXO2PR02l37RnoFKSvMFGAuxBMz7GPtAP6GYXfxk+VU0g0pSoBmBfwXxqJqKcHt5VX16/Yn0uxRA5kI2sZdbbBIBewu7iQlAIpBI8PuegCVpbbFAMQAQ4MZfyK16pQWM4WkpgHQ0p9JM8feafI2AEJ6mGl0pH3aYVeyAtxeVFGQOro33APLxc/WUyOlB5pbq1yQAZCeGktEINKRpD7p/AFARUUFampq8LfuV3yrPnToUNTX10vbmpubsX79es9jnKt8EZHvyl+q9Krt+Ua0N41iqfh3ZdAM3TzviJldN1oZCBoIZYCmmWOXEAMhlv5swB7PRLFUo6ebdpUyXfsFK+pLTBM+pyrlt6S04nRZQas1AyDdbGU1HSBd2Kabk/RiOhBLEDSdENMJWpIQ0w1oSQMx3TC7znTdjGGo66nzkJrsYOggwwAoCaKkeY0K5zCovQFsc0DqRnZ1OlxygnXj5zYuHFY99EtXoJGGhF6GpF4GXY/BuKJD12OgK0kgqUHTNWgJDUho0HQAVzRQAqAkoF0BKEHAFUDrM1CWIKCPgIQOI2GgLKlDSxpA0oCWSKbaDwNIJkBJHdCTIP2KfX8DysxQUpbWsz2khnlvM1Ld5kTQYhVmMP8kQUsC0AaBYjqMpAFDK4M+aBB0LQaDNOhaDDo06ACMmAbdar5iBCNpekEN3TBDT5YTMEg3pcMgHfogAygzoJcnoV2+Ip0/IFwbV1NTg4qKiij/yoLDIhXAxx9/DAD4G/amB2Azgfn4448Rj8cBAFVVVejs7ERfX5/vMarGV+VhAIAxY8agrKzM5VE4d+6cy5NgUVNTo0w/aNAgjB492rduucayt//75IWC1mMgY9lcUHsD2OYA4G/IfKNj3HAbFw7L3t74f8UdbcCXROr1PwD/zW/RFy5cCG1vgCloq6qqcl29vMIiFUBdXR06OjowZcoUvPfeexg+fHihq1T09Pb2or6+Hh0dHairq5P2VVVVRXqhVFRUoLGxEfv27cPXvvY1e/u+ffuwYMEC5TFNTU34wx/+IG37y1/+gunTp6O8vDyyumUD21t2eNlc1PYGsM0x3Mb1B7a37Ojp6cHYsWMxatQoaXsu2rgBAzFERNTT00MAqKenp9BVGRDk+3zt3r2bysvLaceOHdTR0UErVqygIUOG0LvvvktERKtXr6alS5fa6c+cOUODBw+mlStXUkdHB+3YsYPKy8tpz549ealvJtjewsM21z/Y5sLB9tY/2N7Cw+fMDXtSmQHBokWLcOHCBfz4xz9GV1cXPvOZz+CVV17BuHHjAABdXV1SPMGGhga88sorWLlyJbZs2YK6ujo8/fTTWLhwYaF+AjPAYJtj8gnbG8O40Yiu0giwIent7UU8HkdPTw93TQSAz1f/4PMXHj5n/YPPXzj4fPUPPn/h4XPmhuOkpqisrERzc7PnwHZGhs9X/+DzFx4+Z/2Dz184+Hz1Dz5/4eFz5oY9qQzDMAzDMEzRwZ5UhmEYhmEYpuhgkcowDMMwDMMUHSxSGYZhGIZhmKKDRSrDMAzDMAxTdLBIBbB161Y0NDSgqqoKjY2NOHToUKGrVDSsX78emqZJr5qaGns/EWH9+vWoq6vDNddcgzvuuANvvfVWAWs8MGCbU8P2lhvY3tSwveUGtjdv2ObCUfIi9fnnn8eKFSuwdu1aHD9+HLNnz8b8+fOloMmlzk033YSuri77dfLkSXvfxo0bsWnTJjzzzDM4cuQIampqMGfOHHvtZsYN25w/bG/RwvbmD9tbtLC9ZYZtLgSFW+yqOJgxYwY98sgj0rZJkybR6tWrC1Sj4qK5uZluueUW5T7DMKimpoY2bNhgb7t8+TLF43Hatm1bnmo48GCb84btLXrY3rxhe4setjd/2ObCUdKe1L6+Phw7dgxz586Vts+dOxdtbW0FqlXxcfr0adTV1aGhoQGLFy/GmTNnAACdnZ3o7u6Wzl9lZSW+8IUv8PnzgG0uM2xv0cH2lhm2t+hgewsG21xwSlqknj9/Hrquo7q6WtpeXV2N7u7uAtWquJg5cyZ+/etf489//jO2b9+O7u5uzJo1CxcuXLDPEZ+/4LDN+cP2Fi1sb/6wvUUL21tm2ObCMajQFSgGNE2TvhORa1upMn/+fPvz1KlT0dTUhBtuuAHPPfccbrvtNgB8/rKBz5katrfcwOdMDdtbbuBz5g3bXDhK2pM6ZswYlJWVuZ5Qzp0753qSYUyGDBmCqVOn4vTp0/aMRD5/wWGbCwfbW/9gewsH21v/YHsLD9ucPyUtUisqKtDY2Ih9+/ZJ2/ft24dZs2YVqFbFzZUrV/D222+jtrYWDQ0NqKmpkc5fX18fDh48yOfPA7a5cLC99Q+2t3CwvfUPtrfwsM1loHBztoqD3bt3U3l5Oe3YsYM6OjpoxYoVNGTIEHr33XcLXbWiYNWqVXTgwAE6c+YMtbe301133UXDhg2zz8+GDRsoHo/TSy+9RCdPnqT77ruPamtrqbe3t8A1L17Y5rxhe4setjdv2N6ih+3NH7a5cJS8SCUi2rJlC40bN44qKipo2rRpdPDgwUJXqWhYtGgR1dbWUnl5OdXV1dHXv/51euutt+z9hmFQc3Mz1dTUUGVlJX3+85+nkydPFrDGAwO2OTVsb7mB7U0N21tuYHvzhm0uHBoRUaG9uQzDMAzDMAwjUtJjUhmGYRiGYZjihEUqwzAMwzAMU3SwSGUYhmEYhmGKDhapDMMwDMMwTNHBIpVhGIZhGIYpOlikMgzDMAzDMEUHi1SGYRiGYRim6GCRWgA0TcPvf//7wOnXr1+PW2+91XP/gQMHoGkaPvroo37Va9myZfjqV7/arzyY4oPtjck3bHNMPmF7u3opSZF67tw5fPOb38TYsWNRWVmJmpoazJs3D4cPH460HK8LoaurC/Pnz4+snFmzZqGrqwvxeDyyPJnoYHtj8g3bHJNP2N6YXDGo0BUoBAsXLkQikcBzzz2H66+/Hh9++CH++te/4r///W9eyq+pqYk0v4qKisjzZKKD7Y3JN2xzTD5he2NyRqHXZc03Fy9eJAB04MAB33QAaOvWrXTnnXdSVVUVjR8/nl544QUpzfe+9z2aMGECXXPNNdTQ0EDr1q2jvr4+IiLauXMnAZBeO3futPNuaWkJlA8RUXNzM91yyy2edd2/fz8BoIsXL9plx+Nxam1tpUmTJtGQIUNo3rx59MEHH9jHJJNJWrlyJcXjcRo1ahQ9/vjjdP/999OCBQvsNIZh0FNPPUUNDQ1UVVVFN998M7344ov2vi9+8Ys0b948MgzDPrf19fW0Zs0a33NbSrC9mbC95Q+2ORO2ufzA9mbC9pYbSk6kJhIJGjp0KK1YsYIuX77smQ4AjR49mrZv306nTp2idevWUVlZGXV0dNhpfvKTn9Brr71GnZ2d9PLLL1N1dTU99dRTRER06dIlWrVqFd10003U1dVFXV1ddOnSJTtv8YLyy4couwuqvLycvvSlL9GRI0fo2LFjNHnyZFqyZIl9zFNPPUXxeJz27NlDHR0dtHz5cho2bJh0Qa1Zs4YmTZpEra2t9K9//Yt27txJlZWVdmP0/vvv08iRI2nz5s1ERLRo0SKaPn261BiUOmxvJmxv+YNtzoRtLj+wvZmwveWGkhOpRER79uyhkSNHUlVVFc2aNYueeOIJ+sc//iGlAUCPPPKItG3mzJn0rW99yzPfjRs3UmNjo/3d60JwXlDZ5mOhuqAA0DvvvGOn2bJlC1VXV9vfa2tracOGDfb3RCJB1113nX1BffLJJ1RVVUVtbW1SWcuXL6f77rvP/v7CCy9QZWUlPfHEEzR48GA6deqUZz1LFbY3trd8wzbHNpdP2N7Y3nJFyY5J/cpXvoJDhw7h8OHDaG1txcaNG/HLX/4Sy5Yts9M1NTVJxzU1NeHEiRP29z179mDz5s1455138MknnyCZTGL48OGh6xNVPiKDBw/GDTfcYH+vra3FuXPnAAA9PT3o6uqSft+gQYMwffp0EBEAoKOjA5cvX8acOXOkfPv6+vDZz37W/n7PPfegpaUFTz75JJ599ll8+tOf7le9r0bY3tje8g3bHNtcPmF7Y3vLFSU5ux8AqqqqMGfOHPzwhz9EW1sbli1bhubm5ozHaZoGAGhvb8fixYsxf/58/PGPf8Tx48exdu1a9PX1hapHVPk4KS8vd9XbuliCYBgGAGDv3r04ceKE/ero6MCePXvsdJcuXcKxY8dQVlaG06dP96vOVzNsb/6wvUUP25w/bHPRwvbmD9tbdpSsSHUyZcoU/O9//5O2tbe3u75PmjQJAPDaa69h3LhxWLt2LaZPn44JEybg3//+t5S+oqICuq77lhskn6iJx+Oora2Vfl8ymcSxY8fs71OmTEFlZSXOnj2LG2+8UXrV19fb6VatWoVYLIY//elPePrpp/Hqq6/mtO5XC2xvbG/5hm2ObS6fsL2xvUVByXX3X7hwAffccw8efPBB3HzzzRg2bBiOHj2KjRs3YsGCBVLaF198EdOnT8ftt9+OXbt24fXXX8eOHTsAADfeeCPOnj2L3bt343Of+xz27t2LlpYW6fjx48ejs7MTJ06cwHXXXYdhw4ahsrJSShMkn1zw2GOPYcOGDZgwYQImT56MTZs2SYGLhw0bhu9+97tYuXIlDMPA7bffjt7eXrS1tWHo0KF44IEHsHfvXvzqV7/C4cOHMW3aNKxevRoPPPAA3nzzTYwcOTLnv2EgwPZmwvaWP9jmTNjm8gPbmwnbW44o3HDYwnD58mVavXo1TZs2jeLxOA0ePJgmTpxI69ats2cKEpkDsbds2UJz5syhyspKGjduHP32t7+V8nr88cdp9OjRNHToUFq0aBH9/Oc/p3g8LpW1cOFCGjFihG+4jEz5ZBsuQ6SlpYXEvzuRSNBjjz1Gw4cPpxEjRtB3vvMdZbiMX/ziFzRx4kQqLy+nT33qUzRv3jw6ePAgnTt3jqqrq+mnP/2plOeMGTPo3nvv9axrqcH2ZsL2lj/Y5kzY5vID25sJ21tu0IhCDKooITRNQ0tLCy9pxuQFtjcm37DNMfmE7Y3JBh6TyjAMwzAMwxQdLFIZhmEYhmGYooO7+xmGYRiGYZiigz2pDMMwDMMwTNHBIpVhGIZhGIYpOlikMgzDMAzDMEUHi1SGYRiGYRim6GCRyjAMwzAMwxQdLFIZhmEYhmGYooNFKsMwDMMwDFN0sEhlGIZhGIZhig4WqQzDMAzDMEzR8f8Bve7T+U98nsgAAAAASUVORK5CYII=","text/plain":["<Figure size 640x480 with 8 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def result_plot(simulation, prediction, savefig=False):\n","    \"\"\"_summary_\n","\n","    Args:\n","        simulation (_type_): _description_\n","        prediction (_type_): _description_\n","    \"\"\"\n","    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\n","    f.tight_layout()\n","\n","    # Min and max of real data so plots share limits\n","    sim_min = np.min(simulation)\n","    sim_max = np.max(simulation)\n","    \n","    sim_im = ax1.imshow(simulation, aspect=0.125, vmin=sim_min, vmax=sim_max)\n","    pred_im = ax2.imshow(prediction, aspect=0.125, vmin=sim_min, vmax=sim_max)\n","    res_im_fixed = ax3.imshow(simulation-np.asarray(prediction), aspect=0.125, vmin=sim_min, vmax=sim_max)\n","    res_im = ax4.imshow(simulation-np.asarray(prediction), aspect=0.125)\n","\n","    # Colorbars\n","    f.colorbar(sim_im, orientation='vertical', shrink=0.45)\n","    f.colorbar(pred_im, orientation='vertical', shrink=0.45)\n","    f.colorbar(res_im_fixed, orientation='vertical', shrink=0.45)  \n","    f.colorbar(res_im, orientation='vertical', shrink=0.45)  \n","    \n","    #Titles and labels\n","    ax1.set_title(\"Simulated Data\")\n","    ax1.set_ylabel(\"Time-step index\")\n","    ax1.set_xlabel(\"Spatial index\")\n","    ax2.set_title(\"Predicted Data\")\n","    ax2.set_xlabel(\"Spatial index\")\n","    ax3.set_title(\"Residual (fixed)\")\n","    ax3.set_xlabel(\"Spatial index\")\n","    ax4.set_title(\"Residual\")\n","    ax4.set_xlabel(\"Spatial index\")\n","    \n","    # Make spacing suitable\n","    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.6, hspace=None)\n","    if savefig:\n","        f.savefig(\"output_img.png\")\n","\n","# Model inferencing and QC\n","x = torch.from_numpy(scaled_features[:, 1]).to(device)\n","t = torch.from_numpy(scaled_features[:, 0]).to(device)\n","\n","\n","with torch.inference_mode():\n","    prediction = model(torch.Tensor(x).reshape((x.shape[0],1)),\n","                       torch.Tensor(t).reshape((t.shape[0],1)))\n","\n","prediction = prediction.reshape_as(torch.Tensor(U_load))\n","prediction = prediction.cpu().detach().numpy()\n","simulation = U_load\n","\n","result_plot(simulation,prediction)"]},{"cell_type":"code","execution_count":775,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1682006984449,"user":{"displayName":"Harry McHugh","userId":"11095429774898416036"},"user_tz":-60},"id":"rLu8wjNmY3Us"},"outputs":[],"source":["#Save the model for future use\n","output_model_path = f\"../../models/1d-heat-pinn-{epochs}epochs-lr0.001-adam-x51-t1000-alpha1.22e-3.pt\"\n","torch.save(model.to(\"cpu\"), output_model_path)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"25ce94e37f1a25fdf8adcd273d81508f2b1c2f2746a44398f22bfbc0d71ae135"}}},"nbformat":4,"nbformat_minor":0}
